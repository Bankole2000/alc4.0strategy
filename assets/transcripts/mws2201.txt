Play by Play: OWASP Top 10 2017
by Troy Hunt and Andrew van der Stock

In this course, you’ll learn the risks that made the 2017 OWASP Top 10 and how best to utilize the OWASP Top 10 in your organization.

Play by Play is a series in which top technologists work through a problem in real time, unrehearsed, and unscripted. In this course, Play by Play: OWASP Top 10 2017, Troy Hunt and Andrew van der Stock discuss the methodology used to construct the 2017 version of the OWASP Top 10. You’ll learn how the analysis of the data collected resulted in a reordering of the risks from the 2013 version, the inclusion of new risks, and the demotion of some risks that were included in previous versions. By the end of this course, you’ll be familiar with each risk and understand how best to use the 2017 OWASP Top 10.

Course authors
Author: Troy Hunt	
Troy Hunt
Author: Andrew van der Stock	
Andrew van der Stock
Course info
Level
Beginner
Rating
4.7 stars with 74 raters(74)
My rating
null stars

Duration
1h 12m
Released
14 May 2018
Share course

Course Overview
Course Overview
Hi everyone. I'm Troy Hunt. I'm an Aussie security specialist, long-time Pluralsight author, and the creator of many other Play by Plays in the Pluralsight library. I recently teamed up with fellow Aussie and Director of the OWASP Foundation, Andrew Vanderstock, and we created a course on the OWASP Top 10 2017 edition. Andrew is a great guy to do this course with because he's a co-leader of the OWASP Top 10. He's also a senior principle consultant at Synopsys, and he was the perfect guy to learn all about what is new in the OWASP Top 10 2017 edition. We've got four years since the last version of the Top 10, and it turns out a lot has changed in that time. We've actually gotten better at some things, which is great news, that have dropped off the Top 10. But we've also introduced all new risks due to the changing environment in the technology landscape. In this Play by Play, you're going to hear about why we've gotten so much better at cross- site scripting, why cross-site request forgery has disappeared altogether from the Top 10, and why we now have XML external entities and insecure deserialization. And they're both specific risks we've never seen in the Top 10 before. So this course is going to help you focus on the top application security risks that you need to know today and help you understand why they're important. And in this course, you'll see Andrew demonstrating exactly how some of these risks get exploited as well. This is a must see course for everyone building web software today. Please join Andrew Vanderstock and I on this Play by Play journey as we take you through the OWASP Top 10 2017 edition.

Introduction
Introduction
Hi, I'm Troy Hunt. I am a Pluralsight author who has done a bunch of courses on the OWASP Top 10 before, but today we're going to do the OWASP Top 10 2017 edition, and I'm here with Andrew van der Stock. So Andrew, why don't you tell everyone what do you do because you've got some good insight into this whole OWASP thing. Okay, so I'm a Director of the OWASP Foundation. I am also the current connector-leader of the OWASP Top 10 as of about mid-way through last year. I've been looking after the application security verification standard for a number of years, which is a proper standard. We'll talk about that a little bit later. And in my real world, I am a senior principle consultant at Synopsis.

The History of the OWASP Top 10
Okay, awesome, so you're the guy for OWASP. Excellent. So I wanted to sort of start talking about the 2017 edition because we know that on a fairly regular cadence we have a new version of the Top 10. Why don't you give us a bit of an overview about first of all, what the Top 10 web application risks are, and tell us a little bit about that cadence as well because I know it's sort of often, every 3 years, but then we've gone 4 years for this one. So what's up with that? Okay, so the original idea of the OWASP Top 10 was as an awareness piece, not as a standard. And unfortunately, it took off because it was simple and fast, and well people can do 10 things, and so it really, really took off. So the first edition came out in 2003. It wasn't called anything. It was just the OWASP Top 10. It was released a year later with its first year name, 2004. And then we tried to update it every 3 years, and that's been happening, 2007, 2010, 2013. It was supposed to come out in 2016, but yeah, stuff happened. Got busy. Well no, I don't know. The previous leadership team, I think they had some troubles getting Git out the door is what really sort of happened. And by the time that it was starting to get ready, it was already 2017. And then the release candidate 1 came out, and then, you know, all hell broke loose. I guess. I know you're going to touch on that a little bit more in a moment. I think maybe for context, let's just have a look at what is in the 2017 edition and how it changes.

Changes in the Development of the OWASP Top 10
So we're on the Release Notes page here about what's changed from 2013 to 2017. And there's a sentence here, which really struck me because it was, I thought it was very insightful, which says old code never expected to be accessible from the Internet is now sitting behind an API or RESTful web service to be consumed by Single Page Applications (SPAs) or mobile apps. And when I sort of started thinking about it, I went wow, like that it a really big industry shift over that 4-year period. Yep. What else have we seen that's changed that has meant that the Top 10 has adapted so fast? Well we've had to change because every single day, every single week, every single month, there's a new JavaScript framework. You know, back in 2010, there was basically Dojo and Ext JS, which by the way, we'll talk about that another time but. Then there was jQuery, and then there was Angular, and now there is like, you know, then there was React, and now everyone's jumping on the Vue train, and you can't go a week without learning about a new JavaScript plugin, a new JavaScript framework, a new JavaScript paradigm, functional programming. All of this stuff is leading us down a path where more and more of the business logic is changing from the server to the client, and I don't think that's a bad thing. It's just how do we make that secure? And I think the old OWASP Top 10 never considered that. Right. We've had to--- So the nature of the applications are changing. Therefore the risks are what we consider to be the 10 most critical things that have changed in nature. But also, where is it running? I mean 3, 4 years ago, it was mostly on-prem. Now it's, I think, most new projects are being deployed in the cloud, whether it's Zero, whether it's AWS or Google Compute. It's going into the cloud whether people like it or not, and we had to cope with that. I mean there's things like S3 buckets. We've learned things like, you know, serve-less stuff where there's a lot of push to be more or less, you know, from a functional programming perspective, stateless. Security's all about the state. And if you're passing that around, that's huge. And so the Top 10 this time around is actually, it does consider that. So if we scroll down a little bit on these Release Notes and we look at the Top 10 in 2013 versus 2017, and I kind of like this diagram because it gives us a good representation of a bunch of stuff not changing. Some stuff actually deprioritizing in terms of risk. New things, some stuff out. I mean, what's sort of the broad-brush overview of how this has changed? So we basically for the first time, we went out and got a lot of data. And so anyone who actually argues with us has to also argue with a lot of data as well, and that's a good place to come from. Before, like when I did the 2007 version, it was me making it up. I mean literally it was mine of CVEs. I counted them, and I put it in the order I thought. There was no data whatsoever for cross-site request forgery. And so today, that would be very, very, you know, people would get all up in arms. They'd be upset with this because there's no data. We've always shoved things into the OWASP Top 10. It's just no one notice before. And I think that's actually a really good thing because what's happened now is that people care so much about the OWASP Top 10, any change like that where there's not a lot of data behind it, that gets people really antsy, and I don't mind that. It's good to have that discussion. So in terms of the data, the data is obtained in this time instead of just from the NIST dataset, which is also pretty good. We also went out to various consultancies and folks like Bugcrowd and whatnot to get data from the real world. What are people actually finding? And that was actually really interesting. We didn't also have any data for 2016, so we needed to get some more data. We have 43 boutiques, and we have 114 thousand apps' worth of data. Wow, okay. So that's actually pretty good. So I think sort of the really important observation here and I suspect a lot of people don't realize this is that this Top 10 in the prioritization and indeed what's in the Top 10 to begin with is data driven. This is like evidence based. It's not you going yeah, you know, like this seems like the right thing to put in there. I mean to be fair, we had a long discussion about the order. And when we come to that section, we'll have a long discussion about how it got to this particular order. But in terms of where do things appear, it's absolutely data driven, and the new items that we did via survey, which is A8 and A10, that's 500 people in our industry saying what it should be. And so, you know, we're going to always reserve spots for things that are coming up, and that's an interesting thing. But at the end of the day, in 2007 it was me, just me. Yeah. One. Now we've got 500 people whose job it is to do this stuff, to tell us what do you want as the speculative.

The OWASP Top 10 2017
A1: Injection
So why don't we start doing because I'd actually like to go through this Top 10, and some stuff's going to be familiar. It's things that we've seen before. Some stuff will be new, some stuff will be missing. So let's go through that and start talking about why that is. Okay, so let's actually start at number 1, Injection. And injection has been at number 1 for a very long time. So, like, why have we not fixed this yet? Why is this still a thing? Well actually, this time it was a very touch-and-go thing. We honestly were one impact factor away to making it number 4. Really? That's a big drop in one day. The likelihood for SQL injection has dropped from nearly 20% in 2007 to less than 5% today. But the impact is still off the charts. Yeah. And that's why it's still number 1. We really need for frameworks to make it essentially that your program does not compile if you've got like from static code analysis it looks like you've got SQL injection. That's the way we defeat this one is in the compilers and in the frameworks. And the framework is basically providing us really good ways like, you know, the Entity Framework in. NET. That is how we've been advoiding it. Developers have been adopting the correct and safer ways of doing things. And then NoSQL came. Hmmm. Hmmm. Yes, NoSQL. And so now we have a new category of injections, and this is, I think, realistically the data that we've seen coming through from SAST and also the better boutiques. NoSQL injection is just as bad as it was back in the mid-2000s. It was a real step backwards. So well, you know, one of things that you said there that struck me as interesting is frameworks, like Entity Framework, which is an object relational mapper, it prepares statements for you. So it's basically very hard for you to mess it up. Is this a reflection of the fact that individuals are not getting any better at SQL injection? It's just that they're being saved from themselves by the frameworks? Yes. Which is kind of--- We're actually seeing that with React and Angular as well. The cross-site scripting is down because the framework makes it hard to do the wrong thing. I guess the, my hesitation is that it is nice that we have lists of these problems, but at the same time it's like we're not actually making the humans any better. We're just sort of going, you know, like we can cover up your flaws by providing the right frames, which I guess is good, but it's just interesting that the people themselves are necessarily improving. Well, both you and I are trained developers, and I know that's your day job. For me it's a very pleasant experience. I'm going to Paris soon to do that, and I'm really looking forward to that. I just don't know how we can actually prove the effectiveness of that, but it's the only way that I think we can actually get there. We really need computer science courses to make security a mandatory subject. There is an ACM syllabus, and I think the idea that an engineer can like, you know, a mechanical engineer for example or a civil engineer can leave a university without understanding the effect of the buildings that they're going to build. That doesn't happen. They know how to engineer things properly. We must get to the same place. I really do think that we need to make sure that our computer science courses, our software engineering courses, and our short form courses touch on security, and you have to pass a subject like it even if it's just one module. That would really help. Right and hopefully sort of a combination of that and the frameworks getting better would improve things. So it sounds like on this trajectory, the OWASP Top 10 2020 maybe? Yes. We might actually see SQL injection. Well actually, let's be clear. It is injection, right, which is, of course, a super set. Yep. We might actually see injection drop somewhat next time this comes around. Yes, I think so. And, in fact, if we can start working with the frameworks now to work on NoSQL support, I think we can get to the same place. And then if it wasn't for NoSQL, it would've be number 4. Okay.

A2: Broken Authentication
Well I'll tell you what, let's move onto the next thing, which might be the number 1 thing next time we come around. Alright, so number 2 is Broken Authentication. Broken authentication was still number 2 in 2013 as well, so is this another case of not getting any better at it or has something else changed? Humans are terrible at passwords. I don't think--- If A1, if injections hadn't been A1, this would've been A1 by a long, long time. We could see in the last, since 2013, we've had so many credential breaches. You've run Have I Been Pwned? You've pulled in billions, literally billions, of records. Many of them are basically duplicates, but and I'd love to hear more about this actually. But effectively from my perspective, it shows that people reuse their passwords everywhere. We need to either get to a place where passwords are not reusable or alternatively make passwords less dangerous, and I think we have to do that via a number of methods. So that sort of raises an interesting point. So when we talk about broken authentication, are we talking about the sort of the human behaviors or people building vulnerable systems? Let's talk about the human behaviors first because I think that's actually something that we're not going to change. The entire population of the planet is not going to adhere to a password complexity policy. I did some work for a government department a few years ago, and if you're thinking about 6-year-olds with 8-character passwords with complexity that are not allowed to have the same password as last time and needs to change every 30 days--- Good luck with that. Human nature is basically a 6-year-old child. If you allow them to have a weak password, they will. And you're not going to have people be onto do that properly. I mean my daughter's school at the moment, everyone has the same password in her class, which is just like what? Yeah, it's like a great example to set for kids, isn't it? Now I noticed actually looking at the section here on the Top 10, Is the Application Vulnerable?, it says Permits automated attacks such as credential stuffing, where the attacker has a list of valid usernames and passwords. From an application perspective, are we saying that this is now something you need to be resilient against because the bit that I'm sympathetic about for application owners is we're saying someone might come to your site with a legitimate username and password for a subscriber, and you've got to make sure that your system is resilient to legitimate credentials. Yep. And so I honestly think we do need to get to anti-automation because I'm not terribly sure we need to worry about the spear fishing example of one account. You're never going to prevent that. But when people are trying tens of thousands of valid accounts, you need to know and prevent that. And it's different than blocking people because they've tried the wrong password five times. This is actually, they're trying the right password 10, 000 times, and that's a totally different control than blocking someone's whose logged in badly because I've got fat fingers and that happens all the time. So that actually raises an interesting point. I want to show you something and ask your views on this. So I've just loaded the Ubiquiti logon page. So Ubiquiti make wireless networking gear, some really, really neat stuff. I've got this logon page, which has invisible recapture. And it sits down here just under the Create account button, and effectively it is anti-automation on the login. And the reason I thought I'd bring it up here is that I really infrequently see any sort of anti-automation on log in I think in part because traditionally recaptures have been painful, you know, like all the squiggly letters, and then they required user engagements, so, you know, the checkbox. How do you feel about this sort of model about having anti-automation like an invisible recapture on log in? Does this address the point? Yes it does and also 2FA does, but invisible recapture is a great advance. And the number of times that I've actually tried to say oh, find all the cats in this photo, and my eyesight's not that great. Right. You know, I have to put the reading glasses on to find the cats. And also barrier to entry as well, right? Yeah, exactly. And for people who have visual impairment, which is, you know, people, you know who are elderly, those that have been born blind or whatever, the reality is these are barriers to participation in the modern world. There aren't bank branches to go to. They're closed. So we need to make sure that we still maintain that accessibility, and this is the balance that I think many security professionals haven't really understood yet. We need, security is a human problem. It's not a tool problem. It is not a technology problem. It's a human problem. And this is a perfect example of improvement. I like the idea that we've got anti-automation that's basically transparent to the user. So I mean one of the things that I think we need to probably do is really help users choose better passwords without being like really difficult. One of the things that you've done with the Have I Been Pwned then recently is that you actually had an API that lets people test is that password a bad password? Right. Previously we've just told people here's a list of 10, 000 passwords. Don't let them choose this. Well they can choose one of those passwords like Password1 and put Password123456, and it would probably get through. Yeah, and still terrible though, right? Yeah, exactly. But the attack has changed from basically people doing dictionary attacks or brute force attacks to that's their actual password, and so we need anti-automation now. And having something that helps people understand has my password been previously discovered? That is the trick. That's how we prevent credential stuff going forward. We need application owners to pick up the API that you've published, Sure. and, you know, really say okay, that's a breached password. You shouldn't use that. So in this case, we've got Pwned Passwords. This is actually available at my API as well. If you think your password is somehow pwned, I've just chosen the most common password, which is 123456, which is sad in itself. No, I don't want that saved. It's been pwned 20 million times. And just to be clear for everyone as well, this is not actually sending that password to my service. I mean this actually, it hashes it, it takes a subset of the hashes, sends some anonymized data, and that makes a lot more sense when you actually read what's further down the page and read the API. But the premise here is that we know that people use the same terrible passwords everywhere, so we need to start blocking a lot of these. And NIST came out recently as well and said the similar. So, you now, you've got to go through previous breach corpuses, get bad passwords, and literally just blacklist them. Honestly that's a really great point. And NIST, everyone should get 800-63, all 3 volumes, and then realize they don't talk about passwords until volume 2, and then they only talk about them as memorized secrets, which is fantastic, like where to find what you're really looking for. But what they're really doing is they're providing evidence that passwords are, the day is done, has been for a long time. They're really suggesting that we get rid of password complexity policies and put in place a password length policy. And password rotation, do you know the story for password rotation? So I know that they've said you should stop forcing it and you should have other mitigating controls. Is there another backstory? Well, it's--- Back in the day, and I'm talking 1979, Bob Morris Sr., like the guy who's the father of the guy who wrote the first worm, and I believe Brian Kernighan, they used their institution's PDP-8 to crack the password file, which back then was actually DES-encrypted, it wasn't, you know, hashed, on the PDP-8 at nighttime in single user mode and on weekends. Right, so trivially. Yeah, it took them 31 days. Therefore, we now have 30-day password rotation policies that was baked into Orange Book in the early 80s, and we've never updated it to cope with the fact that CPUs have got a lot quicker. If they had GPUs that could do billions of hashes a second or at least, you know, here's a billion passwords and do it just basic--- Just by forcing. They would've realized that password rotation was never a good policy, and it actually works against us because humans are terrible at passwords. And if it wasn't for browsers making that the 5 to 10%, it would only be a fraction--- Yeah, yeah.

A3: Sensitive Data Exposure
Alright so, that's broken auth. Let's move onto the next one. Okay, so number 3, Sensitive Data Exposure. Now we had that in 2013 at position 6. It's actually jumped 3 spots. What's going on there? Uh, it one word, Equifax. Oh geez. But people forget there was actually a big breach before then of a few health systems. Like Anthem sort of thing? And so essentially we need to start thinking not only about those breaches, but also laws that are coming up. So what we've done is we've really focused in on what sensitive data exposure is about. And if anything, I want to talk to people about this is about humans. If you're talking about sensitive data exposure as missing TLS, you're missing the point. This is about exposure of data records. So if it's someone's name and address, their password, that's just a PII record. But sensitive PII, with GDPR coming up, there are very serious fines for not complying with it. And we needed to make sure that not only is the impact here, it went up, but also the number of breaches went up. And so we need to make sure that sensitive data exposure is about GDPR, which is the EU privacy legislation. We also need to make sure that folks who don't have great privacy laws are thinking about it because customers expect you to look after data properly. And if you're not going to do that, even if the privacy laws are weak, you'll lose customers. It can be an end-of-company event, so we need to put that in. I notice here as well, you know, you've just said sensitive data exposure and you've talked about particular classes of data so things like sexuality, health records, I think political affiliations--- Political and religion, yes. Religion, another good one. So does this sort of A3 just cover those, or does it cover my email address, my home address, which may not strictly be considered sensitive, but like it's still personal data exposure, right? So the Australian privacy laws have a concept that you combine two or three pieces of things together, and that combination, that tuple of information is actually private information. The fact that you have my phone number or my email address is not sensitive. But in combination say with my home address and say my birthday, that is absolutely sensitive. But the data itself, not important, but the actual combination of those things. I think that's actually a nuance that many people are missing. I also wanted to remove any sort of technical things. A lot of the times we'd see people reporting headers like this is ASP. NET. I mean, that's not sensitive data. Yeah. It's not sensitive in any way. So all of those machine things were removed. And I mean, when I look at the section here on Is the Application Vulnerable, it's still talking about behavior, so, yeah, unsecured transport load, for example, which obviously, whether the data is considered sensitive or not, if we do that right, it's going to protect everything that you send over. Yeah, but also I mean, let's talk about like, for example, the CEO recently that sent, what was it, 23, 000 private keys. In my mind, that breach was self-inflicted, and yet it barely comes into this section, but the reality is that those keys protect a lot of sensitive data. And so from my perspective, that would be a breach underneath this particular thing. Okay, because that could be the gateway to exposure of other things.

A4: XML External Entities (XXE)
Alright, so let's move onto A4, XML External Entities (XXE). We have not seen this in the Top 10 before. Did this not exist before? Is it a brand new thing? Tell us about XXE. So XXE made its way into the Top 10 all by itself, and it came from a few source code data bundles. So essentially, Veracode was very kind to us, and they gave us a lot of data, so much so that we actually had to change the way we did analysis to cope with the fact that their data swamped everybody else's. But XXE made its way into the Top 10 all by itself just simply because it's incredibly prevalent within code. And so it's just not tested well. Most people don't even know how to test for it. So from a DAST perspective, putting it in, I'm expecting us to see more of this as time goes on. But this is the one I'm expecting to be gone in 2020 because it's so simple to resolve.

Employing OWASP ZAP to Exploit XXE
So let's just define this just so it runs on the same wavelength here. You just said DAST, we've got a reference to DAST here under the Security Weaknesses section. There's also reference to SAST. Can you just define these two terms for us? Okay, so SAST is source code analysis, so static code analysis, essentially tools or people doing manual code reviews. On like the code itself? Yes. And so they have extreme visibility of everything, and that's probably like the gold standard. That's where I come from, and it's where I would love everyone to go to. However, the reality is we've got so many apps, we can't do it. So most people do DAST. DAST is dynamic scanning or dynamic pen-testing. So essentially this is where you've got a person or a tool that's looking at the application that's running, and it just tests it. And so we've got a few tools that do that. Okay, so in the case of say web context, it's like someone is literally going to the URL and probing away at the app and seeing how it behaves when it's running as opposed to SAST, which is like give us all your HTML and your code behind source or your C# code fragment say, Yep. and we're going to see here that you're concatenating up trusted data and executing it or something like that. Would you like me to show you like a little tool? Yeah, let's do a demo. So let's actually see XXE running. Okay, so the DAST tool that I'm using here is the OWASP tool. It's a really good tool, and for the price it can't be beat. It's zero dollars. Zero dollars, right. And so it has a lot of functionality. If you think about all the things you see, this is actually not even the most complicated way this looks. I'll keep it this way. What we're going to do is we're going to run our browser. It's running Juice Shop at the moment. So explain Juice Shop. Juice Shop is a deliberately vulnerable application. It's actually really well written. It's got hundreds of functional tests that pass. So it's the least buggy vulnerable application we have. But it's basically an online store, so think about it from the point of view of someone coming here and wanting to buy juice. So you can go in here, you can say--- And can anyone go and get this, just to clarify? Yep. So if you go to our friend, GitHub, there is the Juice Shop repo. You can clone it. If you just want to play around, there's a couple of ways of doing it. You can deploy on Heroku for 0, you can actually do Docker, which is what I'm doing here, or you can build it by itself. Now the dependencies are a nightmare, so quite frankly, do the Docker. Docker is easy. It's literally 5 minutes and you're running. Right. And so here's the application. It runs. It's actually translated, legitimately translated into all of these. Wow okay, alright. So a lot of work has gone into build a bad application. Exactly. So you can do things like do apple juice, and it will show you apple juice. You can actually log in. Now I'm going to put the browser into my proxy mode, so essentially it sends all the traffic through ZAP. And it actually, nothing will go past it. Okay, so this is probably important to define for folks that maybe are not used to dynamic analysis testing. So every request that you make through your browser here, the Juice Shop is going to get routed through ZAP, and that's then going to allow you to see what's happening in your--- I assume you're then going to probably manipulate some of those requests. Exactly. So this, being a full function application, actually has some additional features. And so we're just going to go through and we're going to create a user. It says not valid. I've listed Batman, batman@batcave, bat. cave. That'll be fine. And I'll use my super strong password of 123456, and we'll Last name of the dentist. Oh, I hate these. Oh wow, they're terrible. I actually use random values for all of them. Yeah, me too. It gets very difficult though when you call up your bank and they say what's your mother's maiden name, and I say okay apostrophe, angle bracket, anyway. Do you know that for most privacy laws you need your mother's consent to actually collect and use that piece of information? You're just making it worse, come on. Okay, so batman wants to log in, and he's going to use his super strong password. And now we can actually do things like actually place orders. We can also do this wonderful thing where we can complain. We're not very happy, not happy. But we can also do this invoice thing where we can upload files. This is where it gets fun. And it only wants PDFs, but luckily for us, that's not necessarily true. I've got an XML file here. Let's have a quick look at that. And so when it fires up, we'll be able to see the code. This is a basic XXE. Let's go through it. The real problem with XXE is it allows external entities, and you can define whatever you want. We can use it for port scanning, we can use it for local file inclusion, and in Windows environments we can actually use it for RFI, but inside the network because you can actually use SMB shares here. And so if you've got an outside web server that has this problem, not only have you not patched since 2014, you also have a problem where you can access internal resources. So we just combined a lot of terms there. So I think what you're saying here that the problem is that once you upload this file, it's going to be uploaded into a web server. That is going to do--- Do you want to define RFI just for a moment? Yes, a remote file inclusion allows you to say I want to be able to pull this file from this remote location on the internet from somewhere. Right. So we could actually refer to instead of file, we can actually pull another file from somewhere else. From HTTP--- Yeah. So the problem here is that once we can start including external assets, if this executes in the context of that server, you're going to pull in some sort of external asset, it's executing on a machine, which then is going to lead to some other series of nasty events. Exactly. In this case, we're going to grab the password file. If I was really hacking this site, I'd be probably going after the web. config. I'd be going after web. xml. I'd be going after database credentials because you could do it. I don't really need to know the password file here. I mean that's not interesting to me. So I take it that the main thing that this is going to be dependent on is when you upload this file, there's going to be paths or someone on the server is going to pass this XML, and then it's going to go and grab that remote asset. Or in this case, it's going to be a local asset, so I guess it would be LFI. Yes. But it's still going to be an asset, which is not meant to be accessible by external parties. Yes. And if we make it like dev random, it will never stop, and it will actually peg your application server. So the XXE here is defined, and we use it there. We can also use this for the billion laughs attack where you basically have external entities that refer to each other. And after about one case worth of referring to each other with recursion, you destroy the system because it runs out of memory. Right, this feels like zip bomb reminiscent or something along those lines. The old stuff keeps on giving. It does. So we're going to pick this file, and we're going to submit it, and we're good. Now it says we've solved this. This is actually one of the really nice parts about Juice Shop is it allows us to go through and say what we're doing. So I'm going to solve another issue. So can I just clarify here? So when we say you've solved this, this is Juice Shop intended to be a vulnerable application saying you have just discovered one of the vulnerabilities within the system. Did I get that right? Yes. And so there's a scoreboard that you can find and you can know what you're doing. It's one of the challenges, and I just gave it away. I'm sorry. But these are all the challenges, and there's so many of them including some really difficult ones. And I'll let you know something. I haven't solved them all. Alright. So it's actually good challenges. It's a challenge. Yeah. And so it only tells you that. Let's go and have a look at what we have here. And so in ZAP, we have a history, and we're going to go to the last post and look at the request. We can see here that we've got im not happy, and there should be another request a little bit up there. Okay, so and again, this was ZAP proxying all your requests, so it saw you submit that form. We saw the request body, which said, you know, you're not happy with your juice or whatever it was. So you can see that we've uploaded the XXE, and it's accepted it. It should only accept PDFs. So honestly as a developer you could say ah, that's not a PDF and don't accept it. But in this case, it accepted it just fine. And here's the password file. So oops, there's actually, there you go. There's the root password file. Okay, so this has now come back in the response. So just to be clear because we're sort of flicking through ZAP, which maybe not everybody's familiar with. You were showing the request, which went up. The request obviously had that XML file with XXE risk in it. Now looking at the response, and when that response has come back, it's also included that file, which you put as a reference, which was our local file includes. Yeah. And this is how easy it is to test. And I think this is the sort of awareness we're after. So everyone who learns how to do this will now have a rich vein of fun that the fix is so simple. Yeah, I was just going to ask about that because we've got to get onto the next thing, but we really should talk about how to not like have this problem in the first place. Patch. So what's the fix? Like literally, if you haven't patched since 2014, you could still be vulnerable. But even then, you still have to turn external entities off if you've got a system that has existed since then. So you've mentioned 2014 a couple of times. What was the vulnerability that got patched in 2014? So all the XML processes like Axis2, and the Microsoft stack and, you know, all of those. This became well known in 2014 in developer circles. And, you know, there is a lot of information that was floating around there. They all fixed external entities. They turned it off by default. So if you start a new project, you're not going to have this problem. If you patch your XML processor, particular on. NET, you don't even have to turn it off. It just doesn't do it anymore. And so this is one of those things that if you do those two elements, patch and turn off external entities, you are safe, and it's like 5 minutes. Right. So in many ways this is the easy thing. It's not like change your code practices. It's just patch your things, which we know we should be doing anyway. That's right. Alright, cool. So I mean as a new one, it's like it's nasty, but it's an easy fix. Let's go to the next one.

A5: Broken Access Control
Alright so, A5 Broken Access Controls. Now this is like new, but more of the same, but things combined. So what's happened with A5? So we've always had what we call IDOR, which is indirect object references, which is where you can twiddle a value in the URL to get someone else's data. So this would be like change the number. And then you change the number and you get someone else here, which was a lack of access controls on that entity in the database. Exactly. But also you can actually do that for updates as well. You can actually update someone else's profile in many cases because of missing, you know, model level access control. The problem we had in the past is that the access control that we asked for in the previous version of the OWASP Top 10 weren't scannable by tools. SAST tools and DAST tools do not understand access control. Because this is like a business logic, right? And so what they can detect is the absence of it, but they can't tell if it's good. Yeah. So we really needed folks to step up. And by making its own category that is clearly stating this is not a tool thing, this is a human thing, any tool that claims they can do A5, show me the general AI. However, we also looked at presentation layer access control in the context of model and single page apps and mobile apps because in the old days that was about re-enabling buttons and putting form fields back. Right, yeah. Today, it's about there's an entire admin section of the app that lives on the client. You see it. It's there. How can I use that? Right. So they need to protect against that. So it's almost like the client has the controls, and we're now saying how do we actually implement protections on the server side so that if someone does see those controls, they're not going through and hitting admin functions and things like that. Exactly. So we needed to up the functional, the controller, the view, the model. We needed to make sure that the domain logic, which is the business logic, has also got access control. So if you're doing a cinema booking system and you're not permitting group bookings, 1 to 15 tickets can be bought; 16, no. We often find that those business limits, which are an access control problem of sorts aren't being enforced. And so we talk about it in this one. Anything else? Well access control is one of those areas that I, you know, I did a penetration test a few years ago on a logistics piece of software that, you know, runs nationally protected infrastructure in many countries. It was 16 years old at the time, and I reckon it had been tested hundreds if not thousands of times by people like myself. And yet I was able to act as an administrator without being logged in. I don't think people are testing this often enough, and we really need people to step up and test, you know, at least some high-value functionality, check and ask for accounts. So if you are doing a penetration test, don't start with no account. Start with two accounts in each role and really make sure that you're, even if you're not actively scanning an admin account, you're actually actively checking access control so that you can't do things outside of your privilege level. Right. So if you're logged into two separate accounts, once you're logged into account A, you can't start to do things under the context or the identity of account B. Yeah. So you don't want to have spoofing or privilege escalation, and those are two elements that we do talk about. So that sort of rounds out the first half of the OWASP Top 10. So these are the worst of the worst. Let's come into the least worst, but still bad stuff. Let's go onto number 6. Sure.

A6: Security Misconfiguration
Security Misconfiguration. Now we had that before in 2013 in the number 5 position, and it was always sort of a bit of a catchall like don't misconfigure all of these different things. So why has it slipped in? Is it still a great big backup for a bunch of stuff? It has slipped, and it is still a big backup. We actually use it as the repository for all passive findings. And the impact is not very high for any of these, but the likelihood is extremely high. So a passive finding. Can you just define that? So a passive finding is one that you can detect without doing any hacking. So if you've go to a website and you see a misconfigured header, passive finding. Alright, so we touched on that before. So if you --- when we say misconfigured header, if you say maybe the server header being returned or the ex-ISP net version or something, that would be an excessive header. Would that fall into this category? It sure does. But also TLS, so TLS findings. So if you've got weak ciphers or, you know, any range of things, we have great tools. And the reason why it slipped is the tools are automatable, and they can be built into CICD. This is helping us get over this issue. Okay. So you just mentioned CICD, continuous integration continuous delivery, which is obviously a very automated part of how we deliver software now. I think whilst you're on this module, this is probably a good time to talk about that because we do want to see a lot more security automation in that part of the software development lifecycle, so can you touch on that?

Integrating Security into the Software Development Lifecycle
Yeah. So one of the things I'm really trying to get folks to do is write, when they do a penetration test, they should be supplying you the Python or other scripts that can test it, that can be put into the CICD server to do regression tests every single build. So the build will fail until they pass or they become an acceptable, you know, this is going to take too much work. You still know it's a problem, but it won't break the build. These for security misconfiguration are so simple to test for and the tools are so readily available and free that it should just be a standard part of everyone's CICD pipeline to check for dependency checks, to check for SSL problems, to check that your, you know, web. xml or web. com figure's correct. These are simple things that we can really make a huge impact on, and I'm hoping this will go down even further if people take up that advice. So that's interesting, and I honestly hadn't thought of it this much before. But just to paraphrase, you're saying look if a pen-tester comes in, does a test, they come back and say look, you've got some weak _____ ciphers, for example, obviously you want to fix those, but you're saying take a script and integrate that into your automation pipeline such that when you release software next month, next year, whenever it may be, you're testing the same stuff again to make sure that you haven't regressed because some server admin somewhere is going to re-enable them. Yeah, and so one of the things that historically as InfoSec have done wrong is that we've treated ourselves like financial auditors, which, you know, arm's length. We're not allowed to talk to developers. It needs to be tested by someone else, and that's absolute rubbish. And what the problem is is that our reports end up in things like RSA Archer, which the developers have no access to. And by the time they get the report or even extracts from it, it's really out of date, and they don't even know what they're really wanting to do. If you give them something that they can fit into their existing toolset and they can build it every single time, that's something they can use every single time. They don't care about a PDF, they don't care about a report as an archer. I mean Archer's a great tool, but it shouldn't be what developers get. Right, okay. This resonates with me a lot because I remember my life in a corporate environment on the development side of things, and the security team would run things like dynamic analysis and they'd create a big document and they'd chuck it over the fence and they'd go here you go, good luck. And that would be it, and then they'd disappear, and that was always an extremely frustrating process. So I really, and we're sort of going off tangent of the Top 10 and security misconfiguration per se, but I love the idea of that sort of closer relationship and leaving I guess actionable measurable things that are built into the pipeline too. Developers and security should be together. They are part of the same team. I like to actually participate in story points and basically working with sprints to say what are the features that you need to work on next. I like to actually work with them to develop constraints. As a user, I only should be able to edit my own profile. That's often not in those use stories. But if they're there, that's a functional test they can write, and they'll pass a pen-test because of it. That's where you need to fix it. Security has to stop treating themselves as financial audit. We are not financial audit. We have never been financial audit. We must be developers with a security bend.

A7: Cross-Site Scripting (XSS)
Okay, so number 7, Cross-Site Scripting, and this to my mind is like one of the canonical web application security risks. It's like that and SQL injection are the two things that just about everybody's heard of. In 2010, XSS was number 2. In 2013, it was number 3. It's dived to number 7. Are we getting better at this, or is it another case of the tools helping us out like with injection? It's probably the frameworks actually and also the technology. By developers rapidly adopting single-page apps and JavaScript as their preferred language, I was expecting to see a lot of DOM XSS because people don't know about it, but it hasn't turned out. And so one of the things that I was really fascinated by is things like React and Angular go out of their way to prevent cross-site scripting. I thought cross-site scripting would be with us until I retire in another 20 years, but it looks like it's on its way down. And I'm hoping that maybe by 2024, it may not even be in the OWASP Top 10. So I mean just to touch on what you mentioned in terms of DOM-based XSS and the likes of Angular. Is this mostly because those frameworks are taking care of the output and coding for us and developers are no longer sort of taking untrusted data and saying, you know, just pump it back out to the screen, that there's like another abstraction between them and the output, and that, a little bit like injection, is allowing us to fall into the pit of success? Exactly. So React. It's a success story because not only to work quickly, you have to use the shadow DOM, which is a React feature. If you don't use a shadow DOM and you're manipulating the DOM by yourself, not only does your app look terrible, it's slow. And one of the great things about that is that they have to use the one function React that allows you to manipulate the DOM by yourself, and it's called dangerouslySetInnerHTML. Right, okay. And that's the one function. And so that by itself means that most React applications are fine as long as you use the templating language they provide. Alright, so this may be another case of people are not getting smarter, but frameworks are getting smarter. Frameworks will save us. It's really good. I'm very happy about this. And React has 14 different contexts _____ automatically with no decision made by the developer.

A8: Insecure Deserialization
Okay, so XSS is mostly good news, and it's going the right direction. But I noticed that number 8 is something that we have not had before. It's Insecure Deserialization. So this is all new for the OWASP Top 10. So tell us what's going on here. So insecure deserialization was chosen by the community. It was one of the top issues that was on everyone's mind at that time, but it had a longer history than that. Chris Frohoff and Gabriel Lawrence actually did a great, like a presentation, and they released a tool called ysoserial where they actually did serialization attacks against Java, and it provides semi-reliable remote command execution on the application server. And in CVSS terms, this is 9. 3. Right, because RCA is serious business, right? Like you're running your commands on someone else's --- Yep, and this is exactly what this is about, so the impact is way off the charts. The likelihood is just not there. We do have a lot of data for this, and this is why it's been selected by the community. I think as we talk about the way apps are being designed now, this will be with us for a very long time because this is the application architecture, not a technology choice. It's literally where are objects flowing? In the old days, they stayed on the server. Nowadays, they go to the client and come back, and that's the pattern that needs to be made more robust, and I think the framework's going to help us here too. Okay, so look I know you've got a demo, and I know you said there's a few steps to it, but I think it's really important because it is a new thing and because I think as a concept it's not kind of obvious what it is. Can you walk us through the demo on this? Yeah, sure. I must point out there's two forms of deserialization that are reasonably common. There's the remote command execution, which is what we talked about. And then on top of that, we also have changing the serialized objects to elevate your privileges or do something interesting, and that's also valid. Okay. And so if you're trusting objects as being not tampered with, Right. that's where the problem really lies. We're going to do a little bit of a DOS, and it will actually stop. It will do a denial of service attack. Juice Shop actually recognizes this issue and will actually only do it for 2 seconds. In a real application server where you can do arbitrary injection of code, it can do it as much as it wants. That'll actually make node. js unusable on this---. So let's just clarify this for everyone as well. So you're mountain a denial of service attack against Juice Shop. So what are you actually doing in order to do that? Okay, so Juice Shop, edit back, is an API. It's got a RESTful API. We're not going to really use that in this case, but this is one of those areas that I'm going to show you the Swagger file for--- The API. Yep, so the API. This is actually very common. If you're doing penetration testing and your app is actually very API- based, get this file from the developers. They'll almost certainly have generated the OpenAPI file for it, and all of a sudden now you've got all the things you need to test. Sure. It's great. And there are plugins for the various tools that later scan this stuff automatically. What we're going to do here is we're going to place an order, and the order's here. If we actually try to do it straight up, here's the request, and we haven't actually run it yet. Let's just try it out. And so you can see that the actual data is coming here. And we'll execute it. We're not authorized. We need a credential. So we're going to grab our authentication token from ZAP. You can do this is other ways, but this is the easiest way for me. And so we're actually seeing here if we go to the Request, the Authorization. This is a JWT token. This in a form is us replaying a serialized object against the application, but that's not the attack. What we're going to do is--- So that's just a bare token that's got to exist in your auth header. You're going to add that into the Swagger interface so you can make an auth request. Yep. And I'm just going to go down and retry, and now we've actually created a new--- The response came back with 200 okay, and that order is done. Now if we look at the orderLinesData here, you can actually see that there's a little bit of Java going on here, and I don't know what that's about, but it may mean that we can actually inject our own JavaScript because it's doing some evaluation on the server side, which is bad. So can you clarify for me? When you say there's a little bit of Java going on here, I mean this just looks like a random string. So JSON can be interpreted by various passes in a safe way, or you can hand do it and run eval. Either way is bad. Like, you know, you can have problems in either way but. Here we've got some JavaScript we're going to just head over and change. We need to grab our demonstration code. Getting the actual syntax correct is the tricky bit, and that's where we can often get into trouble, you know. I'm going to basically paste that--- Oh, sorry. I've got to try it out. So you're picking away at JSON there, and you're going to replace that with your malicious payload. Correct. So you're effectively changing that JSON syntax, which is obviously deserialized here. And at some point in time, that's going to submit serialize execute the statement and bad things are going to happen. Exactly. So if I click Execute here, you can see that curl is doing its thing. We've got our authorization header, and we've got our reserialized object. Juice Shop is actually a very unusual application that knows about this attack and prevents it, and so it's throwing an exception and says Infinite loop detected - reached max iterations. Okay. Now it knows about this because it is designed to test this sort of thing against it. Yep. Like a vulnerable application's just going to blow up, right? It's just going to infinite loop the thing. And so essentially if you're running a node. js application and you've got one node server, that's the end of it. You need to restart the node server. Right. Okay, so this is quite bad. However, if I was attacking your server, I wouldn't necessarily do it DOS. I would actually use the file and network capabilities to do whatever I want on the inside, grab files, scan your network, make reverse connections, fire up an SSH daemon. Whatever it is that I want to do, I can do. And so this is where the power of deserialization is. Okay, so quickly before we move onto the next thing, we would like this not to happen. So what is the prevention mechanism for this? You need to put integrity around your serialized objects. I don't think we can change the pattern of moving state to the client. It's happening already. Too many apps have had that. What we need to do is add a layer of integrity around those objects so they can't be tampered with. Like an HMAC or something like that? Yep, but also they need to care about replay. Does it matter if it's replayed? Right. So to my mind, if you can put some sort of HMAC on the objects you send around and then check the validity of the object type before you unserialize, that would be awesome. But often the act of checking the type deserializes it. Okay, so that's an all new one, and obviously it's slipped into that number 8 position. So it's like it's bad, but not as bad as the other seven things we discussed first.

A9: Using Components with Known Vulnerabilities
Let's move onto the next one because the next one is something that we have had around for a while, which is number 9, Using Components with Known Vulnerabilities. And it was around in 2013, also in the number 9 position. So I take it we're just not getting any better or worse at this? I think the advice in 2013 wasn't strong enough about asking developers to break the build if they have vulnerable components. And so if even though they might be detecting it, they're not fixing it. And so in this time, we've actually upped it. Essentially if you've got vulnerable components, you absolutely should be breaking the build, and you should not deploy into production. It is a solvable problem. It's eminently solvable at the build phase using CICD service. Okay, so I actually thing this is a really interesting topic because it brings into question this whole idea of there's a pipeline of other components it could pull into a system. And more so today than ever before, we're getting all sorts of different bits and pieces from different places. We've got, you know, npm, NuGet, package management libraries, which will execute on the server. We've got a lot of client libraries executing client side. How are you meant to know what is vulnerable, and how do you break your build as a result? Dependency checkers like the OWASP Dependency-Check can actually verify and then, you know, look at your dependencies whether it's Node. js, whether it's JavaScript before you do webpack, whether it's. NET, Java, PHP. If you've got a package manager it supports, it looks up the latest vulnerability databases from NIST and then tries to figure out if what you have is what it sees, and it creates a comparison. And then based upon whether it's vulnerable or outdated, it will provide a different score. You can actually set you CICD server up to say if it's vulnerable, break it. If it's not vulnerable, but just outdated, let's warn. Right. So the developers know that they've got some technical debt they need to address, but they have time. Whereas vulnerable, you shouldn't even put that into production. That's a fail in my view. Right, okay. So that would literally break the build in that case. So, you know, maybe just as an example, what are some of the sorts of vulnerabilities we're seeing when it comes to third-party libraries. Like how bad does this get? Well it can get very bad. We do think that one of the largest breaches of all time is due to the lack of package management. Now in Italy, that then had another bug, which is in the OWASP Top 10. So, yeah, there's two things going wrong. But I think the root cause is they didn't update the packages to avoid the issue because the bug had been patched for over a year. And we know from the Verizon Data Breach Report, almost all breaches occur because people just didn't patch, and there was already a patch available for more than year. And that says to me that corporations still need to work on this. Now that makes me think back to back to think about WannaCry as well where we had this massive outbreak of ransomware, and this was exploiting vulnerabilities that had been patched some time ago. So it sounds like there's sort of this broader issue of organizations not getting on top of patch management as well. But when it's custom apps and this is your app, you're responsible for creating those patches. So effectively, you need to make sure your supply chain is clean to make sure that your app is good because everyone builds on tops of open-source components. Let me ask you one more thing on this because I've got a slightly tangential thing, which is an interesting industry precedent. So we had this incident in Feb 2018 with a plugin called BrowseAloud, plugin external library. And the way this manifested itself is we suddenly saw a whole bunch of government websites running cryptominers. And this was like thousands of different government websites. And what we learned as a result is that there was one external library, which was like an accessibility library called BrowseAloud. And this library, somewhere in its source, had been maliciously modified. It had a cryptominer injected into it. And because it was loaded in real time into clients, then that effectively cascaded down to every single person who came to browse those sites. Is this within scope of known vulnerabilities because this is a hard one too? I mean this is, for all intents and purposes, zero-day, like you didn't know that this was there. We don't explicitly mention it, but it's certainly one of those things that I think people need to pay attention to. The problem is that when people include advertising networks, you're deliberately outsourcing the web page to someone else, and that's a trust. So we've had people like Newsweek and others that have been owned by their advertising network. Was the advertising networks own JavaScript loader vulnerable? No. It was the processes behind the advertising network. So there are some ways, and you've got SRI, CSP, and Trust. Let's talk about those just fairly briefly. Subresource integrity is almost one of the hidden gems of the web standard as it stands in the moment. But it's also a denial of service waiting to happen because every time an external script changes and you've generated an SRI hash, and the idea of SRI is to make sure the things you're loading are real. They're what you expect, right? So for example, you're using Google APIs to put that it, but it changes. Your app stops working. So I actually prefer CSP. I think CSP's got a better chance here because if you're going to outsource your trust to an advertising network, you've made that trust. CSP helps. So I sort of surprised you by bringing these blog posts up here because I know we didn't talk about it before, but the paradox for me, and then, you know, there's obviously the word paradox in the title here, is that we can use SRI, which effectively says the external file we're including must be precisely this like exactly, and if anything changes, don't execute it. But that means that the external library can never change, and that might be okay if you're including jQuery version 2. x. x, you know, because that shouldn't change. But if you're embedding an external service, so whether that be the BrowseAloud service or Disqus or an ad network, if they are maintaining that JavaScript and it does change, I see your DOS point. So there is a course in the library about browser security, and it talks about CSPs and things like that. So that's maybe a little bit tangential, but I just thought it was interesting that we have dependencies, not just the libraries inside our applications, but also things running on other people's infrastructure. So if there's one thing that I could ask folks to look into as part of A6, which is Security Misconfiguration, is learning about CSP. It helps against cross-site scripting. It helps against, you know, people putting bad things in there. I would certainly suggest learn about CSP. It's probably the most powerful of all the things that's not used today. Good. I'm very happy to hear you say that.

A10: Insufficient Logging & Monitoring
Alright, let's go on and do the last thing. Yep. Number 10, all new, Insufficient Logging and Monitoring, and that sounds kind of self-explanatory. Why don't you tell us what it does mean and why it has now slipped in there into the tenth position. Yeah, so I'll bring it up again, the Verizon Data Breach Report from last year showed a really decent decrease in the days between breaches and detection. It's still 192 days. Wow, okay. So it was saying it still takes like more than half a year after getting owned to know that you've been owned. Yes. And almost always, it's someone else telling you that. Right. So this, if we went in and released an information security standard in 2017 that did not talk about checking your logs and making sure that you had some sort of audit trail in place, I think we would've been doing it this service. So I was really happy the community agreed. And this is actually a community one. It's not one that's backed by data. And in fact, it becomes really, really difficult for anyone other than source code reviewers to determine if this is actually going to happen. Okay. And I mean the thing that was immediately coming to mind here is what you're saying is that we're just not very good at figuring out when things have gone wrong and that the solution, or part of the solution, is that if we had better logging and monitoring and we could identify these abnormalities or identify when there's something funky going on in the network, this is going to make a big, big move forward because like 190 days still seems like a very long time, doesn't it? Yep, but it also requires active participation. The Target breach of 2013, they actually had the fired appliance going off for a number of months saying there's a problem, there's a problem, there's a problem, there's a problem, but no one was looking at it. They bought a tool and either insufficient training or no one was tasked to look at it. They had the technology, they just didn't have the process. So again, security comes down to a people problem. This enables the people. The people still need to understand that they need to be checking these things. I call it artificial ignorance. We generate a lot of logs. So many logs. And if you've got someone there looking at the web server logs, that's not really helpful. What we need to be able to do is say help, I'm under attack and escalate properly, and this is what this is about. Okay, excellent. So in practical terms because this does feel like another one of those ones, which is very broad, what should people actually be logging and what should they be monitoring? So the anti-automation side of things should definitely be saying I'm in trouble. I've been invoked, so essentially the recaptures and whatnot, not only should they block it, but they should also let someone know that it's happening because that's often the first sign of attack. If you're using a tool like Burp or ZAP or AppScan or whatever the case may be, that is going to do a lot of things that are automated, and therefore that's very detectable by anti-automation. That's probably your first clue. The second part of it is high-value transactions need to have an audit trail. And if there's sufficient things going on like, say for example, transferring, you know, trillions of dollars of funds in a very short period of time, alarms should be going off. And so all of those bitcoin exchanges that people, you know, it's not just about breaking into a hot wallet and taking all the money. It's about the web apps that sit on top of them to make sure that outflows are within reasonable limits. Okay, and that is obviously going to be very sort of business domain specific, right? So what it, it's almost like what is a behavioral norm within your application, and how can you identify deviations very quickly because, you know, I just keep thinking about that 190 days. Like that just seems an exceptionally long time. If you can get it down to 1 or 2 days, (thumbs up). You know I think that some of the recent disclosures I've been involved with, Have I Been Pwned, and some of these are years. It's like hey guys, here's your data that popped up 4 years ago, you know, and it's the first I've ever heard of it. Yep. Okay, so I think that rounds out the Top 10 pretty well. I'd really like to talk about some of the stuff that got dropped and then also some of the other things we should be thinking about beyond just this.

The Missing Risks and the Big Picture
What Has Been Dropped from the OWASP Top 10?
So let's talk really briefly about the stuff that's gone because I think there's actually significance in losing that. And you mentioned earlier on CSRF. Cross-site request forgery has been in the Top 10 for some time now. It was number 8 last year. Well not last year, but last edition, 2013. Yep. That's gone altogether. So what have we done to fix this? Frameworks. Frameworks have helped us with both A8 and A10, Cross-Site Request Forgery and Unvalidated Redirects and Forwards. People stopped using Struts. Struts, this is a big deal. A10 was a big deal when Struts was a thing. Spring MVC doesn't have that pattern, and then other languages never had that pattern. There's just no data for it, so it was going to fall out anyway regardless of if we had data-driven Top 10 only for 2017. But CSRF, cross-site request forgery, was and still remains a framework issue. And as frameworks started addressing it, people updated to use it, the data for it just went away. It's actually sitting around number 17 at the moment. So and actually, first of all I'm interested to hear that you are keeping track beyond 10, and I guess that's kind of logical. I just never thought about it because we never actually see in the public domain. So we receive CWEs, like 40 old CWEs, and so we know good solid data for about 25 of them because other ones are so literally so very rarely reported that we can really consider them. We looked at the top 25. Then we ranked the top 15 to see where they're like risk ranked, the top 15. And then we got to the top 8, and then we worked out the order. So, you know, going back to that CSRF bit for a moment. So obviously the mechanics of how we're doing anti-forgery tokens and where they get implemented is still there, but we just got a high level of abstraction now where the framework is, you know, as we said with SQL injection and XXZ, what was it, XXS, these are sort of helping us fall into this pit of success, so that's good news. Unvalidated redirects and forwards, you know, I know you mentioned Struts there. I also know that in previous versions of the Top 10 that there's been some debate about this because there are sometimes functional needs to do unvalidated redirects and forwards, and people would argue whether it makes sense or not, but I guess that problem's sort of solved for us now. There was always the argument that unvalidated redirects were a weak form of XXS, and my view is that if it's a deliberate design like your bitly. Yeah, perfect example, because like by design you need to be someone to be at of site redirect to this URL from a bitly domain. And so then it becomes am I redirecting someone to a bad domain? And that's a design decision, that's a business decision. It's not a technical decision. But nowadays, the redirection parameter is pretty rare. You don't find it very often. There's not a lot of data for this anymore, and I don't think it'll ever reenter the Top 10 by itself. Okay, so that's good news. We're getting rid of some stuff.

How Best to Use the OWASP Top 10
I guess just to now start rounding the whole course out thinking about how development teams move forward with this, where should the OWASP Top 10 feature and who really needs to know about this? Okay, so from a developer point of view, I'm going to give you an answer you probably won't like. The Top 10 really is, it might have an order because of asterisks ranking it, but it's the minimum to avoid negligence. It's not a great standard, it really isn't. If you look all the CWEs, we're looking at over 40 CWEs, and we mentioned a bunch more. What really needs to happen from a developer point of view is you need to go and pick a better standard, and the application security verification standard is that standard. It's written as a set of functional tests that you can do unit or integration tests with, and you can pick and choose and fork it and realistically make it your own. The OWASP Top 10 is you must comply and there's no discussion. You must do this. And that's like hmmm, yeah, that's security from the old days. I don't like it. But the reality is if you still have SQL injection in 2017 or 2018, problem. If you have the inability to protect, you know, security breaches, problem. That's A1 and that's A10. Yeah. You have to do it all. Which order you do it in, I think every application and every business is different. Twitter has a huge problem with broken authentication. They probably would be working on that more than almost anything. So I mean I know from my experiences training on the Top 10, the message has always sort of been like this is your starting point, right? Like this is, you don't get to number 10 and go okay, job done, we're over, good. So I guess within development organizations, this is sort of something we do want everyone on the team to understand, right? Like if you're building software and you don't understand all of this, Yep. then you're probably going to have issues with it. Absolutely. As I said before, it's essentially how to avoid negligence. As a developer, you should actually know all of these things just because you're a software practitioner. You should be aware of the danger points even if you're not familiar with how to fix it. You know oh, this might be a problem. I'm going to go and see someone about that and get the advice you need. So what about in terms of things like compliance standards because I know that the OWASP Top 10 does feature in some of those. Yeah. So we are very commonly included as a target of choice. It's actually included as part of PCI DSS. So, you know, on that awareness piece, who else within the organization's building software needs to have awareness off this? From the point of view of the business, you should have metrics showing you how well you're doing against whatever standard you do choose. And if this is the standard, we've tried to make it a little bit more concrete about how you comply with it. If you know that this particular group over here is not doing so well, having that metric to say this people over here have, you know, they're not doing well from a code review or a pen-test point of view on these OWASP Top 10, that could help drive the education piece, giving specific advice like getting you to run through certain Pluralsight modules or whatever the case may be. Getting the metrics is actually really important. I think this is the evidence that the information security industry hasn't really had in the past, and I think we need to get with it in terms of evidence and make sure that we're doing the right things because there's an opportunity cost from doing the wrong things like password complexity. So I think that's probably a really good place to wrap up because throughout this course, we've spoken a lot about this being evidence-based information. And to talk about having evidence about who within the organization is actually doing a good job of complying with this, and I imagine it's the sort of stuff you might get out of CICD tools as well, would be enormously valuable. So, you know, I guess to wrap it up, this has been sort of a good high-level, play-by-play overview. We've got a heap of other material in the library around the Top 10 actually at a code level for different frameworks as well. So hey look, thanks very much for joining me because you're probably the best person in the world to give us this overview about the Top 10. Yeah, no problem, and thank you for having me.

Course authors
Author: Troy Hunt	
Troy Hunt
Author: Andrew van der Stock	
Andrew van der Stock
Course info
Level
Beginner
Rating
4.7 stars with 74 raters(74)
My rating
null stars

Duration
1h 12m
Released
14 May 2018
Share course

