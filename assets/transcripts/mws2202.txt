Hack Yourself First: How to go on the Cyber-Offense
by Troy Hunt

"Hack Yourself First" is all about developers building up cyber-offense skills and proactively seeking out security vulnerabilities in their own websites before an attacker does.

The prevalence of online attacks against websites has accelerated quickly in recent years and the same risks continue to be readily exploited. However, these are very often easily identified directly within the browser; it's just a matter of understanding the vulnerable patterns to look for. This course comes at security from the view of the attacker in that their entry point is typically the browser. They have a website they want to probe for security risks â€“ this is how they go about it. This approach is more reflective of the real online threat than reviewing source code is and it empowers developers to begin immediately assessing their applications even when they're running in a live environment without access to the source. After all, that's what online attackers are doing.

Course author
Author: Troy Hunt	
Troy Hunt
Troy Hunt is a Microsoft Regional Director and MVP for Developer Security,
 an ASPInsider, and a full time Author for Pluralsight—a leader in online
 training for technology and creative...

Course info
Level
Intermediate
Rating
4.8 stars with 861 raters(861)
My rating
null stars

Duration
9h 25m
Released
30 Aug 2013
Share course

Introduction
About the course
Hi, my name is Troy Hunt and I'd like to welcome you to my course on Hack Yourself First, which is all about how web developers can go on the offense before online attackers do. Let me give you a bit of an overview of some of the things we're going to cover in this course. The first thing I'd like to make really clear is that this course is for web developers. It's not aimed at security professionals such as penetration testers. This is for developers that want to understand how to increase the security position of their own code. So everything we're going to look at in this course is going to use tools and environments that are very familiar to many developers. After all once you learn how to hack yourself first, you're the guys who then need to go back and improve the security position. Now one thing that I really wanted to focus on in this course is to make it platform agnostic. And what I mean by that is that it doesn't matter what service side web framework you're developing on, this course is relevant across all of them. If your web application loads over HTTP and returns angle brackets, this course is for you. Now of course how you mitigate the specific risks that we find throughout this course will depend on your technology stack. So I'm going to talk about the sort of behaviors that you can observe that have security risks, and then I'm going to show you how the website should behave once those security risks are rectified, but the execution of how you do that may differ between technology stacks. If you are an ASP. NET developer, I do have another course on Pluralsight called the OWASP Top 10 for. NET developers. And that comes at security from the other angles, so it actually starts at the development side and looks at secure coding practices. So if you're a. NET developer, go and check out that course. And in fact, if you work with any other technology stack, there's still a lot of relevance in that course for you, but the semantics of the implementation may differ slightly in your chosen framework.

Why hack yourself first
I want to start by briefly talking about "Why hack yourself first? " is an important concept. And the most important thing here is that as developers we do really need to hone our cyber-offense skills. We need to understand more about how online attackers think and work. Until we can do that, it's very difficult to protect our applications from attackers. It becomes a very academic, semantic exercise if we don't know how to break security flaws and applications ourselves. So we've got to walk a few miles in their shoes. Now one of the cornerstones of hacking yourself first is that it focuses on how to assess website security from a remote position. Now what I mean by that is that how can we find security vulnerabilities just in the browser or using other common development tools. So we're not talking about going into dedicated penetration testing space here, with specialized equipment and very, very deep security professional knowledge. I'm talking about the patterns that us as developers can readily identify in the way a website is structured and responds to certain types of requests. So we're going to look at all that from the external perspective and we're going to break through weak security from the external perspective. So these are the sort of activities that an attacker will attempt to perform against your website. Now a very important part of all this is the concept of defense in depth. So as we progress through this course, we're going to fix multiple different security flaws that were used by an attacker to exploit the application. What we're trying to do here is avoid having single points of failure, so the idea of defense on depth is it becomes a very layered approach. We're going to tackle each security weaknesses from multiple different perspectives in order to make the application as secure and as robust as we possibly can. I just mentioned the application and indeed I have a dedicated application that we're going to use in order to identify flaws and then another application that we're going to use in order to look at how those flaws have been rectified. I'm just going to show you one more slide though before we move on to that application. You've probably seen something very similar to this in the past, and the idea is that when it comes to the cost of fixing bugs in software, the earlier on in the life-cycle we can fix that bug, the less cost it has. It's much cheaper to fix something in Requirements before we put effort into Design. It's much cheaper to fix it in the Design before we've actually written the Code. And then of course it's cheaper to fix it in the Code than after it's actually gone into a Test environment and you've gotten QA and testers and all sorts of other roles involved. And of course it's definitely much cheaper to fix it right up in that testing phase before it actually gets into Production and people start using it and finding bugs. In the context of this course though, what I think is really important to understand, is that fixing bugs in any of these stages of the software life-cycle is significantly cheaper than having a Breach. Security incidents in websites can bring companies down. That can be enormously costly to an organization. So as much as I'd like to focus on fixing bugs in places like Requirements and Design rather than in Code and Test, the absolute worst possible case we could have is to have a Breach in the system. It can have enormous impact on the customers who use the service. It can do irretrievable damage to a company reputation. And there are also many cases of legal action being taken as a result of sloppy security in an organization's website. This course is all about making sure we don't get to the right side of that graph and end up in a Breach. So it's going to help us focus on identifying vulnerabilities in the application as far left as we can go on this graph. And we're going to look at observable patterns that we can address in Requirements, Design, Code, Test, and Production. And again all of this is with a view to not ending up on the right side of that graph and having a Breach. So let's move on and take a look at the website that we're going to be using throughout this course.

Introducing a vulnerable website – Supercar Showdown
Throughout the duration of this course, we're going to be using a website that I've called Supercar Showdown. Now this is a website that I've created specifically to demonstrate various security risks that we're going to identify as we move through each module of this course. You'll find this website up at hackyourselffirst. troyhunt. com. And it is a public website, so you can wander over there at any time and have a look at the security position of what's going on. And that's very important, because that's the easiest possible way that you can get this site running and have a look at how it works. Now there are a few basic features of the Supercar Showdown website. And the first one I'll point out is that there is a simple account management feature. So you have the ability to Register an account and of course you have the ability to Log in. Throughout most of this course, I'll be logging in with my own email address and I'm using a sample password, a very bad password at that, but there's a good reason for it. And then I'm going to be logging in a lot of the time. And logging in is important in the context of this application. As in some of the modules, we're going to be looking at exploiting authenticated sessions. Now as part of this application, we have a Leaderboard, and the whole idea here is that we're going to vote on which cars we like the best. Now the idea of the Leaderboard is to track which cars are rated highest. But we also have some other features in here. So we can do things like sort the results by who has the fastest 0-100 time, for example. Or who has the Top Speed? Many of the features such as the one you see here have security vulnerabilities that we'll be exploiting throughout the course of this application. When we look at an individual supercar, we'll see that there are some votes and also we'll see that there are some comments by other users with accounts in the system. We can also go through and vote for a vehicle. And if we'd like, we can leave some comments. That's pretty much the entire mechanism of how this application works. It's really quite a basic website, but it has many common features that we would implement in real-world websites. As well as what we've just seen, there are typical features such as the ability to say: Change a password, or Edit a profile, or even let's just Log off. And of course there's a Search feature, this is very, very common throughout websites today, and you've probably built these sort of features in your own websites in the past. Now I've actually built this website on ASP. NET MVC. But because we're going to come at this from an external perspective and we're really just looking at it in the browser, and we're looking at HTTP requests and we're looking at HTML and JavaScript, it doesn't make any difference what the server-side framework is. And again this is the whole objective of hack yourself first. We're going to be very technology agnostic. Now there's one other aspect of this that we're going to see throughout the course and that is there's an attackers website. And that's simply over at attacker. hackyourselffirst. troyhunt. com. Now the idea of the attacking website is it's going to be used in various demonstrations where there's a dependency on having a malicious website mount an attack. So things like cross site attacks are going to use this website, or siphoning off cookies through XSS risks are going to use this website. So you'll see this appear every now and then. It's not branded it's just got the bare basic functionality needed to demonstrate how an attacker may use another website in order to attack the victim website. So that's our sample vulnerable website and the attacking website. There's one other website that I want to show you, and that's the secure website. Now the secure website is simply over at secure. hackyourselffirst. troyhunt. com. And as you can see, the secure website looks almost identical to the vulnerable website. There are only two differences that you'll see on the screen here. Obviously the URL, we have a secure prefix, and just to make it really clear that this is a different website you'll see that there is a gold glow around the navigation. Now one thing that I should point out about the secure website is that as we go through the modules in this course and fix individual risks, it's the secure website which is going to demonstrate the risk. However it doesn't mean that the secure website has no risks whatsoever. Often, we require one or two risks in order to demonstrate another risk that might be a little bit further downstream. So the intention of the secure website is to demonstrate individual secure practices, and not to represent an overall secure position for a website. So you will see some vulnerabilities in the sight in front of you as we progress. Now the last thing I'd like to look at before we get into this course, is to take a look at some of the tools we'll be using throughout the modules. So let's go and have a quick look at that.

Using Chrome's developer tools
We're going to spend a significant portion of the time in this course in Google Chrome. In part because it's the most ubiquitous browser on the web today, and also because it has some really neat tools to make hacking ourselves very easy. Many of the features we're going to use are probably quite familiar to you, so I'm going to run through them all pretty quickly, just to make sure that we're all on the same wavelength. So, for example, one of the things we're often going to do is inspect the source code. Now we can either right-click somewhere on the page, and view page source, or sometimes you'll see me use the shortcut key of CTRL-U. The other thing we're often going to do is drop into incognito mode. So up to the Menu, and then New incognito window, CTRL-SHIFT-N, will do the same thing. Now the point of incognito is that once we go into this mode, and you'll see we get the little spy up in the top left hand corner of the browser. All the browser history, the cookies, the cache, anything else that was already in the browser is discarded so we have a completely clean slate. So I'm going to use this at times where I don't want to bring forward any dependencies that we've already set up in the browser. And that particularly means things like cookies. The other thing that we're going to use quite extensively is the Chrome developer tools, and we can jump into that by pressing F12. Now there's a lot of stuff that goes on in the developer tools, so I'm just going to show you the ones we'll most commonly used. We're going to be using the elements quite a bit, we want to be able to look through the structure of the page, and you'll see that as I highlight areas of the page, in this bottom left hand panel, with the HTML, you'll see it reflected on the screen. The other thing we can always do is just right-click on an element, and go down to inspect element. And it will then highlight the code in this element's tab. This is really neat, not just for inspecting security positions, but in day-to-day developments. Next up we have the Resources tab, and the Resources tab includes all sorts of different assets that have been loaded, or state that has been set as part of the execution of the webpage. We're going to particularly focus on Cookies. And what you'll see in this section is each cookie that is valid for this website will get a Name, a Value, a Domain, and we're also going to be looking at the Path, the Expiry date of the cookie, and those two columns on the right, the HTTP column, and the Secure column. All of these are particularly important throughout the duration of this course. The other thing we're going to use quite extensively is the Network tab. And what we'll find on the Network tab is all of the requests that the browser has issued. So let me show you what I mean by that. I'm going to go up to the Leaderboard, and what you can now see down in this Network tab is a whole bunch of requests. If we pick say the first request, which was the request for the HTML page /Supercar/Leaderboard, we'll see that we've got things like the Method, so is it a GET or is it a POST? The HTTP Status, this was 200, okay we didn't get say a 404 Not Found, or an internal server error, or a redirect, or any of the other sort of status codes that we'll see throughout this course. The other columns are pretty self-explanatory. What we're often going to do though, is drill down into a request, and we're going to look at things like the headers. Now this is another area where we're going to spend a significant amount of time in this course. And this is actually a really valuable view of what's going on. So, we're saying things like the URL that was requested, and the method that was used, and this becomes particularly useful when we look at Asynchronous requests, where we're not actually saying the URL on the browser, it's just JavaScript going off and hitting an API somewhere. We're going to look a lot at Request headers, so particularly things like Cookies. Now when we make a POST request, we're also going to see a request body, which has each of the form fields and values in it. Scroll down a little bit further and we get things like Response headers. So this is what the server is sending back to us, above and beyond the HTML you see rendered in the browser. So we'll see things like the application Server that's being used. All of this is very useful. We're also going to be taking a look at some sub-tabs, such as things like the Response, which will give us the body of what comes back from the server, as well as the Cookies so these are the cookies that were sent with this request, and any cookies that we're sent in the response. So if it's not already, this is all going to become very, very familiar to you throughout the execution of this course. Now there's just one more thing I'm going to show you with Chrome, and I'm just going to jump up to the Menu, drop down to Tools, and go over to Extensions. We are going to be using an extension called "edit this cookie. " And you can find that by Getting more extensions, and just searching for edit, and there it is right at the top, edit this cookie. So this is a free extension that we're going to use to, as the name suggests, actually edit this cookie. So do make sure you Add that if you want to follow through the steps of this course. So that's how we're going to be using Google Chrome. Let me just show you one more tool before we jump into the modules.

Monitoring and composing requests with Fiddler
The last tool that I'd like to show you, is Fiddler Web Debugger. Now Fiddler is hopefully familiar to many of you, and it is an absolutely sensational and free means of monitoring, manipulating, and reissuing HTTP requests. And it's very, very simple. We're looking at Fiddler here on the screen, and what we'll see down in very bottom left of the corner is that it is Capturing and it is Capturing Web Browsers. Now if I jump back to our website, and I reload, and then I jump back over to Fiddler, we'll see a bunch of requests here. Now for any one of these requests, and let's take the first one, which was obviously just reloading that page. We'll then find a bunch of really useful information about it. We're particularly going to focus on the data on the right hand side of the page, and I want to start with Inspectors. Inspectors is broken up into two parts, the Request and the Response. So at the top of the page, we're seeing the Request. So for example here are all the headers that were sent with the request. If we're actually posting data or passing data via a query string, we'll see that here in the Webforms tab. So this makes it very easy to monitor requests that are being sent from the browser. One thing that makes this very different though, to the developer tools in Chrome, is that Fiddler really behaves as an HTTP proxy. And what I mean by that, is that it sits on the wire in between the browser and the target website. Now that's very, very important because particularly in modules such as transport layer security, where we want to talk about what an attacker can observe on the wire, Fiddler is an excellent representation of what an attacker can see, and then do with requests that are sent across the internet. So for example, an attacker can see any of the information that I'm seeing here in the right hand panel. Now as well as that being the stuff at the top, which is the Request, there's also the stuff at the bottom, which is the Response. So for example, the Response headers, and this looks pretty similar to what we just saw in Chrome. When we look at the response, we can also take a look at the Raw Response. And the Raw Response is a combination of the headers and then everything in the body. Now depending on the content type, and in this case it's HTML, we can then render it into Fiddler. So for example, we could go to WebView, now it's obviously not rendering the CSS, it's just rendering the response of the request, but you can see how this is quite a handy feature. We'll also be looking at things like the JSON tab, which obviously isn't showing anything here because we didn't get a JSON response, but when we actually hit APIs later on that do return JSON, this'll make it much easier to inspect what's going on. Now I mentioned before that Fiddler is a very good representation of what an attacker can see on the wire. One thing that's important to note, is Fiddler's position on SSL. And we'll talk about this more in the first module, but if we jump up to Tools, Fiddler Options, HTTPS, we can see that there is the ability to Decrypt HTTPS traffic. Now in order to decrypt HTTPS traffic, Fiddler issues its own self-signed certificate, and we'll talk more about that in the first module. For now though, just be conscious that there is the ability to have Fiddler decrypt that traffic, but because it is a self-signed certificate that won't be valid for the domain, it should set off some warning bells under normal operating circumstances, so just remember that HTTPS position. The last thing that I want to show you in terms of the basic Fiddler functions is the Composer tab. Now what the Composer tab does, is it allows us to take a request such as this first one here, drag it into the Composer and it reconstructs that request in its entirety. So in this case it was a GET request, there are only request headers, if it was a POST request we'd also see a request body. After we reconstruct that request, we can go through and Execute it. And you'll see that there is now another record on the left of the screen and of course it's just another request to the Home page of our Supercar Showdown site. At some points in this module we're actually going to be manipulating the request in the Composer. We're going to mount attacks directly from Fiddler, so this Composer is going to become a very, very effective way of working with the raw requests and reconstructing them in order to mount attacks on the target website. So there are the basic Fiddler functions, let's now move on and look at something just a little bit more complex than Fiddler, but it's something that's going to be very important particularly in the first module of this course.

Modifying requests and responses in Fiddler
What I'd like to show you now is Fiddler script. Now what Fiddler script is, is effectively a rules file that lets us manipulate both requests and responses just like an attacker would, if they were sitting in the middle of the communication. Now what you'll see is that there are a number of different events in Fiddler that we can work with. And the two primary ones we're going to be looking at is OnBeforeRequest which is effectively after the browser makes a request but before it gets to the server. And then OnBeforeResponse, which is the other way around, so the server has responded, Fiddler's going to change that response before it gets to the browser. Now let me give you an example of what we can do with say the OnBeforeResponse event. I've just jumped down to that event, and you'll see that I've got a piece of commented code here. And it's everything under this little Hack Yourself First title. Now before explaining what I'm doing here, let me just jump back over to our insecure website, and jump over to the Leaderboard. And we can see here the title is "Who's the greatest of them all? " Now I'm going to jump back to Fiddler and I'm going to uncomment this code and show you what we have inside this. So what we're able to do in Fiddler script is pick up things such as requests for a particular host name. And in this case it's the host name of our vulnerable website, and I'm going to look for requests where the path and query is the Leaderboard. So this is just a simple condition that's going to pick up requests to the Leaderboard. It's then going to go through and do some decoding, it's going to get the response from the server, and then I can do things like go through and replace contents in the body. So I can go through and say replace the closing H2 tag with a different H2 tag. What do you mean there's no Porsches in this thing, then I can set that response body. So with that uncommented, let's save the script, jump back to the Supercar Showdown site, reload the page and there is our message. So Fiddler is really neat way of demonstrating how we can change requests on the wire. Now we'll look at this particularly in the first module, on Transport Layer Protection. But this is really important because this demonstrates what an attacker can do with unencrypted traffic. Now there's just one more little thing that I'll point out with Fiddler, and that is that there is a very good Fiddler add-on ecosystem. And a little bit like Chrome there are add-ons to do all sorts of different things. The one that we're going to be using though, is one called Intruder21, and we're going to use this for Fuzz testing when we get to the Parameter Tampering module. So if you want to be able to follow through the exercise or reproduce this yourself, jump over to fiddler2. com/add-ons, and grab Intruder21. That's a free add-on into Fiddler. So that's pretty much it, the entire course is going to be centered around using Chrome, and we'll touch on the Edit this Cookie add-on, and Fiddler plus the add-on that you see just here and that's really all we're going to use to hack ourselves first. So they're very common tools that you're probably quite familiar with already. So enough of the overview, let's get into the course and start hacking ourselves first.

Transport Layer Protection
Introduction
Hi. This is Troy Hunt, and welcome to the first module of the course on Transport Layer Protection. In this module, we're going to start out by looking at the three objectives of transport layer protection, or as we'll often refer to it HTTPS, SSL or TLS. We're then going to take a look at what it means to mount a man in the middle attack because this is really the risk that we're trying to protect against when we use transport layer protection. We'll move on to taking a look at protecting sensitive data in transit, which is what most people think of SSL as being all about. And then we'll move on to looking at the risk of sending cookies over insecure connections because a lot of people don't realize how important it is to protect things like AuthCookies. From there, we'll take a look at some risky practices such as loading a login form over HTTP. Many people think that if you post to HTTPS, it doesn't matter that the login form is loaded over HTTP, but that's not the case, and we'll have a look at how we can attack that pattern. Another pattern we'll attack is mixed mode content, which is when we load a page over HTTPS, but then we embed content over HTTP. And finally, we'll finish up with the HTTP strict transport security header, which is also often referred to as HSTS. So, let's jump into understanding those three objectives.

The three objectives of transport layer protection
When we talk about transport layer protection, most people think of it just as encrypting sensitive data in transit, so sensitive data such as a password or a credit card. But it's much more than that, and there's really three objectives we need to consider when we talk about using SSL: Authenticity, integrity, and confidentiality. Each one of these has different objectives, and they add a different value proposition to an application that makes use of SSL and transport layer protection. So, let's take a look at these three objectives in a little bit more detail. When we talk about authenticity, we're trying to get assurance of who we're connecting to. When a certificate is loaded via our website, it allows the user to inspect that and have higher degree of confidence that the website is being served by who we think it is. So, it gives us a guarantee as to the identity of the website. Now, of course, this is all assuming that the certificate authority structure is sound, that there haven't been any attacks against the protocol itself, and as developers in this course, we're going to make the assumption that those things are secure and haven't been breached. There's a whole other world that talks about the integrity of CA's and the underlying certificate mechanisms. Moving onto integrity. This one is really important, and we're going to look at a couple of examples of where integrity is so critical. But really what we're talking about here is can we trust that our requests aren't being manipulated? If we post some data to a webpage, can we be confident that an attacker or a man in the middle hasn't actually changed the content of that request? Now, conversely when the response comes back, can we be confident that the response is legitimate, it is what the server intended to send us, and it hasn't been manipulated somewhere between that web server and our browser? The third point is the one we most frequently associate with transport layer protection, and that's confidentiality. So, when we talk about confidentiality, we're talking about keeping secrets. Can we be confident that when we submit our password to a website somebody isn't eavesdropping and observing it during the transmission? And as with integrity, when a response comes back the other way. So, for example, when our bank account details are loaded. Can we be confident that nobody is able to observe that on the wire or on the wireless as it may be, and that it has actually been kept private? And, again, it's the attribute of transport layer protection which we must commonly think about, but it's not the only one. With those three objectives in mind, let's move on and take a look at what a man in the middle attack is, and then we'll see how transport layer protection does protect us from that risk.

Understanding a man in the middle attack
The whole premise of a man in the middle attack is that an attacker is able to sit in the middle of a conversation. Now, they may just observer that conversation or they may change the content of that conversation. So, there's the integrity piece that we just looked at in the last section. What's important in a web server browser communication is to understand the number of points in which a man in the middle may be able to intercept our communication. So, let's start from the browser. So, let's imagine we're on our PC or our Mac or our smartphone or our tablet, any internet connected device. And, of course, keep in mind as well it may not necessarily be a browser. We could be talking about any HTTP communication such as viral web servers. Regardless, it starts at a device somewhere. In a typical request, that data is then sent through to a router, and very often that will be a wireless access point combination router. Not all traffic goes this way. Obviously we have a lot of wired traffic that goes over internet, and that poses its own risks, but this is just an example of the number of modes involved in an HTTP request. So, let's imagine you're at home. It goes to your router. That request then goes out over the wires. So, it'll normally go out over a telephone line via our DSL. It may go out via cable. Well, sometimes even satellite. The point is that there is infrastructure which takes that request from your home or place of work and then sends it out over external infrastructure. Inevitably that then arrives at an ISP somewhere. So, if we're on a home connection or if we're at a cafe, inevitably there needs to be a service provider which facilitates that internet connectivity. Now, from that service provider, we then send requests out all over the world. Obviously the very nature of the internet is that the destination server could literally be anywhere. So, you're back out over external infrastructure, and through a bunch of nodes, well and truly outside of your control until eventually that request lands at the server in a data center somewhere. Now, of course, all of this may happen in a small number of milliseconds, but regardless, the point is that there's a lot of information flying around the web. There's just the request. Then, of course, there's a response. And we go back out over all of those internet nodes, we go back to the ISP, we go back to the infrastructure between your ISP and your home, back into your router, and finally back into your browser or other internet-connected device. What we need to remember with all of that is that we have all of these different possible points where we could be exposed to a man in the middle attack. Now, of course, the way that you might attack traffic on a wireless network is very different to the way it may be attacked at the ISP. And, of course, the nature of the attackers is probably going to be very different as well. It's very easy to buy cheap consumer hardware to attack traffic on a wireless network, and we will look at that a little bit later too, but an attack at the ISP level normally requires much more sophistication, often government intervention too. And we'll also take a look at an example of that. The point of this though is to establish that there are all these different points where unprotected traffic may be at risk, and ultimately the message is this: If we have traffic where authenticity, integrity or confidentiality is important, we must always make sure it is sent over an HTTPS connection. Any time traffic is sent over HTTP, we must expect that it could be observed or manipulated by an attacker. So, let's jump in and have a look at what that looks like.

Protecting sensitive data in transit
The first demo we're going to do in this course is to simply look at the need to protect sensitive data in transit. So, this is the confidentiality objective of transport layer protection I spoke about just a little bit earlier on. And where I'd like to start is to simply jump over onto the Register page. Now, before I actually register, I'd like to open Fiddler so that we can observe the traffic on the network just as a man in the middle would. So, let me drag Fiddler over onto the screen here, and at this stage there are no requests in the Fiddler timeline. And as we saw in the earlier module about understanding the tools, just keep in mind that Fiddler allows us to observe traffic just like a man in the middle would. So, this could be at the ISP level or at the proxy level. It could be anywhere in that request response pipeline. So, let's jump back over to the browser and register, and then see what we can see in Fiddler. So, let's start with an email address, and we will stick with the F1 theme, and we'll make it alanjones. And we'll have a first name of Alan, last name Jones, and let's give him a simple password. Of course we never really create simple passwords, but it does work for demonstration purposes, and Register. Now, let's jump over to Fiddler and see what our man in the middle was able to observe. When we jump over into Fiddler, we can see that there have been two requests. The first one resulting in an HTTP 302, and the second one in a 200. We'll come back to the second one in a moment, but the first one we can see is a POST request. So, let's take a look at the data it has posted. So, if we go over to WebForms we will see here's the info I've just entered: Email address, first name, last name, and here's Alan's password and password confirmation. So, clearly this is sensitive data. We do not want passwords to ever go over an insecure connection. Not just for the integrity of the site that we're trying to protect, but unfortunately, the prevalence of password reuse means there's a very good chance that our hypothetical Alan has used the same password on other websites. So, rightly or wrongly, as web developers, we do have a bit of an implicit responsibility to protect other web applications due to poor password practices. Now, again, this was an HTTP 302 response, and we can see down at the bottom that there is an object moved here. If we jump over and take a look at the Response Headers, we'll see that one of the response headers is a location, and that is what has caused the second request, which resulted in the HTTP 200. And, of course, that second request, if we have a look at the Headers, is just to the root of the site. There's not actually a path being referenced there. Now, this is a very common pattern. We've submitted a form to the Registration page, the registration process has happened, and then it's redirected us back out to the home page. The key thing though, and we're going to see how this changes on the secure site in a moment, is that we have made a request to the Registration page, which is a POST request with the sensitive data, and we've been able to intercept it. And then after that's been processed, we've had a request back to the home page. Both of those requests are HTTP. As an attacker, we can observe both of them. Let's jump over to that secure app and see how we can fix this. Now, we're over on the secure website. So, we can see that we have secure in the address, and we have the gold bar that are referred to in the introduction module. Let's go and try registering again. And the first thing we'll see is that when we go to the Registration page, it is served securely over HTTPS. Now, that's really important. The other thing that's important is that even if we did accidentally request it over HTTP or had a link somewhere to HTTP, when we hit that address, it redirects us back to HTTPS. So, we simply cannot load the Registration page over HTTP. Let's register again and see where it's going to post. So, we'll register the same account (Typing) Alan, Jones, faster, and faster. And just before we hit that Register button, let's go back to Fiddler, make sure we're capturing requests, and we'll see what we can see this time. Okay, so Fiddler is ready. We'll jump back over to the registration form, let us now register, and now we're back on the home page and back on HTTP. Let's take a look at what happened in Fiddler. So, here's what we see in Fiddler. We just see that HTTP 200 that we talked about earlier on, and if we take a look at the WebForms, there are no form variables in here. And, if fact, if we take a look at the WebView, we will see that what we've got here is just simply the home page because, of course, when we registered, it posted to the registration form and then it did an HTTP 302 redirect. Now, before when we did that on the insecure site, we were able to inspect the POST data, so we actually managed to find Alan's password. This time we posted over HTTPS so Fiddler couldn't intercept that request, and then it redirected to an HTTP website. So, the actual handling of the credentials themselves was sound, and that's really important. So, that's the first demo of transport layer protection done, and it's probably pretty obvious because, again, most people do think about transport layer protection as about being protecting credentials. This is also a really easy way to demonstrate to someone the risk of sending sensitive data over an insecure connection. Let's move on to some other HTTPS anti-patterns that people often don't understand that well and do tend to frequently get roam.

The risk of sending cookies over insecure connections
In the next part of this module, we're going to look at the risk of sending cookies over an insecure connection. And before I actually do the demo, I want to talk a little bit about authentication state and cookies. What we have to remember is that HTTP is a stateless protocol. So, in other words, when we make a series of requests from a browser to a website, there is no persistence of the connection, and that has a number of ramifications. One of those ramifications is that each different requests, for all intents and purposes, is a totally unassociated request to the previous one. So, when we talk about authentication, we need a way to make sure that when I come to a website and make a request and then I make a subsequent request, the website still knows who I am, and this is the role of the authentication cookie or the AuthCookie as we'll often refer to it. Now, let's take a look at what that AuthCookie looks like. So, we'll imagine again we've got a browser, and we've got a server. Now, let's imagine that we log in. So, a pretty simple process. We submit some credentials hopefully over a secure connection. When the server receives those credentials, it authenticates the user. So, it simply makes sure that the username and password are correct and do match the credentials stored in the database. The server then returns a response, and that response includes the auth cookie. Now, we won't go into the detail of an auth cookie structure in this course, but it's important to understand that the auth cookie is a unique cookie. It is only relevant to that one user, and it should be structured in such a way that it can't be forged, i. e. you couldn't just simply create your own auth cookie as another user. And we will have a look at what an auth cookie looks like a little bit later, and you'll see that it is a complex little piece of data. Moving on, we've received that auth cookie in the browser, and now by nature of the way cookies work, any subsequent requests will automatically attach that auth cookie to the request header. What that means is that when the server receives that request, it can now validate the cookie and identify the user. So this is great because it's a very implicit way of identifying the user on each subsequent request. As the developer, you don't need to go through and manually construct any way of re-authenticating. The authenticated state is simply passed back to the server automatically on each request. That's just how cookies work. Now, of course, once that cookie can be validated, the server can return a response, and the whole process will repeat over and over and over. The thing to remember is that every single request to the website is going to pass that cookie. It doesn't matter whether it's a web page or an image or a JavaScript file, that cookie is going to be attached. Now, the really important bit is that cookie is all that is required for the server to validate the request and make an assumption on the identity of the user. So, that cookie is actually a very valuable little piece of information. Let's now take a look at what goes wrong when that cookie is not properly protected. In order to demonstrate the risk of sending auth cookies over an insecure connection, I'm going to start by opening up the resources in the current developer tools and drilling down into the cookies section. And as we'll see at the moment, the site has no cookies. I've deleted them all out. What I want to do now is just jump on over to the Log in page, and you'll see as soon as we do that we get a couple of cookies. So, in this case, we get an ASP. NET_SessionId, and that's simply because the first request to this site begins a session and sets a cookie. We can also see that there's another cookie down here called VisitStart. The purpose of which isn't quite clear at the moment, but it will be a little bit later on. Now, let's log in, and this time I'm going to log in with my own account, and I want to look at what happens to the cookies when we log in. And what we'll see now is that we have a third cookie that is called AuthCookie, and you'll see it's got quite a long random value that we'll look at a little bit closer in just a moment. The important thing for now is that as we browse around the website, that cookie will always be present, and it will automatically be sent with the request. To demonstrate the risk of this, let's jump over to Fiddler and have a look at what a man in the middle might observe when we make a request. So, here we are over in Fiddler. There are no requests at the moment. Everything is clear. Let's jump back to the website and load a page. So, we'll take a look at the GT-R, jump in, and there we go. Now, we are still logged in. It still recognizes me as Troy, so it must obviously have some way of knowing who I am, and again, that's via the auth cookie. If we now jump back over to Fiddler, we can see one request. Now, here's the important bit. This request is obviously an HTTP request, and this request also has the AuthCookie in it. Now, this is extremely important because this AuthCookie is the only thing that allowed the website to actually recognize who I am. If we, as an attacker, can recreate this request with this cookie, we can take on the identity of the victim. Now, because this cookie is a pretty long piece of data, Fiddler actually truncates it when we look in the header view. We can see the ellipses there at the end. So, we're going to need to drop down into Raw view. And once we're down in Raw view, we should be able to see that cookie much, much clearer. So, what we want to do is just grab the value of that AuthCookie, and we'll just copy that guy. Let's now move onto hijacking the session. So, let's grab a new incognito window, and let's jump over to the HackYourselfFirst website. And we'll jump over to the HTTP version. Now, we've started off incognito because when we go incognito the browser doesn't include any cookies that we might have had previously set for the site. So, it effectively erases history. It's just a clean view. And, in fact, to that extent, when we finish this incognito session, none of the history will be retained. The important thing here is we can see that we are not logged in. Now, what I want to do is reconstruct the auth cookie, which I stole as an attacker just a little bit earlier on. So, let's turn on the edit this cookie extension, we'll recreate the cookie, and we'll see if we can hijack the session. So, we'll jump into the Tools, into our Extensions, and we will just show the button for Edit This Cookie again. And let's just jump back over into the incognito session where we are not logged in, and we will now recreate the cookie. And, in fact, we'll see here when we hit Edit This Cookie, we've already got the two cookies there that we saw earlier in the victims session, so we've got that ASP. NET_SessionId, and we've got that VisitStart. Let's now add a new cookie. And if you recall, this one was just simply called AuthCookie. And now we will just paste in the value that we copied before. So, let's also make this a HostOnly cookie, and we will submit the cookie changes. That's it. Now, let's drop back to the browser now keeping in mind that this is our attacker's browser. So, this is the guy who sniffed that cookie off the insecure request. Let's now reload the page. And here is a problem because now the attacker is logged in as me. Just by grabbing that cookie, the attacker has been able to take on my identity. And certainly if we browse around and look at things like my profile, it is my information that is in there. The way we need to think about hijacking a session by stealing an auth cookie is just the same as the victim logging onto a website, then walking away and allowing the attacker to sit down in front of it. It doesn't necessarily give the attacker the password, not unless the website has a way of reflecting that back out whilst you're logged in, but it does allow the attacker to do anything that the victim would be able to do whilst logged in, and that's an extremely serious risk. What it means is that you simply cannot make a request and send an auth cookie over an insecure connection. If you want to serve up content that is only available to an authenticated user, you must do it over HTTPS. It only takes one request as we just saw, and it doesn't even need to be for a web page. It could be for an image or a CSS file or a JavaScript file. That one request is all it takes for the auth cookie to be sent in the clear and for the attacker to grab it and be able to hijack the session. Let's jump over to the secure site and see how this should have been done. Here we are back on the secure site. Let's take a look at how things are handled a little bit differently when it comes to protecting auth cookies. And before I jump into this, let's just make sure that we have Fiddler open and it is logging requests. And at the moment, we have no requests in there, which is just fine. Let's jump back to the secure site, and we will log in. And we're going to log in with the same old credentials, which are mine; same old password; and hit the Log in button. Now, the first thing you'll see is that we are straight into HTTPS. This is an HTTPS web page. The other thing about this page is that everything that is embedded in it, the JavaScript, the CSS, the images are all embedded over HTTPS. If we browse around and take a look at a car such as the Pagani, it is also an HTTPS request. As images are loaded, they are loaded over HTTPS. Even going to things like my profile is HTTPS. Every request we're making with that auth cookie is HTTPS. It's not until we actually log off that we will end up back on an HTTP web page. If we now jump back to Fiddler, we will see only two requests that could be intercepted by the man in the middle, the first request to log in, and if we take a look at the cookies that were available on that request, it's just the ASP. NETSession cookie and the VisitStart, and the only other request we can see is the final request, which was after we logged out. And, again, it's just the same cookies. We can't actually see any of the requests where the cookie was sent in the request header. And this is fundamentally important because it means that a man in the middle simply can't attack that cookie. And this is really the way you need to treat auth cookies. Once it is set, you can never make an HTTP request again whilst that cookie exists in the browser. We'll look at how we can secure this a little bit better when we get to the cookie module a bit later on, but certainly the application needs to be constructed so that you're not inadvertently making HTTP requests when you expect the user to be authenticated. Now, in this case it was pretty simple because once we logged in, all the references to the different pages and the different assets such as the JavaScript and the CSS were all simply relative, so they inherited the same HTTPS scheme when they were embedded. So, that made things very easy. And it was only when we actually logged out there was a reference that expressly included the scheme to HTTP because the website decided we could drop back to a nonsecure connection. That can be a little bit of mucking around, and it can be a bit easy to get wrong as well. And certainly one thing that many sites are doing now is they're simply going HTTPS everywhere. If you take the position that your website only ever needs to serve pages over HTTPS, and of course it's not just pages, remember those images in JavaScript and CSS, but if you take the position that everything is served over HTTPS, it does solve this risk. Now, that's not suitable for every single website, but certainly websites that are very centered around the concept of someone authenticating and then using services that require authorization, HTTPS only is a very easy fix. So, that's auth cookies. But in that demo, even in the secure demo, we still had a little risk. So, let's move on now to the next section in this module and take a look at how loading login forms over HTTP poses an entirely different risk.

How loading login forms over HTTP is risky
Now that we understand the risk of posting sensitive data over an insecure connection, and we also understand the risk of sending cookies over an insecure connection, let's start to move into some of the areas of transport layer protection that are a little less well understood. And one of these areas is the loading of a login form over HTTP even though it might post to HTTPS. Now, the way this pattern looks is let's imagine again that we have a client and we have a server. Now, the client is going to make a request to the server and ask for the login page, and it's going to request it over HTTP. Often we'll see this pattern when there's a login form on every single page. So, it might just be a little username and password box up in the top of the site, and it just appears everywhere you go throughout the site. And obviously you're requesting these pages over HTTP in many cases, so that's a typical pattern that we would observe. Now, of course after requesting the login page over HTTP, the server responds over HTTP. So, now we have the login page loaded over an insecure connection into the browser. Now, when the browser posts back to the server, it posts the credentials over HTTPS, which of course is a secure connection. After those credentials are posted, the server authenticates the user and then naturally sends a response back over HTTPS. So, what it means is that this component down here is secure. That posting of credentials and response from the server goes out over encrypted connection. We can't get a man in the middle into that place of the communication. However, what we can do is get a man in the middle into that first part of the communication, so that insecure request and insecure response. So, this is still vulnerable to an attack. So, what that means to this module is we need to put our attacker hat back on and say hey if we have access just to the login form, what sort of attack could we possibly mount against the victim? Let's take a look at what we can do with that. Now that we've looked at the theory of this loading of the login page over HTTP and posting to HTTPS, let's take a look at what it looks like on our vulnerable website. So, clearly the website has been loaded over HTTP. Let's now jump into that Log in page, and before we actually enter our credentials, I'm going to open up the Chrome developer tools, jump over onto the Network tab, and now let's log on. So, I'm going to enter my usual username and password. Let us now log in. Now, first of all, up in the navigation bar, we can see that I am indeed authenticated. If we have a look at the network requests down here, we can see that the first request is a post to the Login page, and we can see that is indeed a secure address. It is an HTTPS address. Now, yes we can see our credentials in here in the form data, but of course we're looking at this in the browser's tools. The browser knows what the password is. The reality of it is that something like Fiddler can't get this password from that request because it goes out over an HTTPS connection. So, what this means is that we have to now find a way to attack the login form itself simply because we can't attack the post that the login form makes back to the server. And to do that, we're going to go into Fiddler and use a bit of Fiddler script. In the module at the start of this course about understanding the tools, we looked at some of the roles Fiddler can play when we're assessing web application security. And one of the things we looked at is the ability for Fiddler to manipulate both the request and the response. So, for example, it could change the path that the browser had actually requested, or on the other side when the response comes back, it could change the body of the response. When we use Fiddler as a proxy, it gives us the ability to mount these sort of attacks. And, of course, this is just the same sort of attacks that a man in the middle at any one of those points in the network communication that we looked at earlier could potentially mount. So, what we're going to do for this exercise is jump over to the FiddlerScript tab. And what we want to do is modify the OnBeforeResponse event. So, this is after the server has responded, but before it makes its way back to the browser. Let's just jump down to the end of this event, and I'm going to paste in some code which I have in the clipboard. Let's now run through this code and take a look at what is going to happen. Now, the first thing is we only want to modify certain requests. And in this case, we only want to modify requests where the host name is hackyourselffirst. troyhunt. com, so we're going to get the domain right. And the other criteria that we want to apply is we want the PathAndQuery to be /Account/Login. This is the only request we're going to modify. Let's now jump into this script. So, the first thing is as the comment says remove any compression or chunking. We're then going to get the response bytes and read that into a variable. And now the important bit happens. We are going to inject a keylogger into the page. Now, this is not a keylogger as many people think of it in terms of it being say malware that actually runs on someone's computer. This is going to be a JavaScript keylogger. And we'll take a look at what's inside that script just a little bit later on. For now though, let's just focus on getting this JavaScript keylogger injected into the page. And the way we're going to do that is we're simply going to replace the closing body tag. And we're doing this because we want to put it right there on the end of the page. And we're going to inject some script. Now, what this script is going to do is it's going to call an external resource, and it's from the attacker domain. So, this is the first time we're seeing this attacker website in use that we spoke about at the start of this course. What we're going to embed from that attacker website is a path called Scripts and then a recourse called keylogger. js. So, again, this is going to be a JavaScript keylogger. Alright, so that will embed the external script. Now, the next thing that's going to happen is we are going to put a script block on the page, and in that script block we're going to set a destination variable. That destination variable is going to be the same attacker domain, and then it's going to call a path of Keylogger, and it's going to pass a variable called K. And you can see here we haven't actually assigned to anything yet. That will happen automatically. And, again, we will look at the way the script works a little bit later. Close off the script block, close off the body block because, again, we're doing a replace of the original closing body element, and that will do it. And then the very last thing that happens in the script is the response body is set. So, that's all it is. Now, that's very simple, and it's going to mean that every time we load that Log in page over an insecure connection, we're going to inject a keylogger. Now, again, the most critical part of this is to remember that an attacker can do this at any point in an insecure communication. This is not just about using Fiddler on someone's PC, which as an attacker you usually cannot do. This is about attacking and manipulating the integrity of an insecure request, which is that login form loaded over HTTP. Now, there's just one more thing we'll do before we go back to the browser, and that is to save the script. Okay, that is done. Let's jump over to the browser and see what we can see. So, we're back in the browser, and I have logged us out because we do want to try and test that Log in page again. So, let's jump over there now. And before we start logging in, let's take a look at the source code. And we'll jump straight down to the bottom, and here we see our keylogger has now been injected. So, this has been popped in by Fiddler because we've been able to attack the proxy level. And this is precisely what we just entered in that Fiddler script. When we take a look at the keylogger, which is now going to be activated on this page, we'll see that it's just a relatively simple little piece of JavaScript. In fact, this is available over on Google Code via the author mentioned at the top of the page. Now, all that this script is going to do is attach an event to each form element on the page. And what that event is going to do is on keypress, it's going to take the name of the field, and it's also going to give us another unique ID, and it's going to send it off to that path, which we injected into the script block. So, that's the path that we see down here. So, what it means is that every time the victim types a key on the page with the script logger, the attacker's site is going to have that key sent to it. Let's have a look at what that looks like now. So, we'll close the HTML source. And now before we start typing, let's resize both the browser and we'll resize Fiddler because I'd like to be able to show these requests as they come though. There are a couple of requests from the attacker's site when we loaded that script. So, let's just remove those guys. Now, let's start typing. So, as I start to type my email address, we can see in Fiddler each request is starting to be captured. So, clearly this keylogger is now doing its job. And, of course, the page looks just the same to us. We don't know that it's got a keylogger on it as a victim, and indeed it's only been possible because that page was loaded insecurely. Okay, so that is my username and password. Let's take a look at these requests, which we just sent off to the attacker's site. And they're very, very simple. So, if we take the first request, jump over to the Inspector, all we need to do is look at the request path, and we can see here the first key was a T. The field it was entered into is the email address, and then we've got a unique number off the back of that in order to identify this particular session, or in other words, this user. Now, the attacker needs this so that it can join the right keys to the right user. Now, in fact, if we look down under the URL column, we'll see all of those keys. So, those 28 requests are enough to make up my email address, troyhunt@hotmail. com, and then under that you'll see my password, password with a 0. So, in fact, the attacker has got everything they now need in order to log on as me. I haven't even clicked the submit button yet, which as we know would send the password across a secure connection anyway, but the attacker already has it. If we go and look at the response from one of these requests, so this is what the attacker's server is sending back to us, you'll see that it's recorded a bit of information and just reflected it in the response. So, we can see the Referrer so it knows where to go to use the key that was pressed; the key; the field it was entered in; and, again, that unique ID. So, this attacker is building up a little treasure trove of data it can now use to attack accounts. So, that's how easy it is when a login form is loaded over an HTTP address. Let's now go and take a look at how the secure site implements a login form. So, here we are back on the secure site, and this time it is being configured to make sure that the Log in page itself is always secure. Now, what that looks like is very simple. We are on an HTTP page at the moment. There's no HTTPS in the address. When we go to the Log in page, it is served securely over an HTTPS connection. Of course, it still posts to HTTPS as well. The important thing is though that an attacker cannot manipulate this page that we're looking at now. Now, of course, we can still go to other pages and request them over HTTP. We can go to the Leaderboard for example, but when we go back to log in, we always need to make sure that page loads over HTTPS. Back to the Supercar Showdown page, and it's back to HTTP again. Now, I've just been running Fiddler whilst I've done that activity, and if we take a look at Fiddler now, we can see that there are only two requests. So, all we're seeing is the request to the Leaderboard page and the request to the home page. We loaded the Log in page twice within that communication, but Fiddler couldn't capture it. So, again, what this means is that for a man in the middle, not only can they not observe that traffic, but they can't manipulate it. So, they can't inject the keylogger back into that Log in page. Jumping back to the secure site for a moment, one other thing that we need to remember is that it must be impossible to load that Log in page over HTTP at all. And this is simply because sometimes you do end up with hard-coded references from external sources such as Google through to the HTTP address. So, it may be that over time the security position has evolved, the page is now a safer place to be, it's only available over HTTPS, or at least it should only be available over HTTPS. We want to make sure it can't be requested over HTTP at all. So, just to demonstrate that, let's open up the developer tools. We're on the Network tab. Let's now change that HTTPS address just to only be HTTP and see what happens. So, we've got a bunch of requests down there in the developer tools, and we'll look at those in just a moment. The main thing is that we're still over here on HTTPS. Now, the reason is simply that when we go to the first request in the developer tools, we can see that Login resulted in an HTTP 302, and we can see that obviously the requested URL was HTTP. But if we scroll down a little bit, we will see that the server responded with the Location header and told us to go to HTTPS. So, even though we attempted to load that Log in page over an insecure connection, the server said no. We're not going to let you have it insecurely. Go over there and get the secure version. I'd like to show you a precedent, which demonstrates why this is so important. And for that, we're going to jump over to the US Social Security Administration. Okay, so here we are on a US government website, and clearly this the department responsible for managing that very sensitive piece of data, which is the social security number of American citizens. One thing that this website allows you to do is report fraud or ID theft. Now, when we drill down into this link, we have another link that goes off to submit a report. Now, before I go there, we can see at the moment that we are on an HTTP page. So, this page and the previous page were served insecurely. And that's just fine because they don't really have data of any sensitivity on them. Let's go and submit a report though. Now, when we go to submit a report, we can see that we now have an HTTPS address. Now, this site does actually have another little problem, which is why we have a gold triangle on the padlock, but we'll come back to this in the next section of this module. The main thing is that the intention is clearly to load this page over a secure connection. And when you have a look at the content on the page, you can understand why. We've got a lot of very sensitive information on this page including things like your social security number. Now, keep in mind that this is a site for victims of social security fraud possibly via using insecure website in order to report that fraud to the US government. So, clearly these are people in a vulnerable situation. Let me show you the problem though with the way this form loads. And the problem is evident once we search for report social security fraud. So, obviously this is just a simple Google search. A little down the page here we have a link to that same website we were just on. So, let's load that form, and now you can see the problem. This is the same form we were just looking at asking for information such as a social security number, but it's served over an insecure address. This is not an HTTPS address. Inevitably it is exactly the same resource, but it is no longer secure. So, this is why it's so essential to validate that the page has indeed been loaded over a secure connection. You can't just trust that all the links coming into it are HTTPS links. So, the bottom line in a case like this is that we are now vulnerable to a man in the middle attack, and, of course, we've now seen just how easy that can be. But rather than just stop at hypothetical examples of a man in the middle manipulating a form, let me show you one more real world example, which should really bring the risk of this home. Here's a really good example of where an attacker targeting a login form can happen, and also at what point in the communication it can happen. This was reported in 2011 during a time of a lot of political uprising in Tunisia. And what eventuated in Tunisia was that first of all the government owns and controls the ISP's. So, they control a component of the network communication. What they're able to do with that is inject JavaScript to capture the usernames and passwords of citizens loading websites such as Gmail, Yahoo, and Facebook. And at the time, these three regularly loaded login pages over HTTP. What it meant is because the government wanted to eavesdrop on their citizens, it was extremely easy to capture their credentials. Since that time, things have changed quite a bit for these three, and they do now usually serve login pages over HTTPS, albeit with some exceptions such as some of the embedded logins on mobile device apps. But what it showed us is the ease and indeed prevalence with which this can happen. I thought this was a good way to finish this section of the module because it does give us a real world view of how a man in the middle is attacking insecure traffic, not just eavesdropping on insecure traffic, but actually manipulating insecure traffic. So, this is a perfect example of just how valuable transport layer protectin is.

Exploiting mixed-mode content
The next thing I'd like to look at in this module is mixed mode content. And to explain what I mean by that, let's take a typical web page. Now, when we load a page, obviously it has a bunch of HTML and possibly it has some CSS and JavaScript in the source code of that request, but the page then embeds all these other external assets. So, CSS images, JavaScript, sometimes a Favicon, sometimes some fonts, and then maybe even some media such as some embedded video. All of these things go together to make up what we see in the browser as one holistic web page. But here's the thing when it comes to security. You must load all of those assets securely if the page is to be secure. Now, what I mean by that is if you load the page over an HTTPS address, but then you embed an image over an HTTP address, then you as the user can have no confidence that the HTTP request, the image, hasn't been manipulated. So, when that image lands on the page, it could be an image that has been injected by an attacker rather than the original image from the website. Now, the extent of damage you could do with that will really depend on the nature of the site and how creative an attacker can get with the image. So, for example, maybe they could change some of the claims that are made on the website. Maybe they could change the dimensions, and if they're not constrained by the HTML on the website, it could make things go a little bit crazy. Not too serious. However, if you embed JavaScript over an HTTP connection, now you're starting to get into the realm of more serious risks simply because there's so much that you can do with JavaScript. Have a think about it. If you could embed any JavaScript you like in a web page, what could you do? Let's take a look at an example of this on our insecure website. Here we are back on the website, and you can see that I am presently logged in. As a result of being logged in, I have access to my account. And what I'd like to do is go and take a look at the Change Password page. Now, when this page loads, you'll see something very subtly different in the browser, and that is we have this little shield up in the top right hand corner in the address bar. And as we can see, this page includes scripts from unauthenticated sources. Now, if we click on the shield, we will get the ability to load unsafe script. And what this means is that the browser has actually decided not to load the script. Let's take a look at the source code, and we will see why. If we jump right down to the end of the page, we will see that there is an HTTP embedded script, and it's just come off the Google CDN here, and its loading prototype. js. Now, this is a problem simply because that HTTP request cannot be trusted, and as a result, it's jeopardizing the integrity of the entire page. So, in order to protect us, Google Chrome has decided not to load it. Let's jump back to Chrome, turn on the developer tools on the Network tab, and we'll reload this page again. And, in fact, what we can see here is that indeed there are no requests from Google Chrome to prototype. js. So, Chrome has saved ourselves from this risk. Now, the really important thing to note here is that this is the browser implementing its own security defense. Different browsers, different versions will behave differently when the risk of mixed content is present. Sometimes it will load it anyway. Sometimes you'll have a very subtle warning like the shield. Sometimes you'll have something more avert like the gold triangle we saw earlier on the social security website. Sometimes, such as in earlier versions of Internet Explorer, we'll even get an alert on the page and a prompt in order to load it. So, browsers behave very differently depending on the make and depending on the version. For us as developers though, we have to make sure that we never do this because whichever way you look at it, something bad happens. So, either the user gets a warning and says hey this page is trying to load insecure content, and let's face it, we never want to give our users nasty security warnings. It's highly likely the content won't load at all. And particularly in a case like JavaScript, that might actually break functionality on the page. And then if it does load, then you've just opened yourself up to this man in the middle attack. So, none of those options are real nice. Let's just load that JavaScript, and we'll make sure that Chrome is able to load it into the browser. And if we scroll up a little bit in the developer tools, we should see that loaded just here. As soon as we load that insecure content, you'll see that the padlock icon and the HTTPS scheme in the address bar both get great big red crosses through them. It's almost shouting at us this is no longer a secure page. You cannot trust it. And really our only option was that we were in the position that we were in before where the page was actually broken because it couldn't load a piece of functional script or in we're in the position now where the page is insecure and we're getting great big red warnings. Neither of those is real pretty. Let's now take a look at how a man in the middle might attack that, and once again embed a keylogger. And to do that, we're going to jump back over into Fiddler again. So, we're back over in Fiddler, and now we're going to do a very similar thing to what we did in the last exercise where we attacked the insecure Log in page. This time we're going to jump back over to FiddlerScript again, we are going to go down to the OnBeforeResponse event just like we did with the insecure Log in page, and also like last time, I'm going to paste from the clipboard a piece of pre-prepared script. Now, what's going to change this time is that we're going to reference the host that is the Google CDN. Of course, it doesn't matter what the host is. So long as it's making an insecure connection, we can manipulate that traffic. And, of course, the PathAndQuery is going to be a little bit different because we're looking for the prototype. js library. The only other thing that's really different to last time is the response body. And this time we're just going to overwrite the entire body rather than append it. Now, because we're overwriting JavaScript, syntactically we need to be a little bit different if we were injecting into HTML. So, what we're going to do is we're going to call the jQuery getScript method, and this site already embeds jQuery like so many other sites, which actually makes it easier for us as an attacker as well. And then we're going to scroll over a little bit and embed that same keylogger. js script that we did last time, also from the attacker side. And also like last time, we're going to set a destination variable, which is where we want the keypresses sent. And, again, it's going to be the attacker's website, Keylogger path, and it's going to pass a parameter called K. Let's save that script, and now we'll jump back over into the browser and see if we can capture those keypresses. Okay, so back over in the browser, and let's jump on over to the Change Password page again. And like last time, we are going to just resize this page a little bit so that we can Fiddler underneath. Let's just give this page a hard Refresh as well just to make sure that it does actually load that script across the proxy and doesn't just pull it from cache. We want to make sure that keylogger is injected. Let's clear the results on the page here, and we will just start entering our password again. And as per last time, we are starting to get keys logged out across the wire. So, effectively this is really the same attack as last time when we injected script into that insecure Log in page, it's just a different vector this time. We're going in through the JavaScript this time. It's the same end result though. We have managed to compromise this web page due to loading insecure content. So, even though we can see HTTPS in the address bar, albeit with a big red cross in it now, this page is insecure by virtue of loading content from an external resource over HTTP. Let's take a look at how the secure site approaches this. Okay, now we are back on the secure site again. Let's go over and take a look at the Change Password page. Now, of course, the first thing that we're going to see here is that there is no more warning shield up in top right hand corner of the browser. Our HTTPS is green, our padlock is green, there are no red crosses, so this page has loaded securely. Now, it's probably pretty obvious now, but the main thing is that when we embed that prototype. js file, we need to embed it over HTTPS. What may not be as obvious though is that there are a couple of different ways of doing that. Now, the obvious one would be to simply reference the script via the HTTPS scheme, so actually embed it as https://domain and path. Let's take a look at the source code though, and I'll show you what I've done with this particular site. And what you'll see here is what we refer to as a protocol relative URL. So, this embed script actually starts with a forward slash forward slash. There's no HTTP. There's no HTTPS. In fact, there's no scheme at all. Now, this is quite clever because what it means is that if the parent page is loaded over HTTP, the protocol relative URL will pull the script from Google's domain over HTTP. Conversely, if it's loaded over HTTPS, it will apply that scheme to the request to Google's domain. So, this is kind of having your cake and eating it too. It's giving you the ability to make an HTTP request when it doesn't need to be secure, but automatically switching over to a secure request when it does need to be secure. So, protocol relative URL's are a really neat way of embedding external resources from other domains, but ensuring they load securely when they need to.

The HSTS header
One of the problems we saw earlier on is that all it takes is just one little HTTP request with the auth cookie and a man in the middle can gain access to it and hijack the session. It's extremely simple to do if not every request to the site is made over HTTPS. There is a mitigation though that helps us with this, and it's HTTP Strict Transport Security or HSTS for short. And what HSTS helps us do is enforce requests from the browser to only be made over secure connections under certain conditions. Let's take a look at what that looks like, but first, let's just quickly recap on the problem we're trying to address. So, we are presently logged onto the site under the HTTPS scheme. Let's now jump over to the Leaderboard. It's still a secure protocol, so our auth cookies are being protected, and, of course, they're our auth cookies because we can see that it says Hello Troy in the nav bar, so we are actually logged on. And, of course, judging by the gold bar, this is one of the sites we have secured. In fact, it's the one we secured a little bit earlier on when we looked at those auth cookies. So, as we continue to click around, let's say into the GT-R, we will see that it is a secure request, and, of course, the auth cookie is still being protected. Let's jump in and have a look at the source code and take a look at the CSS file. And what we're trying to demonstrate here is that it can just be one really, really little request that brings us undone, and then we'll look at how HSTS will fix that. So, clearly this CSS file has been loaded securely. That's just great. Let's turn on the developer tools, and let's try and load this file insecurely. And if we now go down and take a look at the request, we can see that it is indeed an HTTP request, and unfortunately we can also see that our AuthCookie has been included. So, again, it only takes one little request. It didn't have to be a CSS file. It could've been an image. It could've been a link to say the terms and conditions page or an about us or a contact or something fairly mundane. But because it was an HTTP request, the AuthCookie was sent, and we opened ourselves up to a man in the middle attack. I'm now going to go and turn on the HSTS header for this website across secure connections. Let's have a look at how it changes the behavior. Now, we're back on the home page. We're not logged in. It's perfectly okay to show this page over HTTP. Let's now go over to the Log in page, which, of course, is now over HTTPS, and we'll have a look at this HSTS header and what it means. So, under the Log in page, it is an HTTPS request. What I want to look at though is a slight difference in the response headers. So, we'll go down to the developer tools, give that a little Refresh, and let's look at the first request. Now, when we scroll down in the Headers, we will see that we have a new header, and it's this Strict-Transport Security header, and we can see there is a value. There is a max-age that has been set to 1440. This is in minutes, so this is a period of one day. And what it means is that Chrome can no longer issue HTTP requests to this website for the next day. If we attempt to do that, it will convert it to an HTTPS request. Let's have a look at what that looks like by doing the same exercises we did with the CSS file before. So, we'll jump into the source of the page, we'll load the CSS securely over HTTPS, turn on the developer tools, now let's change that scheme to HTTP, press Enter, and here we can see HSTS at work. So, the first thing is the address bar still says HTTPS, so clearly the resource hasn't been loaded over HTTP. When we look at the request down on the Network tab, we will actually see two requests. We'll see the first request to site. css, and the status here is pending. Now, this is important because it means it hasn't actually issued that request. What's actually happened is if we go to the second request, we can see that it resulted in an HTTP 200, and we can see that the Initiator was actually the first request to the insecure scheme. So what Chrome has done is said hey you have an HSTS header that says you are not allowed to issue HTTP requests to this domain, at least not within that expiration period, within that one day period. Instead, we're going to convert your request into a HTTPS request, and consequently it has issued it securely. And it's fine to then go and issue this request with cookies because we know that cookies will be secure. Now, HSTS is both powerful and kind of incomplete. It's powerful in so far as a developer you can elect to issue that header based on your own set of conditions. It will only work if it's issued over HTTPS, so you've got to have an HTTPS request. So, what you might do, for example, is wait until there is actually something to protect before issuing that HSTS header. So, you might actually issue it in the response from the login rather than issuing it in the response for the Log in page as I just did because ultimately this is primarily to protect the cookies that are sent in the request. Of course, it also ensures that we can't accidentally load any other content on the web page over HTTP, but if you really wanted to do that across the board and not allow any HTTP under any other circumstances, there are other approaches to ensuring that happens. Of course, the HSTS header will protect the user even if they manually put in HTTP and the site redirects because that first manual HTTP request is still at risk of a man in the middle attack. Unfortunately where HSTS is a bit deficient is in the browsers that implement it. Whilst it's fully implemented by Chrome and Firefox, it is not implemented in the current generations of Internet Explorer and Safari. So, Internet Explorer 10 does not implement an HSTS header, nor is it implemented in any of the Safari browsers of the same generation. Now, this doesn't mean that you shouldn't use the HSTS header. It just means the support for it isn't real great. It'll protect crime in Firefox users, but it'll do nothing for Internet Explorer and Safari users. It won't do any harm, but it won't offer them any benefit. So, ultimately HSTS is another good little layer of defense. It's certainly not a panacea by any means, but as we talked about in the introduction, security is very much about applying defense in depth, so placing multiple layers of protection against risks so that if one or two of those layers are breached. So, for example, a request is inadvertently made for HTTP, there are still backup layers of defense. So, use it, but just don't rely solely on it.

Summary
Let's briefly summarize the module. And the first thing we looked at in this module on transport layer protection was to understand that SSL is about more than just encryption, so we looked at three things. Authenticity. Do we know who we're connecting to? Integrity. Can we be confident that the content of the material that we're either sending or requesting hasn't been manipulated? And confidentiality. Are we confident that the content hasn't been eavesdropped on by a third party? We then moved on to looking at a man in the middle attack. And the main thing here was just to understand how many points there are in the network communication where an attacker can possibly get in the middle of insecure communication, anything from wireless networks to routers to proxies to providers and anywhere else in between. And later on we saw a real world example of where this had actually happened at the ISP level in Tunisia. So, it's important to recognize that man in the middle attacks do happen. Of course, this is the very reason why we implement transport layer protection in the first place. So, if we're going to do it, we might as well do it properly. That means not sending any sensitive cookies over HTTP and keeping in mind that it's not just about does the cookie contain data of a sensitive nature, but could it be used to perform a malicious activity such as hijacking the session like it can with an auth cookie? We also looked at how it's important to secure the end-to-end process of the login. So, not just submitting the credentials, but actually loading the login form. We don't want an attacker to be able to manipulate that login form because there are attack vectors that they can use to then gain credentials. And, again, that did actually happen in Tunisia, so it's a real world risk. We moved on to looking at the risk of mixed mode where we actually had JavaScript loaded insecurely into an otherwise secure page. The very fact that happened allowed us to compromise the integrity of the entire page and steal credentials. And finally, we looked at the HTTP Strict Transport Security header and discussed how it could be used as an additional safety net to ensure that once an HTTPS session began, all subsequent requests were HTTPS. It's a great little feature, but unfortunately the support is not real good. It works in Chrome and Firefox. It really doesn't work anywhere else. It's still good to use it in a situation where you want to keep someone on a secure connection, but it does leave a bit of a gap, particularly on Internet Explorer and Safari. But as with all things security, it's one of these defense in depth concepts. Let's keep wrapping as much security as we can around each element of our system, and then if one or two bits do become compromised, we've got some backups. And that's a concept we'll continue to talk about in the upcoming modules.

Cross Site Scripting (XSS)
Introduction
Hi. This is Troy Hunt, and in this module we are going to look at the risk of cross site scripting, which we'll also often refer to as XSS. In this module, we're going to begin by understanding the concept of untrusted data and sanitization. So, we'll define what untrusted data is, look at some of the places it comes from, and then look at some of the typical practices used to sanitize potentially malicious content originating from outside the system. We'll then go and take a look at our vulnerable app and try and draw some conclusions about what sanitization practices are being used, and we're going to need this information in order to then go and exploit risks in the application. Once we understand that, we can start looking at what XSS itself is and delve into the concept of output encoding, and particularly output encoding for different contexts, which is something that people often get wrong when mitigating against the risk of XSS. With that knowledge in hand, we'll then move on to actually identifying how output encoding is used in the vulnerable app, and we'll find there are a couple of different contexts where our untrusted data is reflected. Now that we understand all that, we can move on to actually creating a malicious payload and delivering it via reflected XSS, and then also looking at where a risk of persistent XSS might exist. And finally, we'll round out the module by looking at the X-XSS-Protection header used by Internet Explorer and talk a little bit about native browser defenses. So, that's what's coming up. Let's jump into understanding the concepts of untrusted data and sanitization.

Understanding untrusted data and sanitisation
Untrusted data is a very important concept in security, and it's something we touch on when looking at a number of different risks, which depend on information provided externally to the system frequently from the user. And when we talk about untrusted data, we're talking about a few different key attributes. So, one is that the integrity is not verifiable. It has been sourced from outside the system. We don't necessarily have confidence that it hasn't been manipulated in some way outside what the system would normally expect, and that may have happened organically via the user's browser. It may have happened by a man in the middle. There are various ways where the integrity may have been modified. The other thing we've got to expect is that the intent may be malicious. We need to expect that every single piece of data coming into the system could have an evil intention. Now, of course, once a piece of data contains a malicious payload, it may have an objective such as executing a SQL injection attack, which we'll look at a little bit later on. Obviously cross site scripting, which we're looking at now. It may even be that it's a binary containing some malware. Everything you see there is untrusted data. So, we as the developer need to expect that it may be provided to the system in order to do evil, and we need to protect against that potential risk. Let's have a look at some of the places that untrusted data can come from, and the obvious one is from the user. So, how does a user provide untrusted data to a system? Well, the first thing is there's the query string or any other attribute of the URL. It's easy for a user to change the URL, to manipulate parameters in a URL, and that's something we'll also look at in more detail later on in the parameter tampering module. Of course, the other channel where untrusted data frequently comes from the user if via form data in a post request. So, they fill out fields on a web page, click submit. We can't trust that data. We must expect that could be malicious because ultimately it is untrusted. Another source of untrusted data is from the browser. So, even the most legitimate of requests from the user still causes the browser to send particular pieces of data along with the request. So, for example, in the cookies. So, we must expect that the cookies could be manipulated. It's very easy to simply reconstruct a request and manipulate the cookies. And particularly later on as we start looking at how we can use the composer feature of Fiddler, you'll see just how easy that is. There are also other attributes to the request header. So, for example, the user agent. Every time the browser hits a web page, it sends the identity of the browser, the version of the operating system, and other related information in the request header. That can be manipulated by an attacker. So, if, for example, the application has a SQL injection risk, when it looks at the language used in the browser, which is part of the request header, an attacker could exploit that by manipulating the value of that language header in order to deliver a malicious payload, and they might do that in a tool such as Fiddler. And finally, there are bunch of other locations untrusted data can come from. So, for example, if you consume an external web service. That is a source of untrusted data, and you need to make the assumption that there could be malicious payload in that data, not necessarily because the system you're consuming it from is trying to do evil, but what happens if it gets compromised? And to that effect, your own database could have untrusted data. If you accept untrusted data from a user via a form input and then store it in your system, your system now has untrusted data in it. And this is one of the things we'll look at when we look at the persistent XSS risk in this module. The last thing we'll look at before moving onto the vulnerable application itself is the concept of input sanitization. And what we're talking about here is the system saying hey I'm receiving untrusted data from a user. I'm going to apply some filer criteria to what I thing is acceptable and what is not acceptable. If I get something which is not acceptable, then I'm going to throw an exception or reject the request or take some other sort of defensive action in order to try and protect myself from a potentially malicious attack. So, as an example, you will often find systems rejecting characters such as angle brackets, single quotes, forward slashes, double quotes, backslashes, semicolons. You've probably seen it before where you go and enter one of these characters into a field and have it rejected. That is input sanitization, and there are a couple of different approaches a developer can take to implementing sanitization. And the first approach is to be very specific about what you want to reject, so this is what we would call a blacklist approach where the system is saying hey these are characters I do not trust. Or conversely, anything that is not these characters must be okay. Now, that's a very simple approach, but it's also pretty rudimentary, and it also has some holes in it. It's very easy for that approach to be incomplete, and we're going to see an example of that in this module. One of the problems, of course, is that you may know or you may think you know what a bad character is today, but if a new attack vector is discovered tomorrow, your system may still be at risk. A far more explicit way of implementing sanitization is to use what we would refer to as a whitelist, and a whitelist is effectively the inverse of a blacklist where we say these are the characters that we know are good. This is what we trust. Anything else we're going to reject. Now, this is much more comprehensive because if there are things that are potentially bad that we don't yet know are bad, so long as they're not part of that whitelist, we're going to be pretty safe. So, there are various different ways we'd implement whitelist depending on the type of data. So, an email address, for example, is very easy to implement a whitelist against. There's a spec for email. There's a regular expression that can be written to validate the email. That's an easy one. We don't have to explicitly say an email address can never contain say a single quote. Instead, the whitelist will talk about things like allowable characters and the inclusion of an at symbol and other attributes that make up a well-formed email address. It's a little harder with things like names, but there are still regular expressions that allow common language characters. Of course, there are always edge cases, and it does get more difficult when you start talking about multi-byte character languages and some punctuation, but you can usually get a whitelist, which is pretty comprehensive and keeps out the typical characters that are used in a text such as cross site scripting and SQL injection. Let's move onto the application and take a look at how we can establish what sort of sanitization practices are being used simply by submitting data via the browser.

Establishing input sanitisation practices
Now that we've covered the concepts of untrusted data and also sanitization of untrusted data, let's start to take a look at where we might have incidents of sanitization within the application. And what we want to do is actually look at where we might have gaps in the sanitization process. Now, normally this is something which you would do at each point where untrusted data enters the system. What we're going to do today is just focus on the Search feature, and let's begin by doing a legitimate search. So, in this case, I'm just going to search for Ferrari, and we get one result, which is just fine. One thing to note here is that you'll see the searchTerm as part of the query string in the URL, so it's actually being sent from the Search box as a get request rather than a post. Now, this is pretty common. You'll see this same pattern in search engines like Google, and it's simply because it means that we can take this URL, pass it around to other people, and the content is still valid. That search term is still part of the URL. The reason why this is important whilst we're looking at XSS is that the easiest way to execute a reflected XSS attack is by manipulating parameters in the query string. And this is exactly what we're going to do as we start to work through the module. We're simply going to change the query string. What I want to do now is start to look at what sort of characters the Search feature may sanitize, or, in other words, reject and not allow through for further processing. And because we're talking about XSS and we're going to start to look at how markup plays a role in untrusted data, what I'm going to do is after Ferrari, I'm just going to put in an italics tag. And let's put in enzo, and we'll close off that italics tag. So, now we've got a couple of angle brackets, both less than and greater than, as well as a forward slash. So, let's try that search again. Okay, so what we can see now is that we do have an error. So, clearly the Search feature has rejected the term. There is something about that structure that it does not like. So, what we want to do now is start looking around at what that might be. So, let's just jump back one step, and we'll try this again. And this time what we'll do is we might just leave out the forward slash, so everything else can be the same. We'll just put in enzo. And then obviously this is not particularly valid HTML markup, but let's see if we can get through this time. And again, we're rejected. So, clearly it's not just the forward slash, if at all, which is causing the search term to be rejected. So, let's just try one more option. And this time what we will do is we might just drop out that less than angle bracket altogether. So, we'll try enzo, and we'll forget the less than angle bracket on the closing tag, but then we will put in the greater than angle bracket, and we'll do one more search. Okay, so this time we can see that the search has gone through. So, it appears to be a case of sanitization only of the left angle bracket. Now, this may sound a little bit odd, but this happens. It's common. And, in fact, I wrote about a case using exactly this pattern very recently. So, it is a very real world example. Why would only a less than angle bracket be omitted and not say the greater than angle bracket or the forward slash? It could simply be that the developer thought well, once we can't use a less than a angle bracket, you can't create a tag anymore, so therefore that's all we need to exclude to make the application safe. But as we'll see over the course of this module, that is not the case. Now one of the things we spoke about when we looked at untrusted data and sanitization was blacklist versus whitelist. And one thing that's probably pretty clear in a case like this is in a search term there really isn't a use case for using angle brackets and probably not a use case for using forward slashes. So, this may be one of those cases where really what the search term needs is a regular expression, which just allows natural language characters and punctuation. Certainly the idea of very selectively blacklisting just a small number of characters looks like a risky proposition. When you see this as someone testing the risks within an application, it starts to make you wonder how can I use the remaining characters to attack the application? Maybe I can't create an opening tag, but could I possibly create an HTML attribute or could I possibly pass through a piece of JavaScript? And that's what we're going to look at as we progress through this module.

Understanding XSS and output encoding
Let's now take a bit of a look at how untrusted data can be reflected in a user interface and how that poses a potential cross site scripting risk. And to begin with, let's look at a typical request with some untrusted data. So, the user makes an HTTP request in their browser for a resource on the web server, and it passes with it a piece of untrusted data. Now, normally for a user to pass untrusted data, it's probably going to be in the query string or in form data in a post request. Either way, the server then responds. And when that server responds, the data is reflected in the response. This is a common pattern in features such as a search feature where you might search for say Ferrari, and when the response comes back, just like it did in the demo before, it will say you searched for Ferrari. So, that is reflecting the untrusted data. What it tells us when we're looking for risks in an application is that the website is taking our data and it's putting it into the markup somewhere, and this says that there may be an opportunity to exploit an XSS risk. So, let's take a look at how we might identify the presence of a risk. Alright, so this is pretty much what we did before. We executed a search; that search passed through a parameter, which was Ferrari; and it passed through that parameter in the query string. After we did the search, it was reflected back to us in the markup. So, this is a very typical example of what it might look like. So, what we're actually looking at is a combination of hard-coded text on the page, which is the you searched for; some markup, which is the strong tag; and the data we provided, which is the search term or the Ferrari text. What we need to keep in mind is that we have two different kinds of data here. First of all, the trusted data. So, think back to the explanation in the start of this module. Trusted data has sound integrity, it doesn't have malicious intent, and its data that we really have control over. So, obviously we have control over the domain name, we have control over the search feature, and we also have control over that text you searched for and the strong tag because that's what we have hard- coded into the page as an application developer. That's not dynamic. That's always going to read the same regardless of what the user does. The interesting bit though is the untrusted data. So, in that query string, the word Ferrari is untrusted. That can be manipulated, and that will consequently change the Ferrari text in the markup. This is our untrusted data, and it's the untrusted data that we want to exploit in an XSS attack. So, let's look at what exploiting this data might look like. What we're looking at now is a slight variation of what we saw on the last slide. We're still searching for Ferrari, but now we've got enzo in italics tags. Now, that's the demo we did a little bit earlier on in this module. The way that might manifest itself as a cross site scripting risk though is when it appears in the markup like what we see here. So, when I say markup, this is in the HTML source code of the page. Now, the reason why this demonstrates a cross site scripting risk is that what this markup is actually doing is it is functionally changing the structure of the page. In that what this will do when it renders in the browser is it will make the enzo text appear in italics. Now, this is very important because effectively what this pattern has allowed the attacker to do is break out of the data context, and that search term is really the data context, and enter the markup context. And by markup context, again, we mean that we're actually able to get HTML tags into the source code of the page, which will change the way things render. Now, this may not be much of a risk with an italics tag, but where it does become a risk is when we can start changing things of a more functional nature. So, for example, what if we actually passed through a closing strong tag, and then after that maybe we close off the paragraph. Then maybe we open a new paragraph and inject a whole bunch of new text to actually change the way the page is structured and the information that it conveys to the user. Or alternatively, maybe we just inject a script tag and actually start to reflect JavaScript, which has a functional value. We'll look at some of the things we can do with injected JavaScript throughout the rest of this module. The main thing to understand with XSS is that when we can actually pass untrusted data to the system and change the behavior of the page, we have a very serious risk. Now, of course, we can only capitalize on that risk if we can get a victim to load the link. So, in the example we see here in front of us, we would have to get the victim to load the URL, pass in Ferrari, and then enzo in the italics tag. Of course, there are many different ways that we could have a victim open a link. We could send it to them in an email. We could minify the link using a URL shortener. We could redirect to the link, which appears to be legitimate. As we progress through this module, we'll look at some of the other ways where a victim might be tricked into following these links and the potential impact on them if they do. What makes this risk possible is a lack of output encoding. So, let's take a look at what I mean by that. The thing about this search was that the search term was always intended to be user data and trusted user data at that. It was never intended to actually be markup in the page. Now, the entire reason that this attack was successful was because the untrusted data was able to break out of that data context and into the markup context. So, it was able to go from simply being a passive piece of information to fundamentally changing the structure and the behavior of the page. Now, the best way to mitigate this risk other than sanitization, which is an important mitigation, is to ensure that the untrusted data, when it is reflected, is reflected to the screen exactly the way it is entered rather than being reflected to the markup, and this is where the concept of output encoding comes. So, for example, when we look at that enzo data wrapped in italics tags, we need to ask what would we have to reflect into the HTML source in order to ensure that the untrusted data appears on the screen exactly as you see it there? And the answer is very simple. We need to use HTML encoding. So, the encoding for a less than angle bracket, for example, is just an ampersand, lt, semicolon. The encoding for a greater than angle bracket: Ampersand, gt, semicolon. It's that simple. If we reflect the search term into the HTML source using HTML encoding, by the time it appears on the screen, it will look exactly as the user entered it. So, that's good for the user, but it's also good for our security because it means that data is no longer able to break out of the data context and into the markup context. It just simply stays as passive user data. But there's a little bit more to output encoding than that. So, let's look at one more slide before we move on. The thing about output encoding is the way data needs to be encoded changes depending on the context. So, we just looked at HTML encoding. So, if we wanted to create angle brackets in HTML, we use the HTML escape characters of ampersand, lt, semicolon and ampersand, gt, semicolon. If our output encoding context was CSS, the escape sequence is different simply because CSS has a different markup structure. It's different again with JavaScript. If we want to escape data to be displayed in the JavaScript context, so in other words we actually want to put it in the source code yet have it render to the user so it appears as they entered it, the escape sequence is different again. It's also different when we put it in the URL, and then it's different in all sorts of other contexts, which may not be quite as familiar as some of the more web centric markup contexts. So, things like LDAP distinguished names for example. And, in fact, in this case the escaping is the same as in CSS. But there are a whole bunch of other contexts where our encoding will be different. So, for example, if we encode for an HTML attribute, it's going to be different for if we encode into the HTML body. And then it's different again for things like XML and XML attributes. So, it's really important to be aware that encoding changes fundamentally between different contexts. Now, the reason this is particularly important for us when we are looking for vulnerabilities in applications is that we want to look for cases where maybe that encoding context hasn't been done correctly. If, for example, someone has started HTML encoding data that appears in the JavaScript context, that may offer and opportunity to exploit a risk. At the very least, it means things are not going to function correctly, but at the most, it could actually allow us to exploit an XSS risk, which is being created by virtue of using the wrong output encoding context. Another thing that we'll often see with output encoding context is developers writing their own. And this is a really risky proposition because there's a really broad range of characters and different output encoding escape sequences that need to be applied. If you have to go through and do all of that by hand, you're probably going to miss some. So, for example, we might often see angle brackets manually output encoding, but then they've missed things like quotes or forward slashes or backslashes. The really key message there for developers is that they really have to use a proven framework or library that already has this built into it, either something native within the application platform or a trusted library. You definitely don't want to be doing this yourself, and if you do, it's usually going to be easy for an attacker to find some holes in it. Let's take a look at some of those holes back in our vulnerable application.

Identifying the use of output encoding
We're back at the search we did a little bit earlier where we were looking for how the input sanitization was being done. And what we discovered then was that less than angle brackets were causing the application to go to an error page, but greater than angle brackets and the forward slash let everything go through just fine. Now, one thing that's worth a bit of a look here is the way that the output encoding is done, and we're going to learn a couple of things from this. So, first of all, let's turn on the developer tools, and what we're going to do is use the page inspector to go and have a look at the output encoding of this search term. Now, what's interesting is here in the page inspector, what you'll see is that the forward slash just appears like a normal forward slash. So, what we can see here is the Ferrari text. So, that's the first thing. We expect that to go through okay. The next thing we can see is the I from the opening italics tag, but interestingly we can't see the greater than angle bracket. So, it's actually being stripped out of the output encoding. So, it's really not even output encoding at all in that context. It's actually being dropped. The character is being replaced with an empty sting. And, again, that's quite common as well or it would just be stripped out altogether from the output. We then see the word enzo, and that's fine. That's just plain text that's gone through. Now what's interesting in the page inspector here is you can see a forward slash, and it looks like just a normal forward slash, but this is one of the idiosyncrasies of the developer tools. So, the developer tools give us a very good view of what's being rendered into the DOM. If we go down to the source code though, what we'll find is that when we find that Ferrari search term, we can see that there is actually an escape character in there. So, that ampersand, hash 47, semicolon is the HTML escape character for a forward slash. Again, compare that to the previous screen with the page inspector where it's just a forward slash. The reason I'm showing you this is to understand that what you see in the developer tools is more representation of what's being rendered in the document object model as opposed to what is actually being rendered in the HTML source. So, particularly when you're looking for risks of an XSS nature where we are talking about character encoding, just be a bit cautious about using the page inspector. HTML source is a far truer representation of what's actually being returned by the server. What we want to do next is just start to understand a little bit more about where this search term appears in the response from the server. So, let's actually now just change the search term just back to enzo, and we're going to have a look at where this then appears in the source code. So, let's just go straight to source, Control, you're in Chrome, and we'll do a search for enzo. So, this is clearly where it was being rendered where we saw it at the top of the page, you searched for, and then we have some quotes, and then, of course, the searchTerm in there. But we can see here that there does appear to be a second occurrence of enzo, and this second occurrence sits right down at the bottom of the page in a JavaScript context. And, in fact, we can see here there's just a little bit of jQuery that is setting the value of the search term element, which is actually the input box that we entered the search into, to the text that we entered into the search. So, the word enzo is being reflected into two different places. So, that's an interesting little piece of information, and particularly the JavaScript context is interesting because it starts to beg the question is the output encoding happening correctly in both locations? Let's test that. So, we'll close the HTML source, and let's now go and search for forward slash and a greater than angle bracket as well. Let's view the source again, jump straight to the bottom, and this is now very interesting. So, here was the searchTerm, which appears visibly on the page, and we know that the greater than symbol is dropped and the forward slash is HTML encoded, but when we look down at the JavaScript, we can see that there are no characters dropped and there is no encoding. So, this is now beginning to indicate that hey there is a place here in source code where so long as we can get the searchTerm through the input sanitization, it's being reflected verbatim. We're not seeing any encoding there. We're not seeing any HTML encoding, and we're not seeing any JavaScript encoding, which is what it really should have in that context. So, now you've got to start adding together everything that we know. We know that a less than angle bracket will cause the whole search page to bomb out, so we're not going to get anywhere with that. We know that there are other characters, which we may be able to use in an attack such as a forward slash and a greater than angle bracket. There are probably going to be others as well. We also know that those will be repeated verbatim in the JavaScript context. So, what we're going to start doing now is thinking about how can we actually attack this pattern in JavaScript? So, let's now move on to actually delivering a payload via reflected XSS.

Delivering a payload via reflected XSS
When we finished up in the last section of this module, we identified that the search term is being reflected into JavaScript without any output encoding. And, in fact, we identified this line right down here. And what I want to do is just copy this guy and start to use this line to build up what could be a possible cross site scripting attack. Now, to do that, I'm just going to drag over a text editor, and in that text editor I'm just going to paste that search term. Let's now break this string down into two parts, the trusted and the untrusted data. So, line number 1 is going to be trusted. So, that's clearly what is already hard-coded into the page. We'll keep line number 2 with the untrusted data, or, in other words, what we're entering via the Search text box. And then line number 3 we'll also keep as trusted data. The trick for us now is to look at how we can structure the untrusted data that we see on line number 2 so that it doesn't trigger the sanitization and the search term is rejected altogether, but does actually allow us to start doing something of malicious intent to the page. So, it's this guy here that we want to work on. Now, one thing that's commonly done with XSS is accessing cookies. And as we saw in the first module on transport layer protection, there are certain cookies within the system that compose a significant value to an attacker. So, the auth cookie, for example, as we saw earlier on, if we can grab that, we can hijack the session. So, that is a very valuable piece of data for an attacker to have. So, let's look at how we might just be able to grab all the cookies that are in the browser and send them off to an attacker. Now, what I'd really like to do in order to access those cookies is write a little piece of JavaScript to access document. cookies in the browser, and then send that off to my attacking website. Now, to do that, I'd really like a clean line of JavaScript I can write on. So, what I'm going to do is just simply close off the string encapsulation with another quote. So, remember this is continuing on from line 1, and this is really everything that we will pass in as untrusted data. We're going to need a close bracket as well, and then just a semicolon will close that line off. So, effectively we've given ourselves a new line of JavaScript code that we can now inject into that page via reflected cross site scripting. So, what I'm going to do for the rest of this line is just copy and paste a piece of script that I prepared earlier on. So, I've got that in my clipboard now. Let me just paste that in place here, and let's now walk through what is going to happen. So, first of all, we're going to call location. href, which is going to cause an HTTP request to be issued. It is going to issue it to this domain, and we'll just make sure there's no gap in there. And, again, that is our normal attacking website that we saw in the last module. And it is going to access the Cookies path, all of that attacking website. It is going to pass a parameter called C, and then we're going to close off that string value, which of course, is just simply the URL we're going to hit. We've then got an encoded character. The percentage 2B is a URL encoded plus symbol. So, what this is going to allow us to do is append to the URL another piece of text. We have to encode this because if we pass this through as a plus symbol, it will end up being treated as a space because the plus symbol is used as a method of URL encoding a space. So, in other words, we're URL encoding the plus symbol in order to avoid the browser accidentally thinking that the plus symbol was URL encoding the space. We needed to do this because we want to pass this payload via the URL because after all, that's how a reflected XSS attack is usually delivered to a victim. It'll all make sense when we see it run in the browser. We are then calling encode URI component, and what that's going to do is make sure that the value that we passed to that method is encoded so that it can be sent via the URI because ultimately we're going to append this to a query string. So, we want to make sure that there are no characters in there that might break out of that query string context. Now, eventually what we're going to do is we're going to pass though document. cookie, and document. cookie is going to give us all the cookies in the browser. So, that's great. Anything that the user has in their browser, that can be accessed by JavaScript, and that's something else we're going to look at a little bit later on in the modules on cookies. Any of those cookies will be passed to the attacker. Now, there's one more thing that we need to do here; otherwise, we're going to get a JavaScript error on the page. And that last thing is that we need to close off the remainder of the original trusted data that appeared on the page. So, we need to make sure that this single quote close bracket semicolon doesn't execute. And the easiest way to do that is we're just going to add a couple of forward slashes so it gets treated as a comment. So, that should be everything we need. Let's turn that into one nice neat line, and we'll copy that, and then we'll go through and we'll search for this, and we'll see what happens when we put it in the browser. Okay, now that we've built up our malicious reflected XSS search term, let's go and add it into the browser. And I'm going to drop it up here into the searchTerm because ultimately if we do want to go and weaponize this XSS attack, we're going to do it by distributing a URL. So, let's paste that in. Now, in theory what we would do for any victims is distribute that entire URL. Let's press Enter. Now, here we go. So, look at what has happened. We are now over on the attacker's website. We're back on attacker. hackyourselffirst. troyhunt. com, so this is the attacker's website. This is not a website of innocent intent. And what we can see here is it's reflecting the cookies for us. So, we can see that it has actually been able to grab two cookies. Now, all of this is up in the query string, but this page kindly represents it in a more easily consumable fashion. And we can see here that the VisitStart cookie exists, and we saw that one a little bit earlier on. The AuthCookie also exists. Now, this is what we saw in the previous module on transport layer protection, and it is this great big large cryptographically strong string. And as we now know from the previous module, if an attacker has that string, they can now go and hijack the session. Now, this is a really important observation because what it means is that if we could pass that URL that we constructed to a victim who is presently authenticated to the target site, we will have enough information to hijack their session and effectively take on their persona and be able to do anything on the website that they as a logged in user could do. Even though the website did implement some untrusted data sanitization, and even though it did implement some output encoding and it even dropped some characters from the output context when it rendered in the HTML, we managed to find a vector because the sanitization wasn't strong enough and the output encoding wasn't strong enough. In fact, it didn't even exist in the JavaScript context. Let's now take a look at what would happen if we did the same thing in the secure application. Back on the secure site, let's now take a look at how to properly handle a malicious attack such as the one we saw just before where we searched for the JavaScript string to have as cookies. I've still got that in my clipboard, so let's just go back and do the same thing as we did before. So, we'll search for Ferrari to begin with. That still works fine. Now, let's go and paste in the string that I've still got on my clipboard, which is that malicious attack. So, let's run that. Now, the first thing that we'll find is that the website no longer redirects. So, that's good. We're not seeing the attacker's site and all of our cookies sitting over there on that. The next thing that we can clearly see here is that the search term in the middle of the page is appearing as we entered it. So, this is what we created in the text editor just a little bit earlier. But we already knew that the HTML encoding was working okay. The bit that we're really interested in is the JavaScript encoding. So, let's view the source. And we'll jump down to the end of the page. And here we can see something very different. So, when we look at that search term down at the bottom of the page, we're now seeing that all of the characters which previously rendered into the markup and allowed us to break out of the data context, enter the markup context and actually execute in the browser, are encoded. So, for example, we can easily see the column forward slash forward slash after HTTP have been encoded into backslash x3a for the column, backslash x2f for the forward slash. This is the correct JavaScript encoding context for the untrusted data. Now, as I mentioned whilst we were looking at the PowerPoint slide just before, it is extremely important to use a trusted library in order to do this encoding. You'll very quickly discover if this hasn't been done by passing in a nice array of random punctuation characters and potentially malicious characters and finding that some of them haven't been encoded at all or they haven't been encoded for the correct context. Libraries make these sorts of things easy. Somebody else has already solved the problem for us. So, this ultimately is a very good result. This is how we want our application to look. So, that's reflected XSS covered. Let's now move on and have a look at the risk of persistent XSS.

Testing for the risk of persistent XSS
We've just looked at reflected XSS where untrusted data that the user provided to the system was not properly sanitized or output encoded, which resulted in an XSS risk if we could get the victim to submit the untrusted data with the malicious payload to the server. So, that's one attack vector for XSS. Another attack vector is what we refer to as persistent XSS. And persistent XSS is what already sits in the database. It's come there via another means. Now, this goes back to the point that I made at the start of the module about the possible sources of untrusted data. And I said one possible source can be data that is already in your system. I'd like to take a look at that now, and what I'm going to do is jump on over to the Leaderboard. And now that we're in the Leaderboard, I'm going to drill down into the SLS AMG Black Series. What I want to do now that I am on this vehicle is make a vote. And the reason I want to do this is because when I vote, I, as an end user, have the ability to add data to the system, which is invisible by other users. And what I want to do is see if I can inject a cross site scripting payload into the page via the comment system. So, let's just do a little test. And what I'll do is I'll type AMG, and then I'm going to go and add this italics tag again. And we'll just make that Black, close off our italics tag. So, the question now is going to be whether this will render to the screen and show the italics tag or whether it will render to the markup and actually cause Black to be in italics, or, of course, whether the whole thing is just simply sanitized and doesn't appear at all. Let's click on Vote and see what happens. Okay, so what we can see down here is that we do indeed see Black in italics, which would suggest that there is no output encoding happening. Clearly there was no sanitization, our request didn't get rejected, but it looks like once that data was stored in the database, it's not being output encoded correctly. Now, when I actually submitted that comment, the web page was just updated in the DOM, so it hasn't actually made a request back to the server, and the HTML being omitted without the correct output encoding. So far this all just reflected in my browser. So, to test whether the output encoding is actually happening when the page is rendered on the server, let's jump back to the Leaderboard, and we'll go back again to the AMG SLS Black, scroll down to the bottom, and indeed we can see that we still have Black in italics. So, clearly when the server is pulling this piece of data out of the database, it is not encoding it for the HTML output context before it puts it on the page. So, this has now established a risk, a persistent XSS, via the comment system. Now, of course, italics tags are really a pretty minor risk. They are important though because they do demonstrate the presence of an XSS risk, which we may then probe further. Let me go and show you one that I prepared earlier. And, in fact, we've already got some persistent XSS in this database. So, if we go back to the Leaderboard and we jump down to the Bugatti Veyron, suddenly we see the page redirect. We just saw a very quick flash before of the Bugatti Veyron page, and now we're back onto the same screen that we saw earlier on when we injected XSS into the JavaScript context of the search feature. The only difference this time is that it's being persistent XSS. But let's go and take a look at where this actually appeared in the output context. And the easiest way to do this, we know it was JavaScript that redirected the page, so let's just go and turn the JavaScript off in Chrome for a moment, and then we'll see what we can find in the source code of the page. So, we'll just search for JavaScript. It's in our Content settings. Do not allow any sites to run JavaScript. Save that. We'll close our settings. Let us now go back. Now, we can no longer actually click on the Veyron or any other car here for that matter because it was dependent on JavaScript to add the click events anywhere on the table row. Let's just load up manually, and I know that it is Supercar number 6. So, here we are. This time the Bugatti Veyron page is loaded. We're not getting any rotating carousel either simply because it does have a JavaScript dependency. Let's jump in to the source code, and we'll jump down towards the bottom of the page, scroll back up a little bit, and we can see that there is indeed a piece of script in the source of the page. And this is very similar script to what we saw in the previous section of this module when we attacked the JavaScript context to install the cookies. So, it's the same attacker path, it's the same URI encoding of document. cookie, and we can see here that the script was injected via this user. So, in fact, if we look back at the page, we'll see that there's no actual visible comment because, of course, the script tag won't render to the screen. So, what all of this is showing is that this user was there authenticated, was able to get a very malicious persistent XSS script through the commenting system so there was no sanitization or rejection of the untrusted data, so that's one possible deficiency, but the really important deficiency is there's no output encoding. Now, it may be in a case like this the developer simply trusted their own data. Hey, if the data is in our database, it must be good right? Not necessarily. Let's jump over to the secure app now and see how this should work. Okay, I'm back over in the secure app now, and I have also re-enabled JavaScript because I now have confidence that this site is not going to XSS me by loading persistent JavaScript from the database. So, let's jump over to the Leaderboard, and we will go down again to the Bugatti Veyron, and this time we should be able to click the record now that we have JavaScript back, and we are not being redirected. That's the first good news. When we scroll down a little bit, we can see now that script is being rendered to the page. So, that entire script block actually appears rendered into the screen. Now, of course, this is just exactly what we want, and it's very simply a matter of the web page saying hey once I get this data from the database, encode it for the HTML output context. Don't just assume that we can take whatever we have in our database and push it out to the screen. This is a really fundamentally important concept, and it's something you need to apply for every single piece of data you pull from your database and put on the screen. So, the sort of thing that you want to go through and test in your own applications is can you go to any field in the system firstly via the web interface and inject XSS into the system? And secondly, if you circumvent those controls, go directly to the database. Start putting things like HTML markup in your database. Do they render to the screen or do they actually cause the markup and the structure of the page to change? That may sound a little bit excessive, but it's going to protect the application against one of those oversights where the data isn't sanitized on the way in. You never know how data in the database may later be used in the applications. So, don't just make the assumption that just because you're not collecting that data from an untrusted source, you don't need to output encode it. It's always better to be safe, and most web frameworks these days provide very easy streamlined ways of implementing output encoding. And, in fact, many just do it by default. And that's where we ultimately want to be with many aspects of security, secure by default.

The X-XSS-Protection header
One of the things about cross site scripting is that it does adhere to a fairly predictable pattern. At least reflected cross site scripting does. Because of this, browsers have the ability to implement some native defenses to protect users against potential cross site scripting risks. For example, reflected XSS. If the browser sees a potentially malicious search term passed in the query string in a link from an external resource and then reflected to the page, in many cases the browser can make a reasonable assumption that it is an XSS attack. When the browser sees that, it may elect to block that attack or visually alert or warn the user in another way. So, there is an ability for the browser above and beyond the defenses in the application to provide a layer of protection. Now, of course, for us as developers, you can never rely on that. You have to work on the assumption that the application itself in isolation needs to be secure. And then if there's a browser downstream that implements its own defenses on top of that, that's fantastic. That's a bonus, but we can't expect it to happen. The last thing I'd like to look at in this module is the behavior of one browser in particular and the way the XSS defenses that are natively available within it might be disabled. Now, to demonstrate this, I'm going to first turn on the developer tools and go to our Network, and then I'm going to do a search because I just want to issue a request, and this time we'll search for the gt-r. And what I'd like to show you here is that when we have a look at this first request, and this is just a get request for the gt-r search, what I'd like to do now is just scroll down and have a look at our response headers. And you'll see that there is a response header called X-XSS-Protection, and it has a value of 0. Now, the first thing to understand about response headers is that when the response header starts with an X, it's a non-HTTP spec standard header. So, you can also see that above this one we've got X-Powered-By, X-AspNetMvc, and X-AspNet. All of these are non-standard headers, so they're implemented either by web server providers or in order to target specific features of browsers. Now, the one we're really interested in, again, is this X-XSS-Protection header. And by having a value of 0, it is disabled. Now, this particular header actually only works in Internet Explorer, and, in fact, it was introduced back in Internet Explorer 8. Now, the reason this header exists is it enables the native XSS-Protection of Internet Explorer to be disabled. Now, you might ask, why would you want to disable XSS-Protection? The reason Microsoft did this is that there were circumstances due to the idiosyncrasies in the way developers have built some applications where patterns which looked like malicious XSS attempts were actually required for applications to function. As a result of that, what Microsoft did is said we're going to implement the defense in the browser, but if your application actually requires that pattern in order for the application to work, you can disable the native XSS-Protection in the browser by returning this header and setting the value to 0. Now, obviously from a security perspective, this isn't real good. We really don't want to disable native security provisions within browsers. Certainly a much more appropriate approach would be to change the odd pattern that was triggering that XSS-Protection, and then allow the browser to protect the application from any other XSS risks that may have made their way through into the production environment. In order to see how this works, we're going to need to go and open up Internet Explorer. So, let me go and drag over IE10. So, here's our vulnerable website now running up in IE10. Let's do the same thing as we did with the earlier reflected XSS attack. And we'll just do a quick search for Ferrari, and then we'll manipulate that search term in the query string and paste in that earlier malicious payload we had. So, this is the one that's going to redirect to the attacker's site and take all the cookies. Let's run that. So, here's what's happened. Obviously it has redirected. It's done exactly what we expected it to do. What I want to do now though is go to the secure site that does not have that header disabled and see what happens if we attempt this attack again. So, here we are back on the secure site, and this time we're going to try and repeat that same reflected XSS attack, but we have the X-XSS-Protection header no longer disabled via the website. So, let's do a quick search for Ferrari again, and now let's go and manipulate that search term in the query string. So, this is exactly the same attack vector that we just used in the vulnerable app, and it redirected us to the attacker's site and took all their cookies. Let's try this again. Now, we get a very different result. So, the first thing is we haven't left the page. We're still on the same page. The next thing that you'll see is down at the bottom of the browser we now have a message, which says Internet Explorer has modified this page to help prevent cross-site scripting. So, this is a very good thing because this is clearly a malicious cross-site scripting attack. Chrome didn't offer us a defense against this. Internet Explorer does. Let's not turn it off unless we really, really need to. When you are reviewing the security position of a site, if you do see that header, it does immediately raise a red flag because the only real reason you want to add it is if there is a potential XSS vector in the application. Now, again, maybe there was a legitimate use case in order for the application to behave that way in a pre- Internet Explorer 8 world. As we've progressed though, and as we've become more security aware, the risks posed by those patterns have become much clearer. So, seeing an application return that header is a bit of a red flag. That would then tell you, hey there are probably areas of this application that are at risk. So, certainly getting rid of that header is extremely important. If you see it, go through, find the risk, mitigate it another way, and then get rid of the header because it's a free additional layer of security. And, again, it is by no means a replacement for correct input sanitization and output encoding, but it's just another one of these layers that we keep talking about when we refer to defense in depth.

Summary
Let's recap the module. And the first thing that we learned in this section on XSS was that sanitization is really our first line of defense against untrusted data. Now, keep in mind that sanitization and untrusted data are concepts that go well beyond just cross site scripting. We'll touch on them again in a later module on SQL injection. What we want to keep in mind with sanitization is to try and take that whitelist approach. So, talk about what we know is good rather than what we think we know is bad. The other thing we learned is that when sanitization isn't complete, it's very easy to discover where the holes might be. So, those missing sanitization rules were very easily discovered just by throwing different characters into the system, seeing which ones were rejected, and which ones were accepted. As an attacker, that made it very easy for us to figure out what vector we would use to inject our XSS into the page. By far, the most critical XSS defense is output encoding simply because output encoding immediately eradicates all the risks we have from redisplaying untrusted data into the browser. If we output encode, and remember we have to output encode for the correct context, but if we do output encode and we get it right for HTML or JavaScript or CSS, whatever the context might be, we eradicate that risk of untrusted data breaking out of the data context and entering the markup context. That untrusted data will be rendered to the screen just exactly as it was entered rather than being entered into the markup as it was entered. And as with sanitization, if there are holes in this approach, it's really easy to discover. We just look at the source code, find where the untrusted data is, and check whether it's been encoded or not. Very simple. We also touched on not trusting your own data, and this was something I defined right up the front when we talked about the nature of untrusted data. You have to make the assumption that your own database could have persistent XSS in it. And what that means is making sure again that we're output encoding. But just because you have a field where perhaps today you don't have a data entry form where you don't have an immediate apparent risk, don't assume that it couldn't possibly end up with an XSS attack in it. And finally, those native browser defenses. This is good. It's always another layer of protection, and extra layers of protection are always a neat thing, particularly when you don't have to do anything to get the benefit of it. You really don't want to disable that X-XSS-Protection header, which Internet Explorer uses as a means of turning off its XSS-Protection. If you've got a situation where the application doesn't work when that header is present, fix the root cause. Don't turn off the security defense because that is a nice little safety net that users of Internet Explorer get. And when it comes to security, every additional defense is a good thing, particularly when it's there for free.

Cookies
Introduction
Hi. This is Troy Hunt, and in this module we are going to look at the security of our cookies. We're going to start out with a little bit of cookies 101, or, in other words, the fundamentals of how HTTP cookies are handled by browsers and websites. We'll then take a look at HttpOnly cookies because there's a very fundamental security difference about cookies that have this flag. After that, we'll take a look at secure cookies. And as all encompassing as a securer cookies sounds, it is about one attribute in particular, which helps us mitigate some of the risks we've seen earlier on in this course. We'll then take a look at how we can restrict a cookie by path and how that changes the behavior and consequently the risk profile of a cookie. After that, we'll take a look at also further reducing the risk by setting a cookie expiration, and this is going to be one of those discussions about usability versus security and finding an appropriate tradeoff between the two. And finally, we'll take a look at the concept of a session cookie, which is closely related to cookie exploration, but is a discrete topic that's important to understand in the context of security. So, let's jump into it and start with that cookies 101.

Cookies 101
Cookies are really essential pieces of data that play an absolutely vital role when we're building websites, but they're also a fundamentally simple concept. And a cookie is really nothing more than a piece of text stored in the browser. When a cookie is set by the server, it issues a very simple response header like what we see here. There is a Set-Cookie declaration and then a cookie name and a cookie value. That's, of course, just in the header, and beneath that we then have page contents or the body of the response. Now, of course, this is just how cookies is set by the server. It's also possible to set and read cookies client-side via JavaScript directly in the document object model of the browser. Now, this is a really important concept because this does have a security ramification, and we're going to talk about that in the next section of this module when we look at the HttpOnly cookie. The other really important concept about cookies is that when browsers make subsequent requests to a website, the cookie is sent back automatically with the request for the website that set the cookie in the first place. For example, in the box here at the bottom of the screen, you can see a get request. Now, this is just an HTTP header. We can see that it's getting the website we've been looking at; using the HTTP 1. 1 protocol, which is the standard for pretty much all of the web these days; and then we can see a cookie declaration. And that cookie is just passing in a name and a value. And it's the same name and value that got set in the box towards the top of the screen. So, this is a very simple construct. Server set to cookie. Browser sends the cookie back. One of the reasons this is so important is because as I explained back in the first module on transport layer protection, HTTP is a stateless protocol. We rely on cookies to be this one persistent piece of data, which ties individual requests together so that we can create some sort of persistence as a user moves across the website. We want them to be able to log in, for example, set an auth cookie, and then each subsequent request automatically sends the auth cookie. That auth cookie is what keeps the user logged in and enables them to continue performing tasks under their identity. So, it's a very critical piece of the HTTP spec and the way modern websites work. Let me give you a very simple visual example of this. So, a user makes a request to a website. It doesn't matter what it is. It doesn't have to actually be a web page. It could be an image or a JavaScript file. The important thing is it's an HTTP request, which is going to be processed by a web server. That website then responds, and it responds with the Set-Cookie declaration in the response header. After that, every subsequent request automatically sends the cookie. And, again, it doesn't matter whether it's a web page or an image or a JavaScript file. That cookie is going to get sent with every request that the browser's security model allows it to be attached to, and that's where we're going to start to look at some of the idiosyncrasies of cookies, what the browser's security model enables you as a developer to have some control over when those requests are made. Now, the important thing is that every subsequent request is going to automatically send that cookie. So long as the cookie is valid for the request, and, again, we'll delve into the details of that shortly, it's going to be automatically sent. It'll be sent for the request to the web page, and then it will be sent with every single request to embed content on that web page as well. So, once again, these are just the fundamental basics of HTTP and web browsers. The thing we have to remember with cookies is that very often they do contain data of a sensitive nature. So, on a couple of occasions in earlier modules now, we have looked at the auth cookie. And, in fact, right back in the transport layer protection module, because we were able to hijack an unprotected auth cookie, so that was when it was sent over an HTTP request and we could mount a man in the middle attack and actually intercept it, we could actually steal that cookie, hijack the session, and effectively impersonate the user. So, we could take on their identity on that website, access any data they had the rights to, perform any task that they had the rights to. Very serious risk. Now, browsers do implement some native defenses to protect cookies. So, for example, I can't build a website that asks the browser to give me the cookies for another website that's totally unrelated to mine. So, I couldn't just say hey give me all this user's Facebook cookies. The browser's security model keeps those separate domains sandboxed. So, that's good. What's bad though is as we saw in the previous module on XSS is that there are still risks that allow an attacker through a means like cross site scripting to obtain the cookies of a website that they have absolutely no right to. The thing is though, we have constructs within the HTTP spec supported by the browser to further secure the cookie. So, we're actually going to mitigate the risk of cookies being stolen by XSS as we saw earlier on using a completely different means we haven't touch on yet, and that's just simply by making the cookie more secure. That's what we'll get onto in the next section of this module. But before we do that, let's just take a look at some of the typical attributes that are present on a cookie. These are what we're going to be focusing on today. Domain is pretty self explanatory, and it just sets the validity of the cookie. So, for example, do we want to allow it for any sub-domains of the particular domain sending the cookie or do we just want to allow it for the exact domain, which sent the cookie? We do have a small amount of control over the way the browser handles cookies for domains. The next is the path. And what this allows us to do is talk about what paths of the website can actually access the cookie, even if the cookie was set for the same domain. And we're going to have a look at that in more detail in this module as well. Expiration, another thing we'll delve into. But an expiration attribute will tell the browser when the cookie should be discarded, when it should no longer be sent back with requests to the same website. And then we've got the HttpOnly and secure cookies, and these cookies are going to give us some control over how client script interacts with cookies, and also whether we want to allow cookies to be sent over a non-HTTPS connection or not. When you tie all these together, a typical response from a website setting a new cookie might look like this. So, all of those attributes can be included on the one cookie. And indeed most of the time when we're trying to properly secure a cookie, we will have most of these set. So, let's jump into looking at this in a little bit more detail. And where I'd like to start off is to continue from the last module on XSS and looking at how the HttpOnly cookie can help mitigate that risk.

Understanding HttpOnly cookies
Here we are back on the insecure website, and I'm presently logged in. Now, as we know by now, if I'm logged in, it means that I have an auth cookie set. So, let's hit F12 for the Chrome developer tools, take a look at our cookies, and we will indeed see that there is an AuthCookie present. Now, the important thing about the AuthCookie in this context is there is an attribute here called HTTP. And we can see, for example, that the ASP. NET_SessionId cookie is flagged as HTTP. The AuthCookie is not flagged as HTTP. Now, this is extremely important because what it means is that when a cookie is not flagged as HTTP or as the proper HTTP spec explains it, HttpOnly, it means that cookie is accessible via client script. So, as we saw in the last module, if we can get some XSS into this page that has access to the cookies, we run the real risk of a session hijack. Let's just take a quick recap on that. And we'll go back into the Search page again, and I'll again search for Ferrari, and we'll jump up, and I'll just paste a little bit of script from the clipboard. And, in fact, you can see this is very simple script. It's just going to do an alert of document. cookies. Now, on a page that does have an XSS risk, this will tell us which cookies the client script in the browser is able to access. So, let's run this. And as expected, we can see two cookies here. We can see the VisitStart, which also wasn't flagged as HTTP, and we can see the AuthCookie. So, this immediately tells us that this website has a very serious risk. That AuthCookie, because of how critical it is, should never be accessible via client script. We need to make sure that this can't happen. Now, fortunately I've done this in the secure website. So, let's jump over into that secure site now, we'll log back on, and we'll see how this XSS attack behaves a little bit differently. So, now we're over here on the secure site, and there's one very, very subtle, but very critical difference that has been made to the AuthCookie. And to demonstrate this, I would like to go and log in. Now, before I log in, because I want to show the response here, is I'm going to open the developer tools again, we're on the Network tab, and let's enter my email address and the same old password as we've been using, and let's now log in. The first thing I want to look at is let's just go back up to the first request here, and this is obviously the Login request, and we want to look at the headers. Now, of course, this was the POST request where we sent our credentials to the server, but what I'm interested in is the Response Headers. And what we will see in the Response Header where the AuthCookie is set is we will see an attribute called HttpOnly, and this is literally the HttpOnly cookie. And we can see this cookie again if we look on the Cookies tab. We'll see it's here as part of the Response Cookies. Now, this is really important. If we jump back over to our Resources, and we go down to our Cookies, we can see all the cookies we had before on the insecure site. The big difference this time is that our AuthCookie now has a tic in the HTTP column, and that is going to fundamentally change the behavior of that cookie when it's attempted to be accessed via client-side script. Let's demonstrate this. So, I'm going to go back to the Search page, we'll search for Ferrari again, and I've still got that same XSS attack in my clipboard. Paste it, and run it. And we now see something very different to when we ran this on the insecure website. And, of course, the difference is there's no AuthCookie. There is still that VisitStart cookie because that's still not flagged as HttpOnly, and there may be a perfectly legitimate use case. It could actually be used by JavaScript. It certainly doesn't appear to be too sensitive. The main thing is tough is that because that AuthCookie can no longer be accessed via client script, it's not at risk of a cross site scripting attack. So, think back to all the mitigations we applied in the last module against cross site scripting, all the input sanitization or the output encoding. All it would have taken is for that AuthCookie to have that one little HttpOnly flag and the XSS wouldn't have been able to access it. Of course, you should still do all those things, the input sanitization and the output encoding, but that HttpOnly attribute is absolute gold. It is such an easy mitigation against this risk. Now, depending on the web framework you're working in, this is normally an extremely simple attribute to add. Usually when cookies are constructed on the server-side, HttpOnly is one of the attributes that can be configured. And certainly many frameworks, particularly those that do provide authentication schemes, they'll make it HttpOnly by default. But certainly that's one thing to look for. And if you do see an authentication scheme that's setting an auth cookie, and remember you can check if it's an auth cookie. Just copy the cookie and put it in a new session and see if it automatically logs you onto the website. That auth cookie always must be HttpOnly.

Understanding secure cookies
Back in the transport layer protection module, we had a really good look at the auth cookie. And, in fact, we hijacked some auth cookies using Fiddler in order to imitate what a man in the middle attack could do if they had access to a proxy or any other node, which could intercept insecure requests. And, in fact, back in that module we pointed out how even if the website was mostly secure, it only takes one little request over HTTP, and it need not be a website. It could be an image or a JavaScript file or a CSS file. Just one little request to the same domain will automatically append the auth cookie. And if it's sent over HTTP, then the attacker can gain access to it. So, it was a real risk. Even when you tried very hard to do the right thing, it's very easy just to let one little HTTP request get through. So, let's just recap on what that looks like really, really briefly. So, we're back here on the insecure site. And what I'm going to do is just change our protocol to https:// and reload it. Now, as we saw in the transport layer protection module, this page does actually have a problem. We've got some mixed content; hence, the gold triangle on the padlock. So, the page is secure, but there are assets on the page that are not secure. Let's go and grab Fiddler, and we're going to make this request again. So, here's Fiddler. There are currently no requests. Let's flick back over to the insecure website. We'll just give it a bit of a Refresh. Back over to Fiddler. And we can see that there are indeed a number of requests that have been sent over HTTP. And, in fact, we can see that they are for PNG images. So, if we take a look at what these are, down to the ImageView, okay that is one of our badges. There's another badge. And there's the Pagani badge. So, here's the problem. They're just these little images. The problem also is that we can see here that the AuthCookie is indeed being sent with those requests. So, even though we may not be overly worried about the integrity of a brand logo on the page, we should be very worried about the fact that this request is disclosing the AuthCookie. And, in fact, the reality of it is we don't even need to send the AuthCookie in order to request assets such as these. The reason this is possible though is that when this AuthCookie was set, it didn't have a secure attribute. Now, the word secure sounds like a pretty absolute term, but in the context of cookies, what secure means is that the cookie is not allowed to be sent over an insecure connection. Let's jump back to the vulnerable website and see what that cookie looks like. Okay, back on our website, let's just jump into the developer tools again, back down into our cookies, and what we'll see here is that the AuthCookie does not have a tic in the secure column. Now, that's pretty important because it means that this cookie can be sent over an insecure connection. Let's jump over to the secure site and see how things are handled a little bit differently. So, now we're back on the secure website, and it implements cookies a little bit differently. So, in the last module we saw that HttpOnly is set on the secure site so client-side script can't access it. The other thing the secure site does though is it flags cookies as secure. So, let's take a look at the impact of that. And to do that, we need to log in again. So, let's go back to the Log in page. We will enter our email address again, same old password, and, again, just before submitting, let's turn on the developer tools, over to Network, and let's Log in. Alright, so let's work through what's happening. So, first of all, we'll go up to the first request, which was the Login request. Again, it is a POST to HTTPS, and, of course, this is how our credentials were sent to log in. Let's go down to the Response Headers and now have a look at that AuthCookie again. And what we'll see is HttpOnly, which was there as we saw in the last section. We can also see secure. And if we go and take a look at the Cookies tab, we'll see tics in the HTTP and the Secure columns. Same deal again if we jump over to Resources. We can see that we have both Secure and HTTP attributes on the AuthCookie. That's really good news, but let's take a look at what that actually means by jumping over to Fiddler. So, here we are in Fiddler. We have no requests at the moment. Let's jump back to the secure site. We will give it a Reload, and then back over to Fiddler. Now, what we'll see on Fiddler is a bunch of requests that were secure, so we can inspect them, but then we will also see these same three requests to images, Nissen, Pagani, and the McLaren logo. Now, what's really important though is have a look at the get request. We can no longer see an AuthCookie. Now, of course, when we made that last request, we're still logged on, it still said Hello Troy at the top of the page, and that's fine. So, the cookie was sent on the request to the web page, which was made over a secure connection. The difference is with this asset is that it is an HTTP request. And because that cookie is now flagged as secure, the browser will not send it with an HTTP request. Now, that doesn't make the content of that request secure, and you can clearly see that we can actually inspect and view the logos here. So, the content is still not secure. The difference is that AuthCookie wasn't sent. So, that's the really critical value add for the Secure attribute. It allows us to keep cookies with sensitive data away from any prying eyes on the wire. Of course, what that also means, is that you can never make an authenticated HTTP request to a resource. So, whereas before we could log on over a secure connection and then insecurely pass auth cookies around, which of course you should never do anyway, and we've discussed why not in depth in the transport layer protection module. But if you did want to do it, you couldn't flag them as secure because the cookie simply wouldn't be sent with the request. So, to summarize, when it comes to auth cookies, we want the HttpOnly flag so the client script can't access it, and we want the secure flag so the browser won't send it over a connection that puts it at risk of interception. Those two attributes should be on any cookie of any sensitivity whatsoever.

Restricting cookie access by path
The next thing I'd like to look at is restricting cookie access by path. And I've got a perfect example of this where we have a cookie that really should only be accessible in the one path, but due to other risks on the website and the nature of the data in the cookie, we open ourselves up to a potentially rather serious problem. So, the way I'd like to demonstrate this is that first of all I'm going to log off. And what I'd now like to do is log in again. And this time when I log in, I'm going to log in with the same credentials as what we normally use and the same password. And what I'm going to do a little bit differently is I'm going to set Remember me on. And this is going to give us a couple of additional cookies. So, let's log in. And now I'm going to open up the developer tools again, jump down into Cookies, and we'll see now that we have two more cookies. We have an Email cookie, and we can clearly see my email address there, and we have a Password cookie. Now, we'll come back to what these do and frankly why they're a pretty bad practice when we get to the module on account management. The really important thing that you'll note here about both the Email and the Password cookie is that path column just has a forward slash in it. Now, what that means is that both of those cookies, like all the other cookies that you can see here, will be sent with the request to any path on the website. It doesn't matter whether we're requesting the root of the site, a subdirectory five directories deep, it makes no difference. The cookie will always be sent. So, in fact, all five of the cookies that you see here will automatically be sent off to every request to the website. And, again, it's not just web pages, images, CSS file, JavaScript, all of these cookies are going along with every single one of those requests whether they're needed or not, and most importantly, whether it poses a potential security risk or not. Not only are then sent with every request, but if they're not flagged as HttpOnly, they're accessible via client script in every one of those locations. So, as you can see, it's a very, very liberal position. Unfortunately, it's frequently the default position as well. Now, that makes sense in many cases, but as we're about to see now, it really doesn't make a lot of sense in this case, and there's a much more secure position to take. And to demonstrate that, what I'm going to do is log myself back out. So, we'll hit the Log off button again. And what we'll see now if we look down at the cookies is that the AuthCookie has disappeared, but we still have the Email and Password cookie. Now, the way this particular implementation works is that if I now go back to the Log in page, we can see here that it is automatically logging me back in. And here we are. I'm logged back in again. Now, this may look a little bit odd, but I've actually based it on some real world examples. And, again, we'll talk about this in more detail when we get to the section on account management. The thing is though, these cookies are actually very important because these cookies contain the information required to log me in. Now, let's take an example. I'm going to jump over onto the Leaderboard page. We can get rid of the developer tools now. And I'm going to go to the Bugatti page. And just before we go there, we know, based on the XSS module, that this has a persistent cross site scripting risk. Let's go and run that again. And just like last time, this has actually redirected me off to the attacker's site, and it's grabbed all the cookies from our insecure site and sent them to the attacker. We've seen the AuthCookie and the VisitStart cookie before. We can now see that the Email cookie and the Password cookie have also been attacked. Now, this is pretty serious because this now gives the attacker the information they need in order to log back in as me. And, in fact, it's even worse than that because when we take a look at this password, we can see that it's clearly not my plain text password, but by ending in an equals sign, it's indicating this is quite possibly a Base64 encoded string. Let's take a copy of that. And I'm going to grab a new tab, and we'll just head off to base64decode. org. Now, the thing about Base64 encoding is that it's intended to allow any byte array to be encoded into a set of Ascii characters, which makes it very useful for passing around without having any encoding problems. Let's just paste that string in here, and we'll do a quick decode, and we'll see what it comes back with. Now, here's our password. So, this is the plain text password. And this is the thing about Base64 encoding. You also have Base64 decoding. Many a developer has thought that this is a means of cryptographic security. And, in fact, I have many examples of people thinking that on my blog. So, it does really happen. Now, again, I want to talk in more detail about this practice in the account management section. The important thing to realize now is that because of a persistent XSS risk, which manifests itself on the Supercar page, the attacker was able to steal cookies that are only used on the Log in page. We have a native defense against this in the HTTP spec for cookies, and that is to limit the scope of the cookie based on path. Let me show you what I mean. If we close this tab, and we go back to the website, and we pick a path that doesn't have a persistent XSS risk on it, say the GT-R, we can see the path is /Supercar/1. Conversely, let's just log ourselves back out again. And just to make sure we don't auto log in, I'm going to jump down into the Cookies, and I'm going to delete the Email and the Password cookie. Close the developer tools. Back to Log in. This path is /Account/Login. This is the path that requires those cookies in order to log us in, not the Supercar page. We don't need to be able to access those cookies on the Supercar page. If we could restrict the scope of those cookies to that they only worked on this page, even though we might have cross site scripting flaws somewhere else, and even though we're doing something a bit foolish by putting passwords in cookies, we could actually mitigate this risk altogether. Let's jump over to the secure site and see how that works. Now, we're back on the secure site. And one thing I've changed on this secure site is to restrict the path of that Email and Password cookie. Let's see what that looks like. So, we're going to go to Log in. I'm going to open the developer tools before I do this because I want to capture those Network requests so that we can see the cookie in the Response Header. Same old email address, same old password. We will Remember me. Now, let's Log in. Okay, we've got some requests here. Let's jump up to the first one, which is obviously to the Login path, and we'll start with the Headers. And what we'll see down here in the Headers, in the Response Headers, is that we do have a cookie set for Password. And, in fact, we can see here that the path is /Account/Login. You can see the same thing just beneath that in the Email. Now, what's interesting is that if we go over and have a look at the Resources now, you won't see either the Email or the Password cookie. And that's simply because when you look at the path that we are presently on, we're on the root of the website. We are not in the /Account/Login path. Now, because of that, the browser won't even show you the cookies that it has available for that path. Let's check if the auto log in still works though. So, we want to know if the cookies are actually there. So, we'll Log off. Let's keep an eye on that path column as we go to the Log in page. So, there we go. We can quickly see the start of that path, /Account. We could see those cookies did exist. We're back on the home page now. We are logged in, so clearly it was able to access those cookies and log us in. The real proof of this security measure though is going to be when we go back to the Leaderboard page, and then we close the dev tools and head back over to the Bugatti. Let's see what can be accessed. So, here's our attacker's site. Now, because all I've done on the secure version of site is just secured the path of those two cookies, we can still see the problem with our AuthCookie being exposed. We can still see the VisitStart cookie, but now we can't see the Email address or the Password cookie. And that is just very simply because the page that had the XSS vulnerability that allowed us to access the cookies was on a different path to what the cookies were allowed to be accessed on. So, we leveraged an XSS floor in /Supercar. The cookies are only accessible to /Account/Login. So, this is a really important security defense within cookies, particularly for cookies of a sensitive nature. Consider what path they're actually required in. Can you lock those guys down so that they're only needed in one specific location? Because if you can do that, if you do get another flaw in another part of the website, it's not going to jeopardize those important cookies that you've only made accessible under the one path where they're actually required. So, it's like you've put a little sandbox around your risky cookies. When you combine that with the appropriate use of HttpOnly and secure, you're significantly improving the security profile of your cookies. And as we know by now, both from the AuthCookie and some of the other sensitive data that was leaked in that Email address and Password cookie, cookies are extremely valuable. So, applying these sorts of mitigations to them is dead easy, and it provides some really serious security defense as well.

Reducing risk with cookie expiration
One of the great things about cookies is also one of the worst things about cookies, and that is simply that they stick around for a very long time. Cookies are what give us the ability to make sure we can come back to our website, make subsequent requests, and the website automatically knows who we are. They are a great little persistence model, and they make perfect sense for something like auth cookies in this stateless world that is HTTP. That's fine, but it's also a risk because what it means is that if we have a cookie that has a very long lifespan, whilst that cookie is still active, it exposes us to all sorts of risks. So, we've seen the XSS risk already, and in that case, we simply went to a web page that had a flaw that was able to execute script on the client, harvest off the cookies, and send them to an attacker. Another risk that we'll look at later on in this course is cross-site request forgery. Now, you don't even have to go to the website in a CSRF attack for it to make requests on your behalf and send the cookies along with it. The same again when we look at clickjacking later on. It is extremely convenient for cookies to live a long time and to keep users authenticated, but it also poses a really serious risk simply because whilst that cookie is active, it means that XSS attacks and CSRF attacks and clickjack attacks and all of these sorts of things can take place. Now, of course, once that cookie is inactive and the user actually needs to perform an authenticated request, that in itself poses a problem. It's not a security problem. It's now a usability problem. So, somewhere in here we need to find the right balance between convenience and security. Let's take a look at how this site has configured the cookies. So, we'll jump back into the developer tools again, back down to our Cookies, and we'll see here that there is and Expires column. And what you'll find in the Expires column is that some of these cookies last a very, very long time. This is one year from now, the AuthCookie, the Email cookie, the Password cookie. Now, what this means is that regardless of whether we're actively using the website again, so we might not even use it after today, an attacker has access to the cookies if they can exploit a risk such as the ones I've just described. It means you have to ask the question, is there really a valid use case for this cookie to be accessible 11 months after using the site? I might not even touch it for almost another year, yet there is a risk of an attacker gaining access to those websites. And, again, if it's something like one of those cross site attacks like CSRF or clickjacking, I may not even have to consciously go to this website and the cookie can be exploited. Let's take a look at how the secure website handles this, and you'll see that it takes quite a different approach to the expiration of cookies. I'm back on the secure site now. Let's go and log in again, and we'll see how the approach to cookie expiration changes. So, same again with the old email address and the same old password, and let's Remember me because I want to see what's happened with those Email and Password cookies as well. Okay, so we are logged in. Let's jump into the developer tools again, into Cookies, and let's now just scroll these over a little bit so we can get a very clear view of what our expiration has been set to, and we should now see a very different security profile. And there are two things to note here. First of all the AuthCookie. That is set to expire on the 2nd of July 2013. That is two days from now. So, the AuthCookie now has two days before we will automatically be logged off. Our window of potential session hijacking is now only 48 hours rather than one year. The Email and Password cookies. When we get to the account management module, we're going to look at what's wrong with this approach. And as you can see, I've also removed the path restriction that we put in in the last section of this module because I want to demonstrate that in the case of something like a Remember me cookie, we may actually want to have a longer period. So, in fact, these are going to expire in exactly one month from now. The ASP. NET_SessionId and the VisitStart cookie are both session cookies, and we'll look at those in the next section. The main thing though about the three cookies related to authentication is that their risk profile has now changed significantly. There is no longer a 12-month period where an attacker can gain access to these via all sorts of means. The thing is though, there is no one perfect fit. What you have to do is try and find the right balance between the convenience that is already being logged on or the convenience of the site being able to remember who the user is and consider that against the tradeoff that is the potential security risk. Now, how you come to that conclusion will depend on factors such as the data that exists on the website and the tolerance that the users have to the friction of needing to log back in. So, for example, something like a social media site. Users expect to be able to get back into it at a snap. It should be very, very simple low friction for them even though there can be a lot of personal information of use to an attacker on those sites. Conversely, compare that to something like a banking website. This is where we're starting to deal with financial details, plus it's also an activity, which is probably not performed as frequently as visiting a social media site. There is a much higher tolerance by end users to go through some friction on a site like that. So, in that sort of situation you're probably going to bring down those expiration periods on the cookies quite significantly. In conclusion, for a site like this, it's going to mean that when I come back to this website in 48 hours from now, my auth cookie can't be stolen. When I come back to this website in one month from now, my email address and password can't be stolen. Of course, I may still log back in and reset those expirations and have another two days or another one month depending on the cookie, but at least whilst I'm away from the website and not involved with it, after that expiration period, those cookies will disappear, they won't be sent, risks of having those cookies exposed through attack vectors such as cross-site request forgery and clickjacking will simply disappear.

Using session cookies to further reduce risk
We just looked at how to reduce the cookie expiration period in order to reduce risk, or, in other words, how to reduce that window whereby important information, and let's face it, cookies do have some important information, so where that information can be protected from an attacker by simply expiring it. And we looked at just simply reducing the expiration period to another fixed point in time. Now, of course, usually in code that means some duration from the point it is set, two days, a month, a year, and so on and so forth. There is another very common option when it comes to cookie expiration though, and I'd like to show you what that looks like. And to do that, I'd like to log back in. So, let's enter the same email address as usual and the same password. And I'm only going to focus on the AuthCookie, so let's not bother about remembering me. Now, let's jump down to our developer tools, into the Cookies, and what we'll see here is that our AuthCookie is back where it was before, which is that it will expire in one year from now. Now, of course, we could reduce that to two days or one day or some smaller period, and that would significantly reduce our risk, but it may well be that is a much longer period than what's needed. And one of the options we have when it comes to managing HTTP cookies is to simply make them what's known as a session cookie. And, in fact, you'll see the ASP. NET_SessionId and VisitStart cookies are both flagged as Session in the Expires/Max-Age column. And what this simply means is that when the browser closes, the cookie will be gone. There is a class of web application for which this works very well. Banking is a good example. When someone is in a web browser doing their banking, it is usually a very fair assumption to make that if they close their browser, they're finished with their banking. You normally wouldn't close your browser when you are smack bang in the middle of executing some financial transactions. That's not a usage pattern, which is common to the finance industry. Let's take a look at how the secure site flags auth cookies as being Session only and the impact of then closing the browser. So, here we are back on the secure site, and this secure site is now configured to make the AuthCookie a session only cookie so it doesn't have an expiration date. Let's now log in, and we'll log in with the same credentials as we normally use. Log in. Let's jump into the developer tools, into the Cookies, and we will see that the AuthCookie is now indeed flagged as Session. So, what this should mean is that if we close the browser and then open it back up again, we will no longer be logged on. That cookie will be gone. Let's give that a go. So, let's close it, and now I'm going to go and open a new browser session. So, here's a brand new window, and we will head off to the secure site, and we are not logged in. If we jump back into the developer tools, back into the Cookies, we will see that there is no longer an ASPX AuthCookie. We have new Session cookies for the ASP. NET_SessionId and VisitStart, but that AuthCookie won't be set until we now log in. Now, of course, this is really just a deviation of controlling the expiration. But rather than saying we are going to expire at a certain point in time, now we're saying hey let's just expire when someone's finished with their browser. So, that'll mean when they close the browser or when they restart the PC, that cookie will now be gone. It is a little bit of a trade off though. You may decide you actually want to expire the cookie earlier. So, what if someone just leaves their session active and walks away from the PC for, I don't know, the next two days or something. You may actually want to take a little bit of a harder line than that. But again, when you do that, you are going to now move into this realm where you're trading usability for security. There is no one size fits all. The most important thing is to understand both the advantages and the disadvantages of longer versus shorter expiration and to understand the risk that active cookies pose to your website, and conversely, the advantage that they offer to customers. Somewhere in there, you'll find the best balance for your website.

Summary
Let's summarize the module. And one of the most important things to understand is that cookies really are a very simple little concept. They're just those little bytes of data normally set by the server and then sent back automatically with every request. However, it's very easy to end up with a suboptimal security configuration, and certainly default framework settings are one way this problem gets exacerbated. So, for example, frameworks will often neglect to include the secure flag on an auth cookie. Inevitably they do this because they can't always expect the developer to have access to an environment where HTTPS in enabled, but unfortunately it does sort of get them off on the wrong foot. HttpOnly, absolutely critical in order to mitigate the risk of an XSS attack. We saw in the last module just how easy both reflective and persistent XSS attacks can be. If those cookies are flagged as HttpOnly, that's one attack vector which is totally off the radar for an attacker. Secure cookies, such an essential attribute. And no matter how hard you try and build all your requests to be secure, again, it only takes just that one little HTTP request. And if the cookie is not flagged as secure, it gets sent over an insecure connection and a man in the middle has the potential to access those auth cookies. Don't risk it. Just flag it as secure. We also looked at the path scope of a cookie. So, if we can restrict the cookie so it is only used in one particular path of the website and is not accessible by any other paths, if those other paths do develop a risk such as cross site scripting, the cookie is safe. It just can't be accessed. That is a great security mitigation because it's just such a simple little attribute. And finally, we looked at cookie expirations. So, we looked at either reducing the fixed point in time at which the cookies expires or allowing the cookie to be a session cookie so that it expires as soon as the browser is closed. This is all about reducing the window of risk. But conversely, we have to tradeoff the impact on usability. It does make things harder for the user, so try and strike a happy balance. And this is the sort of discussion you want to have with the business owners of a website. Understand what the advantage is usability wise, put forward the security position, and find that happy balance somewhere in the middle.

Internal Implementation Disclosure
Introduction
Hi. This is Troy Hunt, and in this module we are going to look at the security risks around internal implementation disclosure. We're going to start out by talking about how an attacker builds a website risk profile, or, in other words, how they start to gain a greater understanding about areas of risk that they may probe for in the site. We'll then move on to take a look at server response header disclosure because those server response headers can have some very valuable information for an attacker. With that information in mind, we will then take a look at locating vulnerabilities based on those response headers. It turns out there is a lot of very easily discoverable information once you can gain access to server response headers. Moving on from there, I'll show you how even when you can't necessarily gain explicit pieces of information from the response headers, HTTP fingerprinting can still give you a pretty good idea of what the website is actually running on. We'll then move over to robots. txt and how the robots exclusion file can have some pretty useful information in it to an attacker. Also of use to an attacker is information that being is disclosed in the HTML source of web pages. Moving on from there, we'll take a look at leaking of internal error messages, and we're going to look at some really information that can be gained when the appropriate exception handling doesn't exist and internal messages bubble up to the browser. And finally, we'll take a look at the lack of access controls on diagnostic data. It's often quite easy to get really valuable information such as log files from a website because they just haven't secured them properly, and I'm going to give you a really good example of that and give you a bit of context about just how many web applications are out there with these log files exposed. So, let's jump into it and start looking at how an attacker builds their risk profile.

How an attacker builds a website risk profile
A good way to think about this section of the course is to think about movies where you've got bank robbers trying to understand every single aspect of the bank security before they break in. So, think of movies like Oceans 11 where the characters are performing reconnaissance. They're looking at what security systems are in there, where are the lasers and the motion sensors, what sort of vaults do they have, what risks might that particular model have, are there points of weakness in the building? They're trying to collect as much information as possible about the security profile to understand what attack vectors might allow them to exploit the building, or in the case of website security, might allow an attacker to exploit the application. Now, when an attacker can build up this profile and gain as much information as possible about a broad range of risks, it starts to give them a really good understanding of how everything is put together and where they might be able to find weaknesses. So, for example, earlier on in the XSS module, we looked at things such as the points of untrusted data entry. So, the Search feature. Okay, that is a point where the system is accepting untrusted data. Moving on to things like sanitization. So, we went through the process of understanding what characters are being sanitized and which ones aren't. Understanding that information gave us a better idea of the risk profile of that feature. But moving onto some of the things that we'll look at in this module, an attacker also wants to understand things like the frameworks and libraries that the system is running. Once they understand that, they can then start to look at what vulnerabilities might be present in those. And that's one of the things we're going to look at first off in this module. An attacker also wants to understand the structure of the website. Where are the scripts? Where are files uploaded to? Where might we find admin facilities? It doesn't necessarily mean that they're going to then be able to exploit all of those, but it starts to give them a better picture of where risks might be present. Same thing with being able to view HTML source. Once you can see HTML source, and of course you can easily do this by just right-clicking and viewing source in pretty much any browser, you start to be able to get a better understanding of how the thing is put together. What JavaScript libraries might they have pulled in? Very often, what sort of framework have they used on the server-side in order to generate that HTML? There's often little telltale signs in there. Sometimes there's just simply very useful information disclosed in HTML source. For example, I've seen many cases where there have been inline SQL statements in hidden fields in HTML source. And if you don't know why that's a bad thing to do now, you will after we get to the SQL injection module a little later on in this course. Internal error messages we're also going to look at this module. An attacker will try to cause exceptions in order to then try and understand where risks might be present. Because after all, and exception is a telltale sign that the application isn't able to properly handle the data that is being provided to it. So, the very fact that any sort of exception occurred is a bit of a telltale sign, but then, of course, the exception itself can often have very useful data in it. The other problem is that often these unhandled exceptions may actually be logged and may be viewable later on. Now, it's not just exception logs that are useful. Even things like web server logs can be extremely useful. They can give us really useful information such as the parameters provided to the application. So, for example, is there any useful data in query strings? Sometimes unfortunately you do get sensitive data in query strings. Sometimes even as blatant as credentials. That goes into web server logs. If an attacker can get those logs, they get some extremely useful information about the website. Now, of course, gathering this information is one thing. Actually doing something with it is quite another. So, I'd like to give you an example of how an attacker can use information such as the frameworks that are used to then identify potential vulnerabilities. And to do that, I'm going to jump over into Chrome. The example I'd like to give here is information that can be found by searching for known vulnerabilities in frameworks. And what you're looking at here is the National Vulnerability Database, which is provided by NIST. Now, if you don't already know NIST, they're the National Institute of Standards and Technology. They're a US government agency. And one of the facilities they provide is the ability to go through and search for known vulnerabilities in software. And in this particular case, we can go down and just jump straight into the Vulnerability Search Engine, which will allow us to search for CVE flaws. And CVE's are simply common vulnerabilities and exposures. Now, there are multiple CVE databases. I'm using the one from NIST just simply as an example. And as an example, let's search for a product such as WordPress, which is obviously an extremely popular blogging engine. It's also a product which has had multiple vulnerabilities over time, and some of them have been particularly serious. So, here we find 521 results of WordPress vulnerabilities. And as we scroll through these, we'll see all sorts of different types of vulnerabilities such as cross- site request forgery, which we'll talk about a little later on. Cross-site scripting, of course, regularly features as a vulnerability in all sorts of frameworks. And, in fact, in a product as large and well used as WordPress, you're inevitably going to find quite a large number of vulnerabilities. That will also include things like SQL injection. So, if we drill down and take a look at one of these vulnerabilities, what we'll find is that there's quite an extensive amount of information available to us including external links that explain how the vulnerability might be exploited. Now, inevitably this resource exists in order to try and help developers better protect their systems, but, of course, it's also extremely useful for an attacker because once the attacker knows the framework that a particular website is running on, they have an extensive number of resources, and, again, NIST is only one site which provides a list of CVE's, where they can go and find risks that might be present in that particular framework. We did a very generic search for WordPress. Inevitably, an attacker is going to start to narrow that down to the specific version of the site that they're interested in attacking. So, this is very useful, and I wanted to start with this to try and illustrate why understanding the framework and the version is a very useful piece of information for an attacker who's performing reconnaissance on a website. So, this all comes back to building that risk profile. Now, I'd like to move on and have a look at how an attacker might get that information from a website and how we could take some steps to better protect that website from leaking information such as frameworks and versions. Let's go and take a look at that now.

Server response header disclosure
We're back on our insecure website, and let's say that an attacker wants to start building a risk profile about where there might be vulnerabilities in this particular site. And as part of building that risk profile, the attacker wants to understand the frameworks and versions the website is running. Now, there are multiple ways of establishing that. For example, it's often easy to tell based on file extensions in the path. Clearly if you have a PHP extension, you can make a fair assumption that it's a PHP website, an ASPX extension is probably an ASP. NET website, and so on and so forth. Now, that doesn't necessarily tell you the version, but it starts to give them an understanding about the platform that the product is built on. An attacker can often also find this sort of information in the source code, particularly when it comes to patterns such as how does a website create say anti-forgery tokens, and that's something we'll look at in the cross-site hack section a little bit later on in this course. But it's just an example of another little telltale sign. But, again, it's a very generic sign in so far as it might give them an idea of the framework, but not necessarily details of the framework. Let's take a look though at response headers. And what I'm going to do is just turn on the Chrome developer tools, we're on the Network tab already, and I'm just going to reload this page. Let's click on that first request, and let's now scroll down and take a look at the Response Headers. And what you'll see here is that there's actually quite a bit of useful information. So, down at the bottom here, we will see that everything from Server through to X-Powered-By is telling us what technology this website is running on. So, the first thing it tells us is it's running on IIS 8. Okay, that's great. Not just IIS, but specifically IIS 8. Now, at the time of recording, that's a very current modern technology. But particularly as time goes by and more risks are discovered, that starts to become very useful information. The next three headers I have highlighted are all non-HTTP spec headers. And we touched on this briefly when went into the XSS section and we talked about that last header you see there, the X-XSS header. So, they're not necessarily in the HTTP spec, but they're still very useful. So if, for example, the X-AspNet-Version header. This tells us not only is it running on ASP. NET 4, but it goes down to the minor version details as well. That's very useful. It also tells us that we're running on ASP. NET MVC. And we could probably fairly make an assumption about that based on the way the URLs are constructed, but we wouldn't necessarily know that it's version 4. Now, again, that's quite current as of today. But particularly as we start going back a few versions, that could be quite useful for an attacker to probe known vulnerabilities. So, those two AspNet headers are clearly very specific to the Microsoft stack. The X-Powered-By header, however, is a very common header that appears across different technology stacks. And even though we now already know that this is an ASP. NET website, in other technologies that header can be extremely useful in terms of understanding what a site is actually built on. Now, again, this is obviously IIS ASP. NET, and we have some very specific ASP. NET headers there. When you look at other technology stacks, you'll see that there are very often other non-HTTP spec headers, so headers starting with an X-, that also disclose very specific information about the internal implementation of the website framework. Now, what we really want to do is just get rid of this information. There is no real functional value. It probably helps some websites that like to build up statistics about what sites are running on what version and what frameworks are popular, but it really doesn't add any value to the end user, and certainly browsers don't really use this in any tangible fashion. If we got rid of these four headers, the web application would still work just fine. In fact, it would be a little bit faster because there would be a few less bytes that we have to send down the wire. That's really incidental though. The main thing is that we're not going to be leaking this information explicitly to an attacker. Let's jump over to the secure app and see how the headers look then. Okay, we are now back over on the secure site, which has had all of the HTTP response headers trimmed down to remove anything that might disclose the framework or the server or anything else that might help an attacker build a profile of what technology the website is running on. So, let's open up the developer tools. We're on the Network tab. We'll give it a Refresh. And now let's just grab that first response, down to the bottom of the Response Headers, and now we see something quite different. When we look at these Response Headers, we are missing four of the ones we had before. So, previously we had Server and that was IIS 8; we had the X-AspNetMvc header, which told us it was running on MVC 4; the X-AspNet-Version header, which told us it was running on ASP. NET 4; and the X-Powered-By header, which told us it was running on ASP. NET. All of those headers are now gone. Now, this hasn't changed the function of the site one tiny bit. It still behaves identically. In fact, as I mentioned earlier, we've actually saved a few bytes in the response. There is now nothing left in those Response Headers that gives us any clue whatsoever that this is an ASP. NET MVC website running on IIS. What it means is that an attacker is going to need to do some further research in order to establish the technology version. There is actually one little giveaway that you can see in here, which is a default cookie name of the ASP. NET_SessionId. But, of course, values like that can also be customized. And indeed, one thing many people do is try and make all these names as generic as possible. Perhaps just SessionId, for example. So, again, all of this is about trying to make the responses from the website, from the web server a bit more generic, not letting it accidentally disclose any information about the underlying technology. So, this has made a significant difference to keeping private some of the internal implementation data about the web server and the framework. A little bit later on in this module, we'll look at how a determined attacker can still discover that information through other means. But before we do that, let's move onto the next section and have a look at how an attacker might now start to locate vulnerabilities in a framework based on the response headers.

Locating at-risk websites
In this section, I'd like to talk a little bit about how an attacker can use leaked information in response headers not to just start building a risk profile, but to also locate other websites, which may be at risk. And an example I'd like to give is to look at the Apache release history. Now, of course, Apache has been around for a long time. By all accounts, it remains the world's most popular web server. It is extremely prevalent. And, of course, over time it has evolved significantly. And like all web servers, over time it has also had its share of security incidents. The example I'd like to give though is let's look back to an old version of Apache. So, in fact, let's go all the way back to the start of 2002 when version 1. 3. 23 was released. So, that's back in Jan 2002. Now, of course, this is a long time ago, and during that time, numerous vulnerabilities have been discovered. The thing is though, even though that version was superseded in early 2002, there are still many websites running on this antiquated version. And at the time of recording, and we're about in the middle of 2013 now, it's very easy to find numerous websites that are running on this now more than 11. 5-year-old technology. First of all though, let's see if we can find some vulnerabilities with Apache 1. 3. 23. And, in fact, all we need to do is search for 1. 3. 23, and we will very quickly find even the first result is about security vulnerabilities in this version. Let's drill down and take a look at that. And what we're seeing now is another site listing CVE's. And, of course, in the previous section we talked about CVE's being common vulnerabilities and exposures, or, in other words, a nice little list of risks in particular technologies. Now, in this particular case in Apache 1. 3. 23, clearly we have a very extensive list of risks. And just as when we looked at WordPress before, we can see they span all sorts of different types of vulnerabilities. We've got lots of denial of service attacks in there, cross-site scripting risks, code overflows. It is a very broad list of risks. And we can also see from the little numeric writings here, we have writings that range from being very minor to quite severe. So, one of the things an attacker would do if they were looking at a website running on this version of Apache is they'd want to understand where some of those risks are and to see if the site remains vulnerable to them. Another angle an attacker might come from, and this is why keeping response headers private is so important, is they may simply search around the web for websites running on a particular framework. Let me give you an idea of how we can do that. If we go over to shodanhq. com, Shodan is a search engine for devices on the internet. Now, by devices, we could mean anything from webcams to SCADA systems to obviously web servers. And the thing about Shodan is it makes it very easy to search for particular web server versions. These web server versions are identified from response headers. So, for example, if we look for Apache 1. 3. 23 and we do a search, we will find a nice little list of websites that are running on this very old web server with many known vulnerabilities. In fact, we can then start to drill it down. Interestingly, Japan seems to have a very high prevalence of this web server. Let's drill down though into the Unites States. Okay, so now we're in the US, and as we start to have a look down this list, what we'll see here is that we do have typical HTTP response headers. So, clearly Shodan's crawling engine is simply making requests to the site and looking at the headers in the response. And naturally, all of these response headers are disclosing this very old version of Apache. So, this starts to give you an idea of why keeping those response headers private can actually be quite important. Let's just jump through onto the next page of results. And, again, more results all running Apache 1. 3. 23. Just to reconcile that though, let's just pick one of the results from the list. So, we'll pick this last guy just here, and we'll drill down into this website. Now, it does actually look like quite an old website. Certainly we know it's running on a very old technology. Let's validate that it is running 1. 3. 23. So, into the developer tools again, let's give the page a Refresh, and we'll look at the HTTP Response Headers of that first request. And indeed we can see that the server is Apache 1. 3. 23. So, this is sort of coming at vulnerabilities from the other angle. Earlier on, we looked at a specific website, identified the framework it was running, and then said okay we want to find vulnerabilities in that framework. So, for example, WordPress. This is coming at it from the other way where an attacker says I know that Apache 1. 3. 23 is very old and has serious risks. Let's go out and find all the websites that might be vulnerable to that risk. Tools like Shodan make that possible, but it's only possible because the websites that it has crawled are disclosing that information in the response headers. So, there are two different ways that keeping these response headers private can increase the security profile of the website. Number one by not giving an attacker information about a specific site they're interested in. They're going to have to try harder to get that, and we'll look at that in the next section. Number two by not allowing that website to form part of a database of web server technologies or framework technologies, which can then be searched to find versions that an attacker knows are vulnerable to a specific risk. And again, keeping these headers private. So, not even putting them in the response has absolutely no adverse impact on the function of the site. How you remove those headers will differ from technology to technology. Sometimes it needs to be implemented at the web server level. Very frequently it can be implemented in the actual website itself. Either way, try and get anything that discloses the technology in the website totally out of that response header. Yes you may still have things like hidden fields and cookies and other values which disclose it, but it will keep it out of crawlers like Shodan. It's going to need to be a much more targeted specific attack for a hacker to actually go through and say I want to discover specifically the platform that this website is running on. So, whilst this is certainly not foolproof, it does decrease the discoverability and increase the effort an attacker needs to go to in order to discover this site running a particular framework.

HTTP fingerprinting of servers
We've just looked at the importance of keeping web server and framework information, including the version, out of response headers of the website. And it should not be obvious that information can be quite useful firstly for identifying risks in a specific site, and secondly for locating other sites that might be running on an old version, which could have very specific vulnerabilities that an attacker wants to exploit. The thing is, though, even when those headers are not present in the response, it's still possible to determine many attributes about the server, the framework, and the version. And I'm going to look at a mechanism called HTTP fingerprinting. And if you think about this in the sort of offline world in terms of fingerprinting, it's about trying to identify very specific attributes of a particular website, which might lead it to disclose what is running underneath. It's not going to be explicit like a response header saying hey this server is Apache or this server is IIS, but we're going to look at some other telltale signs, which might allow an attacker to build a profile of the underlying technology. Now, to do this, I'm in Fiddler. And what I want to do is just issue a request to the site that we were just looking at that was running on that very old version of Apache. Now, the site we looked at was wsco. com. And this is the one that was running on Apache 1. 3. 23. Let's issue a request to that site in Fiddler. I want to go and look at the response now. And when I go through and I look at the inspectors, and let's take a look at the Raw response, we're seeing down at the bottom the Response Headers. And in this case, I want to look at two specific attributes of the Response Headers. I want to look at the Date and the Server. Now, of course, the Server is already telling us what technology it's on, but one common approach by developers who want to obfuscate the value of the Server header is to change it to something else, change it to an empty value or even change it to something amusing. I've seen some very funny server response headers in the past. Of course, they could just remove it altogether, but very frequently it is still in there. Now, what I want to show you here that's the point of this HTTP fingerprinting exercise is that the Date header is returned before the Server header. Now, that order is very important because what I want to do now is go and look at our vulnerable website, and we're going to see a different behavior. So, I'm going to go back up to the composer. Let's now issue the same sort of request to our vulnerable website. So, I'm going to jump over to hackyourselffirst. troyhunt. com, and let's now execute a request to that website. Now, of course, this is just a get request to the root of the website, perfectly legitimate request. So, here is our response now. Let's go into Inspectors. And this time we'll see something a little bit different. So, firstly we'll see the Server. And, again, we are actually seeing the explicit server here, but many times the actual value is obfuscated. So, we're assuming that there is a server response header, but we're also assuming that we can't see the value. This time, however, the Date is right down at the bottom. So, the sequence is different. In Apache 1. 3. 23, we saw the Date first and we saw the Server second. So, this little bit of information, which has inadvertently been leaked by the web server, starts to narrow down the field of possibilities as to what web server might actually be behind this site. Now, of course, there are a large number of web servers that return the Server header first and the Date header second. And conversely, there are many websites that return Date first and Server second. So, this information on its own really doesn't tell us much, but it does start to narrow down the field of possibilities. Let's narrow that field down a little bit further, and we'll make a different sort of request. Now, what I'd like to do this time is go back to the Composer. Now, we'll make things easy and just drag that original request for wsco. com over here, and what I'm going to do is change the HTTP version of the request from 1. 1 to X. 1. This is an invalid HTTP version. This breaks the HTTP spec. What I want to do though is see how the web server responds. Let's execute that request, and we can see that there is an HTTP 400 response. Perfectly reasonable. A 400 is the right response for a malformed request like this. Let's go to the Inspectors though, and this time I want to go to the WebView. And what we can see here in the WebView is a very specific response, Bad Request. Your browser sent a request that this server could not understand. The request line contained invalid characters following the protocol string. Quite true. It's not a numeric protocol. We put an X in there. It's wrong. We should get an HTTP 400. Let's go back to the Composer, drag over the request to our vulnerable site, also change the HTTP spec on that one, and execute it. Let's look at the response. Go to the Inspectors. And now we see a very different web page in the response. Bad Request. HTTP Error 400. The request is badly formed. Also all true, but most importantly, different to the response from Apache 1. 3. 23. So, here's another little piece of information that we can use to identify what the underlying server technology really is. This is all starting to give us more information to build that fingerprint. Let's do one more before we move on. And this time I'm going to make a request to my own website for security misconfiguration scanning called asafaweb. com. So, let's execute a request to that site. Now, there are a couple of things we can see here. In the request list at the top left, we can see it's actually responded with an HTTP 200. That in itself tells us something because the underlying server technology on that website is actually returning an okay response for a malformed request. The other thing we can see here is that we have a protocol violation, and this is what Fiddler is telling us. And it's saying here the server did not return properly formatted HTTP headers. Now, if we close that and we take a look at the Inspectors and we take a look at the Headers and jump down to the asafaweb request, we can see quite a different response. This buggy server did not return headers. That's a rather unique response. Let's take a look at the WebView. 400 Bad Request nginx. Now, nginx is the underlying web server. So, the response in the web page has actually disclosed the underlying server technology anyway. But just the fact that we're seeing 400 Bad Request, we're actually an HTTP 200 response. And just to confirm that amusing message, if we jump over to Raw mode, we can see the HTTP header did actually say this buggy server did not return headers. So, the point I'm making here is that we are getting a very different response from each one of those three websites to a malformed request. There are other sorts of malformed requests that we could try or even other HTTP verbs we could try. For example, how does each website respond to the HTTP verb of delete instead of get or post. Different web servers will respond differently, and they all start to give us information to perform this HTTP fingerprinting exercise. So, the point of this section is this. Turn off HTTP headers which disclose your internal frameworks. Make sure that Server, X-Powered-By, and any other non-HTTP spec custom headers, you know the ones that start with an X-, are turned off and not disclosing internal implementations. It'll keep it out of search engines like Shodan so that attackers can't go and find websites with known vulnerabilities in a particular version. It will make it harder for an attacker to figure out the underlying technology based simply on the response headers. But if an attacker is determined, there are many other avenues to discover the underlying technology. Before we saw a cookie called ASP. NET_SessionId. A bit of a giveaway. In something like an ASP. NET web forms application, there are usually going to be. ASPX extensions, there are usually going to be hidden fields called ViewState. Those are giveaways. But then, of course, there is HTTP fingerprinting. So, even if we just created HTML websites, no server-side processing, no framework implementation data leaking into the HTML output, this sort of fingerprinting exercise can still start to significantly narrow down the possibilities of what the underlying web server might be. So, definitely turn off those headers. Just don't think that just because you don't have a server response header an attacker can't figure out the server that the website is actually running on.

Disclosure via robots.txt
The theme of this module has been all about attackers trying to build a profile of a website, trying to figure out what sort of framework it might be running on, what web server it might be running on, and anything else about the site which can start to give them an indication of where there might be vulnerabilities. What could they probe on, what could they discover that might help them actually find a risk that they can exploit? Another very useful resource for attackers is the robots. txt file. Now, robots. txt file implements what's referred to as the robots exclusion standard. And the idea of this file is to provide guidance to web crawlers on indexable content. So, for example, the googlebot crawls the web looking for content in order to build its search engine index. The robots. txt file gives guidance to those crawlers about content that they should not index. And what you see in front of you here is a sample robots. txt file. And, in fact, we can see several declarations here. So, to begin with, we can see a declaration that says hey if the user-agent is the googlebot, I don't want you to index the private directory. Now, a developer might say this because they don't want people searching Google and finding results for content that is in the private directory. The second example here says hey if it's the googlebot-news crawler, don't index anything. Disallow the entire website. And in the third example we've got a little wild card here where the robots. txt file is saying regardless of what user-agent you are, whether you're the googlebot or the yahoobot or whatever bot you might be, do not index the directory called something. Now, the thing about the robots. txt file is it's entirely up to the crawler to be responsible and implement the guidance which is set forth in the robots. txt file. But that's not really the point of showing you this. What I want to point out here is that the robots. txt file very often is quite useful to an attacker because it tells an attacker the areas of the website that the developer really doesn't want other people to know about, yet they have published it in this file. Take that first example, the private directory. The developer doesn't want it being indexed, they probably don't link through to there at all on the website, they really don't want anyone to know about it. It's probably just admin's that would access that path. Had the developer not published this file disclosing the fact that there is a private path, we probably wouldn't even know about it. But now that it's there, now that it's published in that robots. txt, the attacker has a very useful piece of information because they might now go and start probing for vulnerabilities in that private path. Let's go and take a look at a similar example of this on our vulnerable website. So, here we are back on our website. Let's take a look at what is in the robots. txt file. And in this case, the robots file is saying I don't want any user agents to index the images path, the scripts path or the secret/admin path. So, there's a clue. There is a path called secret/admin. There might be something useful in this secret/admin path. So, let's copy this and go over and take a look at what we might find there. Now, in this case, we've just gotten an Access Denied message. So, it doesn't look like there's any immediate ability to exploit this particular path. However, now that we know it's there, let's take a note of that because we're going to come back and try and exploit this later on. The real point I want to make in this section is that the robots file is a broad cast mechanism. It is literally intended to be publically facing, consumable by anonymous agents just like a web crawler. Consider anything in that robots text file to be public knowledge. Certainly I've seen many cases in the past where the robots file has disclosed enough information to actually start exploiting the application. Now, inevitably that does also depend on things like missing access controls. So, for example, rather than seeing an Access Denied message here, we might actually see the secret admin page. Now, of course, this would just be called security through obscurity. The developer might assume that just because they don't link into that page and because they've told the crawler not to index it, nobody will find it. That's a very, very dangerous assertion to make, particularly when a lot of these paths do comply to predictable patterns. Secret, pretty obvious when you think about it. You'll also often see the path admin or administrator or other similar variations. And particularly when you get to third party frameworks, popular third party frameworks, attackers will regularly look for their presence by tying to access administration paths. So, the point again is simply to be cautious about what goes in the robots. txt file. Certainly it's quite valid to tell crawlers that you don't want a path indexed, but be very, very conscious that you're also telling attackers about the presence of those paths that are declared in the robots. txt file.

The risks in HTML source
The next thing I'd like to show you is the risk of leaking information in the HTML source of the page. Now, most people don't often think about the security implications of data which appears in HTML source. For the most part, someone loads a web page and they see exactly what you have in front of you now. They're not seeing angle brackets and markup and JavaScript. An attacker is though. This is one of the things they're going to look at. And, of course, what I'm talking about is simply right-clicking and viewing the page source. All developers know how to do this. Very, very simple concept. What I want to show you though is the sort of information that I do see being leaked via HTML source. So, this is the secret admin page, the one we discovered after it was disclosed by the robots. txt file. Most of this is pretty mundane information. Yet as we scroll down a little bit, we can see some comments in code, which actually appear to be quite useful to us as an attacker. Now, this might appear as a blatantly obvious, frankly kind of stupid example, and it is, but it does happen. I've seen many cases where there have been comments in HTML source that have leaked sensitive information, comments such as the password to use in order to login as an administrator. It happens. Developers aren't necessarily expecting that their HTML source is going to be inspected by an attacker. So, in this case, obviously what it's saying is that hey there is a database. zip file here. And the comment says hey only show this once successfully authenticated. Now, you've got to remember that maybe on the service-side there is other conditional logic wrapped around this thing. For example, to remove the comments when someone is successfully authenticated so that an admin can then download the database. Let's just take a look though and see if this works. So, we'll just copy that path. Let's jump over back to the website and see if we can get anything useful out of this. And, of course, here we go. We have just now downloaded the database. Now, again, this is a rather simplistic example, and it does seem quite obvious, but it does happen. As well as the disclosure of the presence of that database's zip file, there is also clearly a missing access control. I am on this website as an anonymous user. It probably goes to reason that I should not be able to download a backup of the database. That, again, is a quite simplistic example. The other sort of information that you'll find HTML source regularly leaking are things like the external frameworks that might have been implemented in the site. So, JavaScript libraries in particular are very easy to locate in the HTML source. Often JavaScript frameworks will have vulnerabilities such as cross-site scripting. So, if we can view the source and we can locate specific versions of JavaScript frameworks, and, in fact, here you can see that I'm using jQuery 2, and that's immediately obvious once we take a look at the source, as an attacker, I might now be able to say okay what risks can we see in jQuery 2? Now, of course, this is not to say don't use jQuery or any other framework for that matter. The point is to understand that HTML source has very useful information for an attacker. They will discover all these things. They will discover comments in HTML source. They will also discover things like hidden fields. And we'll have a look at what an attacker might do to manipulate the things like hidden fields later on in the module on parameter tampering. Just be conscious that if hidden fields contain sensitive data, so, for example, I've seen them contain things like passwords before, I've also seen them contain SQL statements that could be manipulated to perform a SQL injection attack, all of these things are discoverable by an attacker. So, one thing that's worthwhile doing is simply viewing the source of your pages, having a quick scroll through, and making sure that there is nothing in that HTML source. And remember, it's not just HTML source. Also include those JavaScript files making sure there is nothing in there which an attacker could then use to exploit the website. HTML source is public. Your web server is sending it down to the client. That client could be an attacker, and their intent could be malicious. Always work on that assumption.

Internal error message leakage
One of the most useful pieces of information that you can provide to an attacker on a website is internal error messages. So, these are error messages caused by unhandled exceptions in code. There are many things that could cause an unhandled exception. For example, the database couldn't be contacted or someone's provided a date in a format that couldn't be typecast to a date-type, and that internal exception has simply bubbled up to the user, so it's appeared in the browser. These exceptions can be a goldmine to an attacker because they start to disclose the internal implementation of the code, and that's what I'd like to have a look at in this section now. What I want to do first though is I want to Log in. And let's now put in my usual email address and the usual password, and I'm going to ask it to Remember me this time. And let's log back in. Okay, great. So, now we're logged in again. What I'd like to do now is have a look at one of our top manufacturers, and we're going to have a look at Nissan. So, let's scroll down and click on the View Nissans button, and this all looks fine. So, here we can see a Nissan badge, and we can see the GT-R. Let's take a look at the URL though, and we can see a very semantic pattern to the URL. And what I mean by semantic is that the URL has a very logical structure to it. So, /Make, so we must be looking at makes; /1, so we're probably looking at make number 1. Let's change this to something like 2, and now we will see make number 2. And this happens to be McLarens, and we can see the P1. What if we increment this though to a much larger number? We probably don't have 200 makes. Let's try it anyway. Now, here we start to see an internal exception. So, we have obviously entered a make ID that is outside the bounds of the number of makes in the system. Now, this is an ASP. NET web application, so we are seeing an internal yellow screen of death as it's known in the. NET world, but this is comparable to internal exception messages in all sorts of other frameworks. Now, we're seeing a whole heap of very, very useful information to an attacker here. So, we're seeing the exception type, sequence contains no elements. We're seeing the actual exception details. It's an invalid operation exception. Where it gets really interesting is that we've got line numbers and actual code here. So, now we're starting to see the code that is executing in the database. And we can see here specifically the line that failed. Line 15 is in red. And it's failing because the single operator is being applied where it's actually trying to get one single record with this ID. But as we can see from the exception message at the top, the sequence of makes contains no elements. Single will throw an exception when there is not just one single result. And in this case, there are no results so an exception has been thrown. The other interesting thing though is that it's also leaking information either side of that particular exception. So, we're seeing this next line where there's a supercars variable declared, and we're actually seeing here a SqlQuery in the string, SELECT * FROM Supercar WHERE MakeID =, and we're seeing some string concatenation with an orderBy parameter. And, in fact, we can see that orderBy is a parameter passed into the method, defaults to SupercarId. Remember this because we're going to come back to this later on when we look at SQL injection. The point I want to make here in terms of internal implementation disclosure is that this has just told the attacker a very, very useful piece of information. There is even more information though. If we scroll down a little bit, we will also see the location of the source code. So, in this case, it's actually sitting in my Dropbox on my PC in a folder called HackYourselfFirst. So, we start to get a bit of information here about the structure of the server this website is running on. We also get Stack Trace so we can see all the calls that are occurring in the stack. Very useful information to tell us the sequence of how this error occurred, where it actually occurs in the execution of the page. And then finally down at the bottom of the page we've also got some Version Information here. So, we've got the. NET Framework Version. We've also got the ASP. NET version. The latter, of course, providing us a little more information about the actual version that Microsoft's web framework runs on. And, again, this is not Microsoft centric. This pattern occurs throughout web technologies where an exception occurs, but is not handled by the website. Now, ideally this code should be more robust. If that make can't be found, the website should not be throwing an exception. The website probably should be saying something logical like hey this make doesn't exist or maybe even returning a nice friendly HTTP 404 message. It's not found. 404 is the right response to make. But rather than looking at how to properly handle this exception, what I'd like to do is jump over to the secure website and show you how the website should respond when an unhandled exception occurs. Let's go and take a look at that. Now we're back on the secure site. Let's take a look at how error handling is approached a little bit differently. So, we'll do the same thing again, jump over to the Nissan, and this time what I'm going to do is change the make to 200 again, but we're going to see quite a different response. Let's load that page. Okay, so here's what we see. We now see a friendly error message. Now what I mean by friendly is that we've kept the branding of the site, we've got a little message here provided by the developer, and most importantly, we don't have any internal implementation disclosure. So, we no longer have the type of exception that was raised internally, we no longer have lines of code, we no longer have a stack trace or framework versions. This is really not leaking anything of much value to an attacker. Now, having said that, an internal exception has still occurred for what appears to be a pretty simple error really. We've obviously just gone out of range on the makes. So, this should still be handled properly internally. But the really important difference at the moment is that when that internal error handling doesn't happen properly, we're not leaking internal information. There is, however, still a little bit of leakage here, and it goes back to the previous points on response headers. And what we're leaking here is that we can see the URL has changed to /Error, and then there's a query string that says aspxerrorpath= and the original path we requested. So, in fact what is happening here is that the application is leaking that there has been an internal exception. Now, many people don't worry about this, but it does actually give away a little bit of information to an attacker. And that information is simply that here's a section of the application where error handling hasn't been sufficiently implemented. Indeed that's the very reason we're seeing this page because that out of range exception was not handled properly. One way of obfuscating this a little bit further is to try and ensure that when an unhandled exception occurs the framework returns the exception message on the same path. Let me go and configure this application a little bit more securely and show you what I mean. Okay, I've just secured things a little bit differently here when it comes to internal exceptions. Let's go back to Nissan. Let's change that make again back to 200 and see what happens this time. So, the error message itself is still the same as what we saw in the last example. Still says Error. Still says an error has occurred while processing your request. What's different though is the URL. The URL has not changed. We're still seeing the original path that we requested. So, the real key difference between this unhandled exception and the previous unhandled exception is that we're no longer leaking the fact that an unhandled exception has occurred at least via the response path. Yes the message itself on the page tells us that an error has occurred, but this could just has easily be the error that is displayed if the exception was properly handled. The difference is that an attacker knows that the previous exception, the one that redirected and showed that error path in the query string, an attacker knows that is the pattern that occurs when the exception is unhandled, and that tells them that here is an area of the code where there really isn't sufficient error handling. This could be something worth probing. So, in summary, when it comes to internal error messages, your best option is first of all to handle the exception gracefully in code. In this case, the code should have said hey we haven't been able to get a result instead of the code just saying hey give me that one explicit record, which under normal circumstances would exist, and if it doesn't, file catastrophically and fall through to the framework's native error handling. It would have been better to say if this record does not exist, provide some sort of message back to the user. Hey, couldn't find it or a 404 or something which is more semantic about the nature of the error rather than just effectively throwing up its hands and saying hey I don't know what to do. That's your best option. Of course, as a backup, and this should always be there, there should be an appropriate error message system for unhandled exceptions. Having some form of error message in there is far better than having nothing at all and leaking that internal implementation such as lines of code and framework up into the browser and giving an attacker this little treasure trove of internal information. And ultimately the best option altogether is to implement that internal exception handling, make sure that there are customary pages there for if an exception does occur, and try and keep it looking as legitimate as possible. Try and keep that original URL in the address bar so it's not disclosing the fact that some sort of unhandled exception has occurred. What you see in front of you is the best that we can do under the circumstances. And all of it really just simply comes back to keeping information away from the attacker. Keep problems within your private code private. Don't let them leak back out to an attacker.

Lack of access controls on diagnostic data
The last thing we're going to look at in this module is inadvertent leaking of internal diagnostic data such as log files, or, in other words, where there's not sufficient access controls on sensitive system information. So, we just looked at leaking of internal error messages, and that's where an attacker can cause an exception to be raised and then view internal implementation data about the web application. That's bad. It's even worse, however, when they can gain access to an entire log of these sorts of events, and I want to give you an example of where that often happens. The example I have here is that one of the very popular frameworks within ASP. NET is a product called ELMAH, E-L-M-A-H. And ELMAH stands for Error Logging Modules and Handlers. Now, ELMAH is very cleaver in that what it does is when an exception is raised and it's not properly handled, so just like what we saw before, it will log that exception into an internal log and make it available for developers to view later on. So, when we raised that exception before where the sequence had no elements, that was logged to ELMAH, and that is what you're seeing in front of you here. Other non-Microsoft frameworks have very similar paradigms. Now, it doesn't necessarily have to be logs of unhandled exceptions. As I mentioned in the intro, it could be things like HTTP web server logs. They have very valuable information in them. Not only do they have the IP addresses of customers that are hitting the site, they often have sensitive data leaked via query string parameters. So, there are multiple different ways that internal logs have sensitive data that can be exposed to an attacker. Let's take a look at this ELMAH log though. So, here we can see the exception from before, sequence contains no elements. Let's drill down into it, and we start to see extremely useful information. So, again, we see the exception type, which I pointed out in the exception earlier on; we see a stack trace that includes everything from the path of the code through to the way the request was actually executed; and then we go down to things like our server variables. Now, they're very useful because they give us all the raw HTTP request data. So, they give us things like cookies. And if we scroll down a little bit, we can see things like our AuthCookie. We know now how valuable that AuthCookie is because it lets us hijack sessions. We also know that this website is doing some terrible things with the remember me feature and actually storing the username, which in this case as in many cases is an email address, as well as that Base64 encoded password. This is identical to a real world situation that I have written about on my blog at troyhunt. com. This is not a hypothetical. This happens. Scrolling down we can see even more information of really, really useful value to an attacker including things like the server software that the website is running on. So, again, this was the info that we tried to get out of the headers earlier on. This is indeed an absolute treasure trove of information that an attacker would love to get their hands on. Now one of the things that's really concerning about examples like this is that they're so easy to find. If we go back one page, we'll see that the index page for ELMAH has a nice little message at the top, Error Log for, and then the name of the website and the name of the server. I want to give you an example of just how prevalent these exposed logs are. So, I'm just going to go and grab a new browser window, and I'm going to do a little bit of a search. And I'm going to search for inurl, and I'm going to search for the ELMAH handler. And it's most frequently found on elmah. axd. And then I'm going to let this search auto complete including that text error log for that we just saw on the ELMAH error log page. Let's do a Google search for that. Now, what you'll see is that we've got a staggeringly large number of results for exposed ELMAH pages. Again, keep in mind that these logs have things like auth cookies that can be used to hijack sessions. They also include every other cookie that was sent in the request that caused the unhandled exception. So, if a website is doing irresponsible things like storing passwords in cookies, those passwords are in these logs that you're looking at here. This search result tells us several important things. First of all, it reinforces the importance of not raising unhandled exceptions. Those exceptions can have a very long lifetime. And other than just being a bad user experience, it can be a serious security risk. Secondly, it shows us that default logging frameworks found in predictable paths can pose serious vulnerabilities. You've got to be extremely careful to lock those down. Whether it's ELMAH for ASP. NET or equivalent frameworks for other technologies, sufficient access controls is absolutely essential. And we'll have a look at the secure site in a moment and see how that responds. And thirdly, remember it's not just unhandled exception logs. Remember those HTTP web server logs as well. They're a good example, but that's not exhaustive either. All of these sorts of log files are often made available over HTTP because that's very convenient for the developer, but they're also often accessible anonymously by an attacker. And if not by an attacker specifically looking for that risk on that website, it may just simply be indexed by Google, and that is a very, very serious risk. Here are 594, 000 results that give an attacker a very big head start on compromising websites. Let's go and take a look at how the secure site responds when we request the ELMAH log file. Here we are back on the secure site. Let's have a look at what happens now when we try to access the ELMAH log. So, it looks like it's asking me to log in. It hasn't actually provided that log to me as an anonymous user. Let's just check that even if I do try to log in, I should not have the rights to access ELMAH. Log in. I'm logged in. We can see that up here in the navigation, but clearly it hasn't shown me the log. Let's just try accessing it directly one more time. And it's taken us back to the Log in page. So, obviously I do not have the access rights. So, the real message here is that tools such as ELMAH and similar products that provide this sort of diagnostic information over HTTP are very valuable. They can be secured, but you must be exceptionally cautious with them because it really is an absolute treasure trove of data to an attacker. If you are at all in doubt or unconfident about the security position of these sorts of products, disable them. At least disable the handlers which then expose this data back publically. The middle ground is that you can often capture these sorts of exceptions on the public website, but then not expose the interfaces publically to review those. Perhaps keep those interfaces private. Ship the data back and internal behind a file or somewhere. Then review it. Choose the risk profile that best suits your situation. But whatever you do, never let this sort of data get public. Not only might it get indexed by the likes of Google, but it's then cased as well. So, even when you secure it later on, that data is still out there. The ramifications can be serious because particularly once you've had credentials exposed, you then have to ask yourself who might have accessed that? Who's indexed it? Do we now have to go back and reset passwords on accounts? It can lead to an absolute disaster for a website. So, look after this data very, very carefully. Since we're talking about the lack of access controls on diagnostic data, and I did just show you a Google search that demonstrates how easy it is to find unprotected files on a website, I want to just show you one more Google search before we wrap up the module. So, let's flip back over to Chrome. I'm just going to paste in a sample search string that I have in my clipboard, and I'd like to explain what's going to happen here. What we can see here is that the file type it's going to search for is config. So, it's looking for an extension of. config. It's also looking for a URL that contains the works web. config. Now, this is the configuration file of an ASP. NET website. It contains things such as connection strings, API keys, sometimes other credentials. Very sensitive information. But in the URL I'm also going to look for FTP. So, what this is predominately going to give us is web. configs that are accessible over FTP. Let's have a look at the results. Now, again, this is a really stunning set of results, several thousand different results where websites have got a web. config file exposed over FTP. What this means is that anonymous FTP is enabled on those sites. It's not just web. config's that are exposed. It's all sorts of other content on the website. And, of course, it's not just question of ASP. NET websites with insecure FTP implementations. You can pick other similar examples from other technology stacks. Along with things like config files, there are also often log files. So, now we're going back to the heart of this actual risk, which is simply that there is a lot of diagnostic data that is publically accessible. Sometimes it can be found when an attacker targets a specific website and looks for common paths. So, for example, is there an ELMAH path available on a website? But just as I showed you with the Shodan search engine before, it's also possible to find an entire collection of websites that might have this sort of data exposed because that's the nature of search engines and crawlers. They just go around and index all this stuff. And if an attacker knows the patterns to look for, they can easily discover these logs. It has nothing to do with whether you think someone might be able to find that path. If there are not access controls over it, you have to make the assumption it will be found no matter how obfuscated the URL might be. So, in summary for this section of the module, be very, very conscious about what content is publically accessible. Always go through and do these checks. Manually check that an unauthenticated user can't access resources that only should be available to site administrators. And equally, make sure that protocols such as FTP don't have anonymous access enabled. You can see how easy it is to find vulnerable sites using simple searches, so be very, very vigilant.

Summary
Let's summarize the module. And the first thing we covered was about keeping information about frameworks and server versions as private as possible. I showed you how it's very easy to locate known vulnerabilities for specific frameworks and specific versions. We looked at that very old Apache version. Heaps of vulnerabilities out there easy to locate with some simple Google searches. Conversely, when you know that a particular framework and a particular version is vulnerable, search engines like Shodan make it very easy to find a bunch of websites that might be out there and vulnerable. So, be conscious that once you're on the net, you are searchable based on your framework and version. So, definitely obfuscate them and don't disclose anything you don't absolutely positively have to. Also, don't rely on obfuscation alone. There are other ways of an attacker identifying the framework and the version. So, we talked about things like the names of cookies or the names of hidden fields. We looked at HTTP fingerprinting, little subtleties like the order in which the HTTP response headers are sent in can disclose the framework version. Also, how they handle errors. We issued requests with an invalid HTTP spec and saw that we got very different responses from three different server technologies. So, you need to remember that frameworks and versions are actually very subtly leaked by the server. Also, be conscious of what you might be inadvertently disclosing. And by that I mean things like robots. txt. Have you possibly got paths in there which disclose parts of your website you really don't want people knowing about? And if you do, you need to be very, very certain that they are properly secured. Also, does your HTML source possibly disclose things that you didn't intend it to? We looked at a very basic example where it pointed to a backup, but there are many examples of things like credentials or SQL strings or other really sensitive internal data being exposed in HTML source. Whether that's in the HTML page or whether that might be in JavaScript, be conscious that for all intents and purposes, HTML source is public. Internal exceptions, extremely important that these guys get kept away from users. If you have an unhandled exception, you must use the framework's features to ensure that an error message is displayed to a user that doesn't disclose any internal implementation. Users should never see file paths, lines of code, stack traces, versions of frameworks. None of that should bubble up. And also be conscious if you're concerned about it how those error patterns might disclose the version of technology. If you can, just make sure that the requested path is returned so the address bar doesn't change, you're not responding with an HTTP 301 or 302 or anything like that, and that there's a friendly error message displayed. So, for all intents and purposes, the pattern looks like a valid response. And lastly, those internal logs. We saw how ELMAH has so much valuable data in it. And it's not just ELMAH. There are all sorts of other examples across other technologies. Not only do they have sensitive data in them, but they're easily discoverable via Google. This stuff gets indexed. Not just log files, but also things like configuration files stood up over anonymous FTP. We saw thousands and thousands of results there in those Google searches of extremely vulnerable websites that could almost certainly be readily exploited right now. So, be very, very conscious about your access controls on that sort of content. Always check. So, for example, fire up an incognito browser session and make sure that as an anonymous user you cannot access any of this stuff. If an attacker gets that, it can be absolutely catastrophic.

Parameter Tampering
Introduction
Hi. This is Troy Hunt, and in this module we are going to be looking at parameter tampering. We're going to start out the module by briefly looking again at the concept of untrusted data, which we first covered back in the XSS module. This time though we're going to start to focus quite closely on untrusted HTTP request parameters or other aspects of an HTTP request that might be manipulated by an attacker. We'll then move on to actually capturing some of the requests that are being issued by our insecure app and manipulating the parameters in order to get the application to behave in ways that the developer never expected it to. We'll then continue to manipulate those parameters to circumvent existing application logic. And it turns out that in this particular app, once we start to tweak some of those request parameters, we can get the app to behave in ways that it was never designed to do. We'll then move on to having a look at how we can exploit the fact that there is missing server-side validation because some of the features of the application are entirely dependent on client-side validation. And it turns out that we can circumvent that control pretty easily. We'll then move on to having a look at the concept of model binding, which is a pretty common concept across all sorts of different server-side frameworks. Once we understand model binding, then we can move onto a mass-assignment attack. And this sort of attack is also pretty common across different types of frameworks that implement model binding. We'll also then take a look at HTTP verb tampering. So, when I say verb, we're talking about things like GET requests versus POST requests. How can we tamper with those in order to exploit weaknesses in the application? The last thing we'll look at in this module is fuzz testing. And what this will involve is using some automation in order to bombard the application with unexpected data so that we might be able to automate the process of finding weaknesses in the way it handles parameters. So, that's what we're going to cover. Let's move on to recapping on that untrusted data.

Identifying untrusted data in HTTP request parameters
This module is going to be very focused on how an attacker can provide data to the system in such a way that it behaves outside the expected bounds of the way the developer implemented it. So, we're going to look at numerous way that an attacker can change attributes of the HTTP request to do all sorts of things from circumventing access controls to bypassing validation and all the way through to exploiting some native framework features that are primarily intended to make development easier, but may actually be used by an attacker to breach a system. Now, when we talk about parameter tampering, we're really talking again about untrusted data. And if you recall, back in the XSS Module we looked quite a bit at untrusted data. I'm going to look very briefly at two slides that we covered before just to recap because it's extremely important to understand these concepts for this module. So, when we spoke about untrusted data, we spoke about where the integrity of the data is not verifiable. So, for example, something like a query string, which is normally just passed as a hyperlink from one page to the other, may have actually been manipulated in the address bar by the attacker. We also discussed how you must expect untrusted data to potentially be malicious. It's untrusted. We don't know what the intent is. We must expect that the intent could be evil. Then, of course, that untrusted data may contain attack payloads. Things like SQL injection, which we'll look at a little bit later on in the course; cross-site scripting, which we've already covered; or even things like binaries containing malware. All of these are examples of attack payloads in untrusted data. The other thing we looked at briefly earlier on in that XSS module was the common sources of untrusted data. So, for example, the user provides untrusted data in the URL via a query string or possibly a route. So, in other words, the actual path that is being requested. Another very common source of untrusted data is in the POST body of a request. So, a user fills out a form. It gets posted to the server. Then, of course, there is data that comes automatically from the browser. So, things like cookies or other request headers. And we'll look at this in detail in the next slide. We also covered the fact that untrusted data could come from all sorts of other sources such as an external service or even in your own database, and we looked at the risk of persistent XSS earlier on where the attack was already in the database. So, when it comes to parameter tampering, all of these different sources of untrusted data are points where an attacker may change the data that is being sent to the server, or in other words tamper with it, in order to get the application to behave in a way that the developer never expected it to, certainly in a way that they never designed it to. Let's have a look at just how much data we can tamper with in an HTTP request. So, this is a very typical example of an HTTP request, and, in fact, this HTTP request is when I logged on to the insecure site. Now, there is a lot of data on this screen. There are more than a dozen individual attributes which could easily be manipulated by an attacker. What you've got to remember is that everything you see on this screen, although automatically sent by the browser, can also be sent by an attacker and manipulated in any way they like. And we're going to look at how to do this in Fiddler in just a moment. What I'd like to do first though is just go through some of the key areas of this request that an attacker might want to manipulate in order to exploit an application. And the first part of the request that could be manipulated is the HTTP verb. So, in this case, it is a POST request. And it's a POST request because we've just filled out a form and submitted it, so it has a POST body, which is the data down at the bottom of the screen with the email address and the password. Now, an attacker can easily change a POST request to be say a GET request, or they could make it a PUT request or a DELETE request or any of the other less common HTTP verbs. The point of all this is simply that that verb may be changed. And during this module, we'll have a look at how we can actually mount an attack by changing the verb. The next part of this request is the path. And in this case, we can see that it's an HTTP address. Now, the fact that it's an HTTP request doesn't save us from parameter tampering because, of course, an attacker can easily manipulate an HTTP request and simply reissue it themselves. All it really means is that their attack payload is going to be encrypted in transit. So, great for them. Not real great for the application. Now, of course, we can change this path. So, for example, we could change the route. Rather then being Account/Login, an attacker could manipulate it to something else. The path also often has a query string, and an attacker can manipulate the query string. The next piece of this request is the HTTP version. And in the previous module when we looked at internal implementation disclosure, we manipulated the HTTP version to give it an invalid version when we made it X. 1 in order to do some HTTP fingerprinting, or, in other words, to try and identify what the web server was running by looking at how it responded to a request with an invalid HTTP version. So, you might not normally think of this as untrusted data, but certainly it can be manipulated in order to make the application behave in an unexpected way. The next piece here is the Accept header. So, in this example we can see that there are a number of different formats that the browser will accept. So, obviously it will accept HTML markup or XHTML markup or XML. That Accept header can be manipulated to any value the attacker likes. And the web server will often behave differently based on the value of the Accept header. A very common example is whether or not the browser accepts JSON or XML so that a web service knows what format to return the data in. This is just another attribute of the request, which an attacker could manipulate in order to have the application behave in an unexpected fashion. Another piece of data that applications commonly rely on is the User-Agent. And the User-Agent is used so that the application can try and identify the device and the browser that's making the request. So, for example, this User-Agent identifies that I'm using a 64-bit version of Windows 8 running Chrome 28. Applications often pass this data in order to determine how to respond to the client. They also often store this data. So, for example, this data is frequently stored in log files. If an attacker was able to inject say some SQL injection in the User-Agent, there may be a vulnerability in the application they can exploit when this data is saved to a database. That's not the only attack vector for the User-Agent string, but it's just an example of how it might be exploited. Another point an attacker might focus on is the Referrer. The Referrer is often used in application logic so that the page being request may behave in different ways depending on where the user has just come from. If, for example, that Referrer path is reflected to the screen, an attacker might be able to exploit an XSS risk in the referrer header because ultimately the Referrer is just like all the other attributes you see on this page in that it can be manipulated. And it can either be manipulated in the request itself or an attacker may construct a request such that a victim goes through a path that has a malicious payload in the address, and then the browser automatically attaches that when they link through to the target site. Another easily exploitable attribute of an HTTP request is the Accept-Language, and this attribute is regularly used in order to tailor the language of the page to the user. So, for example, the developer may send the Accept-Language value through to the database when the request is made in order to pull back the correct language for the user accessing the page. If that database request had a SQL injection vulnerability, an attacker may be able to manipulate this value in order to exploit the application. Another very common source of parameter manipulation is the cookie. And throughout this course we've looked at cookies a number of times in terms of the way they pass things like authentication tokens. Also, in terms of the fact that often they can have some sensitive data in them, and often they're used as a persistence mechanism in order to tie an individual user across multiple requests. Now, hopefully that's done with a secure tamperproof auth cookie, but very frequently it's not. And, in fact, it's quite often very easy to manipulate cookie values and then circumvent access controls or get the application to behave in a very different way to what the developer intended. And finally, we have the request body. And in this case the request body is part of the POST request, and we can see these attributes have come from submitting the long on form. So, obviously I've provided the Email address and the Password and the RememberMe checkbox. Manipulating POST data is extremely easy, and it's a very, very common route in order to exploit an application, particularly for things like SQL injection. Now, when we talk about the parameter tampering of POST data, manipulating form data or data that was actually filled out on the web page in things like text boxes is one thing, but you've also got to remember that applications very frequently post form data from hidden fields, and they use this as a means of persistence. So, for example, I've seen many cases where there have been SQL strings in hidden fields. Now, as soon as you see that, that opens up the potential for things like SQL injection. So, the point is that it's very easy to observe and manipulate form data that you can actually see on the web page in HTML form fields. It's quite another thing though when there are hidden fields. And I say that simply because developers often don't expect hidden fields to be manipulated, but they are untrusted data so they go back to that earlier slide about not being able to trust the integrity of a hidden field. So, these are all different attributes of the HTTP request that we can tamper with in order to get the application to do things that it's just not designed to do. Let's now move on to actually capturing a request and starting to manipulate some of these attributes so that we can exploit our vulnerable application.

Capturing requests and manipulating parameters
In this part of the module, I would like to look at how we might capture and manipulate parameters in order to get the application to behave in an unexpected way. And, in fact, what we're going to do in this case is we're going to capture a POST request, manipulate the form data that is sent in that POST request, and some of it is sent via hidden fields, and we're going to use that to circumvent access controls in the system. Now, the first thing I'm going to need to do is log in because what I'm ultimately going to do is vote on a vehicle. So, same old user name, same old password. Let's Log in. And I'm going to jump over to the Leaderboard, and I'm going to jump down to the Lexus LFA. Now, I do want to vote on this, but before I vote, I want to jump over and make sure that Fiddler is running and capturing requests. Okay, so here is Fiddler. There are no requests in there at all. Let's jump back to the Lexus and leave a vote. So, at the moment there are no votes at all for the Lexus, so let us now vote, and we might be a bit cheeky and say is this a Toyota? And let us now Vote. Okay, the vote has been cast. We can see there is now 1 vote out of 20. So, that has been lodged. Thank you for voting. Let's go and see what was captured in Fiddler. So, this is a very typical POST request. It has been posted off to api/vote. We can see my AuthCookie has gone with the request. And if we have a look at WebForms, we can see my userId number 1 has been posted, we can see the supercarId of number 10 has been posted, and we can see my cheeky comment here about whether or not this is Toyota. What I want to do now is I want to reissue this request, but I'm going to manipulate some of these parameters. Now, the easiest way to do that is we'll just jump up to the Composer tab, we will drag the request over here into the body of the Composer tab, and we can now see all my Request Headers up at the top just here, and we can see my Request Body down at the bottom just here. Now, before I actually manipulate any parameters, I need to figure out which ones I would like to manipulate. And to do that, I just want to jump back to the web application and find another car that I might like to vote on. Now, just before I flip back over to the browser, I'm just going to stop Fiddler from capturing so that we don't see the other requests I'm just about to make in our timeline here. So, let's jump back over, and I think I'll jump back over to the Leaderboard. And this time, let's go down and have a look at the Aston Martin One-77. And we can see that there is presently one vote for the Aston. Now, the other thing we can see is up in the address bar the Aston is supercar number 8. Okay, so let's flick back over to Fiddler and start to manipulate those parameters. Now, the first thing I'm going to manipulate is the SupercarId. So, let's make that number 8. That's the easy one. Now, of course, that alone really couldn't be considered parameter tampering because there's nothing to stop me as a logged on user from going back to that Aston Martin page and simply clicking the vote button. What I want to do though is start to actually manipulate data, which the developer probably never expected. And what I'm going to do is actually change the value of this userId field because what seems to be happening here is that my ID is being passed in the Request Body. Now, this is a little bit odd because I'm already logged on, there's an authentication cookie, and that's really the attribute that the developer should be looking at to identify me, but for some reason, they're passing my user ID. Now, this seems odd, but it's not that uncommon where there's this sort of side channel of identity and it's being done by passing a parameter that we can manipulate. So, let's actually change this. We're going to change it to 10. The last thing we might do then is just change the comments here. So, let's actually change this to Parameter, and we'll put a plus in to escape its space, tampering, for the win. Okay, that should do it. Now, this is really important because what it means is that if we can successfully submit this request and it is actually recorded against userId 10 and not userId number 1, we've been able to tamper with parameters in order to circumvent access controls, and that's a pretty serious risk. Let's execute this. Okay, it's executed. We can see the request here. We can see the result is 201, and that's the HTTP status code for created. And clearly what this has done is actually created a record, so that's a perfectly valid response code. Let's jump back over to the Aston and see what we can see. So, here's where we left the page before. There was 1 vote out of 20, and there are currently no comments for the One-77. Let's now Reload this page. And here we go. We can now see that there are 2 votes. And, in fact, we can see that Nico Roseberg has made a comment of parameter tampering for the win. Now, we know that wasn't really Nico. We know that was us manipulating the parameter of the userId, and as it turns out userId 10 is Nico. Now, the thing about this example is that there is no way you can get the application to do this just by using it legitimately in the browser. The developer may have done extensive testing. QA may have done extensive testing. All of this testing done in the browser would not have shown up this risk. You have to drop back to the level of the raw HTTP request and start manipulating parameters in order to discover this risk, and that is a very, very important pivotal concept of hack yourself first. You have to step out of the comfort zone of the browser in order to try and exploit an application in the way that an attacker would. And certainly as you can see here, when you do that, it's possible that you'll find serious weaknesses in the application. So, clearly this is a serious risk. This is an access control circumvention via parameter tampering. Let's now jump over to the secure application and see how it handles this situation. Now that we're over on the secure site, let's see how the application responds differently to parameter tampering like we just exploited on the vulnerable side. I'm already logged in this time, so let's just jump straight over to the Leaderboard, and we'll repeat the process. Let's go back over to the Lexus. Let's make another vote. There are 0 votes at the moment. Same as before. And we'll leave the same cheeky comment, is this a Toyota? And then same as before, just before we actually submit this form, let's jump over and make sure that Fiddler is running, and we'll just start at capturing requests again because we want to be able to grab this one. So, jump back over to the web page. Let's now cast our vote. Okay, that's good. We've now got 1 vote out of 20 there. Back over to Fiddler. There's the vote that we just cast, and we can see now that is on the secure. hackyourself host address. We'll drag that over into the Composer. Before we changed this so that userId was number 10, and we changed the SupercarId to number 8. And now let's change this again to Parameter tampering for the win. Okay, now let's execute this and see what happens. Alright, now we have a very different response. We have an HTTP 403 this time. And, of course, a 403 is forbidden. This is the correct status code for the application to return when the user is not authorized to issue the request they're attempting to send. Now, in reality it's still probably a little bit pointless that this request is sending a userId and also sending an AuthCookie. However, there may be valid use cases where you need one channel that explicitly identifies a user and another channel that explicitly identifies an authentication state. So, for example, there may be an administration facility to vote on someone's behalf. The authenticated user would then be the administrator, and the person making the vote would be another identity. So, it's possible. And certainly one of the things worth validating is whether these two separate identity channels, the AuthCookie and the explicit userId field, are actually required or not. In the case we just looked at, they're not. But, again, maybe there's another facility somewhere where an administrator can go and unlodge that vote on someone's behalf, and that would be a case where this might make sense. The important lesson in all this though is, again, you've got to drop back out of the browser and get down to that raw HTTP request level in order to probe for weaknesses of this kind. And, of course, it's extremely easy to do. You just fire up Fiddler, capture requests, and then start manipulating parameters such as what we saw here. It's an extremely simple task. And, in fact, as we progress through this module, we'll look at how to make it even easier using approaches such as fuzz testing. For now though, this is the very simple introduction to what it means to actually tamper with parameters. Let's now move on to taking a look at how we can start to manipulate application logic and circumvent other controls through further manipulation of untrusted data via parameters.

Manipulating application logic via parameters
Now that we've looked at the ability to circumvent access controls using parameter tampering where the application isn't actually validating that userId correctly, let's move on to having a look at how we might be able to manipulate some application logic, again, by manipulating parameters. And what I'd like to do this time is have a look at the GT-R, and we've got it here on the front page. And we can see here on the GT-R we have a little message saying you've already voted for the GT-R. Now, the GT-R has 4 votes out of the 20 total, and clearly one of those is my vote. Now, that's great, but I'd really like to make some more votes for this car. So, what I'd like to look at is how I might be able to circumvent the logic, which restricts an individual from making multiple votes. Now, what we've got to remember is that the page that we're looking at here has obviously turned off the vote button. So, if you recall, we're just going to check another car, something like say the Lamborghini has a vote button just here. If you have not voted, you can click on the vote button. If we go back though and jump into the Nissan, if you have voted, you get the message like this. So, clearly there is application logic on the server-side which says hey if you have voted, show the message you see here. If you haven't, show the button. Now, that's fine. But what I'm interested in is whether there are the appropriate access controls on the resource that vote button hits to ensure that the same person can't vote twice. So, what you're seeing on the screen here is almost like security trimming, or, in other words, turning the visibility of features on and off depending on the vote history of the user. But that's really just a facade. What about the service behind that? So, here's what I'm going to do. Let's jump back over to Fiddler, and we've still go the earlier requests I made from the previous section in this module. What I'm going to do is drag over the very first request I made, which had my userId on it, and it was to supercarId number 10. Now, the GT-R is supercarId number 1. And what I'm going to do now is I'm also going to change the comments. So, let's just call that GT-R, and, again, we'll escape the space symbol, for number 1. Let's now see if we can issue that request. And we've had an HTTP 201 response, or, in other words, an HTTP created. For all intents and purposes, it looks like we've just cast a vote. I want to be sure though. Let's just make a couple more votes. That looks like it should be enough. We've now just made three votes for the GT-R. Let's skip back over to the browser and Reload the page. Here we go. Our votes have just gone from 4 up to 7, and clearly we now have a number of different comments here as well. So, what this has demonstrated is that there is not a sufficient control to ensure that the person can't actually vote more than once. Yes the button was hidden, but the service, which sits behind that button, and if you recall, the path of that was /api/vote, that service isn't validating whether this user has already voted. And clearly it's allowing me to gain the system, or, in other words, manipulate the outcome to my advantage. And in this case, the advantage I'm looking for is to get the votes up on the GT-R. So, clearly this is now another case of insufficient access controls. Let's jump over to the secure site and see how it approaches things a bit differently. Here we are back on the secure application again, and now we should see a very different response if we try to make multiple votes for the same vehicle. Let's jump into the GT-R again. And, of course, I have already voted. It's the same situation as in the vulnerable app. Now, let's jump back over to Fiddler. And I'm going to do the same thing as I did last time in so far as I'm going to take a request that I've already made to the secure site like so, and I'm going to change the supercarId to number 1, and I'm also going to change the comments. And we will make it the same comment as before, GT-R for number 1. Now, let's try and issue that request to the secure site. And here we see an HTTP 403 forbidden. So, it is not letting us submit that request. Like before, we'll just try and hit it a couple more times. 403, 403. It does not appear to be letting us get that request through to the website. Let's just jump over and make sure that really is the case. We'll give the page a Refresh. There are still only 4 votes. There is still just the one comment from me. That is it. I have not been able to go and gain the system or manipulate the votes by adding more votes when I've already voted once. Now, of course, all of this doesn't mean that I can't go and submit a vote via Fiddler. And, in fact, if we take an example, let's go to the Leaderboard, let's go down to the Lamborghini, I haven't voted on the Lamborghini. The Lamborghini is SupercarId number 7. Back over to Fiddler. Change that supercarId to number 7. We'll be cheeky and just leave that comment there. Let's execute the request. We're getting an HTTP 201, which is just fine. That is a created response. We'll go back, Reload, and now there are 2 votes, and here is my comment about the GT-R for number 1. So, clearly I've still been able to vote via Fiddler. And that's just fine because ultimately all I've done is made an HTTP request. 99. 9% of the time that will come from a browser, but there's nothing to stop me from making a request via Fiddler and it still being a valid request. And I'm making that point just to try and help you start to think about abstracting between the HTTP stack and the web server underneath and the clients that sit on top because what tends to happen is developers build a lot of controls into the HTML and into the markup, and that's exactly what we saw in this example here. The access control was whether or not the vote button could be displayed. The access control in the vulnerable application did not exist on the service itself. And what we need to remember is that access control needs to persist across every point in the system where an attacker could potentially attempt to exploit the app. And, again, all of this comes back to just trying to take a step away from the browser. Drop back down to this HTTP stack. Look at those requests in Fiddler. Look at all the request headers. Look at things like the path and the cookies and the accept headers. And look at the request body. And, of course, that's what we were just manipulating. If you start changing those values, which again is what an attacker will do, can you cause the application to behave in a way that it shouldn't? That is the essence of parameter tampering. With that concept now understood, let's move on to how we can circumvent other controls in the browser by issuing requests directly out of Fiddler.

Testing for missing server side validation
A very common pattern with web applications is to perform validation on the client side before posting it to the server. So, for example, you're filling out a registration form, and the registration form requires a name and an email address. The name field must be completed, and the email address must adhere to an allowable pattern. Now, you could just validate that on the server, but, of course, if say the name was missing, it would require a post back to the server, which introduces latency for the user whilst they wait for that to happen, and, of course, it puts a little bit of load on the server while it processes the request when in reality, using JavaScript in the browser, we could have already determined that this form really wasn't ready to be submitted. Consequently, client-side validation is very popular. And there's nothing wrong with client-side validation on its own. The problem, of course, is that attackers have control over the client. And what I mean by this is that if they don't want to run JavaScript on the client to perform validation, they don't have to. They can circumvent it and just issue the HTTP request directly to the server using a tool such as Fiddler. So, client-side validation is great, but it must be complimented by server-side validation. And I want to give you an example of where this can go wrong. So, let's do this. I'm going to log myself out, and now I'm going to go over to the Register link. And what I'm going to do now is register a new account. And the email I'm going to use is jameshunt@f1. com. First name James, but in the last name I'm going to put in some XSS. Let's keep it really simple, and we'll just say <script>alert. And we'll just alert out the words XSS, close the statement, close the script block, and then I will give it a password. Let us now try and register. And here's what we'll see. Right at the top in our validation, we can see that we are being told it is an invalid last name. Now this happened very quickly, a little bit too quickly. It looks like this is being validated on the client. And just to confirm that, let's open the developer tools, let's go to the Network tab, and let's submit this again and see if we actually get an HTTP request. And we don't. I've just clicked that. I'll click it again and again. There is no HTTP request. This validation is happening entirely on the client side. Now, once again, all this is fine. This was great. It was very responsive. I got immediate feedback that last name was incorrect without having to wait for it to post to the server. But let's have a look at how we might circumvent that client-side control. So, what I'm going to do is change that last name to Hunt. And just before I post this, I want to go and grab Fiddler. And we can see here that there are presently no requests in Fiddler, and it is actually capturing. Let's go back to the WebForm. We will register. And now we can see that we are logged in as James, so obviously that has been successful. Let's jump back over to Fiddler, and we can see a couple of requests here. So, we can see the HTTP 302, which posted the form, and then we can see the 200, which is where the registration form redirects to after it has successfully processed the form. I'm just going to stop capturing requests so that we don't have anything else appear in here during this exercise. And what I want to do now is actually manipulate the request that we made. So, we're going to go back to parameter tampering again. So, let's go over to the Composer, and let's drag over this POST request we made. And here we can see the form that we just posted. So, for example, we can see the Email address, the FirstName, the LastName, and so on and so forth. What I'd like to do now is manipulate these parameters to see if we can circumvent the validation. So, we know that the validation on the LastName happened on the client. Let's see if validation on the LastName is also happening on the server. Now, we've already registered one account with the email address jameshunt@f1. com. Let's make this one jameshunt2 because this system demands a unique email address. Now, the other thing I want to do is go back to that LastName because that's what we tried to manipulate last time. Let's try it again. And this time I'm going to send script. And what I want to do is a little location. href to force the browser to redirect. And the path that I'm going to give it is going to be to our attacking website, http://attacker. hackyourselffirst. troyhunt. com. And what I'm going to do is I'm going to inject a little link through to malware. exe, which should be a pretty self-explanatory name. Let's close off that string, close off that statement, and then close off the script block. So, now we have reconstructed the original legitimate request. We're going to leave this password as it already is, which is Winning with a capital W. Let's now Execute this composed request. And here we go. We have had an HTTP 302 response, which is again what we would expect, which, of course, then results in an HTTP 200 after it redirects. So, this is the same pattern. Let's jump back to the website and see if we can log on with that new account. So, here's the old one. We're going to Log off that one. Let's try and Log in now. And the email address is going to be jameshunt2@f1. com, Winning, and we'll Log in. And it's saying Hello James. So, obviously this account has been successfully created. Now, what I'd like to do is jump back over to the Leaderboard, and I'm going to jump down to the Ferrari LeFerrari. Now, one of the first things we'll see here actually is that we somehow have a Lotus logo on the comments left by Kimi. Now, what's a bit interesting about this is that as you saw earlier on, when you vote you can only provide plain text. There really isn't a facility to do anything like add HTML markup or any other sort of rich text format. So, for all intents and purposes, it looks like Kimi might have taken a little bit of a shot at some persistent XXS here. And, again, as we saw earlier, we know that this feature is at risk of persistent XSS, both due to lack of input sanitization, and also lack of output encoding. Regardless, we're now logged in as James Hunt. I would like to vote on his behalf. And what we might say is something like never liked these guys. And let's go through and cast that vote. Now, the first thing that we'll see is down towards the bottom left of the browser, we can see malware. exe. And what appears to have happened is that this page has auto-redirected. And indeed we can see James' comment down here, but what we actually see is just James' first name. We don't see Hunt. We don't see that last name. Now, of course, what's happened is if we go through and run the inspector on that element, we will see that last name is indeed there, but what's actually happening is the last name was that piece of XSS, and that's why we're not actually seeing Hunt. We're seeing exactly what we entered. We're seeing the XSS that we managed to send directly to the server during registration. Now, obviously we've looked at persistent XSS before, and the real story in this module is not about XSS. The real story though is that there is client-side validation that didn't allow us to register with that last name when we entered it in the browser. The pivotal piece in relation to parameter tampering is that validation doesn't happen on the server side. So, get rid of the browser, go straight to Fiddler. And obviously once you're just posting an HTTP request, there is no client-side validation in place at all. We were able to entirely circumvent the input validation. Now, it's a little bit worse than this as well because for this particular feature, it's not just me as a logged in user who's going to see this XSS. If we go up here and we copy the URL, and then in Chrome we can do Control+Shift+End and get a new incognito window, what we've done is that by circumventing that input validation, we'll find that even an anonymous user can go and load this page, and they're going to get hit with malware as well. So, now we can see down at the bottom left it has downloaded another instance of malware. exe. It's a second instance. That's why there's a 1 after the file name. So, this is now a combination of a persistent XSS attack, which we were able to execute by circumventing client-side validation and posting directly to the server. So, that's also a good example of where attacks start to chain together. So, you might not normally think that something like missing server-side validation on its own is too important. However, combine that with an attack like persistent XSS, and you can see that we've actually got a pretty serious problem here. A more creative attacker might have named this file something a little bit less obvious than malware. exe, perhaps something that sounded like it was related to the site. Maybe the latest Ferrari wallpaper for example. Now, if a victim went to the Ferrari page and was served up from this site a file called ferrariwallpaper. exe, the attacker has a much greater chance of the victim actually executing that malicious file. And indeed malicious software is very, very frequently delivered via legitimate websites. It's just that they've been compromised by an attacker. So, the lesson here is very similar to the last couple of parts to this module, which is that when you go around the browser and you issue HTTP requests directly from a tool like Fiddler instead where you can manipulate parameters and circumvent client-side JavaScript and then start tampering with parameters, very often the results are quite different to what normal testing shows up, to what a developer might test their application for. Now, there's another very easy way to do this as well. I'm going to close this incognito session, and I'm going to go back and log us out here. And I'm going to go back to the Register page. We can get rid of that malware. exe. And what I'm going to do now is go into my Settings, and I'm just going to search for JavaScript. And we're not going to allow any JavaScript to run on this site. Let's now close the window. And now that we've turned JavaScript off, let's just Reload this page. And when we do that, we'll get the little icon up here in the top right of the browser, which indicates that JavaScript was blocked on this page. And let's now register a new account, and we're going to make this nikilauda@f1. com, first name Niki. And let's just try that very basic XSS attack again because all we want to do is just demonstrate that we can actually get some script through. Close off the string, close off the alert, close off the statement, and close off the script block. We'll give him a password. And now let's Register. And what do you know it, Niki has been able to register. This page now looks a little bit odd. We've got no image carousel because it is dependent on JavaScript. But the real message here is that when we turned JavaScript off in the browser, there could be no more client- side validation. So, this is another way to easily test for the presence of input validation on the server side because the client simply can't do it anymore. Indeed there are people that legitimately turn JavaScript off. So, you've got to be very conscious that even outside of attackers, and certainly this is one way for an attacker to test for the presence of validation, but outside of attackers there are legitimate use cases where people don't have JavaScript enabled and you must be able to fall back to validation on the server. Let's now go over to the secure application and see how it deals with server-side validation when it hasn't happened on the client. Now we're back over on the secure site, and I want to look at how input validation is performed on the server- side, as well as the client-side. So, let's try the exercise we just did again. And that means that we need to jump over to Register. Let's just check that Fiddler is actually capturing traffic. So, we'll make sure that's running. Back over to the registration form. The email address we entered was jameshunt@f1. com. And, of course, this was the legitimate post so that we could put it into the Composer in Fiddler before we manipulated it. Let's Register. Okay, back over to Fiddler. And here we see again the same old 302 followed by a 200 pattern. Let's now go to the Composer, and we're going to drag over that initial request, the one that posted the registration. And, again, we will change the Email address to jameshunt2 and the LastName we'll just go back and so our basic script alert again. So, alert, XSS, close off the script block. Let's now go and execute. Now, here's what we can see. We've actually got an HTTP 200 response. So, the first thing we see is it's not the same 302 followed by a 200 pattern that we've seen when we've registered on other occasions. Let's go to Inspectors. And we can see here that we are on the WebView. And if we have a look at the contents of this response, and we scroll down a little bit, we can see that there has been some validation on this page that says invalid last name. And, of course, we can see the script block there that we just entered into the last name. So, what's happening here is that we're seeing exactly the same response as when only the client side did the validation. Of course, we're not seeing the CSS in this view because it's just the raw HTTP response, but clearly the markup is the same. Now, this is really important because we have entirely circumvented the client-side input validation, and, of course, we've done that just by posting from Fiddler, yet the server has still performed the same task. So, in this case, the server-side validation has saved us from being able to sort of go around and dodge the controls that exist on the client side. So, the lesson in this section is simply this. Always go through and test how the application behaves when the client-side validation doesn't exist. Turning off JavaScript in the browser is one way of doing it. Capturing the requests in Fiddler and then manipulating them is another. And, of course, once you do that in Fiddler with the Composer, it's also much easier to manipulate the parameters whilst you're there. But really in both these examples, so the parameter tampering and the manual reissuing of requests in order to circumvent client-side validation, all come back to trying to take the browser out of picture and throwing all sorts of random input at the application and seeing how it responds. And as we've seen with our insecure application, there are all sorts of attack vectors that can be exploited when we start doing that. So, again, that's something that really needs to form part of our your testing process as developers. You're probably not going to get that sort of thing from people performing quality assurance testing or user acceptance testing. It really is about hacking yourself first in this example where you're trying to break your own system using the sort of techniques you've seen here, which is exactly what an attacker is going to do once your site is out there on the World Wide Web.

Understanding model binding
What I'd like to talk about next in this module is to help you begin to understand the concepts of model binding. Now, model binding is a fairly common construct and a fairly common pattern within web-based application frameworks. And ultimately it's a pattern that's there in order to help the developer build applications faster and easier. Now, this pattern centers around the concept of a model. And what you're looking at in front of you now is an example of a model. And a model is simply a representation of some form of entity. So, in this particular example, we are seeing a model of the user profile entity. Now, this user profile happens to be a class in my application. It is an ASP. NET application, but the same object-oriented principle applies to many other frameworks, and this user profile model has the attributes that you see here. And in this case, they're represented as properties, Email, FirstName, IsAdmin, LastName, Password, UserId. This is a sample model. Now, this model may also be represented by a table with columns in the database, which align to the model and to the properties that you see here. That would be a pretty common sort of practice. And then a lot of modern frameworks provide mechanisms in order to persist that database structure through to the application as a model and make it easy to interact with. So, easy to load, easy to edit, easy to create. And that's the sort of thing we often see being done by technologies such as object-relational mappers or ORMs. But moving on, that's our model. Let's take a look at what model binding means. So, let's imagine a case like this, and this is clearly off our sample application. Now, in this particular case, we're looking at the edit your profile form. Now, this form takes the first name and it takes the last name. They're the only fields that you're presented with on the web page. Now, what happens when you submit this form is that a POST request is made to the user profile path. Now, of course, there are bunch of request headers that go in there, but the important bit is that what is actually posted is a FirstName and a LastName. The model binding happens when the framework is able to take those form parameters and bind them directly to that class in the application. So, what that means for us as developers is that so long as we have a form, which conforms to the model structure, many frameworks can simply map that form data into the model, or, in other words, bind it to the model, and then technologies such as our ORMs can persist that model through to the database. The value proposition from a development perspective is great. We've got a model in code that matches the one in the database. So long as we have the right attributes in our form, magic happens, everything gets bound up together, and we've save ourselves all of this manual plumbing work that we used to do in a pre-model binding world such as manually requesting form attributes, setting properties on classes, and then manually passing attributes to things like stored procedures. There are cases where we might still do that, but certainly now there are very streamlined easy constructs available through the use of model binding. Now, that all works great. Where it gets a little bit interesting is when we post additional model attributes that aren't in the form, yet can still bind to the model in code. So, let's move on to the next section of this module and look at executing a mass-assignment attack by exploiting the way model binding functions.

Executing a mass assignment attack
Back on our insecure application again, I want to have a look at exploiting the model binding functionality of the edit profile page in order to execute a mass-assignment attack. Now, to edit my profile, I'm going to need to log in first. So, let's log in with the same old email address and the same old password. And now let's go up to My account, and let's go down to Edit profile. Now, before we go any further, I'm going to drag over Fiddler, and I'm going to make sure that we are capturing requests. Let's jump back over to the Profile page, and let's just simply Save the profile. Back over to Fiddler. Let's just stop Fiddler from capturing any more requests. And now take a look at what we've got. So, it's a very similar pattern again. Two requests. The first one is a POST request to the user profile page. It has resulted in an HTTP 302, which has then led us down to an HTTP 200. So, it's just simply redirected. And we can see in the URL column it's actually a slightly different URL. So, a very similar pattern to what we've seen before with facilities such as registration and log in. What I want to do though is take a little bit of a look at this request. So, let's go over and look at WebForms, and we'll see that what is being posted is just a FirstName and a LastName. Now, of course, when we made that request, the headers that we sent along with the request would have included the AuthCookie, and that's how the web application has identified that it is me who is asking for my profile to be changed. What I want to do now though is jump over to the Composer, and I'm going to drag that request into the Composer. Now, this brings us through to the point where we can start talking about a mass-assignment attack in order to exploit model binding. Now, if you remember in the previous section, we looked at the idea of a model in a web application, and I explained how model binding can take the Request Body of a form and simply pick up the attributes that map to the model, automatically update the model, and persist that change through to the database. What that means is that if we can manipulate this Request Body to pass other attributes of the model and there's a mass-assignment risk, we can actually change the persisted value in the database even though those fields don't exist in the form. Now, all of this centers around the fact that you need to know the other attributes of the model. In some cases, it's fairly easy to speculate. When you're talking about say a user profile account, it's pretty easy to figure out you probably have things like first name and last name and email address, and even they're not immediately obvious in the user interface, they may well exist under the covers in the database and in the model. We're going to cheat a little bit because we've had access to the code, and I know that in the code there is a field called IsAdmin. Now, how you discover this will differ from case to case. In a case such as an open source framework, everyone has their code. It's easy to discover. As we saw earlier on, there were also vulnerabilities such as when unhandled exceptions occur where the internal implementation may be disclosed externally. So, that would be another way that someone might discover the other attributes on a model. And, of course, really when we're talking about security, you do really have to assume that the code itself is known. That doesn't mean credentials or encryption keys or anything else of a strictly private nature is public, but the actual code itself must be resilient if it is known by an attacker. So, let's move on. I'm going to send an IsAdmin attribute, and I'm going to set the value to true. Let's now go and Execute that request. We can see the same 302/200 response over here. Let's now jump back to the web application and see if anything looks different. And I'm just going to jump to the home page. Now, we can see something different. We can see that I now have an Admin link. I didn't have this before. It is only since I've been able to manipulate that request and actually mount a mass-assignment attack by sending through an attribute that is not normally sent when the application is used as intended that I've been able to exploit the system. Let's see what we get by doing this. And here we go. Now, I can see a list of all the users in the system. So, this is a case of privilege escalation. I have been able to change myself from a garden variety user to now become an administrator who has access to some very sensitive data. This is our users list. And worse than just being our users list, it's also a list of passwords. We're going to look at why this is a bad thing when we get to the module on account management, but clearly what you see in front of you hear is not something you would ever want an unauthorized user to be able to gain access to. Now, just in case this sounds a little bit farfetched, I wanted to show you one piece of press of a recent precedent where a mass-assignment attack was used to great effect against GitHub. Back in early 2012, GitHub was alerted to a vulnerability in their Ruby on Rails implementation. And in order to demonstrate the nature of this risk, the individual who initially disclosed it executed a mass-assignment attack to place his own public key against somebody else's repository. Now, as it turns out, the root cause of the vulnerability was failure to properly check incoming form parameters, which is a problem know as the mass-assignment vulnerability. This is a pretty high profile example, and this was done at a time where GitHub had enormous popularity. And certainly it still does at the time of recording, but it was a very good demonstration of where this risk can exist. Now, as the description here says, it is simply a case of failing to properly check those incoming form parameters. And in the case of GitHub, as was the case in our example just before, it is simply a matter of when form parameters are just blindly bound to the model, and if they line up, hey they get persisted to the database. That is at the heart of this mass-assignment vulnerability. Let's go and check the secure application and see how it behaves differently. Here we are back on the secure application again, and the mass-assignment risk has been rectified in this app. So, let's go through and repeat the same process as before. We'll go over to Edit profile. I'll drag over Fiddler, and we'll make sure that it is capturing. We'll go back to Edit profile. We will just Save as it stands, and then back over to Fiddler. Let's stop at capturing. Drag on that POST request with the form data. We will add IsAdmin=true, and let's try and Execute. Now, it still executed okay. It's exactly the same response pattern as before, HTTP 302 followed by 200, so obviously there are no problems with the form. Let's go back to the website, and if we now go to the home page, if this has worked, we won't see an Admin link. And there we go. It has worked. There is no more Admin link. So, clearly I have not been able to escalate my privileges by way of a mass-assignment attack. The way a mass-assignment attack is mitigated against will depend on the framework, and it generally breaks down into a couple of different approaches. And that's to use either a whitelist of the attributes, which the framework is allowed to bind. So, in this case, I've updated the application to say hey when you do this automatic model binding, you can only bind first name and last name. Or alternatively, you'll often find that there is a blacklist approach. When you do the model binding, don't bind the IsAdmin field. As we've looked at in earlier modules, wherever possible, whitelists are always safer. They're more explicit. So, that would certainly always be my preference. Now, of course, all of this doesn't mean that every implementation of model binding is at risk of a mass- assignment attack. Certainly in some frameworks such as ASP. NET, there are ways of doing model binding, which are at risk, and there are ways of doing model binding that are very safe. Either way, now you know how to easily test for the presence of a risk. Simply create a legitimate request, capture it in Fiddler, recreate the request in the Composer, and add another couple of attributes. If those attributes are persisted onto the model then onto the data layer, you know you've got a mass-assignment risk. It is a little bit of an obscure one, but as you can see, when an application is at risk, the ramifications really can be catastrophic. So, it is well worthwhile investigating whether your app may have a mass-assignment risk.

HTTP verb tampering
Another aspect of HTTP request that may be tampered with is the HTTP verb. Now, when we talk about verb, we're talking about things like whether it's a POST request or a GET request. They're the two really obvious ones. There are also verbs such as PUT and DELETE among others. Now, what's interesting about HTTP verb tampering is that sometimes applications behave differently depending on which HTTP verb is used. Now, indeed that's the semantic intent of HTTP. You expect a GET request to simply return content without manipulating anything on the website whereas you expect a DELETE request to obviously delete some sort of record in the system. That's the semantic intent. However, particularly when we get to GET request versus POST request, they're often used a little bit interchangeably. So, for example, we might use a GET request with a query string so that the URL can be shared and the context persisted to pretty much perform the same activity as a POST request with a piece of form data. So, as an example, if we go up to the Search field and we search for Ferrari, and just before we do, we will turn on the Network tab in the developer tools, let's search, and we will see that this has issued a GET request. There it is right there at the top. Now, in this case, even though we've obviously sent some data from a form field to the server, it has been passed via GET. We'll come back to the verb on this search feature in just a moment, but let's just quickly go back to one of the things we observed right at the start of this module when we looked at cross-site scripting. And what we found is that there is certain input sanitization that is applied to the search term. So, for example, if we go back and change the search term to script and we try an alert document. cookies, and we just close that off, and now we try and search, we got an error. So, there was some input sanitization that was stopping us from performing this activity. The other thing we discovered though was that the input sanitization was only being applied to the less than angle bracket. So, if we go and remove the first angle bracket and then we remove the second angle bracket and we resubmit this query, it still goes through. So, in short, there was logic which allowed some requests to go through, but rejected other requests based on characters in that search term. What I want to do know though is capture this request in Fiddler, and then we'll go and take a look at how it can manipulate the verb. So, let me grab a new Fiddler window. And we can see here that it is actually capturing. I'm going to go back to the web application, and let's now search again for this term. So, we'll just Reload the page. Back over to Fiddler. We can stop capturing now. And here is that first request. Now, what I want to do is jump over into the Composer, and we're already on the Composer tab. Now, let's drag that last request into the Composer. And what we want to do now is change this from a GET request to a POST request. Now, what that also means is that we're going to move away from using the query string, so that means chopping out everything here in the search term, and we're going to send it in the Request Body. So, we're going to take out the question mark, and we can remove all the URL encoding to get this back to a nice clean piece of JavaScript. So, alert, document. cookies, and then we can close off that statement and close off the script tag. Now, the last thing that we're going to need to do here is change the content type. So, let's just jump up, and we will change this content type to Content-Type: application/x-www—form-urlencoded. That should do it. Let's now go and reissue this request. Now, the first thing we can see here is that we do indeed have an HTTP 200 response. So, even though we sent less than angle brackets to the search page, as the value of the search term, it hasn't been rejected like it was before when we searched in the web application with the GET request. So, the first thing this tells us is that we have been able to bypass the process that threw that exception earlier on. Let's go and take a look at the Inspector though, and take a look at the WebView, and this looks pretty much as expected. You searched for is empty because it's just a script tag. It won't render to the UI. What we're really interested in though is the Raw response. And if we now scroll down a little bit and take a look at what we actually searched for, here we can see that searchTerm. And the really important thing here is that there is also no output encoding. Now, this is very significant because it means that not only have we circumvented input sanitization, we have also circumvented output encoding. So, clearly there is something about this application which isn't properly sanitizing or encoding the searchTerm value when it is sent via POST instead of via GET. If we now scroll down to the bottom of the page, we'll also see that when it appears in JavaScript there is no output encoding. Now, what we've got to remember with all this is that there are a couple of different ways of web applications reading untrusted data from the user. One way is that it could explicitly read from the query string. So, depending on the framework, there is usually a way of requesting something like request. querystring, and then passing a string value for the name of the parameter that you want to access. So, that's a very explicit give me the query string sort of activity. The same paradigm also exists for the forms collection. It might be something like request. form, and then the name of the form. So, a very similar implementation, but explicitly grabbing from query string versus from form. Many frameworks also have a very generic request collection where you can implement the same sort of pattern as we might for the query string or for the form, but it might just simply be request and then the name of the parameter that you'd like to pull from the request regardless of whether it's in the form collection or the query string collection. What sometimes happens is the developer applies input sanitization and output encoding to one particular verb, so, for example, in this case obviously that has been applied to when it's a GET request and the untrusted data has come by the query string, but they may then later reference that data in a very generic fashion, so, for example, just reading from the request object, which means that if we sent the data as a POST such as what we've done here, it won't get caught by the input sanitization, it won't get caught by the output encoding, but it will still be processed later on. Now, it does sound a little bit odd for a developer to go accessing some things on the query string and other things either on the form or without specifying the verb whatsoever, but certainly it does happen. So, manipulating that HTTP verb sometimes yields some very interesting results. Depending on the application, there are a couple of different ways of mitigating this risk. Let's jump over to the secure app, see how it defends against this particular attack vector, and then we'll talk about some mitigations. Over on the secure site now, I want to show you what happens when we try to request the search page via POST. I'm going to keep this pretty simple. We'll just search for test. And before we actually click the Enter button there, I'm going to make sure that we are running Fiddler. So, let's fire it up, and it is currently capturing. Let's jump back to the browser, and let's now run that test search. Okay, I got a few results. Back into Fiddler. Let's stop capturing. And we'll go to the Composer tab, which is already there, drag the request over, and we'll do the same thing as before. So, we'll take that searchTerm, we'll change this to a POST rather than a GET, we'll put the searchTerm down here, remove the query string. Now, let's just add the Content-Type. Same as before, application/x, form, urlencoded. And let's now Execute this. So, here we see a very different result. And, in fact, what we have now is a 404 page not found. And certainly if we go to the Inspectors and we look at the WebView response, we'll see a very standard resource cannot be found response. The approach that the secure application has taken here is that it is only ever okay to load the search page via GET. If you use another HTTP verb, including POST, the application will simply return a 404, and that's a very semantic way of saying the resource that you're after simply isn't there. Of course that path still exists, but it will only be returned via GET. Now, that's a pretty hard lined approach to take, but it really is the most secure in so far as the application is now being very explicit. Hey, you only ever need to load the search page via a GET request. There is simply not a circumstance where there is a valid case to post data to the search page. If we wanted to be a little bit more liberal, we could've been much more careful in the execution of the code itself. And what I mean by that is rather than obviously accessing some data on the query string collection and then other data either in the form collection or in that generic request object and then possibly having a risk where some verbs implement sanitization and output encoding and other verbs don't, we could've just said okay right across the board we're only ever going to access the request collection. So, load that searchTerm from the request collection without specifying query string or form, and then apply input sanitization, and then apply output encoding. So, that would've been a more secure approach that would've allowed both GET and POST. The best situation altogether, of course, is to make sure that only the verb that you intend to be used for that resource is actually implemented. Depending on the framework, you may find that there are easy ways to do that. So, for example, some frameworks allow the path to have an explicit statement on it saying that it's only allowed via HTTP GET, for example. That is very explicit, and it almost brings us back to this point of saying whitelist all the things. Be very, very clear about what it is that we allow, and anything that is not within the scope of what we allow and what we trust, reject it. That's always going to be the safest position to take.

Fuzz testing
The last thing that we'll look at in this module is the concept and execution of what's referred to as fuzz testing. But before we start looking at the specifics of fuzz testing, let's just recap briefly on some of the typical payloads an attacker may send to a website via HTTP request. So, for example, we have cross-site scripting, which we've already looked at in an earlier module. And clearly the intention with cross-site scripting is to try and break out of the data context on the page and enter the markup context. And ultimately the objective of doing that is to try and change the structure or function of the page. Next up, and something we'll look at in a later module in the course, is SQL injection. And what you'll see when we look closer at SQL injection is that the objective is to try and change the execution of SQL statements in the database in order to either maliciously change data or disclose it to the attacker. And as with cross-site scripting, there are typical patterns that an attacker will use to try and probe for the presence of a SQL injection risk. There are also other methods of attack such as directory traversal where an attacker is trying to access other files in the system, which shouldn't normally be available to external users. So, you might often see requests consisting of a pattern to try and move back up through directories and access system files. The point with all three of these request payloads is that they conform to a pretty common set of patterns. An attacker will normally try the same sequences in order to probe for potential risks in the system. Now, inevitably once they identify that there may be a risk, they'll very specifically tailor the attack, but just that process of trying to look for the risk in the first place is something that we can automate with fuzz testing. The idea of fuzz testing is that process of searching for vulnerabilities does commonly adhere to a very regular pattern. So, for example, back in the cross-site scripting module we saw how it's very common to look for whether it's possible to get a script tag through a form field. So, is there any input sanitization, which disallows it, and then is there any output encoding, which makes it impossible to render it into the HTML markup? That's a very common pattern. The thing is though there are a lot of common patterns, and manual testing for this sort of vulnerability can get very laborious, not just because there's a lot of common patterns, but because there are also a lot of attack vectors. Think of something like a registration form. You might have a dozen different fields on that form. Going through and testing for specific vulnerabilities for things like cross-site scripting and SQL injection on every one of those fields gets very laborious. Now, this is where fuzz testing comes along. And the idea is that we might be able to automate the process of bombarding the application with these possible attack payloads. Now, in many ways the attack payloads can also be pretty random as well. How does a field respond to different character types, for example? But, of course, within there as well, we'll get those common sorts of patterns. So, does a field accept script tags? Does a field accept statements which adhere to a pattern that an attacker might use for SQL injection? And assuming those fields do accept those patterns, what does the response look like? Is the response the same as a normal response from a legitimate request or is it possibly returning an internal exception or even disclosing internal data? And this is one of the neat things about fuzz testing tools in that they highlight when the response doesn't appear to be the same as the response to a legitimate request. Now, that doesn't necessarily mean that hey a flaw does absolutely positively exist, but it gives the attacker an area to start focusing their attention on. Let's go and have a look at an example of how we can do some fuzz testing against our sample application. There are many different fuzz testing tools available including a bunch of free ones and a bunch targeted at security professionals, which not only cost money, but can also be quite complex in terms of the concepts you need to grasp in order to maximize their effectiveness. The tool I want to use today is extremely simple, and it integrates into Fiddler, so it's an environment that we're already familiar with based on the work we've already done in this course. Now, what I want to do is load up Fiddler, do a search, take that request, and then run my fuzz testing. So, let's go and grab a new instance of Fiddler. And now I'm going to jump back to the website, and in this case we can just search for test, then jump back over to Fiddler. Okay, so here is our request. I'm just going to stop capturing other requests now so we don't see anything else from any other processes running on the machine. And now we can see a very typical request here, which is the one that was made for our search. Now, Fiddler is pretty familiar by this point in the course, but clearly we can see things like the searchTerm here, we've also got the SessionId, and because I'm logged on, we've got an AuthCookie, and, of course, there's that VisitStart cookie, which is always set when a session starts. Nothing unusual about any of this. What I want to do now though is go up to this request, right-click, and go down to send to Intruder21. Now, Intruder21 is a free add-on to Fiddler. And when we select that option, we get a new window, and it looks just like this. Now, what Intruder21 is doing here is it's showing us the raw HTTP request, and we can see we've got some areas highlighted. So, at the top here we can see that we've got searchTerm highlighted. Now, what Intruder21 has done is it's recognized that this is untrusted data that is being sent as part of the request. It's also picked up on that SessionId, and it's picked up on the AuthCookie, and it has picked up on the VisitStart cookie. Now, all of these are highlighted because these are the fields that Intruder21 is going to apply fuzz testing to. So, it's going to start sending this request again with potential attack payloads in those fields. Let's have a look at the Payloads tab. Now, the first thing to understand here is that this is not an exhaustive set of fuzz testing payloads. We'll look at a more complete set at the end of this section. However, what we can see is a bunch of SQL injection-type attacks, and, again, we'll look at SQL injection in a later module. We can also see some XSS attacks, and we can also see some command attacks. And some of these look like directory traversal style attacks. We've then got some options down at the bottom around Request Threads and around a Delay between individual requests. There's a little bit of customization that can be done. We're going to leave all of this as default. We're going to skip past the Session tab and jump straight over to Results. Now, because I want to keep this as simple as possible, I am just going to start the test. Now, we can see two things. In the background in Fiddler, we can see a whole bunch of requests being issued, and also in the Intruder21 window just here, we can see some results appearing. And there we go. The test is finished. I'm going to come back to the Intruder21 window. Let's just look quickly at Fiddler. And we'll go back to the top, we'll take the first request issued by Intruder21, and as we can see now, we're starting to get some potential attack payloads. So, here we can see that the searchTerm is test with a single quote on the end. If I just click through some of these results, we'll see that attack payload changing. There are two single quotes, or maybe it was a double quote, some backslashes, single slash, SQL injection string, and so on and so forth. Now, as we go through, we can see that it's the searchTerm that keeps changing. When we go down a little bit further, we will find now it's the ASP. NET_SessionId value that's changing. So, now we're getting a couple of backslashes, now we're getting a SQL injection string, and so on and so forth. Keep going down further and it will be the AuthCookie. Keep going down further again, and now it's the VisitStart. So, you can get a sense here of how automated and indiscriminate this process of fuzz testing is. Intruder21 has just simply bombarded the application with different payloads in order to see what happens. Now what happens is the important bit. And the best way to look at that is to flick back to the Intruder21 window, and now let's just maximize this so we can see what's going on here. Now, each row you see in that top table is a request that has been issued to the website. Down at the bottom of the screen, you can see the actual request that is being issued, and that's now a pretty familiar pattern to you based on the previous modules of this course. And then in that grid on the top, we're getting columns such as the position where the attack payload was injected; in this case, it was the searchTerm; a comment about the type of request that was issued; then we get things like the signature, the HTTP status code. Now, that status code is quite important because attackers want to see when the application doesn't respond with an HTTP 200. And that actually goes back to the previous module on internal implementation disclosure where I spoke about not leaking the fact that an HTTP 500 has occurred. So, responding with a 200 in that case, even though there was an internal server error, keeps it off the radar of tools such as this. We get the page title. And then the next column over is quite important, this search column. It's important because this is telling us when the input string provided by the fuzz tester appears on the page. Now, what we'll see here is that if we go down to request number 12, there is a result in the search column. This is important because what it's telling us is that when we search for that string, and, again, look at the signature column, I'll just expand that a little bit further, that signature column contains an XSS payload with quotes and an equals sign. And what it's telling us is that particular search string appears verbatim in the HTML markup. In other words, it is not being output encoded. Now, we had to go through quite a bit of manual testing to establish that earlier on, but what Intruder21 has done here is it's just allowed us to take a legitimate search request, automate the injection of attack sequences into each piece of untrusted user data that came from the browser, and now it's automatically telling us hey you probably have a cross-site scripting flaw. This has made the process of identifying a risk extremely easy. Now, this has been just a very basic look at the concept of fuzz testing, but hopefully that illustrates enough to understand what the process involves and how easy it is for an attacker or for yourself, in order to hack yourself first, to take typical requests to areas of the application that may be at risk, which is predominately areas taking untrusted user data, and simply bombard the system with typical attack payloads and see how it responds. This makes your life as a developer looking for risks in your application significantly easier than going through and manually testing every field with every possibility that you can think of. Now, as useful as this process has been, we can also see that ultimately we're looking at about 24 different attack payloads. And in the scheme of possible attacks against websites, 24 different sequences is a pretty small subset of what we could possibly use. So, just before we wrap up this section on fuzz testing, let's go and take a look at fuzzdb as a means of finding additional attack sequences you can use to do a more comprehensive probe of your application. Over on Google Code there's a little project called fuzzdb, which is a very handy set of attack payloads for fuzzing. Now, it's not the only database of fuzzing payloads, but it's quite a popular little one, and I want to give you an idea of the sort of data that we have in here. And the easiest way to do this is just to take a look at this version repo. Now, what we find here is a pretty well organized set of data that can be used in most fuzzers. And if we take a look at something like the attack-payloads, let's look at XSS because it's a little bit familiar to us now, and we'll go and take a look at this one from rsnake, and what you can see here is what should now be a pretty familiar set of possible XSS payloads. So, things like script tags, things like alerts to go straight into JavaScript. And, in fact, if we have a scroll through this, we can find about 77 separate examples just of XSS payloads in this one file. And clearly if we go back and look at the previous page as well, we can see that there are similar examples for things like SQL injection. And, of course, we'll have a look at this a little bit later on, and we'll look and things like blind SQL injection. But for now, what we can see is that it's a similar sort of structure in so far as we've got a whole bunch of string patterns, which attempt to exploit potential flaws in the application. Now, these are just collections of strings, which is what makes them so easy to load into any sort of fuzzing tool including things like Intruder21. So, fuzzing is something you want to take seriously. It makes it very easy to just grab a list like this, load it up into Intruder21, and fire it at the website that you're testing. Now, fuzz testing is never going to automate the entire process. It's not going to turn around and actually give you an XSS attack sequence that you can immediately go and weaponize or a SQL injection script that will automatically give you all of the data out of the database. You'll still need to go through and put that together yourself in order to demonstrate a risk. However, it does make the process of identifying areas of the application to focus on significantly easier because it does automate that process of bombarding different types of data at different fields of the application. So, whilst fuzz testing isn't going to do all the work for you, it does make things significantly easier and allows you to focus on doing the things that humans do the best, which is working out, once you know where a potential vulnerability is, what's the right way to go and exploit it the best way possible for that specific use case. And that's a pretty good balance of automation and human interaction.

Summary
Let's summarize the module. And the single most important message that I'd like to get through is that you must assume that every single aspect of an HTTP request can and will be manipulated by attackers. I find that very, very soon after I stand up a website that is publically facing, even a test website, it will start getting hammered by attackers. And I see this because I keep logs of things like exceptions. It will happen, it will be automated, and they will have a go at every single aspect of the application possible. And I'll do that in a very indiscriminate fashion. Things like the verb, the path, the protocol, the accept headers, the user agent, the referrer, the accept language, cookies, and, of course, the request body that may be sent from a form. All of these aspects of an HTTP request can be changed by an attacker. You as the developer have absolutely no control over the types of requests that are issued to the website. The only thing you can control is the way the application responds when any of these attributes are manipulated. Now, that leads us to the second point here as well about not relying on controls that depend on the browser to implement them. When we stand up a website and we test it, we tend to click around on links and fill out forms. That's great, but that's not what an attacker will do. An attacker will change URLs, they will change query string parameters, and they will change every other aspect we just looked at in that previous point. They will also deliberately circumvent validation. And earlier on we looked at how validation of the name on the registration form was only happening on the client. As soon as we took the browser out of the picture and went to Fiddler, or even as soon as we turned off JavaScript on the client, that validation became absolutely useless. We had to have it on the server. You need to remember the client can do anything they want. And attacker has full control over their own client to be able to issue whatever requests they like. The only thing you have full control over is the application running on the server, so that's where you have to build your defense. By all means, maximize your user experience by also doing a validation on the client, but expect that it will be circumvented. We also took a look at model binding and mass assignment. And the underlying message here is that when frameworks attempt to automate things and streamline processes, sometimes that introduces inherent security risks. So, the idea that every single form attribute posted to a page, which may be bound to a model, will automatically try and map those attributes to the model regardless of the fields that may have actually been present on the web page does present an inherent risk. It's fine when everything lines up and you're happy to have a user actually manipulate all of those fields on the model, but in a case like we looked at earlier, which resulted in an escalation of privilege just like GitHub had back in 2012, that poses a security risk. So, certainly understand the approach to model binding in your chosen framework and assess whether a mass-assignment risk may be present. We also looked a little bit more closely at HTTP verbs and the way verbs may be changed in order to circumvent controls that may only be present against say a GET verb, but not against a POST verb. My view is to always try and whitelist verbs, always be explicit about what you want to allow. In a case like that search feature, it's only ever going to be an HTTP GET. We do not need to support HTTP POST. Returning a 404 is a perfectly valid response if someone tries to construct a POST when it should only ever be a GET. Of course, along with that, wherever possible removing explicit references to the request type, i. e. whether it's a query string or a form field, and then making sure that all input sanitization, output encoding, and any other sort of validation goes through the same pipeline regardless of whether it's from the query string or the request body via a POST is a very sound practice. And finally, we looked at automating testing. And Intruder21 in Fiddler is probably one of the most basic examples I could have given, but is shows how a process like fuzz testing can actually be quite powerful. Even though it is a very simple process, it automated something, which can be laborious. And frankly, any opportunity we get to automate processes like this, and as a result get a more comprehensive testing profile, is a very good result. Definitely look at expanding that fuzz testing payload range though, and resources such as fuzzdb can be extremely useful. You'll probably find you'll build up a little collection of sample fuzz testing payloads that you consistently use. Particularly when you have a fast connection through to the website, so, for example, when it's in a local development environment, it's easy to just bombard the application with a very broad range of fuzz testing payloads across a very broad range of fields. The more that you can do in an ethical fashion against your own application, the more resilient that application will become against real online attackers.

SQL Injection
Outline
Hi, my name is Troy Hunt and in this module we're going to look at the risk of SQL Injection. We'll start out by establishing an understanding of what the risk of SQL injection really is. It's an extremely prevalent, extremely dangerous risk and I want to take a moment to explain how it manifests itself in a vulnerable application. We'll then move on to taking a look at the app we've been using throughout this course and we will test it to try and identify if there might be a risk of SQL injection. Now, once we've established that, we can move on to disclosing internal information about the application such as the database structure. So, we're actually going to issue some malicious requests to the application and get it to disclose that info. Once we have an understanding of the internal structure, then we can move on to actually harvesting some data out of the application. So, we're actually going to pull out information that we would never want an average user to have access to. Now, we're going to do all that in very manual fashion in order to properly understand SQL injection. But then we're going to move on to automating an attack with Havij. And the real reason I want to show this is it's going to demonstrate just how easy SQL injection can be with some of the automation tools that are available today. After that we'll also take a look at blind SQL injection. Things start to get quite a bit trickier then. But blind SQL injection risks are often prevalent where the more easily exploitable risks have already been mitigated by the developer. So, it's very important to understand how a blind SQL injection risk actually manifests itself and is exploited. Lastly, we'll go back to our secure application and have a look at some of the patterns that it implements. And we'll find there are a couple of different defenses in order to keep this really serious risk that is SQL injection out of the application. So, let's move on and establish an understanding of what this SQL injection risk really is.

Understanding SQL injection
I want to start off this module by focusing a little bit on just how significant this risk called SQL injection really is. In front of you are the top few risks in the OWASP Top 10 Application Security Risks. Now I've got another course on Pluralsight dedicated to looking at each one of these top 10 risks in ASP. NET. So, go and check that out if you want to get into detail. But for now, the important thing is is that OWASP, who is the Open Web Application Security Project, which is a not-for-profit organization dedicated to detailing and educating developers on web application security risks, produce a publication every few years called the Top 10 Application Security Risks. Now this is a very real-world, practical guide of what the risks are that are currently bringing web applications undone, and SQL injection has been right at the top for some time now. Now it's not just OWASP, there are many other publications and studies that have been done that always bring out SQL injection, if not in the top 1 risk, then the top 1 or 2 risks. And the reason it's always at the top of these lists is in part because it is so prevalent. There are a huge number of websites out there at risk, impart also because it is so easily exploitable. And particularly as we go through this module when we get down to the automation with Havij, you'll see just how easy it is. But perhaps most significantly, when a SQL injection risk exists and is exploited, the result can be absolutely catastrophic. Now that result can be anything from the entire database being manipulated so that malware, for example, can be injected into pages. It could be that privileges are escalated so that attackers can give themselves rights to directly connect to the database and access data whenever they like. It could be that an attacker just goes through and drops tables. Or in other words, just maliciously destroys the thing. But probably one of the most prevalent and one of the most severe possible outcomes of SQL injection is data disclosure. And very often when see lists of user names and passwords appear on sights such as Pastebin, often from hacktivists groups such as Anonymous, it's very frequently as a result of a SQL injection risk. So, we need to take these risks extremely seriously. Let's move on and take a look at how the risk in a vulnerable application. Let's imagine we have a URL that looks like this. Now this is a very typical structure. And the important thing in the context of SQL injection is that we have a query string. And in this case there is a path called Widget and query string name is Id and the value is 1. Now as a developer, it's probably pretty obvious that what's going to happen in the background is something like this. That query string value is going to be passed down into a SQL statement. And there's probably a table called something like Widget and the SLQ statement is going to get us the Widget with the ID that was passed in the query string. Increment the ID, the SQL statement changes, and you get back Widget number 2 instead of Widget number 1. All that's pretty obvious. What we need to understand is that both of these lines, both the URL and the SQL statement, consist of two discrete parts. Part 1 is trusted. So, think back to when we're talking about XSS and we looked at what was trusted in terms of the markup. And then the other piece is what was untrusted, which is in terms of the user provided data. Or what we're often referring to as untrusted data. Now what this means is that we trust the domain, we trust the path, we trust the query string name. But that value, that number 1, could easily be manipulated. As I just said, it could be manipulated to 2 and you get a different result. Now obviously that is within the bounds of how the developer designed it. But we'll look at what happens when it's out of the bounds of what they expected. The important thing is that that untrusted data then persists down into the query. So, now we're changing the Widget that's being selected and we're passing untrusted data to that query. Let's take a look at where this can go wrong. Let's take that same path we just looked at before. /Widget and then a query string parameter named Id with the value of 1. That's fine; now imagine if we were to do this. The significance of what we've just appended to this query string becomes clear when you see how it might translate down into the SQL statement. Now this is a perfectly valid SQL statement. But the really important thing is, by appending that equivalency test, the or 1=1, we have fundamentally changed the structure of this SQL query. So, before what we were going to get is one record where the ID was equal to 1. What we're doing now is by adding an or statement and a condition, which is always going to be true, is we're going to get every single Widget in the database. Because that second part of the WHERE condition will always be true. This looks pretty innocent, but what's really important about it, is that we have actually changed the structure of the query. So, we haven't changed the data parameter which is passed to the query, rather we have changed the way the query will execute and we fundamentally change the results set that will come back from the database. And again, this is relatively innocent. But, as we progress through this module, we'll see how once we establish that there is this risk and the risk is breaking out of the data context into the query context. So, again think back to the XSS module. It was a little bit like breaking out of the data context into the markup context. So, not that different, in some ways. Once we understand that risk and we've established it, we'll be able to perform all sorts of other queries against the database so that we, with our attacker head on, can start to perform some pretty malicious activities. Now there are a few different types of SQL injection attacks, so let's take a look at those before we move on. When we talk about SQL injection, there are really a number of different approaches to how an attacker might exploit a risk, and they break down into two distinct categories. One being very explicit and one being very implicit, which we will often refer to as blind. Now an explicit, there are two very common approaches. One is what we would call a union-based attack. And the idea here is that an attacker wants to try and append a results set of data that they want to harvest from the application to an existing result set that the application is already returning to the browser. So, for example, perhaps the browser is returning a list of Widgets. By carefully constructing a query that exploits the SQL injection risk, the attacker might not only return that list of Widgets, but at the tail-end of that, append a list of passwords. And that's normally done with a statement such as Union All where you can just append a set of results to an existing set of results. Now if that works and they all get appended together at the database server, they come back to the application and they get rendered into the HTML output. So, that's probably the most basic of SQL injection attacks, probably the easiest way to get data out of the application. The net one is an error-based attack. And this is what we're going to look at in this module. Now the idea of an error-based SQL injection attack, is that an attacker can get the database server to disclose internal information by causing an exception to be raised. If the application is not properly handling that exception, and we looked at examples of that earlier on in the module on internal implementation disclosure, that internal database structure can be exposed in an error message in the browser. An attacker might use that approach not only to disclose information about the structure of the database, but also about the data in the database tables themselves. So, we'll take a really good look at that in this module. When we move on to the more implicit styles of attack, we're talking about attack vectors which aren't actually returning information directly in the HTML markup. So, union and error-based attacks will put things like table names or data in the browser directly. Something like a blind Boolean-based attack is where an attacker tries to test for a particular condition. And then based on the response, draw a conclusion as to whether that condition was true or false. We're also going to look at this towards the end of this module. And we'll have a look at what sort of questions an attacker might want to ask the database that results in a true or false answer and allows them to actually discover what's happening internally. The final blind-based SQL injection attack is what we would call a time-based attack. And in this example, an attacker is going to cause the application to delay the response under certain conditions. Based on how long the response takes, the attack will then be able to draw conclusions. So, for example, they might ask a question of the database and if it responds immediately they'll say okay, well the answer to that question is true. And if it doesn't respond immediately, they'll then know that the answer to that question is false. So, it's almost a little bit of a combination of the Boolean-based attack then with the delay that would be part of the time-based attack vector. So, that's another way of making an implicit blind SQL injection attack on the application. So, with that understood, let's move on and actually start to test for some injection risks in a vulnerable application.

Testing for injection risks
The first thing that we need to do before we can establish how we're going to actually employ a SQL injection attack against this application, is establish whether it is actually vulnerable in the first place. So, here's what I'd like to do. I'm already logged on as myself, I would like to now jump over to the Leaderboard and we're going to jump into the Pagani Huayra. Now the reason I've chosen the Pagani is that I want to cast a vote. Now before I cast that vote though, I do want to open Fiddler because we going to do this SQL injection attack from Fiddler, which is now a pretty familiar tool by this point in the course. So, let's just drag Fiddler over here and we will make sure that it is actually capturing requests, which it is; capturing from web browsers, back over to the vulnerable app. Let's vote for the Huayra, and we'll give that a good old Whoa! And let's cast the vote. Okay, vote is in. Back over to Fiddler and now we can see our vote. Let's stop capturing so that we don't end up with any other requests jumping in there. And let's take a look at that vote. Now what we can see here is that the vote was a POST request, which is what we'd expect when we're sending data to the server. Let's take a look at the Web Forms tab. And here we can see a few different form values in the body. Now the one we're going to be really interested in is this comments value. And what I want to do is test whether there might be an injection risk in that comment field. Now to try and help you understand what I'm going to be doing here, I'm just going to grab a little Text Editor window because we need to be able to visualize what's happening with the SQL statements underneath. Now what's probably happening is something like; insert into vote and then we had an userid, we had a supercarid, and we had some comments. And what we'll probably find is in that insertion statement it's going to be something like; values and then we had my user Id that was 1. We had the super car Id that was 3, and then we had the comment. So, it's a pretty safe bet that the SQL statement looks something like this. Now what I want to do to try and establish whether there might be risk is actually break this SQL statement. And one way we can break it is by putting another little single quote at the tail end of that comment. If we did this, we would now have a piece of invalid SQL. Now one thing that's worth pointing out at this point, is that different database servers require different injection attacks. The way we approach this with SQL server is going to be different than the way we might approach it with something like Oracle, which would be different again from something like MySQL. Now when a risk is present, there are vectors that make it pretty easy to establish what sort of database server it is. Now because this is an ASP. NET application, and we've established that several ways earlier on when we looked at the Internal Implementation Disclosure module. It's usually a pretty safe bet that a Microsoft ASP. NET application has a Microsoft SQL server behind it. So, the syntax we're going to be looking at in this module is all going to be intended to target Microsoft SQL server. So, moving on, let's go back to Fiddler. And I'm going to try and issue a request just like this to establish whether they might be an injection risk. So, back over to Fiddler. And I'm going to jump over to the now very familiar composer. I'm going to drag the original request in there and now I'm going to add that single quote to the end of the comments value down in the Request Body. Let's Execute that statement and see what happens. Okay, so we can see that there's been an HTTP 500 returned here. So, obviously something that we have done has caused an unhandled, internal exception in the application. Let's jump to our Inspectors. And because we know that this is an API working with JSON, and we established that earlier on in the course, let's jump down and look at the JSON tab. Now, the message down here is actually giving us quite a bit of information. So, we can see here that there's an exception message; unclosed quotation mark after the character string Whoa!, incorrect syntax near Whoa!. So, that's pretty much what we expected. And again, think back to that little example in the text editor where that extra single quote was going to be invalid. Now we can also see down here that it is an ExceptionType=System. data. SQLClient. SQLException. So pretty clearly, this has caused an internal exception on the database. So, that should be the first red flag. We're able to actually change the query structure such that it's causing an exception on the database server. Let's go back to the text editor and see if we can manipulate this a little bit further. Now when I wrote this earlier on, I had this hypothesis that this was the way the query was structured when it was sent to the database. So let's do this, what if we close the bracket? And then we commented out the remaining part of the query. What would happen if we changed our comment to this? I'm going to copy that onto the Clipboard. Jump back over to Fiddler. Jump into the Composer, and I'm going to paste on the string that I've just created. Let's now Execute this again. Now this is interesting because the query has now run successfully. So, what it demonstrates is that now we're able to change the SQL statement to the point where we're actually commenting out parts of the original query. So, we're going even further down this path of manipulating the way queries are executing within the database server. Let's take it a little bit further. So, we'll jump back to the Text Editor. And let's try something a little bit different. So, what we might do is after this statement, and before the commenting, let's put a semicolon. Now that'll close this statement off. If we can successfully close that statement off, we can start to add our own statements. Now this is very interesting because it means that we can do something like this; let's now try and append another statement. And the statement that I want to run is just a select. So, we're going to run a select * from users. Now this is important because what I want to do is see if we can establish whether there is a table in the database called Users. Now what that means is, is that our entire SQL injection payload now looks like this. I'm going to Copy that onto the Clipboard and jump back over into Fiddler. Now, let's go and change the value of comments that we're ascending before. And I'll Paste in the payload that we just created. Let's go and Execute this. Now we've got another HTTP 500. Let's take a look at the response. Back to Inspectors, and here is a very useful message. Invalid object name users. The database is actually telling us that there is not a table called Users. So, this is extremely useful because by asking the right questions of the database, it's actually starting to disclose information. By now, we have really clearly established that there is indeed a SQL injection risk. It seems quite obvious that we're able to break out of the data context and into the query context. And we looked at how to do that so that there are exceptions returned that explicitly verify that. And we've also looked at how we can comment out the remaining part of the existing query in the application, and we've looked at how we actually terminate the existing query at our own query, and get even more information out of the database. So, it's pretty clear by now that there is a serious risk in this application. Let's move on to discovering what that actual database structure is by issuing some more, very cleverly constructed requests.

Discovering database structure via injection
In the last part of this module, we issued a request which caused a SQL statement such as the one you see here to be issued against the server. And in fact, what we managed to do is establish that there is not a table in the system called Users. Now that can be very useful information, but what would be even more useful, is if we could establish what the tables were called. So, the question now becomes; what sort of request can we make to the database server in order to have it tell us the names of the tables in the database that this application is connecting to? Now there's a very easy way to do this in SQL server. And the way we go about that is to select * from sys. tables. Now, normally if we run that against SQL server, we would get a list of all the tables in the database. So, let's see what happens if we now take this new payload and send that to the vote API. So, I'll Copy that. Let's jump back over to Fiddler. And now let's go back to our Composer again. And we'll jump down and we will Paste that new payload into the comments. Run that. And now we have and HTTP 201. And as we established earlier on, an HTTP 201 is simply the status code for credit. In other words, this request has been successful. Now what's significant about that, is that although it actually hasn't told us the names of the tables, it has established that we can run a query to select the names at assist. tables. Now, one of the reasons why that is significant, is that the database account that the web application is connecting to that database with, has the rights to select from that table. Very often, developers will give the account that that web application uses, very, very broad reaching rights. You'll very often see rights that allow that user to create objects and drop objects. In fact, it's not uncommon to see rights that actually have entire server administration privileges. Now that might make things really easy for developing because the account can just do whatever it needs to, but it also makes things really easy for attackers. So, what we've now learned is that we can select some pretty important information out of the database server that would certainly never be required under the normal operation of the web application. Our Supercar Showdown app does not need to be able to query the database to discover what tables exist. So, let's take a look at how we can exploit that as an attacker. I'm going to jump back over to our Text Editor. And the objective now is to try and get the database server and the application to disclose the names of tables. And the way I'm going to do that is I'm going to change what I'm selecting out of this table. Now I know that sys. tables has a column called Name. And what I want to do is, I want to select the top 1 Name out of it. So, we're just going to get the first name. But that is not going to tell us anything. What it's going to do is select one record and it's never going to come back to the UI in any way. But there's another little trick that we know we can do. We've established that the database server, when an exception occurs, is sending that exception back up through the web UI. So, what if we could cause and exception that discloses the name? Now, there's an easy way we can do that because what we can do, is to convert to int the name. The name of the table in the database is almost certainly not going to be an integer. What the means is, is that this query will fail and because the application is disclosing those internal error messages, it should tell us the name of the database table. So, let's now take this payload, we'll take the entire comment, Copy that. Back to Fiddler again, and we'll go down and change this comments payload again. Paste in the new value. Execute, we've got a HTTP 500 so there has been an internal exception. Let's go to Inspectors, and now we have a very useful piece of information. Because the exception message is telling us that the conversion failed when converting the in voucher value of Make to data type int. We have just been told, very explicitly, that the first table in sys. tables is called Make. This is extremely useful information. However, it is only giving us one table name. We know there are going to be a bunch of other tables in there. So, let's look at how we can discover the names of those other tables. So, we're going to jump back to our text editor again. And this time I'm going to go and grab a pre-prepared statement and Paste it in. So, I've got a statement in Clipboard and I'm just going to overwrite the existing select statement. And then we'll step through it. So, it starts out in a very similar fashion. We're going to select the name, which is converted to an integer. Which we know will cause an exception which discloses it from sys. tables. But then we're going to add a where clause and we're going to ask for a particular object ID. Now we have a nested statement which is going to select the top 1 object id from another nested statement. Now, this nested statement is also going to select the top 1 object id. It's going to give an alias to that result set and it's going order it by the object id, but in descending order. Now the reason why we're doing this, is we're going to use these nested statements to select different result sets that are going to disclose each table name one-by-one. It's going to make more sense when you actually see it executed. So, let's just copy that entire payload again from there through to there. And we'll jump back over into Fiddler. And let's go to the Composer and we'll put in that new payload, let's Execute that. Now we're getting an HTTP 500. Let's inspect that. And we can see the same error message here about not be able to convert the value Make to data type int. Now what's happened here is that we've got the first table from sys. tables and that is called Make. We knew that already. Let's go back to Composer. Now what I'm going to do now is change one of these sub-queries to select the top 2 object Ids. Now the reason why this is important and the reason why we have these nested statements, is that if I now take two records, so I take Make and whatever is next, and then I order it by descending and just take the top one out of that. What I'm actually going to get is the object ID of the second record. And then the statement that surrounds that is going to try to convert that name to an integer. And it's going to file. And if everything goes right, I'm going to get the name of the second table in the database. Let's Execute it. HTTP 500, over to Inspectors, and here we go. So, now the conversion is filed when converting the in voucher value Supercar to data type int. So, we've now got the name of the second table, it's called Supercar. We could keep going and going and going. Let's change this to a 3, Execute, back to the request. Over to the Inspector, user profile. You could innumerate through the entire list of database tables like this. What I'd like to do now is establish what columns are in that user profile table. Because then we're going to use them in a subsequent attack to get data out. So, let's jump back over to the text editor. And here is the last statement we ran. Now I can get column data out of sys. colomns. But before I do that, I want to know the object Id of the table that we just discovered. So, the user profile table. Now in Fiddler, we managed to increment that top statement to grab the third record in sys. tables, and that was the table we wanted. What I'd like to do now is get the object id. Now the problem, of course, is that object ID is already an integer. So, if we try to convert it to an integer, it's not going to raise an exception. It's not going to bubble up in the HTTP response, and we're not going to know what the actual object ID is. So, we're going to have to convert this object ID to another type that is not an integer. And then when it attempts to do an integer conversion, it's going to fail. So, let's do this. Let's do another convert. We'll just make it a voucher 20. And then the second parameter is the value and we'll close off the brackets. Now just to make sure that this defiantly won't be able to convert back to an integer, we will add a string at the end. Now when this happens, we should get an exception, which is the object ID with an A appended to the end of it. So, let's select that entire payload again. And we'll go back to Fiddler. Over to Composer, let's now set that as the value of comments and we will execute it. Let's take a look at the response, over to the Inspectors. And we can actually see we've got a slightly different message. Incorrect syntax near A. Now somehow, that A we added has actually resulted in invalid SQL. Now we can understand the reason why when we jump back to Composer, and take a bit of a close look at where we're appending that A. The problem is this plus symbol. And the problem is simply because, when we make an HTTP request with a plus in the URL, that is used as the escape character for a space. So, what's going to happen is that the web server will convert that plus into a space. And then the A is just going to be floating out there and it's never actually going to be appended to that converted object ID. What we need is the escape character for a space for the URL context. And that is just %2B. Let's try that again. Back over to the response, Inspectors, and now we can get what we want. And in fact, what we're getting here is we're getting the object ID of the user profile table. That's very useful information, let's Copy that. Now we'll jump back over to the text editor, and I'm just going to make a note of that down here. And what I'm going to say here is that the user profile table has an ID that is this one just here. Now, obviously, that is going to be an integer and we can take the A out, and that's very useful information. Now, this is a very typical sort of attack pattern. Start capturing information, writing it down, and building up a profile of what's inside the application. Now that I have this information, and I know that the user profile table inside sys. tables has this ID, I can now go to sys. columns and start selecting out columns with that ID. Now, what I'm going to do is take a piece of pre-prepared SQL because this does start to get a bit lengthy. But, what I'm going to do is just quickly take this ID and I'm going to paste it into my pre-prepared statement over here, and then I'm going to grab that statement and bring it back over here into our attack payload. Paste it there and here we go. I want to go through this in detail. But it's very similar to the previous attack. The important thing you can see here is that I've taken the ID of that user profile table and repeated it in a couple of places. The bottom line is, we're going to start getting the columns out of sys. columns for the user profile table. Let's take that whole payload again, all the way through to there. Back over to Fiddler, back into the Composer, and we'll drop this in. Let's Execute it, inspect the response, and here we are told that it cannot convert UserId to data type int. So, now we know that there is a table called UserId. I want to discover the other as well though. So, let's quickly establish what they are. And it's the same sort of deal where all we need to do is just increment one of these nested select statements. So, we'll take that up to 2, Execute, Inspector. The next column is Email. Back to the Composer, 3, Execute. The next column is FirstName. Into the Composer, 4, Execute. The next column is LastName. Back to Composer, 5, Execute. The next column is IsAdmin. Now remember also, we saw IsAdmin earlier in the module on parameter tampering. And in fact, we used that IsAdmin column to mount a mass assignment attack. This is one of the attack vectors which may then lead to an attack such as mass assignment because it has been able to disclose that internal implementation. Let's just do one more. Over to Composer, take the Id up to 6, Execute it. Let's see what column name that is. Password, alright that's a good one. Let's now note down what we've discovered. So, in fact we've found six columns, let's make a note of those; user Id, email, first name, last name, isadmin, and password. So, now we know this is what our table looks like. That's very useful because we're now going to use this information to move into the next section in this module, and actually suck data out of that table. Let's go and take a look at that now.

Harvesting data via injection
In the last section of this module we went through and discovered some internal object names. So, we discovered that there's a table called userprofile. And then by selecting out of sys. columns and trying to convert those columns names between integer, we had internal exceptions tell us that there's a column called userid, email, firstname, lastname, isadmin, password. Now we know the internal structure of the application. What that now means is that we can go and start pulling data out of the system. So, let's go and manipulate our SQL query here. And what I'm going to do is just do another select statement. I'm going to use the same pattern of trying to convert to an integer. And of course, if it is not an integer that's going to cause an exception, and that's what's going to give us the data. And the fields that I'm really interested in are going to be the email and password because their effectively the credentials for the application. So, let's grab the email. And, of course, we now know that this is going to come from the user profile table. So, this is good, this is a good SQL statement. But the other thing we can now do, is that we can limit that result set so that we can get this value record by record. So, let's add a where clause and we'll say where userid=1. Now we actually know that this is my account. So, this is going to allow us to establish that we are indeed pulling the right record out. And that the password does match the one I've been using throughout this course. So, let's go and drop this in Fiddler. And see if the attack vector works. Back to Composer, we will drop this in the comments, Paste, Execute. Let's inspect the response. And here we can see my email address. So, that's great. We have been able to pull this out via a SQL injection attack. Now of course, we can go back to our Composer. And change that column to something like password. Let's Execute that. Back to the request, Inspector, and here is the password that I've been using throughout this course. So, this is pretty serious information. But, this is my record, I already know this. Let's go and get somebody else's record. So, go back to Composer, and let's change userid to say number 7. Let's Execute that. Over to the request, Inspectors, and here is the password; gogogo. That is the password for record number 7. Of course, to do anything useful with it, I really need to know the email address as well. So, let's go back to Composer. And we will just change the column that we're trying to convert to an int from password to email, Execute. Let's inspect that response. And it is Mark Weber, markweber@f1. com. Let's go back to our vulnerable application and see if we can actually log in as Mark. Now I am presently logged in as me so, I'm going to log myself off. Now, let's go to the Log in page. Let's try the email address, markweber@f1. com. Password, gogogo, and see if we can Log in. Here we go, we are now logged in as Mark. So, this is a very serious attack. Not only have we been able to discover the table names and the column names, but now we're actually pulling data out of the system. And this is real data that actually works too. This is why SQL injection is so serious. We have just been able to pull out data of significant importance using nothing but HTTP requests. That is extremely valuable information to an attacker. And as you saw, it really is quite a simple process. You just need to understand what requests to make to the web server in order to get responses that disclose very serious, internal information. So, that's the heart of the SQL injection risk. And one of the other things it's actually told us, is that the password storage is insufficient. The passwords are just sitting there in plain text. Now remember that because that's going to be very important when we get to the module on Account Management. Now that we understand the actual mechanics behind SQL injection, let's take a look at how the entire attack can be automated such that it really is just a point and click affair. And to do that, we're going to go and take a look at Havij.

Automating attacks with Havij
The thing you need to remember with SQL injection is that it's a very repeatable attack. Earlier on, when we went through and located all of the table names and then column names that existed in the database, once we had a pattern that could disclose that information, it was just a matter of enumerating through them. Now, repeatable patterns are something that software does very well. So, there is indeed software available that'll automatically issue those injection attacks, suck the data back out, and obstruct the entire underlying process of breaking out of data context and into query context away from the person using the tool. Now this is very important because it's going to help us understand just how easy it is to automate these attacks. Now, what I'd like to do to demonstrate this is go down to the Makes and take a look at Pagani. So, let's scroll down and view the Paganis. And of course we have just got the Huayra in the Pagani list. What I want to do though is change this Make ID. So, rather than 3, let's increment it up to a high enough number that it's going to give us an exception. Let's make it 300. Ok, so now we have an internal exception and as we now know, internal exceptions are extremely useful for SQL injection attacks. Now, what I want to do in order to automate this attack is have a nice, clean URL that an attack payload can be attached to. Now one thing that we're seeing with this exception, and again this is actually an ASP. NET MVC application. So, this is a case where understanding the internal framework is actually quite useful. We can see here that we have an action result being returned from this controller. Now when we look at this method, the Index method, we can see that there's a parameter called orderBy. We can also see that down here on the next line, there is a piece of in-line SQL. And we can see the orderBy parameter simply being appended to the SQL. Let's now try and add that orderBy parameter to the query. And in fact, what we'll do is let's just go back to 3orderBy. And we can see in the Controller action that is defaulting to Supercar ID. So, let's just also give it Supercar ID. And that's fine. So that's executed without a problem. Now just for testing purposes, let's add a random character to the end of this and see if we can raise an internal SQL exception. And we can, we can see SQLClient. SQLException. So, we can now say there's a good chance we're going to be at risk of a SQL injection attack. In fact, the database is already telling us that it is an invalid column name. So, clearly it is actually taking that piece of untrusted data, passing it through to the query, and trying to execute it against the database. Let's take that out and I'm going to Copy this URL. And now what I'd like to do is go and grab Havij and automate an attack. So, let me just drag Havij over here. And now I'm just going to maximize it to this window. Now, Havij is an extremely basic tool. It's so basic in fact, that I have a video on my blog of my three year old son using this to attack a test website. It is really that simple. Now Havij is created by an organization called iTSecTeam. And you can go and grab Havij from iTSecTeam. com. And in theory, Havij is targeted at penetration testers or security professionals. In reality, when you look at the information available on Havij on the Web, particularly when you look at things like YouTube videos, you'll very quickly get a sense that this is predominately not being used by penetration testers. Rather, it is being used by what we would locally refer to as Script Kiddies. In other words, this tool is so easy to use, that people who know nothing about SQL injection, let alone web security in general, are able to fire it up and attack websites. And indeed, it is tools like this that often lead to breaches that make the front pages of the news. Let's have a look at how simple this is. I'm going to change this Target and I'm going to Paste in the URL we just copied from our vulnerable application. And I'm going to tell it to Analyze. Now, down on the bottom we can see Status window. And the first thing we'll see here is DB Name: HackYourselfFirst. This is the internal database name behind my application. So, already Havij is being able to identify a piece of internal information that we would never want to leak. Let's go up and have a look at the Tables tab. Now this is where it starts to get really interesting. You can see on the left of the screen, we have HackYourSelfFirst. Which is the database name and it is checked. Let's go and get all of the tables from this database. And here we go, here are all the tables that are in that database. And this is where you start to realize just how easy SQL injection attacks can really be. Probably the most interesting table in here is going to be the UserProfile table. Let's check that. Now, let's go and get all the columns. Now, this is exactly what we discovered earlier on via some pretty manual labor. And indeed, the reason I showed you earlier on how to actually make these requests to the application and the SQL syntax beneath it, was so that you could properly understand the mechanics of SQL injection before seeing how it could be automated. But from that exercise, again we did see that this is a very repeatable pattern. So, it should now come as no surprise that pulling this data out can be a very simple point and click affair. Let's now tell Havij that we'd like to get the Email address. And we'd like to get the Password. And we'll go over and Get the data. And there we go, here is all that data. Now, that was amazingly easy and we can see here that we have a full database of email addresses and passwords. Now in the background, Havij has gone through and issued a whole bunch of HTTP requests designed in a very similar fashion to what we used in the earlier sections of this module. So, for example, it uses a very error-based centric attack. Where it's simply making requests that cause internal exceptions that disclose the data in the database. The difference with Havij, is that it's been able to issue these requests extremely quickly. So, in clicking that Get Database button, there are dozens and dozens of requests that fired off after clicking that button. And remember they're HTTP requests, and all that data was pulled back almost immediately. And this is the real story about Havij. Automation of attacks like this is extremely simple, the barrier to entry is extremely low. Anyone can go up there, grab this tool for free right now, point it at a website with the parameter in the URL, and if there's a SQL injection vulnerability, potentially pull back all the internal data like we've just done now. That, more than anything, shows why SQL injection is such a critical risk and one that we need to be extremely conscious of. So, with that established, let's move on and take a look at blind SQL injection. And then most importantly, we'll look at how a secure application would respond to a SQL injection attack.

Blind SQL injection
So far, throughout this module, all of the SQL injection attacks we've looked at have been what we call error-based attacks. In that their success has depended on the application returning error messages with internal data on them. In the introduction of this course I also mentioned an attack vector called union-based attacks. Where data would actually be appended to a result set, return to the screen, and showing after the legitimate data that the website would normally display. Now both of these attacks are very explicit. You have data in the user interface. It's actually admitted as part of the HTML. Either by appending to a result set, or in an exception message that's bubbled up to the HTML. But there are times when neither of these attack vectors will work, so, for example, when error handling is properly configured and internal messages aren't linked out to the user interface. And indeed, that's what we discussed in that Internal Implementation Disclosure module. Now, just because we can't get the application to explicitly tell us about internal structures and internal data, doesn't mean that we can't still discover that information. And this is where blind SQL injection comes into play. Back in that introduction I mentioned two types of blind SQL injection; Boolean-based and time-based. What we're going to do now is look at a Boolean-based SQL injection attack. And to do that I want to jump over to the Leaderboard. Now, we're going to look at a different attack vector on the application this time. And what I want to do is just expand this little Sort results panel. Now, it's already sorted by votes. And we're seeing the most popular vehicle first. Let's now Sort by Power. Now that we've done that we can see that the URL has changed. And, in fact, we have two parameters here, orderBy which is obvious power. And then we have a parameter called ASC, which looks like an abbreviation for ascending. Certainly, that is the syntax that we would use in a SQL server orderBy clause. And if we take a look at that Power column, we do see the most powerful vehicle first and the least powerful last. Which is what you'd expect when ordering by power. So, this is clearly one more parameter which is being passed to the application and used in the construction of the SQL statement. We know by now, just by looking at a URL like this, there is a possible SQL injection risk. It is highly likely that there is a concatenation of a SQL statement happening in the background that is taking orderBy and appending that in. And then it's also probably ordering, either by ascending or descending depending on the Boolean state of that ASC value. Let's see if we can validate that. And what I want to do is just add another character to this Power by value. So, let's just add a 1. Load the page. And what we can see now is that an error has occurred. But this exception is very different to the exceptions we got earlier on; where the internal exception bubbled up to the user interface. So, what actually appears to be happening here is that the application is actually catching the exception, and giving us a nice friendly response. Now, of course, this is the way an application should respond if an unhandled exception occurs. It should respond in some sort of friendly message. Usually templated like the rest of the site. And not respond with the details of an internal exception. So, so far this actually looks pretty good. We're going to need to get a little bit more creative. Let's Copy this query string. And then jump back over into our text editor. And Paste it in here because we're going to need to experiment with this a little bit. So, let's begin by breaking this down the way that the statement is probably structured in SQL server. So, this is probably going to be something like select * from supercar order by. And then we've got our first value, and then we'll just take out that 1. And then we're probably going to find that that second value is passed through. So, let's just wrap those in some braces so that we can differentiate where we think our untrusted data is appearing in the query. Okay, now assuming this is the case, we have control over the values passed through in both these pieces of data; PowerKw and asc. Let's just put this down a couple of lines and leave us a bit of blank space here to write out how we think we might mount this attack. What we want to do with blind SQL injection is ask questions of the database. And we want to ask questions that have a Boolean response; yes or no, true or false. Usually some sort of equivalency. The other trick, of course, is that we have to express this statement in a way that it works as part of the orderBy clause. So, for example, what we might do is say let's put a comma and then add another statement. Now this is simply going to be the second value that the statement orders by. The next thing I really want to do is be able to ask a question that is going to give a true or false answer. There are many different ways to do this, but one approach would be to add a case statement. So, let's say case, when, and now we can put a condition. So, let's check, for example, how many tables there might be in the database. So, what I'm going to do is select count * from sys. tables. And I'm going to check if it equals 0. Now, if it equals 0, what I want to do is return a value that won't cause an internal exception. Now if it doesn't return and internal exception, it means that page will load successfully. And we can then assume that this is true. So, let's just return a 1. Now, if there's not just a single table, let's put in an else statement. And we'll go back and do another convert. And what we might do here is we will convert to int, and we will try and convert an X to int. Now, clearly, this is going to fail. What this will tell us is that if we can pass this payload through to the application and we see an exception in the browser, it doesn't have to be an internal exception bubbling up to the user interface. It just has to be that friendly exception we saw earlier. That will tell us that there are not 0 tables in the database. Let's now end this and we'll comment out anything else that happens after it. So, this is a very simple blind SQL injection test. Let's copy this string, and jump back to the application. Now what I'm going to do is insert this just after PowerKw. Because, of course, this will really just go through and be treated as a second orderBy column. Now, let's load this. We see an exception. What that exception is implicitly telling us, it that there is not 0 tables in the database. That's probably pretty obvious. Let's go and see if there are 20 tables in the database. And to do the we will simply change the equivalency from 0 to 20. Now, this is the value that we pass through to check the account. Once you start editing in the URL, everything looks a lot more confusing because now we have escape characters for the URL. So, every space that we had before now appears to be a %20. This is one of the reasons why I like editing these SQL injection attacks in a text editor. Because you've got a nice clean place to work. This one's easy enough though, so let's make it 20. Still an error, there must not be 20 tables in the database. What you end up doing is just simply enumerating through the different possible values. Let's try 5, it's not 5. Let's try 6, no good. And again, keep in mind things like Havij which can just automate this process. So, although this looks manual, it need not always be. 7, no joy with 7. Let's try 8. Ah-ha! Now the page has loaded successfully. So, if we go back to that text editor and look at what's actually happening. This case condition, and of course, we changed 0 to 8 in the example we just did, is now returning 1. As opposed to trying to convert X to an integer. So, this is the heart of blind Boolean-based SQL injection. All we're doing is causing the browser to respond differently in Boolean fashion depending on the data that we have sent to it. So, this is great, we now know there are eight tables in the database. But, of course, the next thing we want to know now is what the names of those tables are. So, we're going to have to combine some of the attack vectors we saw earlier on with this blind Boolean-based approach. So, what I'm going to do in this case is go to our select statement. And let's take the first record and then we'll take a substring of that record. So, this is going to give us just one segment of the value that we passed to it. And I'm going to pass at the name. So, this will be the name column from sys. tables. I'm going to start at position 1, and I'm going to take 1 character. So, what this is going to do is give us the first character of the first name that is found in sys. tables. Now, of course, this is never going to end up equaling 0. So, the other thing we need to do is now change this, and we'll just start at a. So, looking at this statement again, what's going to happen is if that first table has a name that begins with a, then we're going to return 1. So the page will load with that error. Otherwise, we're going to try and do an invalid conversion so the page will load with error. Let's take that value. Jump back over to the browser. Jump into just after that power code, W query string value. And all the way through to that next value and paste it in. We have an exception. So, what that tells us is that that first table does not begin with the letter A. Now, we could repeat this process, B, C, D, and keep going through until we get a hit. But, of course, that is going to be a very laborious process. On average it's probable going to take about 13 go's, or halfway through the alphabet, before we actually get a hit. And there is a more streamlined approach; we just have to ask the question a little bit differently. The question I want to ask is where in the ASCII table range that character falls. So, keep in mind that every character has an ASCII value. That ASCII value is an integer. We can now start saying, does that character fall in the first half of the alphabet, or the last half of the alphabet. To demonstrate this, let me first grab an ASCII table. And, in fact, there's a very easy one just over on Wikipedia and I have a link directly through to that. So, here is our ASCII table. And what we want to focus on is the lower case ASCII values. And those ASCII values range in decimal value from 97 for A, through to 122 for z. And the character in the middle, which is always the M, is 109. Let's go make a note of that in our text editor because we're going to want to come back and refer to this. So, we'll just jump down here, a=97, m=109, and z=122. Okay, with that in mind, let's now change our query to discover which segment of the ASCII table, our Boolean-based equivalency falls into. So, we're going to need to go back up to our SQL injection here. And the first thing I want to do is lowercase the name because if we don't lowercase it, the range of ASCII characters literally doubles. There are different ASCII character values for uppercase characters then what there are lowercase characters. And for this example we are assuming we're not worried about SQL server collation, we're just going to make this lower. And then of course we need to close off that method. So, now we have a lowercase letter. The other thing we're going to do is we're just going to wrap around an ASCII method. And in SQL server, this ASCII method is going to convert that character into its equivalent, ASCII value. What we can do now is look at where that character falls in the range of ASCII values. Now keeping in mind that we need to ask a true or false question, this is Boolean-base SQL injection. Let's check if it falls further down than the mid-point which is 109. So, let's look at this again. If the first character of the first table in sys. tabels is greater than an m, so, somewhere between n and z. We're going to get 1, so this will pass, the page will load without an error. Otherwise we're going to get an invalid conversion and we'll see and error on the page. Let's copy this, put it in the browser, and see what we get. We can get rid of Wikipedia now. So, let's Paste this back into the same position, everything after powerKw all the way up to when that next query sting value is passed, and press Enter. We have an exception. What that exception means is that the first character of that first table name falls in the first part of the alphabet. So, just jumping back over to the text editor, that means that the value must be somewhere between a and m. So, somewhere between 97 and 109. And that's 109 inclusive because we're doing a greater than test here. Let's now go halfway in between. So, let's see if it's greater than 103. So, back over to the browser. We'll just find where we had that greater than test, which will be just a little bit further along. And we'll change 109 to 103 and load the page. Now the page is loaded successfully. So, let's make a note of what we know. What we've established is that our value is greater than 103, but less than or equal to 109. Let's now go halfway in between. So, we'll go 106. We'll find the value, there it is, 106. Page load successfully. Okay, now we know that it is greater than 106. Let's go 108 this time. 108, page load successfully. Now we know that the first condition was testing for greater than 109. Now, this is actually told us exactly what that letter is. If we jump back to here, we know that it was greater than 108, but it wasn't greater than 109, which was our first test. Therefore, we know that the first ASCII character is indeed 109. Therefore, the first letter of the first table in sys. tables is an M. That is a bit laborious. It is, however, faster than individually checking every single character. Although, of course, the other thing is all this has told us is the first character of the first table. We now have to go through and increment it such that our sub-string starts at position two and takes the second character. And this whole process has to be repeated. Character by character, table by table. Now, clearly we're not going to go through and manually do all that here in this example. But, it is enough to demonstrate how even when there is no explicit feedback to the attacker, such as our union-based injection or error-based injection. The internal implementation of the system can still be discovered. And just as we saw with Havij when it attempted an error-based SQL injection attack, using blind Boolean-based SQL injection can also be automated. Of course, it's going to take a little bit longer because it needs to make more HTTP requests. But, ultimately we can end up with exactly the same result because this application is still allowing us to run arbitrary SQL statements on the application. So, this is a really important message to leave at the end of this section of the module. Just because when you test your application you can't see internal information disclosed explicitly in the output, doesn't mean that there's not a SQL injection risk. And it doesn't mean that an attacker can't still discover everything they could otherwise, simply by asking the right questions. And, of course in this case, they were just Boolean-based questions. So, there are our two different approaches. The explicit error-based injection and the implicit Boolean-based injection. Let's now go and take a look at the secure application and see how it protects against these risks.

Secure app patterns
Now we're back on the secure website and we're going to take a look at a couple of different SQL injection mitigations. And those mitigations are parameterization and whitelisting. And in a way, it's actually quite similar to the way we used outputting coding and whitelisting in the module earlier on, on cross site scripting. Now how you actually implement both parameterization and whitelisting is going to be very dependent on the framework and the database server that you are using. It is going to differ from technology to technology. So, what we're going to be able to look at is the expected behavior in terms of what you can observe through the web browser. If you do want to see this implemented in ASP. NET, go and take a look at my other Pluralsight course on the OWASP Top 10 for. NET for Developers. For now though, I'm already logged in as myself. Let's just go over to the Leaderboard and we're going to try and repeat the attack we did very early on. Which was to start manipulating the comments in the vote. So, let's go down to the Koenigsegg. And I'm going to click on Vote. And I'm going to leave a very similar message to what I did early on which is, Whoa! And I'm going to add a single quote to the end. Now when we did this right at the start of this module, when we're trying to establish the likelihood of a SQL injection risk, this actually caused an internal exception. Let's try it again now. So, that worked. We didn't get an error message this time and indeed, if we scroll down just a little bit, we can see that that comment has appeared down here. Now, this looks very subtle, but let me explain what's important about this. In the comment, we can see that there is a single quote. Earlier on, what the application was doing was appending the comment to an existing SQL statement. So, when we put this thing together in the Text Editor, we looked at how what was probably happening was the comment was being concatenated to a query and passed in between single quotes. That's just normal SQL server syntax. When we added a quote into the comment itself, that actually led to invalid SQL. Because that one quote closed off the string in the Insert statement. And then left this other quote, the original one which was part of the original query that the data then got concatenated with. It left that original quote hanging out there on its own with no closing quote. That's what caused the internal exception. Now, the big difference here is that I have parameterized this value in the SQL statement. Now again, how you actually do this will differ from technology to technology. So, we're not going to delve into the actual implementation of it. The important thing is though, is that when we parameterize a SQL statement, each of the pieces of data is passed as a discrete unit without the possibility to break out of the data context and into the query context. It's no longer a matter of just concatenating together one big string. What you'll normally find is that parameterized values in a SQL query will appear in the SQL statement using an identifier such as an @ symbol. So, for example, where this appeared in the insert statement, we might have seen comments appear with an @. And then the actual value would be added to that statement through a construct, specifically designed to add parameters. No matter what value we put in that comments field, it will always be taken verbatim and inserted into the database. That is the single most important factor for mitigating SQL injection. So, look that up for your web framework of choice. How do you parameterize untrusted data in a SQL statement? That is absolutely critical. So, that's one approach. The other one I mentioned was whitelisting. So, let's back up to the top of the page. We'll go Home. And I want to go and look at the Paganis again. And if you recall, it was this page where we were able to add an orderBy clause. So, what we did is, we said,? to starter for query string. And I can just grab this one here from my history. Orderbysupercarid. Now this works just fine. The problem we had last time was when we added a character such that the column name became invalid, an internal exception leaked the fact that that column name didn't exist. Let's try that again. Supercarid1. Now we have quite a different response. Clearly we've got an error message. And it's explicitly told us that there was an Invalid order by clause. Let's try changing this to something else. So, I know from the Leaderboard page that there was an ability to oderby powerkw, for kilowatts. Let's try that. That works successfully. So, clearly that must be a valid column. We'll append a 1 to that. And it fails again. What I've done here in order to secure this feature is applied a whitelist. Now if you recall, back to the earlier module on Cross Sight Scripting, when we looked at untrusted data, the idea of a whitelist is it says, this is what we trust; these are the values that we know to be good. In this case, what I've done is I've created a whitelist of allowable columns which this page can order the results set by. So, there are a whole bunch of them in there. And if any one of those values are passed through in that order by parameter in the query string, we'll get a valid result ordered by that column. If anything changes, the very first thing that's going to happen, it that the whitelist validation will say, hey this is not an allowable column. The way we're going to handle this is we're going to return this error message here, which makes it very clear that this is not on; it's not going to work. Now, this may even be a little bit too much information. For an end user, it might be better just to say something a little bit more generic along the lines of an error having had occurred. But, it does illustrate the point here very well. Now, whitelisting works well when there is either a very discrete set of values, such as we have, there are only a small number of columns that I needed to put in my whitelist, and it also works well when we can create a pattern for the whitelist. So, for example, if we were expecting an email address, it would be easy to create a regular expression which described the allowable pattern for an email address. If we were passing an email address through as untrusted data, and we validated it against the appropriate regular expression, you would not be able to get a single quote into there. So, that would be a SQL injection attack vector that would no longer be possible because of the email address whitelist. Now, whitelists are by no means an excuse not to do proper parameterization of the query which is what we just looked at. In reality, whitelists and parameterization are mutually inclusive, in that what we really want to do is apply both of them. So, this is defense in depth again. Now it does get a little bit trickier when we start talking about whitelist for things like that comments field. Clearly in a comments field, you wouldn't want to say, disallow single quote. That's a very valid component of English language punctuation. You couldn't exclude that. And indeed, in something like a comments field, you really aren't left with a lot of choices. Sometimes you'll see some web applications try and reject data that might have say, a Union All in it. In fact, I've seen web applications that explicitly give instructions saying you may not enter text such as Union All. That does worry me a little bit because you wonder how much focus the developers have put on blacklisting potential SQL injection attacks without actually focusing on that most essential underlining practice which is parameterization. So, there you have it. There are your two predominant approaches. There are further mitigations. Things like applying the principle of least privileged on the database account that the web is connecting with, so that an attacker can't select from places they're not meant to. Or do things like drop tables or escalate privileges. That's another very good pattern. That becomes very specific on the framework. And again, it's something I talk about in my other Pluralsight course in the first module on Injection. So, go and check that out if you want to see some details of how to mitigate this risk at the ASP. NET

Summary
Let's summarize the module, and the first thing we started out doing is taking a look at what a SQL injection risk really is, and after establishing how it remains number 1 in the OWASP Top Ten, and just how critical and prevalent the risk is. The most important thing we established was that a SQL injection risk is all about breaking out of the data context and entering the query context. So, now we're back to untrusted data again. We keep coming up against this concept of untrusted data having malicious payloads. And this is also what SQL injection is all about. Untrusted data, not properly validated, not parameterized, changing the function of the query. After we looked at how to establish whether an injection risk actually exists, and that's when we put that single quote on the end of the comment when we voted. We moved on to how we can use error-based SQL injection in order to discover both table names and column names. So, this was really important because this disclosed the internal structure of the database. Once we could establish what that internal structure was, then we could apply the same principles to extracting data out of the system. Now, in this module we've really only looked at discovering information and pulling it back out. But, certainly one thing that can be done with SQL injection, is the attacker can get far more malicious. If that web application is connecting to the database server with an account that has the credentials to do things like drop objects or create objects, the damage can be severe. The attacker can just wipe out entire tables. Just start deleting everything. Creating objects can be even worse because it may well be that they can just create their own user account. Give it full control over the database, and then use their own tools to connect directly through to that database and not even have to worry about going through the web application in order to mount a SQL injection risk. Another thing they could do is just shut down the database server. Just turn it off. Or go even further, get a remote command shell on the server. There's a lot that can be done with SQL injection. And we've only really just scratched the surface of the most common styles of attacks in this course. One thing I do hope really left an impression was how easy it was to automate an attack with Havij. When you see that's simply a matter of downloading a piece of free software with a nice graphic user interface, and then Copying and Pasting a URL with a query string parameter on it and suddenly being able to pull out all the data of the system, almost instantaneously, that's what should really bring this risk home to you. That's where the penny sort of drops and you say hey, I can now see why there are so many dumps of passwords on Pastebin, and not necessarily by elite hackers. This is a very, very simple attack. And in fact, if you do go out there and Google around for Havij, one of the things you'll find is lots of information on actually how to actually identify websites that may be at risk of SQL injection attack. So, predominately looking for URLs that have pinned things like an ID in the query string. So, you may then find it is generally script kiddies, literally kids, who go and run this application against vulnerable websites. And so long as they know how to Copy and Paste, they can mount a SQL injection attack. After that, we took a look at blind SQL injection. So, this was when we couldn't get any explicit feedback from the application. We couldn't use a union-based attack in order to append an unintended results set to a legitimate result set, and show it back in the browser. And we couldn't used an error-based attack because the path we were looking at simply wasn't disclosing internal error messages. So, that's why we went blind. And, in fact, we used a Boolean-based blind attack where we simply asked questions of the database. Hey, does the first table in the database begin with the letter A? Or, does the first table in database begin with the letter whose ASCII character is in the second half of the alphabet? These are simple blind-based attacks. And even though they are a bit laborious, remember how Havij automated the process and certainly there are tools out there, including the paid version of Havij, which can automate blind SQL injection attacks. And finally we moved on to the mitigation in our secure app. And the two key mitigations were parameterization, so making sure that any untrusted data was never just concatenated to the query, it was always passed as a structured parameter so that is couldn't break out of that data context, and whitelisting; so being explicit about what we want to allow. By literally listing out in an array of allowable column names in the code, I put a dead stop to the ability to pass through an invalid name with a potential SQL injection payload. And as I said in that part of the course, this by no means negates the need for parameterization. It is an extra layer of defense. So, let's finish the module on that concept. Mitigating SQL injection is about applying layer on layer of defense. Get that parameterization in there. Try and whitelist everything you can. As I said in the section on securing the apps, even go further, and look at principle of least privilege, and other mitigations that exist in your framework of choice. But, that is really key, you will have to look at this very carefully in your framework of choice. There will be mitigations and there will be ways of easily getting it wrong and introducing a very serious risk into your application.

Cross Site Attacks
Introduction
Hi this is Troy Hunt and in this module we'll going to take a look at Cross Site Attacks. We're going to take a look at a few different attack vectors for a cross site attack. But before we do that, I want to start by understanding the nature of these attacks and what it is about website design that makes them successful. We'll then move on to specifically looking at cross site request forgery risks, and you'll often see this sort of attack referred to as CSIF. We'll then move on and take a look at the role of anti-forgery tokens, because they're really the only solid defense we have against a CSIF attack. But as we'll see in our vulnerable website, anti-forgery tokens are very frequently not present in web applications. After that we'll also take a look at the risk of CSIF against APIs. Very commonly we'll find CSIF risks mitigated in normal HTML pages, but then the API is left vulnerable. So, we're going to take a look at that attack vector as well. And finally we're going to take a look at clickjacking, and this is an attack vector that many developers are not aware of, and you very very frequently see websites at risk of this. So what we'll do is mount a clickjack attack on the vulnerable web application and then we'll review what a secure implementation of a website looks like, and how it stops a clickjack attack dead in its tracks. So let's move on to understanding what makes a cross site attack possible.

Understanding cross site attacks
Cross side attacks are predominately mounted against authenticated user sessions. Because ultimately a cross side attack boils down to an attacker wanting a user to perform an action on their behalf. Now there's not a whole lot of value in most cases of an anonymous user performing an action. But there is a lot of value if an attacker can get a user that is authenticated to a website to perform an activity under their identity. So a classic example is an attacker might want to a user who is authenticated to a banking website to transfer money into the attackers account. If the victim is authenticated, and the attacker can trick that victim into making a request on their behalf, they might actually be able to get that victim to send them money. Now under pinning all this, is the simple fact that authentication state is usually persisted by an auth cookie. And we've looked at auth cookies many times now in the earlier modules. So this is the way that we persist state, and in this case authenticated state, in the stateless world that is HTTP. The beauty of the auth cookie is that it is automatically sent to the website with every request. So once you can issue a user with an auth cookie, every single time they make another request for the site, so going back to the banking example, maybe they load a page with their account balances, that request automatically attaches the authenticated identity of the user. Every request they make to the domain that is valid for that cookie is, an effectively, an authenticated request. The cookie is sent automatically. Now of course once that cookie is sent to the website, the user can then be identified and then authorized simply by the website referring to that cookie. Now usually there are all sorts of encryption and other integrity controls to ensure that that cookie is indeed legitimate and hasn't been forged. So web applications do normally put in controls to make sure that the integrity of those cookies is sound, particularly native implementations within frameworks designed to persist authenticated state via these cookies. So the point is that we have a high degree of confidence that if that cookie is sent with a request, then the user is who the cookie says they are. Now here's the trick with cross site attacks. What if we, as an attacker, could get that user to make a request that they didn't intend to? So how could we trick that user into issuing a request, which they never intended to and has malicious intent, in order to advantage an attacker? That is at the heart of these cross site attacks that we're going to look in this module. Let's break it down a little bit more visually. So imagine we have our user. Now this user has already authenticated to the website. So let's assume the whole authentication process has happened successfully, they've received an auth cookie. Now every single time they make a request to a resource, that request is going to be accompanied by an auth cookie. So really what's happening is every time the user makes a request they're sending a form of identity verification along with them. However, it's not really the user that is consciously doing this, the user is really just clicking on buttons in the browser. In reality, it is the browser that is actually making the request for the resource. Now this is an important distinction because it's the browser that we want to trick into making an unintended request. The user is really doing exactly what they want to, there're clicking on buttons and loading pages. But here's where the attack component comes in. What an attacker wants to do in a cross site attack, is have the users browser issue a request on the attackers behalf, and when that request is issued, the cookie will naturally accompany the request. Now of course all this is predicated on the fact that the attacker is going to trick the browser into making a request to the site which the cookie is valid for. So in the banking example, the attacker wants that browser to make another request to the banking website, but the attacker wants to construct the request a little bit differently such that it passes different parameters. So the attacker really wants that users browser to issue a request which is going to send them money, and they don't want the user to be any the wiser. All of that is going to happen against the legitimate banking website, with a legitimately constructed request, it's just that the user never intended to perform that action. All of this makes a lot more sense when you actually see it happen. So let's move onto the next section of this module and start testing for CSRF risk in our vulnerable application.

Testing for a cross site request forgery risk
In order to test for a cross site request forgery risk, in our vulnerable site, I've set up a little demonstration. Now the first thing I'd like to point out is that I'm currently authenticated to our vulnerable website. We have a Hello Troy up here in the navbar. Now that authenticated state is important, because what the attacker in this example is going to do is take advantage of the fact that I'm authenticated by causing me to issue a request that performs an action that only an authenticated user can perform. The way I'd like to demonstrate this is to start out by performing a very typical activity. And that activity is going to be loading my Facebook page. Many attacks come from sources, like Facebook, where attackers can share links. And these cross site attacks are predicated on the fact that an attacker is going to cause a victim to follow a link to their website, which mounts the cross site attack. In some ways it's a little bit similar to the reflected cross sites scripting risk we looked at earlier, where the attacker passed their payload via a carefully crafted link. The commonalities that these sort of attacks usually depend on a little bit of social engineering in order to get the user to go somewhere that allows the attacker to mount their attack. So let's start off by going to my Facebook page, and clearly I'm currently logged onto Facebook. What I'd like to draw your attention to, on this page, is that in my timeline there's something rather enticing, right at the top. In fact we have free iPhones. Now free iPhones, or free gifts of any kind, are a very common trick used by attackers to entice victims to click on links. And certainly this does look pretty legitimate and in fact we can say that there's a link here at the bottom of the post to apple. com/freeiphones. Let's go and take a look at this. So here we go. There is an offer for a free iPhone, and it looks like winning one is a pretty easy affair. Now of course for us being a little bit more in tune about web security, we can see that the URL is clearly not apple. com. And what you'll often find is that attackers end up redirecting through all sorts of intermediaries to try and circumvent browser controls around things like known fishing sites. In this case we've just gone straight to our attacker website. Now everything here actually looks pretty straight forward. Want to win an iPhone, of course you do, click the button below and it's yours. So let's go through and do that. Let's win. I wanna win. You won, click OK, and it's done. Alright let's do that, OK. Alright so according to that we have somehow just won an iPhone, we haven't actually provided any information, but it looks like we've won. It certainly doesn't look like anything evil has happened. However, there is a problem. And to illustrate this problem, I'm going to open a new tab. And I'm going to jump back to our vulnerable website. I'm going to log myself out. And I want to try and log back in again. And I'm going to use the same email address we've been using throughout this entire course, and the same password I've been using throughout this entire course. And log in. Except it didn't work, the email or the password provided is incorrect. I'll try that again just to make sure that I didn't get anything wrong. Log in, nope not working. Somehow our password has been changed, and our password has been changed simply by clicking on that win link on the attacker's website. Let's go and take a closer look at what's happening. I'm going to go back to the attacking website tab, and I'm going to open the developer tools. And what I'd like to do in the developer tools is jump down to network and I'm going to try and win again. Now let's see what happens after I click the OK button. We'll go up to the top request. And here's something interesting. The very first request is a post to hackyourselffirst, in facts it's a post to the change password path on hackyourselffirst, which of course is our vulnerable application. Let's take a closer look at this request. Post request, it's responded with a 302, we've already established it's to the change password path. Now let's scroll down a little bit and I want to look at the request body. So here's the thing, our request has posted a new password called hackpwoid, and a confirm password of hackpwoid. So what's actually happened here is that this attacking website has changed our password. Now how is this possible? Well it's possible simply because all it's done is reconstructed the request to the change password resource and passed the correct form body. So what do I mean by reconstructed the request? Well let's take a look. It has requested the change password path, it has made an HTTP post, when it is posted it has automatically sent all of the cookies for that domain. And of course when I just tried to win now, I'd already just logged out, and that's why we're not seeing an auth cookie. But originally I was logged in and that auth cookie would have been sent so I would have been identified. And then the only other thing that this attacking website has done, is it has sent the correct form data, a new password and a confirm password. Now of course it's easy to establish the form data that's expected by the target website, you just need to go there and try and change your password. So in essence, this is a perfectly legitimate HTTP request to our target website. It's exactly the same, other than that auth cookie, which of course we had when we initially fell for the attack. But the point is, is that it's exactly the same request as if I was on our vulnerable website changing my password. This is the essence of a CSRF attack. The attacking website has simply tricked the browser into making a request which I, as the victim, never intended it to make. Now the way it's done this is really fundamentally simple. If we view the source of this page, this is all that's in there. So there is a form action, which goes all the way through to that change password path. There's one hidden field called new password, with a value of hackpayword. And another hidden field called confirm password, with the value of hackpayword, and that's it. That's the entire form structure. Then of course when we click on the I want to win button, we get the alert, after we say OK to the alert, the form posts, and the entire attack is complete. The attacker now has my password. Or conversely, I am now using the attackers password, either way, the attacker now has enough information to log on to my account. Now just so that I, as the victim, couldn't see what was happening, the target of this post is hidden frame. Hidden frame is in iframe down here with display:none. So even though my post, to change the password would of returned a legitimate response with HTML markup, that gets hidden, it gets put in that frame and the display turned off. So that's why I didn't see any response from the legitimate website. So this is the entire execution of a CSRF attack. An attacker simply figures out what the request needs to look like, constructs a site that's going to issue that request on the users behalf when they visit it. And then simply has the user perform an action that issues the request. There are even more subtle ways of doing this. So for example, if it was a get request, the target site could have simply embedded an image that had a source of the vulnerable path that the attacker wanted the victim to make a request to. In that case, just loading the page would have caused that to happen. And indeed we could have automated this attack even further by just automatically posting on load. So there are lots of different ways of mounting this CSRF attack. Let's move on though, and take a look at the role of anti-forgery tokens and how we can defend against this attack.

The role of anti-forgery tokens
What made the cross site request forgery attack, that we saw in the last section of this module, so successful and indeed so easy, was that it simply repeated a known pattern. And that pattern is the way an HTTP request must be structured in order to change the user's password. All it had to do was make a post request to the change password path, and pass through those two fields the new password, and the confirmation of the new password. So as long as that request was then made by an authenticate user, so they had a valid auth cookie, that was all the attacker needed in order to mount a successful CSRF attack. Now the mitigation for CSRF is what we refer to as anti-forgery tokens. So let me explain how an anti-forgery token works. First of all let's imagine we have our user, and our user requests a page with a form. That request obviously goes off to the server, and then the server comes back with an HTTP response. Now there's a little trick in the way the server responds. And there are two very small differences to the way the server responded in our vulnerable app. The first difference is that we have a hidden field with anti-forgery token. Now we'll take a look at what that token looks like in just a moment. But the key thing for now is that it is a unique string. Now the other piece of information the server adds to this response, that we didn't see in the earlier response, was an anti-forgery token in a cookie. SO now we actually have these two anti-forgery tokens, one is a hidden field, and one set in a cookie. Now there are two very important things to understand about these tokens. First of all, they're paired. So these tokens actually belong together. Now normally there is some form of cryptography applied to these tokens, so you won't obviously see any pairing just by looking at the token. The important thing to know is that within the content of those tokens, there is an explicit relationship between the two. The other thing that is important about these tokens, is that they're keyed to the current user. So what we mean by that is that if I log on as Troy Hunt, and I get an anti-forgery token in the hidden field and in the cookie, that token won't be of any use to anyone else. It simply won't be valid for them. And we'll have a look at that validation process in just a moment. So this is what we get when we load the form. Token in a hidden field, token in a cookie, paired together, and unique to the current user. Now let's imagine the user submits the form, what happens then is the browser sends back both the hidden form field, and it just simply goes back as part of the request body. It's simply another form field. And of course the cookie goes back, because every time we make an HTTP request for a website, the browser will send back all the cookies that are valid for it. So effectively with sending back both these pieces of information to the server. Once the website receives these tokens, it will then validate them. So the website is able to decrypt the tokens, it will validate that they belong together, and by that I mean that the token from the request body is correctly paired to the token from the cookie. And of course that the tokens do belong to the current user. Now if all that doesn't work, the website rejects the request. But how does all this actually mitigate the risk of a CSRF attack? Let's take a look at that now. First and foremost, anti-forgery tokens add randomness to the request pattern. And it's randomness in so far as the attacker does not know the token that the user needs to submit. So they don't know the value of the token that was served up when the user requested the form filled. Now of course in many CSRF attacks, such as the one we just saw, the user didn't request the form filled to begin with. So they have no token for the attacker to use anyway. But even if they did, the browsers security model is not going to allow the attackers website to make a request to the target website, request the anti-forgery token, and then allow the attacker to construct a malicious request with it. Now when a legitimate request is sent, so the right anti-forgery token is sent in the hidden field, the one in the cookie is sent along with it. And that one in the cookie provides independent verification of the legitimacy of the token in the hidden field. So now we've got these two channels. We've got the cookie, and that's going to go along with every request even forged requests, and we've got the hidden form field. And together they give us confidence that if they all line up, so the pair matches and their keyed to the current user, that the request is legitimate. The attacker simply can't reconstruct that request without finding some way to have the user load the form and access the token in the hidden field. With that now understood, let's go over to the secure site and see how it handles the same attack as we saw earlier. So here I am on the secure site. Let's do what we did before, and go into my account, and go to change password. Now what I to do this time, is I open up the developer tools, we're on the network tab. Let's change the password and see what is sent with this request. Okay, password changed. Let's go up to the first request. And let's have a look at the headers. Now for the most part this looks just like the header from the vulnerable site. Same requested URL, certainly it's the same path at least. It's still a post, it's the same response code, and of course if we go down and take a look at our cookies, we still have an auth cookie. Indeed that's the only way the website knows who we are. The difference this time is that we also have a request verification token. And clearly what we have here is a cryptographic string for the value. And as I mentioned before, that cryptography is important because the integrity of that token is absolutely essential, so there needs to be some cryptographic protection on it. You don't want the anti-forgery token to be forged. Let's continue down a little bit and what we will find is in the form data, we also have a request verification token. Now that token is clearly different to the one further up in the cookie, but they are keyed together. So they're the two new pieces of information that are going back to the website when we change the password. Let's now go over to that attacking site and we'll try to see what happens when we go to win an iPhone this time. So we go back out of the attacking site. I've updated it so that it's now targeting the secure site, I'm going to open the developer tools, we're on the network tab. Let's click I want to win, and OK. Alright so now we can see that there has been one request and we can see that that request has resulted in an HTTP 500. So clearly something on the server has gone wrong. Let's click on that request. And let's take a look at the preview. And what we can see here is that the required anti-forgery form field, and there's the name of our form __RequestVerificationToken is not present. And of course it isn't. I haven't added it to the attacking website. Now our secure website has actually looked for that token and found it's not present. So it's going through that validation process. Let me go over and add it to the attacking website and we'll see what happens then. Now I'm on the attacking website and I'm going to go and add my own anti-forgery token hidden field and we'll see if anything changes. So let's just jump down and we'll put in another input, the type, of course, will be hidden. Simply because, of course, we're not going to show this to the victim. Now the name in this case is going to be exactly the name of that request verification token we saw in the network request tab for a post to the secure website. And that was simply RequestVerificationToken. Now the value is where the problem is, and the problem is simply that, as the attacker, we don't know what the value should be. We have no way of knowing what it should be for the victim. Let's just say, I don't know, and that's the truth, I simply don't know. All I can do is guess. Let's save that and then we'll flick back to the attacking site and see how it handles it. Okay I've just put that in our attacker website. Let me know reload it. And I'll just clear those network requests. Let's now click I want to win, again, OK. We do have another HTTP 500, let's check it out. So now we have a slightly different error message. The anti-forgery token could not be decrypted, so here's the encryption I was talking about earlier on. That token must be encrypted. Now, of course, so for me, as the attacker, I'm not going to have the private key used on the server to encrypt the token. So there is no way I can have a valid encrypted token. And in fact if we jump over to our headers and we take a look at what was actually posted in the form data. Here's my request verification token. I don't know, and this is the thing, the attacker doesn't know what the value should be. There's only one other thing, in fact, that the attacker could actually do. They could take somebody else's anti-forgery token and inject that into the attacking site. Let me go and do that and I'll show you what happens then. So what we're going to do now is put another user's anti-forgery token into the hidden field here. So I've got one in my clipboard that I've copied out earlier. Let's just go and drop that into the value and it looks like that. Of course this is an encrypted token, so you can't tell a lot just by looking at it here. Let's save this and then we'll jump back over to the attacking website and see what happens this time. Okay I've just dropped somebodies else's anti-forgery token in, let's now reload this attacking website. We'll clear our requests again. Let's try and win again, OK. Now we've got another HTTP 500 which is what I was hoping would happen. Let's click on that request. Let's go to preview and now we see a different message again. The anti-forgery cookie token and form field do not match. Now this is important, so this is this pairing that I was talking about. An attacker can always reconstruct the anti-forgery token that they send in the request from the hidden field, because they have control over that post body. However, they attacker does not have control over the cookie, that is simply going to be sent automatically with a request for the target site. Now as a result, even though we had a valid anti-forgery token when we attempted this attack, it wasn't from the right user, and it doesn't match the cookie that I've got in my browser as a legitimate user of this secure site. So hopefully this should show you that once we have this anti-forgery token, and we've got the matching pair between the hidden form field and the cookie, there's simply no way, within the browser security model, that an attacker can trick a user's browser into making a request on their behalf. Now how you implement your anti-forgery token will depend on your framework. Once again in my examples here, this is an IS pair up net MVC application, and it has very good native support for anti-forgery tokens. In fact it's just one line in the controller and one line in the view, very very simple stuff. Doing investigate for your framework of choice, what the anti-forgery token provisions are. And then of course when you test your applications, when you hack yourself first, go through and check what happens when you do things like, miss the token all together, drop the token out of the request, or grab the token that was issued to a user logged in under a different account. And try and submit that. These are the sorts of exceptions you should be seeing. So that's mitigating cross site request forgery attacks in web pages submitting forms. There is another pattern I'd like to look at as well. So let's move on to the next section and take a look at what happens when we're consuming APIs.

Testing cross site request forgery against APIs
Earlier on in this module, we looked at the risk of a cross site request forgery attack, which was mounted by making a post request to the page which changes the password. So effectively, what the attacker did in that case, is just simply recreated the appropriate request, complete with the path and the form parameters. And then when the users browser was tricked into making that request, their authenticated state was sent along with the request and their password was changed to the one the attacker had hardcoded into that attacking website. We then also used an anti-forgery token to defeat that attack. So that all worked out quite well. The risk of CSRF though, goes well beyond just post requests to web pages. And what I want to take a look at now is the impact of CSRF on APIs. Now the first thing I'd like to point out here is that I'm not presently authenticated to a vulnerable website. In fact we can see the log in button, just up there in the navigation. Now that's important, and we'll see why in a moment. What I'd like to do now is just grab a new tab. And I'm going to paste in a link to another attacking website. Let's take a look at this one. Now of course this is a very similar proposition to the one we saw earlier, we could win an iPhone. And in fact in order to load that page, I showed how it may simply be a link on something like Facebook or social media, which engineers the victim into following a link to a malicious site. So let's assume we've gone through a similar sort of process to land at this page here to win a GoPro. Let's have a look at the execution of this attack. So we'll click the I want to win button, and we'll click OK. And everything appears to be very similar. Let's now open the developer tools. We're on the network tab. And we'll try this again. I want to win, you won, click OK, and it's done. And here we go. Now what's interesting in this case is that the single request that has been made has resulted in a 403 forbidden response. So whatever it is that this attacking website has tried to do, the user has not actually had the rights to. So let's just take a look at this a little bit more closely. And in fact we'll go over to the headers and now we can see that it was actually a post request. And it was posting to api/vote. Now we've had a look at the vote API a few times earlier on in this course. And one thing we now know about it, is that you do need to be authenticated in order to vote. The API has actually got some other pretty serious problems. But one thing it does get right is that if you're not authenticated, you can't vote. Now when we scroll down a little bit and we have a look at the cookies that were sent with that request. In here we cannot see an auth cookie anywhere. Now of course before I showed you this page, I showed you our vulnerable website and I pointed out that we weren't authenticated. So the point I'm trying to make here, is that the success of a CSRF attack is usually predicated on the user already being authenticated to the target site. If they're not authenticated, it's effectively just an anonymous user making a request. So short of possibly trying to mount some sort of distributed denial of service attack by having lots of people make requests to a target site, even though they might be anonymous. There's really not a lot you're going to be able to do with an unauthenticated user. The value proposition of CSRF to an attacker is being able to force an authenticated user to make requests that they never intended to. Let's go back over to the target website. Let's log in. We'll use the same old credentials as always, same password, and log in. Now let's go back to that attacking website. We'll clear that result. Let's try and win again, OK. Now here is an HTTP 201. Let's take a look at the request. So this time what we'll find is that the request does actually have an auth cookie. Everything else is identical, but now that we've authenticated, the auth cookie has been sent with that forged request. The other thing we'll see is that if we scrolled down a little bit, we should get the form data. And what we can see here is that it's passing user id 1, super carid 8, and a comment of GoPro rocks. So think about this in the context of maybe a social media application. This could be the attacking website tricking people into making positive comments about a product. So imagine this was being posted, say to your Facebook wall, which of course does actually have very good CSRF protection, but it's a fairly familiar paradigm. Let's see what this has actually done. So we're going to go over to supercarid 8, let's go back tour vulnerable website. We'll just jump into any old car. And we'll change the ID to number 8, and here we can see our forged comment. And of course the comment is actually against my user id. Now this is important, because it is demonstrating how a CSRF attack is taking advantage of that authenticated state. Having said that, we also know from the earlier module on parameter tampering, that you can actually pass any users id to the vote API. And indeed when we had a look at the forged request just before, we saw it was user id 1 that was being sent to the website. But it still needed an authenticated user, even if it wasn't the user who the user id in the request belonged to, in order to actually consume that vote API. Now implementing an anti-forgery token in a case where an API is being consumed, is going to be a little bit trickier. To understand that, let's go and have a look at the way this website calls the API. So what I'd like to do is jump over to the leader board, I'm going to jump down to the Ferrari, Laferrari, simply because I haven't voted for it yet. And I want to make sure that all the controls visible that would normally be used in order to post a vote. Now let's go and look at the source code of this page. And if I scroll down to the bottom, there is a JavaScript file called vote. js. Now here's how the vote works. And it's simply a jQuery post. It's posting off to the path/API/vote. And in the body of the post it's posting the values. The userID, the supercarID, and the comments. All of these are actually retrieved from controls on the page. There's a data attribute for user id, there's another one for the supercarID, and of course there is the comments. Now this means we need to approach things just a little bit differently to what we would with an anti-forgery token simply sitting there in a hidden field. We're going to need to make sure that that anti-forgery token is actually sent as part of the request. So let's go and taka a lot at how the secure site approaches this. Now that we've seen how an API can be vulnerable to pretty much the same sort of CSRF attack vector as a typical webpage. Let's take a look at how this secure site tackles this. So I'm going to jump over to the leader board. We'll jump down to the Ferrari, LaFerrari again. I'm going to open up the vote window. And just before we vote, we'll turn on the developer tools. It's already tracking network requests. And let's just vote straight away, we don't need a comment in this case. So there goes the vote. Vote has been successful, let us now inspect this. And what we want to look at is the headers. So most of this looks pretty typical, pretty much like it did before. We're still posting to the same URL, and of course it is a post. The other thing we'll find as we scroll down a little bit, is that we now also have a request verification token cookie. So that's what we saw before. Where things are a little bit different though, I'll just jump straight down to the forms, is that we don't have any sort of request verification form data. And in fact, what I've done instead in this example, is I've passed it through as a custom request header. So I've created a header, called X-Csrf-Token, this is the token that we would of otherwise passed in the actual request body. So that's what we saw earlier on. Now depending on your implementation, sometimes it makes more sense to pass this token via the request header then the request body. In terms of a CSRF defense, it's pretty much the same thing. This is a piece of data that's only known to the website, and there is no way for an attacker, at least within the browsers security model, to gain access to this token before it's actually posted. Let's take a look at the source code and see how this actually happened. We'll just jump straight down to the end of this document, to that vote. js file again. And here's what we have. It's actually very, very simple. There is a hidden input in the page called request verification token, that's pulled out, and it's set into a custom header, called CSRF header. The name of that header is what we just saw in the request, that's our custom X header. And remember, headers that start with an X-a nonhttp spec, so that prefix makes it pretty clear that this is something that we have made specifically for our purposes. So the value of that request verification token is set. And then I've just changed that jQuery post to an AJAX post instead. The type is post, but because it's now using the AJAX method in jQuery row in the post method, we can do things like set custom headers. And there's our CSRF header value. Now again, this is not the only way of doing it. We could have sent that token in the post body and the other thing that's really important is that you need to remember the there are cases where we need to add CSRF protection to get requests. And a very common way of adding that to a get request would have been to send it as part of the query string. Whether it's form data or whether it's a custom header or whether it's a query string, doesn't matter too much. The point is, is that this is all information that the attacker can't directly access. And it's also information that won't automatically get sent with the request like a cookie would. Let's go over to our attacking website and see how it behaves now. I've updated it to make it post to the secure site. Let's turn on the developer tools. Let's try and win again. OK to that. And here we have an HTTP 500, which again is what we'd kind of expect. Let's take a look at that. And we'll take a look at the response. And if we scroll across here we can see that the anti-forgery form field is not present. This pretty much takes us back to where we were in the last section of this module when the attacking website was trying to post directly to a web page. So yes we could go along and create a request verification token field, but we wouldn't know what to put in there. We could go and get somebody else's token, but it wouldn't be valid for the current user. So I'm going to end this section of the module the same way I ended the last one. Which is simply, that once we have that token present, and the page receiving the request validates it, make sure the pair of tokens, so the one in the cookie and the one via the other channel. Whether that be post data, header data, or get data via query string. So it has to make sure those match and make sure it is keyed to the current user. Once that happens, the risk of CSRF all but goes away.

Mounting a clickjacking attack
Now that we've had a look at a couple of different cross site attacks, using CSRF, I'd like to take a look at something a little bit different. And this one is what's referred to a clickjacking attack. It's still an attack, from one site to another, and it's still an attacker tricking the victim into performing an activity that I didn't intend to. But it is quite a fundamentally different attack. Now, the way I want to demonstrate this is by starting out logged in again. So here we go, hello Troy, I'm definitely logged in. And now I'm going to go to the attacker's website. Now of course how we got here is the same sort of scenario as the last couple of examples. So maybe we fell for a fishing scam. Maybe there was a promotion on social media. The allure of winning something or getting anything for free is a very common approach to finding victims for an attack such as this one here. So let's take a look at how this one works. It's all about winning a Surface Pro, in the two boxes below, just type win now, then click I want to win. Don't worry if you don't see the text appear, you can still be a winner. And then after that we'll enter the email address and press Enter. Let's give this a go. First box, we'll type win. Now second box, win now, I want to win. Okay, there's that bit done. And now the email address, troyhunt@hotmail. com, enter. Alright, here we go. I am a winner and apparently I am going to hear from them soon. Now of course in reality you never hear from them at least not to get anything for free. The other reality of it is, is that I have just been scammed by a clickjack attack. Now I couldn't see anything happen, and certainly I couldn't see anything that looked suspicious in terms of any sort of responses or warnings or alerts, or anything like that. Let's go back and examine things a little bit more closely. Let's go back one. Reload to clear that data. Let's turn on the developer tools. We'll put it on network. And I'm going to scroll down a bit and let's try this again. Win now, and we'll try another win now. Let's click I want to win. Okay, so here's a bunch of requests. Now let's go up to the first one and in fact we can see the first one is a post request to change password. Let's take a closer look because this actually looks very similar to the CSRF attack we saw earlier on. It's posting to change password. It is indeed a post request. The status code looks okay, it's a 302, so it's going to redirect after it's processed my request. But here's where things change a little bit. When we scroll down a bit, we can see that there is a request verification token. There's already a CSRF defense in here. And in fact if we go down a little bit further, we'll see that there's also a request verification token in the form data. Now here's the new password and the confirm password. And it's win now. It's the text that we just entered. So the question now is how was this attacking website able to make a post to the target website and send request verification tokens in the cookies in the form data and not receive some sort of token validation error. The other thing is that if we take a look at the cookies, there is an auth cookie, because I was authenticated. So somehow this attacking website has been able to forge everything, not just the cookie, which of course will be sent anyway for a request to the domain. But it has somehow managed to get away with sending the request verification token and it has validated. How has it done this? Now I want to go and inspect this page a little more closely. But what I'm going to do before then is just refresh, so that everything goes back to its initial state. Now that we've done that, I'm just going to go down and select our inspector. And I'm going to move over and select this element here, so we can see that there is an element somewhere on the page that we can't quite see. Let's click on that. And that we can see down in our HTML view, is that there is an iframe in here. The source of that iframe is the change password page. It's even been loaded up over HTTPS, so it should be nice and secure. Now what we can see about this iframe is that it has a style where the opacity has been set to zero. What that means is, is that the iframe will be hidden. You cannot see it. Let's change that opacity and we'll change it to. 5, so it'll be about 50% hidden. Well what that now means is, we've got a little bit of transparency, so we can actually see that iframe. Let me close this page. And now what we can see is the change password page. It's actually collapsed down into mobile view because it's fit into a very thin space. We can see the same thing if we go back to our tab over here. Detach it, and then resize it a little bit. We should see something that looks very similar. So there we go, there's that same black bar at the top. Let's drop that tab back. But let's now take a little bit of a closer look at what's going on here. We have the change password page, but our tacking website has some elements that are lined up perfectly with elements on the change password page. Now what's happening is that the legitimate page is sitting on top of the attacker's page, but then the opacity is taken down to zero, so it's hidden. The attacking page is then prompting us to click in locations and it does this by showing its own elements precisely lined up with the victims page. And then it asked us to perform an action, in this case it was the I want to win button. Now if you look closely you can see that the I want to win button is perfectly overlaid with the change password button. In fact, the under laid the change password button is part of the change password page in the iframe on top of all this. It becomes a little bit clearer when we see the source codes. So let's jump into that. And what we'll now see is all the header information about winning a Surface Pro, we won't worry about that. But then we've got input boxes, we've got text boxes and these are absolutely positioned and they are perfectly lined up to be the right position from the top. And then they're positioned just perfectly horizontally, and that is what we are seeing when we first load this page. So this would be the one that asks for the first password. This would be the one that asks for the second password. And then here is their button. All of this positioning data, the position from the top, and then the right margin, is to make it line up perfectly with the buttons on the legitimate site. Everything else beneath there, the bit about entering the email address and then clicking on Enter, is just a rouse. By the time we go and click on that, we've already clicked on that I want to win button, which has changed the password. The important bit is down on the bottom where we've got that iframe. So there's the iframe imbedding the change password page, positioning it perfectly over the top of the attacking websites controls, so everything lines up. Take a look at it again. There's the first text box on the attacking page, but of course we're clicking and focusing on the target website. There's the second one, there's the button. It's only when you pump that opacity up a little bit, so that you can partially see the victim page, that it starts to make sense. But there's another really neat way to visualize this, and to show you, I'm going to drag over Firefox. Now one of the neat things about Firefox is it has a little feature that enables us to view things in 3D. So we're going to jump down to the web console. And we're going to go over here and hit the 3D view button. Now once we do that, everything sort of starts to jump out. So as we now tilt this on its side, we can see the first textbook, the second textbook, and the submit button. Now we can then select these guys and get a good visualization of what it actually looks like. So for example, there is our iframe. And in fact if we grab the inspector, and we'll scroll up a little bit, we can click on it and it shows precisely where it is. So there's the iframe and then here lays input boxes, first one, second one, and then of course the button. The good thing about this view here is that it gives you a sense of the depth of the fact that we've actually laid some things on top of other things. This is not just a simple form with text boxes on the page. This is a form with a series of text boxes and then an iframe sitting on the top of it, which then has its own text boxes in. Everything just lines up. Now the reason the anti-forgery token submitted just fine, is that in reality what we just did in this attack, is loaded up the change password page. It just happened to be inside a hidden iframe, and then we clicked the change password button after filling in the two fields. So what we just did, without knowing it, is filled out the change password form in exactly the same way as we would have, if we were on the website itself. That's how the cross site request forgery token was defeated. I'm going to show you how the secure site handles the clickjacking risk in just a moment, but before we do that, let's just go and take a look at a quick slide. The way we're going to mitigate this clickjack attack risk is using the X frame options, or XFO header. Now the idea of an XFO header is that it's going to be returned with a request for a web page and that header is going to tell the browser how it may or may not frame that particular page. Now once the browser receives that header, it's really got three different options. And these are described in the value of the header. So first of all, framing can just be denied, or in other words, the browser may not put this page inside another frame. Now what that means is, in a case like we just saw, if that attacking website tries to embed a page in an iframe, that comes back to the browser with an XFO header of deny, the browser is not allowed to load it into the frame. The other option is same origin. And effectively what same origin says is that, Hey, you can put this page inside a frame, but only inside other pages on my site. So this is a handy way of saying, look there are valid use cases where we might want to frame something, but we only ever want to frame our pages inside other pages on our site. We don't want somebody else to be able to put our page in a frame. Now the third option is allow from. And you then need to specific a URI. Now what this means is, yes the page can be framed and it can be framed by an external site, but only by the one that we specify in this response header. So this is the mechanics of the clickjacking defense that is the XFO header. Let's go and take a look at what it looks like in practice when we try the attack against our secure site. Okay, so here's our attacking web page again. And I'll set it up this time to try and embed the change password page from the secure site. Everything still looks the same, but of course the iframe has the opacity set to zero, so we're not going to see what is in that iframe. We can however see a big difference if we jump into the developer tools. We're on the network tab already. Let's reload this page. Now here's where we see the difference. The attacker page loads fine, nothing wrong with that. But of course that attacker page then embeds an iframe that asks for the change password page of our victim website to be loaded. Now what we can see is that this request has turned out red, there is something wrong with it. And in fact what we can see is that the status is cancelled. Chrome is not allowing this attacking website to load our victim website into the iframe. And in fact if we drew down and take a look at this request, we really won't see much information in here. We're not seeing any of the response headers or anything like that. And indeed if we go to the response tab, it says there's no data available. Chrome is not able to show us anything. However, that doesn't mean the page didn't load, and indeed the only way that Chrome can know that it can't embed this page, is that it has to load it to begin with. Because it has to get that response header. Let's jump over to fiddler and see what happens when we load this attacking site. So drag over fresh fiddler window, there are no requests in there at present. Let's go back to the attacking website. We'll give it a reload. Back to fiddler. Let's now just stop capturing so we don't have anything else appear there. And the thing is, we can actually see that there is indeed a request that has resulted in an HTTP 200. And this is a request, to our secure site, to the change password page. Now the point I'm making here, is that the request is still actually made, nothing changes that. The difference is that if we scroll down a little bit over here, and we take a look at our response headers, we can now see that there is an X frame Options header. And that X frame Options header is set to deny. So the lifecycle here is that Chrome makes the request, it receives this page back and indeed fiddler is showing us that the page does actually successfully come back. It inspects that response header and then it says, Okay, I can't load it. That's why when we flick back to Chrome, we see that the status is cancelled. Even though we can't see the response body here in Chrome, the page loaded in its entirety, but it didn't load into the iframe, and that's the important bit. Because if this does not load into the iframe, then the attack cannot happen. What this all boils down to is that defending against a clickjacking attack is extremely simple. It is just that XFO header. And indeed if there is no reason at all to embed any pages from the site inside a frame, it's easy just to set the header across the entire site. Where XFO does start to fall down a little bit is if you want to have multiple policies. So if for example, what if you want to embed a page both in other pages on this site, and on an external URI, you can't do it. XFO doesn't have the provision for it. Likewise, there's no provision for embedding a page in multiple external URIs. The only option in that case is actually to turn off the XFO header all altogether. Or in other words, not return it in the HTTP response. So XFO is equal parts an amazingly simple defense, but also one that leaves a lot to be desired if you're do indeed want to allow some cases of embedding pages in frames. Certainly though, one of the first places to start in hacking yourself first, is to see if this header is present and if it's not, the very next question needs to be, Why not? Is there a valid reason? Do we need to embed this page inside frames on another page? The answer to that will tell you if the site is unnecessarily vulnerable to a clickjack attack.

Summary
Let's summarize the module. And the first thing we established when we talk about cross site attacks, is that they're very centered around the concept of an attacker tricking the users browser into issuing a request that the user never intended to make. Now usually this request is made whilst the user is authenticated. And of course an authenticated state is really just established by the presence of an auth cookie. That cookie is going to be sent automatically with every request the user makes for any resource that the cookie is valid for. So the attacker simply needs to construct a request to the target site in the user's authenticated state is persisted along with it. When we talk about cross site request forgery attacks. That's really all it is. An attacker simply recreating a request that's consistent instructed to a legitimate request but of course containing the attackers paid load. And in the example we looked at, that pay load was simply a new password. CSRF attacks are easily mitigated by using anti-forgery tokens. And really what we're doing here is we're adding randomness to the request. So what we talk about when we say randomness is adding an encrypted token that the attacker has no way of knowing. Now the way we did that is that we passed the token in both a cookie, which of course will be automatically sent anyway, along with the auth cookie. And we passed it in some form data. Now the attacker never had access to that form data. The browsers security model will not allow them to access it, save via JavaScript from their own site. Now both those tokens were paired to each other. If the right tokens weren't sent together, then the request was rejected. The anti-forgery token was also keyed to the user, so in fact we tried to take somebodies else's and use it, but if was from another authenticated identity. It didn't work, it was rejected. So that keying to the user is very important. We also looked at APIs and established that really APIs are at the same risk as any normal web page. And just like any normal web page, the defense is the same, we need an anti-forgery token. When we protected the API, we sent it as part of a custom request header instead of via the form body. We could also send it via a query string if it was part of a get request. Anyone of those mechanisms will work, simply because the attacker has no way of accessing it. And of course with each one of those, we'd also send via the cookie as well, so that there's some verification. Finally, we looked at clickjacking. And the first thing we found with clickjacking is that it could easily circumvent the CSRF protection we made. And it circumvented it simply because clickjacking is predicated around actually loading the target page into that hidden frame and then submitting it. So it loaded the anti-forgery token, it set the token into the cookie, and then it posted everything off together. Everything lined up, valid for the current user and the attack was successful. Of course the mitigation was very easy. We just added that X frame Options, or XFO header, and set it to deny. As soon as we did that, even though the attacking website could cause the user to load it, it wouldn't render into the browser, because the browser adheres to that XFO policy. So that was a very easy fix. But we also discussed how XFO does have a few short comings as well. It's certainly not a perfect solution. So that's a few different ways of mounting cross site attacks and a couple of really key ways of identifying if those risks exist in your application and the mitigations that you should be looking for.

Account Management
Introduction
Hi, this is Troy Hunt, and in the final module of this course we are going to take a look at account management. Being the final module of the course, I'm going to cover a whole range of different account management practices. And we're going to look briefly at the risk of each one of them and how our secure site takes them over a best approach to each one of these points. We're going to start out by understanding password strength and attack vectors. It's really important we understand these attributes in order to offer our users the most secure possible experience for their account. We'll then take a look at how the vulnerable site limits characters in passwords, and the risk that that then presents to users. We'll then move on to emailing credentials on a count creation, which is an unfortunate but not uncommon practice. After that, we'll take a look at account enumeration, or in other words, how an attacker can remotely discover the existence of accounts in a system. Another remote attack we'll take a look at is a denial of service attack by exploiting a vulnerable password reset feature. And that's another one that does appear just a little bit too commonly in web applications today. With that understood, we'll then take a look at correctly securing the reset process. And there are a few nuances to getting this bit right. Password storage is another really critical area of account management. And we're going to take a look at how we can identity when a website is not properly protecting our password in storage. The remember me feature is another area of account management, which is often gotten wrong. And indeed we've seen some examples of the vulnerable website doing this throughout this course. So we're going to take a closer look at that and how to implement it properly. I'll also touch on real authenticating before key actions because that's another thing that we've seen gotten wrong already in this course. And finally we'll look at testing for authentication brute force. And this is a very serious risk with many real world precedence of where attackers have used it, to take over accounts when systems haven't provided adequate protection against brute force attacks. So we're going to cover quite a lot in this module. Let's start though by understanding the attributes of a good password and some of the vectors that they can be compromised by.

Understanding password strength and attack vectors
Much of this module is going to focus on password security. And particularly provisions offered by websites in order to help a user maximize their password security and then to keep that password secure once the user entrusts the website with it. And we're going to talk a lot about trust and the responsibility of websites in protecting credentials. Now really the security of an individual password is driven by two primary factors. And they are simply strength and uniqueness. And we're going to look at each one a little bit more closely in this section of the module. What's probably pretty obvious though, is that the stronger and more unique the password can be, the better. It really is that simple. We, as application developers, need to help our users maximize both those attributes. We need to give them every opportunity to make passwords strong and unique. So let's talk about strength for a moment. And where I want to demonstrate strength is I'm going to drag over passwordmeter. com. Now there are a lot of password strength calculators out there, and many of the them are pretty generic. What I like about this one is that is does actually apply some proper mathematics behind it. Because ultimately when we're talking about password strength, we're talking about the different possible combinations and permutations of the characters that make up a password string. Now what's probably pretty obvious is that if we use a password like say, qwerty. And this is a pretty common password because it adheres a to a keyboard pattern, we can see just beneath that we have a score of 8%. Clearly qwerty is a bad password, it's all lower case, it's short, it's a pattern on the keyboard. Once we start mixing that up a little bit though, and going with say, upper case characters. Our score starts to increase dramatically. We've just gone from 8% to 27%. And we can see in the first table, just beneath that complexity writing, that now we have a green tick next to upper case characters. The other thing, of course, we want in passwords, when we talk about randomness, is some numbers as well, we want different types of characters. So if we chuck a one in there, suddenly things get a lot more secure again. Same again if we jump over another space and put in say, a slash. Now we're getting very strong, 78%. If we start to add even more random characters we will get to 100%. Now I think implying that any sort of security measure ever gets you to this absolute position of 100% is probably a little bit enthusiastic. But you get the idea, and what it boils down to is this. We need to give users the maximum possible flexibility to use whatever type of character they want, and as many of them as they want. Many websites do implement draconian restrictions on both those factors, that's length and variety. And it's an extremely dangerous position to put users in. We're going to look at this a little bit more closely in a subsequent section, so I won't dwell on it now. But establishing those two factors, the length and the variety of characters, is absolutely critical for the other pieces that will now come in this module. So that covers password strength on an individual bases. The next thing I want to look at is uniqueness. And to demonstrate uniqueness, I'm going to drag over a password dictionary. Now this is a password dictionary called hash killer. Hash is of course, being the best possible way to apply cryptographic storage to credentials. And we'll talk more about hashes during this module. What I want to show you here though is what a password dictionary looks like. And the first thing you'll see here is that this doesn't look like, say an Oxford Dictionary, or Cambridge Dictionary. We're not saying plan English words here. In fact if I page through this, we'll see that there's a huge variety of words mixed with things like punctuation. And in fact if I jump, say down in the middle of this file, we'll see that's there's an extremely large number of varieties all with the same sort of string. It just goes on and on and on. Now what a password dictionary really is, is a collection of pre-used passwords. Now where these dictionaries often come from, is from previous breaches. So we've seen many, many breaches where passwords have been dumped on the internet and those passwords have been combined to create password dictionaries. In a case like this what I jump all the way to the end of the file, we can see that are more than 23 million entries into this dictionary. And these are all entries that come from typical password patterns. And again, predominately they come from breathes. Now the reason why this is important, in terms of uniqueness, is that when someone reuses a password from one location to the other, even if that password might appear to be quite strong. And by all accounts many of the passwords we see on this screen here, would probably write quite well on that password strength test that we just saw. The very fact that it has been reused puts is at risk. Because if an attacker comes along and uses a password dictionary in order to try and brute force the account, and we'll talk more about brute forcing during the course of this module. There's a much higher chance of that password being compromised. So this is why uniqueness is so important. Let's go back to the PowerPoint deck.. 000 Let's start with remote attacks. So remote attacks is when the attacker is not located next to the passwords. So they don't already have a set of passwords or they're not already sitting there next to the server. Now we've already looked at some of these remote attacks. So for example, in the first module of this course, we looked at a man in the middle attack. Insufficient transport layer protection means that anyone who can get in the middle of the communication between the browser and the server, can very easily observe all the traffic over that connection. So that would be a type of remote attack against the credentials. Passwords being retrieved after being sent in an email is another good example. When a website sends passwords in an email, and we'll look at that more closely in this module as well. You end up with a stash of passwords sitting there in peoples email accounts. Brute forcing via HTTP posts is another good example and in fact we'll look at a demo of that. This is where an attacker could be comfortably sitting at their PC and simply attempting to log onto an account with a whole range of different passwords. Compromised admin facilities is another good example. And in fact, earlier on in the parameter tampering module, we looked at a mass assignment attack that elevated our privileges to that of an administrator. And then we just simply remotely accessed the passwords through the admin feature. We also looked at SQL injection and the epitome of that was when we used ______ to simply point that little graphical tool at a vulnerable URL and pull all the credential out of the database. So that was a very, very simple remote attack. The other sort of attacks we often see are more localized. So for example, an attacker simply gets passwords from a backup. There are many sloppy backup practices that leave passwords exposed. For example, taking a backup of the database and just putting it on the website so that it is accessible over HTTP. Then of course we have admins. So admins have direct access to credentials. Now you might think, okay well they're admins, they should have access to everything. But they shouldn't have access to passwords and we'll talk about that more over the remaining sections of this module. Then finally we have brute force attacks against the password cryptography. So in this case there's been some attempt to protect passwords with a cryptographic scheme. But because the attacker now has access to the password ciphers, they can start mounting a brute force attack. The only thing that's going to save those credentials now, is how effective the cryptography is. Now the last thing I want to show, in the opening section of this module, is a real world example of where password uniqueness is really important. I'm just going to drag over a browser window here with a news article in it. And this relates to when Gawker was hacked, back in 2010. Now Gawker made very big news at the time because a huge number of passwords were retrieved from Gawkers database and dumped publically. And certainly that's something we often see in attacks against websites. Accounts get disclosed, passwords were not sufficiently protected, and then suddenly you end up with tens of thousands, hundreds of thousands, or even millions of user names, and passwords dumped in places like a paste bin. Now as we can see from the screen grab of this tweet just here. What ended up happening was that there was a bit of a problem when people reused passwords between Gawker and Twitter. And in fact what ended up happening was peoples Twitter accounts were being attacked simply because they reused the credentials from Gawker. Now that doesn't necessarily mean that those who attacked Gawker were now attacking Twitter with those credentials. Unfortunately the reality of it is, once a system is compromised and passwords are released publicly. You now have literally millions, well actually it's really billions, of people who have access to your password. It's up there in plain text on the internet for anyone to see. So what ended up happening in this case was that after Gawkers was compromised there were a large number of tweets being sent about acai berries. And in fact as we can see here, it's seems likely that the spam is coming from already compromised accounts, rather than malicious code from the acai news links. In other words, because people weren't applying uniqueness to their passwords, and they were reusing those passwords. Even if they were strong, because that password was now public, someone was simply taking peoples user names and passwords, testing them against Twitter, and then sending out spam. This is an absolutely perfect example of how important uniqueness is. Now of course uniqueness is something that the end user needs to take responsibility for themselves. We, as developers, can't force people to create passwords that they've never used in URLs. However, what we as developers need to recognize is that this is a problem, people do reuse their credentials. Now what this means is, is that the way we handle passwords is not only protecting accounts on our websites, but it also having an impact on the security of our customer's accounts on other websites. We have implicitly become responsible for protecting those external sites, which in reality we have nothing to do with. Now in a way that doesn't sound very fair, but it's an important observation because we need to recognize the responsibility we have. Just because we stand up a website, where we may not think there's a whole lot of value in an attacker gaining access to someone's credentials, doesn't mean that there's not a whole lot of value to those credentials in another service. They might have reused that password on their email, for example. And as much as we'd like to stand up and say, hey look you really need to take more responsibility and create unique passwords. If one of our systems does get compromised and those passwords do get retrieved, we have become indirectly responsible for an untold number of other breaches. And that is a very serious concept worth reflecting on a little bit. So with that said, let's move on to looking at how we can help our users strengthen their accounts.

Limiting characters in passwords
One of the most common anti-patterns of good password management is when a website limits the allowable characters you can use in a password. And I'd like to give you an example of how our vulnerable website does that. So let's jump over to the register link. And what I want to do before I fill this in, is let me just drop over text editor. And I'm going show you the password I want to use. I want to use this one, P@ssword. Now this is clearly a terrible password, never use this password when you sign up to a service. Now interesting we know it's terrible by looking at it, but it is eight characters, it's got upper case, it's got lower case, it's got a symbol. But of course it's terrible because it's predictable and it's going to appear in just about any password dictionary as well. Regardless, let's select that password, we'll put it on the clipboard, and jump back over to our vulnerable website. Now I'm going to try and register. I'm going to be jackbrabham@f1. com, Jack, Brabham, and then I'm just going to paste in that password, and paste it in again in the confirm box. Let's try and register. Now we have a message saying the password cannot contain special characters. All we did was put in @ symbol. Yet somehow this has been viewed as special. This is really not a sensible position for a website to take. Unfortunately though, it is extremely common. It may not always be an @ symbol. Sometimes it may be an angle bracket, or a quote. The point is though, that once you start excluding allowable characters from passwords, the potential range of passwords decreases very quickly. And as a result, the potential combinations of passwords dramatically decreases. And along with that, our strength decreases. Let me show you another example. We'll go back to the text editor. And let's try, to be or not to be. Now past phrases are a very common way for people to create passwords, which are longer, yet can still be memorable. Of course they have their own risks because they do tend to adhere to predicable patterns. But certainly this is one approach that many people use. Let's try this one. We'll copy that out. Jump back, paste it in, and again, and let's try registering. And we've just got the same result, the password cannot contain special characters. It doesn't like spaces. This is a terrible practice because not only does it limit the number of characters and consequently the strength, but it also limits very common patterns that people may use. Now you could argue that people shouldn't be using common patterns anyway, but in the vast majority of cases, you're not going to try and push people to adhere to your own view of password strength beyond some very basics, such as length and perhaps the inclusion of a couple of different character types. Certainly you're not going to start ruling out individual "special characters", because that has nothing but negative impact. Let's just try one more approach here. We'll jump back and we'll take out the spaces on this phrase, so it will all just be one word. Now we'll copy that. Paste it in. Paste it again, and try and register. The password cannot be longer than 10 characters. Another very common anti-pattern and another terrible password practice. Clearly the longer a password is, the stronger it is. And arbitrarily low limits really don't do anyone any favors. It imposes a limit on the user, and if passwords are being stored correctly, as cryptographically secure hashes, and we'll talk about hashes a little bit later on this module. The cypher text is of identical length, so it has no impact on the size of the data stored in the database. The only time a website is going to limit individual characters, or the length of a password, is when it's following one or more very bad password practices. So this is terrible. Let's go and take a look at the secure website and see how it approaches this quite differently. I'm back on the secure site, and I've filled in some of the registration data that we used on the insecure site. Now before I enter the password, I'm going to flick back over to my text editor, and I've got a password in my clipboard I'm going to paste in. And it looks like this, yes, this is the password I'd like to use. Now of course this would be a terrible password to remember, although I am personally an advocate of password manages. So actually remembering an individual password really isn't an issue. The point I'm trying to make here though, is that this is a really long password, so in fact it's a 119 characters long. It's got a broad range of characters, upper case, lower case, symbols, numbers. And it also has the sort of characters that upset a lot of websites. So in fact this is a string that we used early in the XSS attack. So what I'm advocating here is that we should be able to use a string that is an XSS attack in the password. And there are two reasons for that. Firstly, because there should be absolutely no limitation on the characters a user wants to choose. And secondly, because you should never render the password back to the screen anyway. There is no XSS risk if you never admit this to the output. And we'll talk more about that later on in the module when we talk about the appropriate ways to store passwords. So this is the password in my clipboard, let's jump back to the website. Into the password field. Into the confirm password field. And let's register. And it's as easy as that. We are now logged on as Jack. So this is where I want to leave you on the section of limiting characters in passwords. Don't put any restrictions on the character types. If you do need to put a restriction on the length, for any reason, make is massive, make is something that is not going to restrict people from using any sort of reasonable password. And by reasonable, I mean anything that they can generate that might end up being hundreds of characters. There's just no reason to stop them.

Emailing credentials on account creation
Another password anti-pattern that you see every now and then, when registering an account, is an automated email sent to you afterwards with your password. Let me show you what I mean. I'm going to sign up with an email address that I can actually receive this time. And we'll make this guy, Jackie Stewart, and we will give him a password. Let's now register Jackie. And that registration's gone through just fine. We can see that he's now logged on. Now unfortunately, what sometimes happens, is we then get an email, something like this. Welcome Jackie! Your new Supercar Showdown account has been created. Just so you don't forget, your password is tartan. Now this is a real problem because what we've just done is sent that password over a plain text connection. There is no implicit transport layer security on SMTP. So what it means is, is that the email has just been flying around the internet without any protection. And then of course, it's now sitting in my inbox, without any cryptographic protection. In fact because it's gone to Hotmail, and it's synced to a bunch of devices, it's now in my PC, my laptop, my iPhone, and my iPad. Sitting on every single one without any cryptographic protection. Sure I have passwords and pin locks and things like that, but passwords require a much greater due diligence in terms of how they're secured. There is never any reason to tell someone a password which they only just entered themselves. This is not even a reminder feature. And certainly the last thing you'd want is people actually retaining this email in an insecure location so that they could refer to it later on. If forgetting the password is a concern, then that's where the password reset process comes in. And we'll look at that later on in this module. By all means, send a new registrant a welcome email. Send them something that they can keep and refer to, or forward on to other people because it might have useful information. But whatever you do, don't put passwords or anything of a sensitive nature in email. It's just not designed to handle that sort of data, and there are multiple risks in doing this.

Account enumeration
One of the risks that often isn't considered when building account management facilities into a website, is account enumeration. And I'd like to show you what I mean by that. Now to do this, what I'm going to do is jump over to the log in page. But rather than logging in, I'm going to go to the forgot your password feature. Now let me show you what I mean by account enumeration. I'm going to try and reset the password for alainprost@f1. com. Let's reset that. Now what we're seeing here looks pretty benign, but what's actually happened is that the website has confirmed that that user does not exist in the system. Let's try one that we know does exist. So I'll try my account. troyhunt@hotmail. com. Reset. Now we have a very different message. Your password has been reset, you should receive an email with a new one, shortly. Now we'll come back to the problem with the resent process itself a little bit later on in this module. The point I want to make now though, is that from account enumeration perspective, we've established that this web application will tell you both, when an account does not exist, and when an account does exist. Now I've just performed this activity as an anonymous user. So what this means is, is that if I had a list of users, and I wanted to know if those users had accounts in this system or not, I could easily do that just by entering their email address. This may not sound too bad, but it can be depending on the nature of the website. So for example, websites where a user would reasonably expect to have their privacy protected. So maybe a dating website for example. Many people might not want just anybody to be able to go along and establish whether they are trying to find a partner online. Use your imagination. There are plenty of other websites where your presence as a member might be something that you want to keep private. So privacy in disclosure is one side of it. The other side of it, of course, is that once in an attacker can establish someone does have an account on a website, then they can move onto attempting to brute force that account. And we're also going to look at that further in this module. So this is the whole point about account enumeration. If a website confirms the existence or the nonexistence of an account, that then creates certain risks. Of course this then begs the question, how do you actually provide feedback to a user with the features such as the password reset function. How do you let them know that the email address they entered doesn't actually match a valid account? To demonstrate that, let's jump over to the secure website. Now I'm over on the secure website, let's take a look at how it handles things a little bit differently. So what I'm going to do is enter the same email address as before, alanprost@f1. com. Now this is the one that doesn't actually exist. Let's try and reset that password. Now here's quite a different message. An email with further instructions has been sent to the address you entered, that's quite a different approach. Let's do another reset. Log in. Forgot your password. We'll enter my email address this time, and we'll try again. Now remember my email address does actually exist in the system. Reset. And here we see exactly the same message again. Now the reason this is significant is that this process, the reset process, is not disclosing whether my email address exists or not. The channel that it uses, in order to give me feedback about the process, is the email address itself. And in fact as a result of this process, I will have now just received an email addressed to my account. Now I'm just going to try this one more time with an email address that I can actually receive mail on, but won't have a presence here. And I'm doing this simply so that I can show you what it looks like when the account doesn't exist. So let me now jump over to my email, and I'm going to drag a couple of these up to show you what it looks like. So let me first show you the one I sent where the account is not valid. Now this message is very important. You or someone else, because remember it could be anyone that initiates this reset process, you have no authenticity when you're filling out the reset form. Anybody could come along and initiate a reset for anybody. So this is where it says you, or someone else, into this email address to reset the password of your account. However, this email address does not have an account on this site. Now by giving that feedback in the email itself, it's only the legitimate email account holder that's ever going to see that message. And that's a very, very important distinction because it means that we're not just leaking that information to the public. Now there's one other thing that I like to add to a password reset email like this, and that's the IP address that the activity was performed from. And I do this simply because it gives the user a little bit of a sense of where this reset process has been initiated from. Now this may not be suitable for all audiences, but certainly when it's a more technical audience, this makes a lot of sense. Now as well as the IP address, I normally provide a function where we can click and here we actually get a location. Okay, so someone in Melbourne has reset my password. That's not my IP address, that's certainly not my geographic location. That's obviously just a little bit odd. Let me show you now what the legitimate reset email looks like. So here's one that goes to an actual account holder. Now this is pretty similar. But this time we can start off by actually addressing the user, because we can retrieve their name from the account. Dear Troy, I then like to have the same sort of message about you or someone else, just to make it crystal clear that it really could be anybody that initiates this process. We've then got the new password in there. And again, we'll come back to why this is a bad practice in just a moment. And we've got the same IP address message in there. So this is a very different approach to the way many websites tackle password resets. We have kept that risk of account enumeration at bay, simply by not providing anonymous users feedback on the account existence. The only way you can find out if an account exists or not, is if you can receive an email for the address that you're testing. Now there's one caveat in all this, where things get a little bit trickier. And that's with registration, because normally when you register for an account you won't be able to use an email that already exists. Now there are a couple of different approaches with registration. If you really worried about an account enumeration, you have to begin the registration process with an email to the user. This is one of the those cases where in order to achieve a higher level of security, we've got to put people through an inconvenience. It would have to be something like, enter some information then click here to receive an email to initiate the process. And just like the reset process, whether that account exists or not, you'd have to provide the same response to the user interface in order to avoid disclosing the existence of the account. The email would then contain some sort of a token that you'd follow back to the website and complete the sign up process, if indeed the account didn't already exist. That is a high usability friction process. A more middle ground might be to put a lot of validation on the sign up process. You've got to have a valid name, you've got to have a valid address, maybe phone number. Put something like a capture in there, as well, to try and avoid the automation of the process. None of that is going to stop someone from manually sitting down and establishing whether an account exists or not, but it can stop brute force enumeration. So as with many things security, think carefully about the advantage gained by avoiding account enumeration risks, and the negative impact on usability, and whether that may be a barrier to entry for your customers.

Denial of service via password reset
In the last section of this module we looked at the account enumeration risk using the password reset feature. Now one of the things we noticed when we used that feature, is we got the email message you see in front of you here. Now red flag, in this email message, is the line that says, your password has been reset and it is now, and then obviously we have a new password. Now the problem with this is that any anonymous user has the ability to change the password of any other user using this feature. The ability to do that is what we would classify as a denial of service risk. And it's a denial of service, not in the sense that we often think about it in terms of say distributed denial of service, where a website is getting flooded with malformed packets in order to keep legitimate requests there. It's a denial of service in the sense that this feature gives an attacker the ability to lock someone out of their account. Now of course if the person receives this email, they can always go and use this new password and then log back in, and then probably change it back later on. But particularly for some classes of application, this can be a serious inconvenience for the user. In fact it can really undermine the integrity of the application. For example, imagine it's an auction application, and someone's actively bidding and an attacker sees that person bidding and then goes and simply resets their account, locks them out of the system. That would be a major inconvenience for the user and could possibly also have a financial implication. Another risk is that this could be brute forced. And what I mean by that is that if an attacker has a list of email accounts, it would be very easy for them to simply go through and try and start resetting the passwords on all of them. Earlier on, in the parameter tampering section, when we looked at the risk of mass assignment, and we elevated our privileges to be an administrator. We found that we could identify the email addresses of every single person in the system. With that information, and the fact that this feature allows an anonymous user to reset someone's password, based purely on their email address. An attacker could cause major disruption to a system, simply by going through and resetting everyone's email address. It would be a very, very simple proposition to do that. Now of course all this begs the question, if you can't simply reset a password by entering an email address, what's the correct way of doing it? Let's jump over to the secure site and take a look at how it handles it.

Correctly securing the reset processes
We're now over on the secure site. So let's now take a look at how the password reset works quite differently. What I'm going to do is start with my email address. And you'll see that this part of the process is identical to what we saw earlier on. Where things are fundamentally different though, is in the email that gets sent when the reset process is initiated. So let me just drag that email over. And what you'll see here is quite a fundamental difference in this line here. So rather than just automatically resetting the password to something else and sending it to me in email, which of course is a risk in terms of email being insecure. And it's also a risk in terms that denial of service attack, given that anybody could reset the password of anybody else, so as long as they know their email address. What we have now is a prompt to follow a link to continue the process. Now what you've got to remember about this, is that by me receiving this email, it's verification that I am the account holder. What we want to do then is provide that verified account holder with an opportunity to change their password. Let's follow the link. So here's what we now have. And the first thing you'll notice here is that in the URL, there is a token. Now this token is keyed against my account. And the token has several very important attributes. First of all the token has enough entropy, or it's strong enough that it shouldn't be brute forcible. You don't want an attacker simply being able to guess the tokens of other accounts undergoing the password reset process. The other thing about this token is that ideally we want a time limit it. We only want to allow the person resetting their password a limited window of opportunity in which to follow that email and complete the reset process. Anywhere up to about an hour is normally a pretty safe window. If you initiate the process but don't follow through within in an hour, the token gets invalidated. Now the other thing is that once you do actually go through and successfully complete the process, we also want to invalidate the token. And this is the important distinction between sending someone what is effectively a one-time password in their email, this is sending them a persistent password, which is what we were doing before. If an attacker does gain access to my in box, or does intercept this email along the wire, the scope of use is very limited. Compare that to the scope of use of a persistent password, we could go on using it indefinitely. So what's going to happen now is that this token combined with the new password, and I'll just enter a password here. And the confirm password is going to be enough to validate that I did indeed receive an email at the registered address, and that the token is still valid, and that I'm allowed to create a new password for the account. Let's change it. And there we go. That's the entire process now complete. So it's actually very, very simple and there's really only a tiny little additional step on top of the way it was done before. Which is that you are going to need to enter your own password. It might only be one tiny additional step, but the security profile of this mechanism, is fundamentally improved over the old mechanism of sending a password insecurely across email and then letting it reside in someone's in box. And then be valid in definitely. That's a very, very different security proposition.

Establishing insecure password storage
Password storage is a really critical area of security that many, many websites get wrong. And there are a few very easy tests that you can use to discover information about the way passwords are stored. Firstly though, let's look at three very common ways. The first way is just in plain text. And what I mean by that, is that there's been no attempt, whatsoever, at any form of cryptography. The passwords are just sitting there in a database column, just the same way as the user name or the email address. There's no cryptography. Anyone who can access that database gets the plain text passwords out immediately. Now clearly if there's any form of database breach or a risk, such as SQL Injection, and in fact we did see this earlier on in the module on SQL I. Those passwords are immediately exposed. There is nothing saving them. As we've also discussed in this module, we need to keep in mind that those passwords protect more than just the user's account on this website. They've inevitably been used elsewhere as well. So we have a responsibility that goes beyond our own websites. Rightly or wrongly, that's just simply the password landscape. Another common model is to use encryption. Now the thing about encryption, and we're normally talking about symmetric key encryption here, so there's just a single private key to encrypt and decrypt. But the thing about it is that there is this decryption. There is a process available to take encrypted passwords, so take that cypher text, and convert them back into plain text. And indeed we saw earlier on in the module on parameter tampering, when we exploded the mass assignment risk and elevated our privileges, we could actually see a list of users and their passwords. Encryption of passwords is used in times where those passwords do need to be retrievable. Or at least when someone thinks they need to be retrievable. It does pose a huge risk. And it poses a huge risk on a couple of fronts. So the one I just mentioned, where we can actually see those passwords in a user interface. If that interface does get breached, you've got an enormous problem. But the other thing is that if those passwords do get exposed in the same sort of way I was explaining with the plain text ones. So maybe a backup is retrieved or there's a SQL injection risk. If that private key can be retrieved, then all those passwords can be immediately decrypted. Now of course that's the same with any form of encryption. Once a private key is disclosed, it's pretty much game over. The thing about passwords, though, is it's entirely unnecessary. And it's unnecessary because 99% of the time there really isn't a valid reason to take the password that someone is using for their account and convert it back to plain text. Now this brings us to hashing. A hash is simply a one-way deterministic algorithm. And what I mean by deterministic, is that you can always apply the same algorithm to the same input text and you'll always get the same output text. The important thing is though, it is one way, there is no un-hashing function. If a database of hashed passwords gets breached, the only way those passwords can be converted back to plain text, is if an attacker can brute force them by taking something like a password dictionary, rehashing passwords using the same algorithm, and comparing them to the ones in the breach. That's a very simplistic view of hashing. In my other Pluralsight course on the ______ top ten for. Net developers, I talk in a lot more detail about hashing. And in particular about using salts and also about using secure hashing algorithms. And we're talking about hashing algorithms that are slow enough that they can't be easily brute forced. So go and check out that course if you want more information on hashing. The important thing is though, that out of these three models, hashing is really the only one that we would deem satisfactory for storing credentials in websites. Plain text is useless, encrypted is almost useless. Let's jump over to our vulnerable website and we'll have a look at a couple of different ways that we can identify that an insufficient password storage mechanism has been used. The easiest way to tell if passwords have been stored as either plain text or encrypted, is to exercise some sort of activity which causes the plain text version of the password to be disclosed. Now again, earlier on in that mass assignment attack, we actually elevated privileges and got access to an admin interface, but of course that was all predicated on finding another vulnerability with the system that we could exploit. Let me show you another example. I'm going to go over to my account and change password, clearly I'm already logged in. And we can see here that the new password and confirm password fields appear to already have been populated. Now of course their password types, so we're only seeing obfuscated characters. But if we jump in there, and inspect the element, here's what we find. We actually have a value in here for the password. Now inevitably what's happened here is it's just simple model binding. There's a model which contains the password and change password fields. That's being bound directly to the UI and pumped those values back out as default values in the password fields. And even though I'm authenticated and even though we're seeing the server HTTPS, the insecurity of this is that it is confirmed that the passwords are not stored as cryptographic hashes. Now this may look like a crazy practice, and it is, but I have seen this in real life. This does happen in websites. And of course this practice discloses the fact that that password is stored in a retrievable fashion. If the system can retrieve it, an attacker can retrieve it. It might take them a bit of effort, but we've seen multiple attack vectors where attackers could get this data. There is another way, though, of identifying insufficient password cryptography. And this is one we've probably all seen before. Let me just go and grab something from my email. Now this is something that we saw earlier on in this module. A simple password reset process. Now in this case, the process actually involved creating a new password overriding the stored one, and then sending it to me in email. What you will very frequently find happens though, is that the process for when someone forgets their password is for the website to email it to them. Now of course we've already discussed the risks of websites sending passwords via email. They're insecure in transport and they're insecure in storage. But of course the other thing about it is that if a website can email you your password, that is immediate confirmation that it is not stored as a cryptographic hash. Now this is a rampant practice. And frankly it's also a pretty indefensible practice again in 99% of cases. There are some edge cases, where a website might need to store credentials so that it can then say, authenticate to another service on the users behalf. But again for 99% of cases where you're just creating an account on a site to log in, there's absolutely no reason not to hash the password. Now this practice is so rampant, that a website has sprung up purely for reporting and tracking offending websites. And I'd like to show you that to give you a sense of what I'm talking about. It's over at plaintextoffenders. com. Now here are the sort of examples I'm talking about. Log in information sent in the email. So usually it'll be a very friendly email. Hey, we heard you forgot your information, here's your user name, here's your password. Now of course every one of these sites that are following this process are inadvertently disclosing some really rather sloppy security processes. And indeed I also see many people contacting me, particularly I have a Twitter, saying hey why are these guys sending me my password. What's wrong with their password storage. And why is it going over email as well. So to summarize on password storage, plain text is useless, encryption is almost useless, and the only real solid option is those cryptographic hashes. And again go and check out that other Pluralsight course on the OWASP top ten for a lot more detail on implementing hashes securely. Because certainly it is possible to implement hashes in a fashion that's not much better than encryption or plain text as well. So there are some nuances to it you need to be aware of.

Testing for risks in the 'remember me' feature
A very fundamental account management feature, which is sometimes implemented very poorly, is the remember me feature, when you log in. Let me show you want I mean in the vulnerable website. If we jump over to the log in page, and now let me enter my email address. And my password. And I'm going to check the remember me box. Let's now log in. Now what I'd like to do is open Chrome's developer tools, down to our Resources tab. And then down to our cookies. Now there are a couple of cookies here that are a little bit concerning. And the cookies that I'm talking about are the email cookie, and the password cookie. Now we can tell just by testing, logging on and checking the remember me box, this is just logging on without a remember me. That email and password are only set when we're asking the site to remember us. Now this is concerning for a number of reasons. And the first reason is that in effect, what's happening here is that the password is being stored on the users' device. So their desktop or their phone, or whatever device it may be. But it's being stored there in plain text. There is no protection whatsoever for that password when it's being stored on the device. So that's the first problem. The second problem is that as we saw in the earlier module on cookies, the fact that it's not HTTP only, so we have no tick in the HTTP column over here, means that it is accessible via JavaScript. One little cross site scripting risk and an attacker can remotely gain access to this password. Now I should also point out here that even though that password looks a bit random, we did establish in an earlier module that that's just simply a base 64 encoding of my password. Anybody can take that and just base 64 decode it. It's certainly not encrypted. The other problem with this, and we saw it on the internal implementation leakage module, is that because I'm going to send that cookie back with every single request I make to the website now. If there's a risk, such as exposed logs that capture internal exceptions and I happen to raise an exception, this password is going to end up in my logs. These are all real world scenarios. And certainly they happen many, many times. But the question now is why do we have email and password here? In order to automatically log me back in. Let's look at the execution of that. So I'm going to log off. I'm going to open my network tab. We'll just clear all those results. And I will go over to the log in link. Now what we're seeing here is this logging you back in automatically prompt. And in fact if we scroll back up a little bit, what we will see is a post to log in, and if we have a look at the headers and we scroll down a little bit, we will see that in the form data we actually have the plain text password. And of course we have the email address. So what's actually happened here is the website has manually reconstructed the login process. So just be visiting that login page, the fact that I had an email cookie and a password cookie, has caused it to automatically authenticate me again. Let's have a look at that script. I'm going to log off. Back to log in. Quickly into the source code before we lose that page. And then down here we will find some JavaScript. And the JavaScript is simply retrieving the email address and the password from cookies. And then if they're not both null, it's base 64 decoding. It's giving us our little model window to show the logging on process. And then it's actually setting the value of the email field, the value of the password field. Giving it a little delay so that we can see the loader and then it is submitting the login form. This is terrible. It's an extremely manual, clunky, risky way of implementing a remember me feature. Particularly when the correct way of doing it is so simple. I've recently wrote a very comprehensive blog post on how to do this, so you'll find a lot of information about the remember me feature on troyhunt. com But one of the most simple ways of doing it is already staring us right in the face. If we look at the resources and then we take a look at our auth cookie, we'll see that this auth cookie actually has a very far reaching expiration. It doesn't expire until about one year from now. Now we talked about the risk of long expiring cookies back in the cookies module. And certainly as a default position you don't want your auth cookie to last an entire year. You probably really only want your auth cookie to last a day or two. Maybe even a few hours. It really depends on the nature of the site. However, if you check that remember box, that's when you want to extend the life span on that cookie. Remember me can be as simple as a far reaching cookie expiration. Maybe not a year, maybe it's a month, or two months. It really depends again on the nature of the website. The point is that we don't need email, we don't need password, we don't need to manually reconstruct the log in. All we need to do is make that auth cookie last long enough so that when someone comes back after they would have normally been logged off. But within the time period that you want the remember me feature to last for, the auth cookies still valid and they just immediately identified, they're not actually logging in again, they're just still authenticated. There are other ways of approaching this as well. But in its most simple form, that is how the remember me feature should be implemented. Certainly not by persisting sensitive data in cookies.

Re-authenticating before key actions
Throughout this course, we've looked at a number of different ways of highjacking a session. So for example, in the first module on transport layer protection, we found that when auth cookies weren't properly protected, a man in the middle could easily sniff that cookie and then reconstruct it in their own browser and consequently take over the session of the authenticated user. So that was one approach. Another approach we saw was in that internal implementation disclosure module where our login framework had automatically saved authentication cookies into the log, which was then not properly protected. And anyone could come along and get those cookies. There are multiple different ways that an attacker can take over someone's session. Plus of course, there's the old fashioned way of simply walking up to a PC where the user is still authenticated. So that might be as a result of something like that far reaching authentication cookie that lasts for a year. Six months from now somebody's still logged in, an attacker walks up, sits down at the PC, and hey, suddenly they are their victim. Now all this is important in so far as we must acknowledge that there are various attack vectors and risks around someone having their session high jacked. Because of this, sometimes it's pertinent to actually authenticate the user again before performing certain tasks. Let me give you an example of where we're getting this wrong in the vulnerable website. If I jump over to my account, and go to change my password, I don't have to re-authenticate again. I can simply change this password. Now that's a problem, not only because it means an attacker can easily change my password, if they're able to high jack my session. And then of course once they can do that, even if they never knew the original password, they can get themselves back in at any time. But we also saw how this feature was abused by cross site request forgery when we looked at cross site attacks. Changing a password is a pretty critical account management feature. And it's the sort of thing that really requires re-authentication before it's done. Now it's not just changing passwords either. You might have a system which involves an action that has a financial impact. That would be a good example of where you might want to re-authenticate someone. Of course there is a usability impact. You've got to ask somebody to enter their password again, but from a security perspective, I'm sure you can see how beneficial it is. So this is wrong the way we've done it here. Certainly changing passwords, which is an infrequent activity, with high impact, requires re-authentication. Let's go and take a look at how the secure website handles this. Over on the secure website, our change password page looks quite fundamentally different. At least in terms of the fields that we have here. And the most important difference is that we are asked for the current password. Unless we can properly authenticate ourselves, again, the process of changing my password won't succeed. Let's try it. And I'll just enter a random password here. And I'll try and enter a new valid password. Let's change that. And here's the point I'm making. Unless the person trying to use this feature knows their password already and is consciously trying to change it, so they're not falling victim to something like a CSRF attack, the password on the system won't be changed. All the valid information must be held by the user. This is a fundamental security feature. Now let's change it. There we go. So as I said earlier, consider the other points were re-authenticating might make sense. Activities that have an impact, but aren't too frequent, are a perfect example. So clearly changing passwords, I mentioned sometimes before committing to a financial transaction, perhaps also before changing contact data. You don't want an attacker to be able to change something like an email address to their own, and highjack the account. You want to have a little bit more verification in a process like that. And really this is a very, very simple feature to implement. It's just one more field, callback into the authentication mechanism, establish that much higher degree of confidence that the user is who they say they are, and the website will be in a much more secure position.

Testing for authentication brute force
The last thing that we're going to look at in this module and indeed the entire course, is the risk of brute forcing the authentication scheme. Let me show you what I mean. If I jump over to the login page and I enter my email address. And now I jump down and try, let's say any arbitrary password, just a few characters. Let' try and log on. It wasn't successful, another three arbitrary characters, also not successful. I can keep going and going and going all day long. This system happily keeps letting me retry different combinations of characters. The risk of course, is that if an attacker tries enough combinations of characters, or enough passwords, as it may be. Sooner or later there's a good chance they'll stumble across the right one. So think back to the start of this module as well, where we talked about the propensity for password reuse and the prevalence of password dictionaries. If an attacker is working to a finite list and the system is allowing them to continue making attempt time after time after time, sooner or later, there is a very good chance the attacker is going get a hit. I want to give you a demonstration of that with a little brute force tool I've written, just to test breaking into this authentication scheme. I'm going to drag it over here, it's just a little console application. And all I'm going do here is called PasswordBruteForcer. exe, I'm going to pass the target path that I'm trying to log into, which of course is the login feature of our vulnerable application. And I'm going to pass my user name. Now when I do this, what's going to start happening is that the application will start testing a whole range of different passwords from a password dictionary. Now every one of these is an HTTP request. They're just being fired off one after the other at the target application. And as we can see now, eventually the brute force tool will get to a password that works. Now of course the success of an attack like this, which is sent over HTTP, does depend on some factors, such as the proximity of the server to the attacker, the available bandwidth, and of course the number of simultaneous threads we can run. In this case it's a local machine. So the latency was very low. And the pipe was pretty much unlimited, but then I only used a single thread. And it's only a single machine doing the attacking. So in the real world, some things would be slower, some things would be faster. The important thing is that we can see there's been a huge number of attempts to break into this system and our vulnerable application has allowed this brute force tool to just keep going and going and going and going and hammering away until it finally gets down to that last password, which we've been using through this course. Now of course another thing about this application is that is forced poor password selection upon us. It made me choose a password that didn't have "special characters" and was less than 10 characters. That dramatically decreased the space in which a password could fit. So for an attacker trying to brute force the system, their job got a whole lot easier when we put those draconian restrictions on password strength. Now fortunately there are multiple easy ways of mitigating this risk. Let's go and take a quick look at a slide to explain some of those options. We have a few different options available to protect against the risk of an attacker trying to brute force an authentication scheme, such as we just did with our vulnerable website. Now the first thing to say is that none of these are really perfect, and again they're all a tradeoff between security and usability. There is an adverse impact to each of these. So the first one is probably your most common and it's just simply account lock out. After someone tries to log on to a particular account, a certain number of times, so for arguments sake say five times, the account is locked out. Even a legitimate user, with the correct password, cannot log in. The problem of course, is that at some point you've got to be able to unlock the account. And the question then becomes, what is the authentication process used to identify a legitimate user such that the account can now be unlocked? In many cases it will be an off line process. There may be a call center or a number that someone can dial and identify themselves over. Now naturally that has quite an overhead, and even if you leave the whole process on line and say, contact an administrator, then the administrator still needs to go through some sort of identification process in order to have confidence in the user. Now that identification process may simply be that, look that's the registered email address and that's enough. But it is an area that requires some thought. Another fairly common process is to restrict the login attempts by IP address. Now that may not necessarily be just for the one account either. In the example we just saw, there'd be nothing to stop us from taking a password out of the password dictionary and trying it against a dozen different accounts. So in a case like that, what we're talking about, is an attacker moving through a whole range of different user names and passwords so that they're not exhausting one to early. You could probably quite easily take the top 10 most popular passwords, and if you had a large enough list of users in the system, sooner or later you'd get a hit. So restricting log in by IP, may not necessarily mean, by IP and account user name. Now the problem of course, is that in many cases attackers do have many IP addresses, and they have them by virtue of owning or renting botnets. So we're talking about infected PCs used to do anything from send spam, through to brute forcing accounts. On the flip side, you have many cases where you might have multiple legitimate users behind the one IP address. Corporate internet gateways are a great example, often it's the one out going IP address. But you could have hundreds, thousand, tens of thousands of people sitting behind that one IP. Another angle is to fingerprint the client and scale the rate at which you can authenticate. Now by fingerprinting we're talking about looking at unique attributes of the client and building a profile out of that. So for example, you might look at the user agent string, and then combine that with say the language of the client. By combining multiple factors together, even though you might have multiple people using say Internet Explorer 10 Non Windows 8, you'll very often get very unique fingerprints. So that's a way of uniquely identifying the actual client, not just the IP address. And one option then is to say, well we're going to do now, is we're going to slow the rate at which that person can authenticate. So if they get a login wrong, the next time they get a login wrong, the process sleeps say for a second, before returning a response. The next time it sleeps for two seconds, and then four and then eight. So it could actually increase exponentially. Now of course the risk there is that a fingerprint can be manipulated by an attacker. Once they're aware of what's going on. And it's not too hard to figure it out. They may simply start randomizing request headers. All of that is perfectly possible because they control the way the request is constructed. So in short, there is no _____, we can't just pick out one of these practices and say this is always the right way to do it. Probably the path of least resistance is that first option and then providing contact information for an administrator if they do get locked out. But of course you've also got a denial of service risk with that first option. Now this is exactly what we looked at earlier on when we established it's possible to reset somebody else's password. If an attacker wants to have a go at someone, all they need to do is, try and log in with their user name, but an incorrect password, say five times, and the persons locked out. So everything is this kind of unfortunate tradeoff. There is no one right answer and you need to pick the one that is the best balance for the unique circumstances of your website.

Summary
Let's summarize the module. And going back to where we started out, one of the most important things about standing up a website, when it comes to password security, is to not put arbitrary limits on the password. Don't put low max links. And again, by low, anything under a hundred or a couple of hundred characters is just totally unnecessary. Definitely don't exclude special characters either. Assume that every character is equally special, don't block people because they want to use a space or a quote or an angle bracket, or anything like that. There's no reason to. And speaking of passwords, credentials should never ever ever go into an email. Email is not sent securely over the internet, and it's not stored securely in mail boxes. Passwords never go there, full stop. We also took a look at the account enumeration risk by testing the password reset feature. And what we found is, is that it's possible to identify both people that do have accounts in this system and don't have accounts in this system. So be conscious about whether that does pose a risk to you and whether you need to actually do that identity verification by email rather than directly in the browser. Now of course that also extends to features, such as log in, so not telling someone that they've got an incorrect user name. And also registration. And that's the tricky one. Because if it's important not to disclose the presence of accounts, you need to design your registration in such a way that people won't get a message in the browser that says you can't register with that email address because it already exists. Denial of service attacks on user accounts is another risk. And we exercise this by resetting someone's account. We literally lock them out of the system by changing their password. Now of course they would have gotten that password in email, which we also know is not a very good practice at all, but it does lock them out and it does cause quite an inconvenience. So always provide a reset link in order to help someone set a new password. Now that reset link needs to have a token that is time limited, it's a one-time use, and of course it's keyed to the user. So in a reset process, someone can take that URL with the token, and then go and set their own password. That's the correct way to do password resets. I've also got a dedicated post on troyhunt. com specifically about how to implement password resets. So go and check that out if you want some more info. Another really important thing about password security on websites, is how those passwords are stored in the system. We looked at plain text, encryption, and hashing. And if it's not the later, if it's not a secure cryptographic hash, it really is insufficient. Plain text is useless, encrypted passwords get decrypted. If you can ever retrieve a password in plain text, from the system, or even if you can talk to an operator who can do that, that is insufficient password storage. Remember also the concept of re-authenticating before key actions are performed. Changing a password is an obvious one. And we exploited the risk that is created by not re-authenticating earlier on, when we actually mounted a CSRF attack. We've also looked at multiple ways of highjacking sessions which would then allow an attacker too easily change someone's password or perform other key actions which probably should be protected by re-authentication. Simply because they're able to highjack the session. So re-authenticate, but do so selectively with consciousness of the usability impact that asking someone for their password means. And finally you really don't want to allow just endless attempts to authenticate someone to a system. Look at lock outs, look at throttling, and look at the fingerprints and changing the rate at which someone can authenticate. None of these are perfect systems though, they all have tradeoffs. And those tradeoffs are both in security and usability. And it's probably the single most use case specific example of security we've covered in this course. It's something that you really, really need to assess on the bases of the value of what's being protected, the likelihood of an attacker, and the resources you have available to put in mechanisms to prevent this from happening and to support your customers. And ultimately that's a good way to finish the entire course. Security is always about this balance, of how do I make things as safe as possible for the user, yet still help them get their job done on the website. And ultimately all of this is only there in order to make the website successful. So do take a pragmatic approach to security and be conscious that everything is a balance. And there are rarely absolutes. And on that note, thank you very much for watching my course, please do reach out to me at any time on the contact details provided on the Pluralsight website and in the introductory slides. Thank you very much.

Course author
Author: Troy Hunt	
Troy Hunt
Troy Hunt is a Microsoft Regional Director and MVP for Developer Security,
 an ASPInsider, and a full time Author for Pluralsight—a leader in online
 training for technology and creative...

Course info
Level
Intermediate
Rating
4.8 stars with 861 raters(861)
My rating
null stars

Duration
9h 25m
Released
30 Aug 2013
Share course

