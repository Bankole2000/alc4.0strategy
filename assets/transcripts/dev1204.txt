Continuous Monitoring: The Big Picture

by David Clinton

Adding continuous monitoring to your application management will make both your developers and users happy. This course, you'll learn how CM makes it easier to catch bugs, simplifies regulatory compliance, and integrates perfectly with DevOps cycles.

To properly ensure your application is running - and running properly - you'll need to understand how continuous monitoring works. In this course, Continuous Monitoring: The Big Picture, you'll learn about continuous monitoring and how it fits into DevOps development cycles. First, you'll dive into the principles and benefits of continuous monitoring. Next, you'll explore how continuous monitoring can be used as part of an Application Performance Management system. Finally, you'll discover how continuous monitoring can improve your compliance with both regulatory and industry standards. When you're finished with this course, you'll be ready to make the software and system choices to help you fully integrate continuous monitoring into your application management process.
Course author
Author: David Clinton
David Clinton

David taught high school for twenty years, worked as a Linux system administrator for five years, and has been writing since he could hold a crayon between his fingers. His childhood bedroom wall...
Course info
Level
Beginner
Rating
3.4 stars with 30 raters(30)
My rating
null stars
Duration
0h 45m
Released
6 Jun 2017
Share course

Course Overview
Course Overview

If your application isn't available or running properly, then it isn't going to generate all that much revenue for your company, and if you're not constantly monitoring its performance, there's really no way to know what it's doing, at least before the customer complaints start pouring in. Adding industry-standard monitoring protocols to your team's workflow can bring you into regulatory compliance, make your product more reliable, and perhaps most exciting, compliment all those efficiency gains you hope to realize through adopting DevOps systems. Customer feedback for your company's web-based application has been just great, whenever the thing is actually running, and you've just discovered that there's a whole world of regulatory compliance out there that has yet to touch your infrastructure. You've got some serious research and work ahead of you to improve your DevOps and company protocols, but you don't know where to begin. In Continuous Monitoring: The Big Picture, I'll introduce you to the principles and benefits of continuous monitoring and application performance management. I won't go into specific technologies, but I will talk about the various classes of software tools that exist so you'll be ready to make the smart decisions it'll take to keep your application functioning at the top of its game.
Introduction to Continuous Monitoring and DevOps
Introduction to Continuous Monitoring

Welcome to Continuous Monitoring: The Big Picture. By monitoring, I mean keeping a close watch on your running application to make sure it isn't about to fall over and die or isn't quietly providing bad guys with inappropriate access to your money and resources. Any by continuous, I mean maintaining an attentive and unblinking eye on it every second of every day of the year. I hope it's obvious that the eye I'm talking about isn't attached through optic nerves to a human brain. That wouldn't work too well with the every-second-of-every-day bit. Human brains need sleep and cute cat videos every now and then, after all. Rather, I'm talking about using software tools to keep a watch on your company's important stuff while you're off watching or even creating those videos. A lot can go very wrong with an application, and when it's public- facing applications that go wrong, things can get really dark really quickly. So the sooner you get the bad news, the sooner you can start working on the fix, and the sooner you can stop the bleeding. Having a solid, continuous monitoring process in place means that all this can happen, well, sooner. Through the rest of this course, we're not going to dive into any specific CM technologies and solutions. Other Pluralsight courses will handle that. Instead, we're going to learn about the value of CM when it's intelligently applied to both your code and IT infrastructure, the specific areas where it's most effective, the threats it comes to address, and the ways it can improve your overall operations. We'll then explore different categories of monitoring, both active and passive, and explain their value and use cases. We'll learn how to apply CM tools and principles to meet your specific needs from setting priorities to effectively consuming the log data that pours out of the other end of the process. And finally, without going into such great detail, we'll talk about the classes of monitoring tools that are available. After all, without knowing what's out there, how can you possibly make an informed and smart choice over which direction to point your next step? That's the big picture. Coming up in the next clip, just what is continuous monitoring?
What and How Does Continuous Monitoring Monitor?

Continuing monitoring aims to solve a problem. As I mentioned before, if your application and infrastructure are going to fail, and face it, at some point both of them will definitely fail, you'd rather know about it right away. But besides making sure your software is actually still running, there's a long list of other potential problems you'll want to track. So for instance, it's important to understand the quality of the service you deliver over time. Do your users experience website latency? Is your back-end database fast enough? More important, is it accurate enough, or are there access errors or missing records? Perhaps most important of all, are the financial transactions you're performing accurate? Are they ever incorrectly duplicated? Is private information properly protected? And speaking of privacy, are there appropriate security controls in place, and are they active? Are there any unpatched vulnerabilities in your software stack or network infrastructure? Are you even keeping up with the latest patch information? Besides the immediate and hopefully obvious security and operational issues, you should regularly ask yourself if your application is meeting your company's business goals and requirements. This can cover things like service level agreements you signed onto and government or industry compliance standards. If you aren't watching, how can you know if you're on the right track? So those are the problems continuous monitoring comes to solve. Now you're probably wondering about the how. I would organize it into four steps: research, selection, implementation, and consumption. Let's take those one at a time. You can't know what needs doing before you've mapped out the lay of the land. You'll need to understand how the application software is supposed to work, what makes up its technology stack, what security controls are already in place, and how data is supposed to be collected, shared, and stored. You'll also need a good sense of the business goals and limitations, along with the regulatory and industrial environment within which you live. It's unlikely that any one person will just happen to have all that information immediately at hand, so you'll have to gather it through research. Based on that research, you'll be in a better position to figure out which monitoring technologies will work best. Selecting the right solution will, of course, require more research and probably a whole lot of demoing and trial and error too. Deploying the solution you end up using will involve configuring and fine-tuning the monitoring software that fits your needs, including how often the monitoring scans should take place, and then, of course, testing the whole thing to make sure it actually works. Nothing says quality like an alarm system that's not plugged in. And finally, you'll need to figure out what's going to happen to the information your monitoring solution spits out at you. What formats should reports use? Who should receive those reports? Is there a process for effectively assessing and handling alerts? That's continuous monitoring. Now I'll bet you want to know what all that has to do with DevOps. Stay tuned.
Continuous Monitoring and DevOps

There's no way I can win this one. No matter how I describe DevOps, I'm going to annoy someone. On the one hand, many of you have probably been practicing and living DevOps for years and don't need to hear any definitions from me. And I'll bet that all of you already have, at least, some kind of a mental picture of how it works, and there's a good chance that that picture won't quite match mine. Still, if we're going to properly understand the form and function and full context of continuous monitoring, then I'll at least have to give it a shot, here goes. DevOps is about collaboration between a project's development, QA, and IT teams that's designed to facilities faster time-to-deployment and software update cycles, and to allow greater levels of process automation. Often, the automation dividends come through the smart implementation of continuous delivery tools like Ansible, Jenkins, or Amazon's AWS CodeDeploy. Being able to simple plug new or updated code into a kind of virtual assembly line, with all the underlying infrastructure and compatibility details invisibly taken care of, can certainly speed things up, but it can also greatly improve quality and reduce errors. A very important component of DevOps is incorporating usage feedback and product fixes into the larger development cycle. The more feedback you get and the higher the quality of the feedback, the faster and more focused and effective your updates will be. So imagine if you could move beyond having to wait for end users to complain that something's broken or for the results of periodic testing to come in. Imaging having smart eyes on your application 24/7, kind of sounds like continuous monitoring, doesn't it? Of course, continuous monitoring setups aren't limited to the management phase of your DevOps cycles. In fact, there's no reason why you can't also apply some of that CM goodness to your code as it moves through the dev and staging steps of the process too. But besides being a great friend of DevOps shops everywhere, continuous monitoring can also pay off big time in your efforts to achieve regulatory and standards compliance. We'll look at that next.
Continuous Monitoring and Regulatory Compliance

Besides the ongoing integrity of your application, continuous monitoring can also be applied to regulatory and enterprise compliance standards. While integrating compliance-related activities with your continuous monitoring process might take a lot of work to set up the first time, having ongoing access to system status data can save you countless hours and big headaches down the road by avoiding the need to tool up for quarterly and annual audits. With that in mind, it's probably worthwhile spending a couple of minutes on a quick review of some significant compliance standards. I'm going to focus mostly on Sarbanes-Oxley and FISMA, even though they're regulation-specific to the United States government and, in some implementations, to US government agencies. Now, for those of you who, like me, live and work outside the US, this might seem odd, but the truth is that many of these rules apply even to non-US companies doing business in the US. In addition, many other governments will have their own similar accountability and monitoring requirements, so it doesn't hurt to be aware of this stuff. In any case, the Sarbanes-Oxley Act, more formerly known as the Public Company Accounting Reform and Investor Protection Act, was passed as a reaction to some serious financial mismanagement in publicly traded companies back in the 90s and early years of this century that resulted in the loss of billions of dollars of investors' funds. In an attempt to make corporate financial practices more transparent, Sarbanes-Oxley imposed accountability processes spread across 11 categories known as titles. Of course, most of those are purely financial in nature and will have little direct impact on the IT world. Nevertheless, there is plenty of overlap between those rules and IT operations. Therefore, for instance, you'll want to focus attention on IT controls in general, and especially any systems directly involved with financial transactions and reporting. In short, you've got to be absolutely sure that your financial data is available and reliable. FISMA, the Federal Information Security Modernization Act, is a regulatory framework meant to guide managers in US federal government agencies through annual reviews of the threat resilience of their operations and assets. The steps to compliance with the act are outlined in the National Institute of Standards and Technology, NIST, Special Publication 800-37 known as the Guide for Applying the Risk Management Framework to Federal Information Systems. Those steps can be summarized as scoping and organizing the data that needs protection, choosing, implementing, and documenting the appropriate security controls you'll apply to that data, assessing how effective your controls are, submitting your plans and documentation to an appropriate authority who can approve a proposed risk versus protection balance, and engaging in ongoing system monitoring. It shouldn't be difficult to see how a lot of those requirements line up pretty comfortably with our own DevOps goals. If you're not yet familiar with NIST, they're an agency of the US Department of Commerce whose job it is to support innovation and industrial competitiveness through researching and setting standards and through their cyber security programs. They also run the National Vulnerability Database whose data is used to feed just about all the vulnerability assessment tools currently in use. Before we move on to our next module on understanding the kinds of activities that fall under the heading Continuous Monitoring, we should probably take a minute or two to review what we've seen so far. We listed some of the benefits of continuous monitoring including getting quick alerts about failed states in your application and to infrastructure vulnerabilities before they cause havoc to your users and your company. We discussed the four steps you'll probably need to work through to get a continuous monitoring system going for your application, research, selecting a solution, implementing and configuring a solution, and consuming the data that's generated. We discussed the world of DevOps and how its emphasis on fast update cycles and resource integration are a natural fit with the kinds of results continuous monitoring will produce. Not only is a DevOps shop better able to adopt continuous monitoring, but it stands to benefit the most from it. And we devoted some of our attention to regulatory compliance, learning about US government laws, like Sarbanes-Oxley, that, while focused primarily on US entities, are likely to have an indirect impact on just about everyone in the IT industry, either because they're doing business with American companies and institutions or because their own governments have created similar legal structures.
Understanding Continuous Monitoring Categories
Understanding Continuous Monitoring

Welcome back. This module will be all about the practice of continuous monitoring, meaning a step-by-step description of the core goals for your monitoring and the things you'll do to achieve them. As I mentioned earlier, we won't talk about any specific tools, and even a general discussion of the various classes of tools will have to wait until the final module, but I will present a kind of functional mind map of the process. I suppose all that does sound a bit abstract, but don't worry, it's not as bad as all that. We'll begin by talking about how to build a clear picture of the problem. In other words, what are you afraid might happen or might already have happened to your application infrastructure that has you worried? Knowing exactly the kinds of the things that can go wrong will inform the way you work to prevent them. Then I'll introduce you to Application Performance Management, or as it's sometimes called, Applications Performance Monitoring, which is an important framework that can help guide you towards an intelligent and holistic implementation of monitoring. We'll see that APM functionality is usually divided into two complimentary monitoring modes, active, or synthetic, and passive. Finally, we'll talk about monitoring your infrastructure environment. After all, no matter how smoothly your application itself might be running, if the servers or network connectivity falls over, you won't earn too many positive user or supervisor reviews. I don't know about you, but I'm ready to get started.
Risk Assessment

Just what might go wrong with your application, and just what, therefore, needs monitoring? Many, many years ago before the internet was all that useful, IT marketing was done by lugging heavy hardware from potential customer to potential customer. I remember nearly 30 years back, a couple of software developers bringing their pitch to my institution. They must have spent the best part of half an hour just finding a suitable power source and getting their PC running, and then another half hour loading a suitcase full of floppy disks into its memory to run the program for us. In case you're wondering, we didn't buy anything, but we did smile and nod a lot. I recall a cynical joke from those days. The best way to kill a sale is to run a demo because something would almost always go wrong. In that sense, not too much has changed. Developers still leave bugs in their code and sysadmins still drop connectivity, although being a sysadmin myself, I'm confident that we mess up far less often than those developers. But at any rate, the very first thing you'll really want to know is whether your application is actually running over a given stretch of time. If something does go down or is about to, it will also be critical to be able to very quickly figure out what the problem is, a software bug, a broken network, or some hardware failure. The greater insight you have into the dark inner workings of your application platform, the better. If there are systemic inefficiencies or aging and fragile technologies, you'll definitely want to know about them. Some problems can, of course, be revealed by the kind of software monitoring tools we're talking about here, but there's also no substitute for good, old fashioned audits of your physical environment. Who knows, you may discover that the office cat has been using your $25, 000 Juniper switch as a litter box. We also need to look outwards. There's absolutely no justification for ignoring the threat of malware and network-based attacks. They say that 83% of all statistics are made up on the spot. So in that spirit, I'll solemnly inform you that more than 98% of all malware and ransomware attacks could easily be prevented if admins and users only applied all the easily available and simple, common sense measures to protect themselves, and you can quote me on that. But in any case, your continuous monitoring procedures must include ongoing scans to ensure that you are, indeed, doing everything possible to avert disaster and that there's nothing you can find that's already eating away at your system. Perhaps the most important object of your attention should be the one that's hardest to define. I'll call it situational awareness. This is the kind of practical intelligence that covers the kinds of perils that are particularly threatening to you within the context of your business and your environment. What's your competition up to? Is it possible that you might be a target for foreign governments? This kind of observation can suggest where to concentrate your monitoring resources. Years ago, I made an insurance claim for a bit of weather damage to my house. While speaking with the insurance company's adjustor, I learned that they were working under significant pressure to finalize all the payouts where I lived at the time in Ottawa, Canada, because many of their appraisers were soon going to be moved to the Southern US for the coming tornado and hurricane seasons. These guys are really aware of the larger context of their business and were super efficient at focusing their resources. We should be sure to learn from them. In the next clip, we'll learn about directly monitoring your application itself through Application Performance Management.
Application Performance Management

While the specific monitoring tool stack used might vary from one company to the next, the basic process will usually follow a common pattern. As I mentioned in the introduction to this module, there are two parts to an APM setup, active monitoring, which is sometimes called synthetic, and passive. The goal of active monitoring is to reproduce and precisely measure the real user experience of your application. The methodology often revolves around a script that actually loads the application and submits it to the kinds of things actual users will do. The script will keep track of response times and the way the app behaves in general, and everything is carefully recorded. In this context, the term synthetic makes sense because you're not measuring real users, but simulations. On the other hand, you're free to run these tests whenever you'd like, during both high and low demand periods and against staging and dev versions of your app in addition to production versions. And of course, the metrics you get are precise because they were collected under controlled conditions. Because you can run active monitoring scripts as often as you like, they're effective for carefully watching changes in responsiveness, availability, and long-term uptimes, all of which are essential for spotting trends that indicate trouble on the horizon. Passive monitoring, on the other hand, is used primarily for forensic assessment of past events. It's passive in the sense that you're not throwing anything at the application, but just passively watching performance data as it comes in. From that perspective, you're not as likely to be able to spot bad stuff before it happens, but you will be able to perform full-bore postmortems on events after the fact. Data is delivered by what's called network port mirroring, a switch level process that sends copies of data packets traveling into or out of one network port to a second port where it can be analyzed. In fact, this can go much deeper than just scrolling through massive log files looking for evidence. Assuming you've got a full stack monitoring solution in place, you can run analyses against multiple data sources and general infrastructure maps to produce event correlations connecting individual events to specific application layers or infrastructure elements. Naturally, the more data you have, the better the results will be. So for instance, you'll want to capture both user experience metrics, which might include averages of page or database load times, and the performance of your hardware resources. Smart solutions will allow you to visualize all those data sources together to more easily understand events in their full context. With this depth of information, you're in a much better position to quickly track bottlenecks and component failures and add capacity or replace elements as necessary. Building your APM system on top of a full set of baseline performance metrics will give you even more insight into events as you'll be able to measure new data against a known healthy systems state. I've described APM here from a lower level, purely functional perspective. The fact is though that some see APM in much more formal terms. You may find it worthwhile to explore a couple of conceptual models of APM created by Gartner Research and described on the APM Wikipedia page. These models break down the Application Performance Management Framework into a number of smaller dimensions, but all that's extra credit. We won't go into those here.
Infrastructure Monitoring

The final piece of the continuous monitoring puzzle is infrastructure monitoring, as distinct from the application monitoring we just covered. Besides the importance of having a full awareness of all the machines you've got running, both virtual and physical, you also need to know about all your resources on the network and storage layers. You can't very well claim to be on top of things if there might be, say, a virtual machine somewhere happily chewing through memory and storage space on some long-forgotten and useless mission. And don't think it doesn't happen. I've seen VMs spun up as short- lived experiments still churning out gigabytes of log data until whole dry partitions just fall out of service. The moral of the story, you'll need eyes on that too. This principle applies just as strongly to vulnerability assessments. Vulnerability assessment tools are generally software suites that coordinate a full range of scanning, network sniffing, and hacking tools, and apply them against your public-facing infrastructure in coordination with up-to-date databases of known system vulnerabilities. The goal is to find and report any holes or axis vectors that might be open to malicious exploits. The more complicated and multi-tiered your infrastructure is, the more you desperately need to run vulnerability assessments, so don't even think about leaving them out of your overall continuous monitoring plans. In the next module, we'll talk about making sense of all the truckloads of data this monitoring will produce, but first, we'll take a look back at what we just covered. We talked about how important it is to simply know that your application is running and find out fast if it ever stops. You must also understand your hardware and software stacks to know what should and shouldn't be running. It's important to have situational awareness that goes beyond your own company and its resources, but encompasses the larger ecosystem within which your application exists. We learned about Application Performance Management and how it uses both active and passive tools. Active monitoring simulates a user experience through running scripts that load application workloads, and passive monitoring automates a collection of event data that can ideally be correlated and contextualized with everything else you're collecting. And finally, we touched on how much you need to remain aware of everything in your system, both the good stuff and any existing vulnerabilities.
Defining an Appropriate Monitoring Process
Introduction

Up to this point in the course, we've learned about the basic purpose and value proposition of incorporating continuous monitoring into your software development cycles, especially if you're part of a DevOps team. We've also seen the kinds of monitoring that are possible, including the various elements of application performance management. So now it's time to talk about actually implementing a continuous monitoring system. Of course, since this is a Big Picture course, you're not going to watch me crack open a command line terminal and start typing the CM structure into existence. That, as you already know, is for other technology-specific courses. But what I will do right now is take you through the process of designing a monitoring system. To that end, in this module, we'll look at the project scope, which is to say how you decide what to target with your monitoring and what to leave out, and how to figure out the difference. We'll address timing, the fine art of scheduling your monitoring operations so they'll be at their most effective, and then, everything reporting, because all the monitoring in the world won't do you an ounce of good if no one gets around to reading the results. All set to get started? Not so fast. There's one more thing, but it's something I won't discuss here, despite the fact that it's probably the most important part of the whole exercise. Let's assume that you've heroically built your continuous monitoring system and set the whole thing in motion. Leaning back in your comfortable office chair, you take real pleasure thinking about how everything is humming along so nicely until, that is, you realize that you haven't got a clue what will happen if an alert actually goes off, whoops! You forgot to create and implement an incident response protocol. It's eminently possible that some flashing red light and ear- splitting siren will go off sometime in the next 5 minutes, and no one in the office will have a clue what they're supposed to do about it. So if incident management is so critical, why am I avoiding it? Because the protocol you develop will be unique to your company. I can't tell you who has to get the phone call in the middle of the night, as long as it's not me of course. And I can't tell you where to log in to find out what's going on, or even how to turn off that annoying siren. That's your business. Now we're ready to move on.
Defining the Scope of Your Monitoring Project

As I mentioned earlier in the course, before you can make any kind of smart design decisions, you'll need to know exactly what resources you've got running. As I think I also mentioned, unless you work for a very small company, you're probably not going to be in a position to personally know all the servers, services, and VMs that are currently at work. I suppose you could go room to room looking under desks and following cables through ceilings. You'll also need to hit the server room racks and see if you can figure out what each of the machines you see there is doing, but that certainly won't help you uncover your cloud resources, VMs, and containers. So you'll either have to hope the IT department has an updated inventory map of their own or just resign yourself to rolling up your sleeves and talking to, you know, actual people. Speaking of the cloud, there's obviously no need to include those infrastructure elements that are handled invisibly by public cloud providers like AWS in your monitoring scheme. That means you won't have to worry about the health and security of the physical layer of the equation, which you can't access in any case, and if your application is running on a Platform as a Service provider, like fors. com or AWS Elastic Beanstalk, then you'll pretty much have nothing to worry about besides your code. So here's our first answer to that how do I set the scope question. As a general rule, you only need to monitor what you control. Here's another consideration. Continuous monitoring is not free. It's true that you could choose to use only open source software in your solution and that's definitely a viable option, but there's still the cost of setting up. There's the time your admins and developers will spend designing and building the system, which might require creating custom APIs and client software to access them and quite possibly the cost of a monitoring server and the storage space to host it all. There might also be some performance costs associated with the monitoring scans. These aren't things that should be ignored. Therefore, like everything else in business, the scope of your continuous monitoring project will partly depend on its budget. Application modules that are relatively simple or are less vulnerable or even less important may just have to live without frequent scans or perhaps with none at all. But it's because of tough decisions like those that they pay you the big bucks, right?
Learn to Effectively Time Your Scans

I hope you didn't think that continuous actually means continuous. There may be exceptions, but most of the continuous monitoring software I've seen is meant to be run periodically on a schedule. The thing is that incorporating the whole system with all its many moving parts into a managed script takes it out of the hands of administrators who tend to get distracted and forget to do important things like taking the dog for its walk and running monitoring scans. I would've used forgetting to pick up the groceries as an example of human frailty, but I think that's now taken care of by amazon. com. In fact, come to think of it, I'll be their drones will do the dog thing soon too. The magic of scripted solutions is that you can apply the value of monitoring at a very precise level. Those application components that are the most fragile or vulnerable will be scanned more often. Those scans that look for relatively low volatility problems will be run less often. Scans that can use up valuable bandwidth can be saved for low-demand slots in the middle of the night, it's all up to you. There's no reason to restrict your monitoring activities to a schedule however. Why not set scans as responses to real-world events, like third-party software updates, bug reports, or even your own version releases. The tools exist. Finding the perfect solution is really a matter of maximizing your creativity and imagination.
Reporting Scan Output

The setup job is nearly done. All that's left is to arrange for a useful way to consume the monitoring reports. As you probably already know, the volume of data this kind of operation, or better, these multiple operations, will generate, isn't something you're going to want to read from start to finish. Have you ever seen a log file with more than a million lines of plain text? Let's just say that this is another reason you might want to limit the scope of your scans. Of course, it's not necessarily as bad as all that. Most of the individual software packages that you use for your continuous monitoring come with tools to filter scan results for you so you're not overwhelmed. And if you're lucky, you might find bundles that combine the output from the whole range of tools into a single manageable feed right out of the box. But if you're going to build your own solution from the ground up, you'd better sharpen your data parsing skills because funneling the streams you're going to face will require some serious preparation. Once you've successfully reshaped your data into a form that'll be useful, you'll need a way to get it front of the right people. The approach you end up adopting will probably depend on the software choices you make, as going with the built-in functionality they offer will usually be the simplest route. That will most likely include email or text messaging alerts along with some variation of graphs on a status screen, but if that's not enough, then you might have to adapt. Besides configuring messaging alerts aimed at email addresses or phone accounts, you could also use process data streams to form your own custom graphic representations of the latest state of your application. You could then serve the data for browsers, which you teams members can keep in an open browser tab or redirect it to displays mounted prominently around your office, perhaps powered by Raspberry Pi boards strapped in back. The ultimate goal is to keep as much useful information in front of as many of the right people as possible. It's review time. We touched on the critical need to have an appropriate incident response protocol in place and discussed how shaping such a protocol will depend entirely on local considerations. We then addressed building up inventories of your physical and virtual resources, so you can have a proper sense of what needs to be monitored. Applications or application layers running in a cloud or on a Platform as a Service environment don't require the same level of monitoring as locally hosted applications. Remember, you only need to monitor what you control. We saw how it was important to carefully calculate the costs of continuous monitoring and how those costs, within the context of your project budget, will partly determine the scope of your system. Finally, we learned about the power of carefully scripting the timing of your scans and then covered a few possible models for delivering monitoring results to the folks who will need to see them. Coming up next, what kind of software's available for continuous monitoring?
Continuous Monitoring Tools
Available Application Performance Management Tool Features

I'm afraid that there's no single software package that you can simply install, configure, run, and forget about as it provides you with all the wonders of continuous monitoring. There are, as we'll soon see, plenty of application performance management tools available that at least claim to be one-stop shops, covering all your APM needs, but that doesn't take you quite the whole continuous monitoring distance because CM wants you to look quite a way beyond just your application. In this module, we're going to start with a class of almost-full- service APM tools. We'll talk about the features that they mostly share in common, and then about the features that might not be universal that you may nevertheless really need. We'll talk about monitoring your larger infrastructure and how it fits in with continuous monitoring, and finally, just a word or two about dealing with event logs on a massive scale. That should keep us out of trouble for a bit. As far as software packages for application performance management are concerned, you're looking at a very crowded market. What all the leading candidates share is common, however, is the ability to look inside your infrastructure, aggregate data from your servers, databases, and services, trace transactions right down the stack, and track overall application behavior. They should also provide useful reports that illustrate larger patterns while allowing you to drill down deep to find out what's really going on at the molecular level. Okay, perhaps not molecular, but at least down to the line-by-line code level. What they also share is the need to climb a noticeable learning curve before you can get things working quite the way you want. Learning to configure a new APM interface requires a significant investment, so you'll want to have a pretty good idea of how a particular package might work out before you start. For some projects, your needs might be so unique that you're better off outsourcing the configuration work of tweaking an existing package to an experienced consultant, or even just having them build something new from the ground up. When you are ready to go shopping for the right tool, there's some capabilities and environmental features you'll want to know about. Is it an SaaS cloud-based tool, meaning that you and your team members access the interface through browsers after having installed some kind of software agent on your servers, or do you download and install the tool itself on your local servers? Can it handle lots of containers and virtualized networks? Does it speak your language? Remember, full application integration can only happen if the software can read and understand your code. If, for instance, you wrote your application in Malbolge, and I have no clue why you would, you'll want to confirm up front that it's supported, hint, my guess is that it's not. Can the tool integrate with both the locally hosted and cloud-based parts of your stack? If you're planning to gradually migrate parts of your application to or from the cloud, you'll want to be sure that selecting the wrong APM tool doesn't leave you permanently locked in. Finally, how much will it cost you? Is the option you're looking at a commercial product or open source? How much will you pay monthly for the specific level of service you need? One very nice feature included in some products is native integration with collaboration tools, like Slack. Being able to reach your team where they already spend their time can really go a long way to increase the visibility of events and problems when they're caught, and consequently, make the whole thing much more effective. But applications live on more than just performance. They also need warm and healthy infrastructure environments. We'll explore that in the next clip.
A Quick Look at Infrastructure Monitoring Tools

APM tools will watch your application's moving parts, and if they're configured properly, let you know when something strange happens, but you'll also want to keep a close eye on the overall compute and network neighborhood where your application lives. Mainstream APM software won't, for instance, tell you about network configuration vulnerabilities that only recently surfaced in the National Institute of Standards and Technology's National Vulnerability Database, but vulnerability assessment software will. Here's the deal. Before you can be sure that your small corner of the internet is truly safe, you'll need to scan all your servers, desktops, and network-attached appliances, including Internet of Things devices, for poor configurations, buggy software, or possible exploits. The problem is that there are so many known vulnerabilities, many tens of thousands at this point, that there's no practical way you could regularly search through all of your assets looking for them. What vulnerability scanners do is constantly update their databases and apply their knowledge against the resource profiles you defined. You can script automated scans every day or week, and any vulnerabilities discovered whose threat score is over a predefined threshold will trigger an alarm that you should receive. With a little luck, you'll notice it and do something to fix it. You should also engage in regular OSINT gathering. OSINT, of course, stands for open source intelligence, and OSINT tools are built to do two things, scour the public internet for exploitable data or authentication keys related to your application or business and search your researches for private information that's been inadvertently made public. Don't think those are such a big deal? Just try out a quick demo scan for yourself. You probably won't believe how much information there is out there already and how much that information reveals about the inner workings of your company. Both vulnerability assessment and OSINT gathering tools are hugely important parts of a complete continuous monitoring scheme. On first glance, they may not seem so closely related to applications, but it's not hard to see how little value great coding and software design will have if you can't keep your basic resources running securely.
A Quicker Look at Log Monitoring Tools

One more stop before we're done. As I said earlier, and as I'm sure you already know, log files can very quickly grow to insane sizes. When you take those insane sizes and multiply them by all the processes you've got running across your application infrastructure, and then multiply it again by the six months your app has been running so far, then you know dealing with the whole mess isn't going to be simple. Fortunately, many of the packages from the categories we've discussed in this module come with their own log management tools, along with customizable filters and alerting features. But if you end up working with one or two lower-level admin tools as part of your setup, or if you have no choice but to build your own solution from scratch, you'll need to find your own answers. The answers you'll find will, of course, depend on the operating system you're using to process the files. Windows Server or Windows 10, you can't go too far wrong with Event Viewer. Linux machines using systemd, journalctl is probably going to be your weapon of choice. In either case, you'll probably need to apply some pretty sophisticated text stream parsing tools, like on the Linux side, combinations of grep, oc, and sed. So just what did we cover in this module? Without going into any specific products, we listed some of the most important features to look for when choosing APM tools, like programming language support, integration with virtualized and cloud-based resources, and hosting platform local or Software as a Service. We looked at infrastructure monitoring tools like vulnerability assessment and OSINT gathering software frameworks, and finally then briefly touched on some event log file handling.
Course Review

Since that's just about it for this course, let's take a bit of a look back at what we saw, and then maybe a word or two about where your next steps might take you. We spoke about the many benefits of building a monitoring system that never stops. We saw how continuous monitoring can keep you up to date on all the moving parts, ensuring the quality of service your app's users enjoy. We learned about the four hoops through which you'll need to leap to apply some kind of continuous monitoring system of your own, and about the way DevOps works and how the DevOps feedback cycle is a natural fit for continuous monitoring. We then discussed how continuous monitoring systems can make your compliance with government and industry regulations and audits a whole lot faster and cheaper. In order to address the many risks that can affect your application health, you'll need to know what they are, so we talked about some of the stuff that you should definitely focus on. We spent some time in the world of application performance management, talking about both active monitoring, where you simulate user sessions with your app, and passive monitoring that intelligently process system and application data after events. We also talked about monitoring the resources in your larger infrastructure. We turned our attention to designing an effective continuous monitoring system, starting by carefully setting a project's scope, which includes creating, or at least discovering, an up-to-date resource inventory covering all the elements used by your application. Of course, besides getting that complete inventory, you'll also need to pick and choose which elements actually require monitoring at this level or for which of them you can afford it. To that end, you'll distinguish between local and cloud resources and what's critical and expendable. Besides scope, we talked about various design options affecting the timing and scheduling of monitoring activity and the ways you can report the products that you're monitoring. And of course, you'll certainly write a full incident response protocol to go with all that, right? We closed out the course in this module with a look at the kinds of tools that are available for continuous monitoring. We discussed APM tools and saw some of the features that are common to pretty much everything on the market, but touched on some specific considerations that could definitely impact your choice. Then we talked about infrastructure monitoring tools, like those used for vulnerability assessment and OSINT gathering. And finally, we brought down the curtain after a very brief word on managing logs manually, and that'll do it. This course was, as the title suggests, just an introduction. From here, you'll hopefully have a much better idea of what's available and what kind of combination of tools and systems will work best for your company and your application. There are already a lot of related courses on Pluralsight teaching a lot of the tools created to solve the problems we've seen here. And in the next short while, Pluralsight should be publishing still more. I really hope this has been useful for you, and I hope to see you again. Be in touch!
Course author
Author: David Clinton
David Clinton

David taught high school for twenty years, worked as a Linux system administrator for five years, and has been writing since he could hold a crayon between his fingers. His childhood bedroom wall...
Course info
Level
Beginner
Rating
3.4 stars with 30 raters(30)
My rating
null stars
Duration
0h 45m
Released
6 Jun 2017
Share course
