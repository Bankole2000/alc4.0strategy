Architecting Scalable Web Applications Using Google App Engine
by Janani Ravi

App Engine is the PaaS offering on the GCP and is ideal for developers seeking to build and deploy web applications while staying focused on writing code. In this course, you will learn about the App Engine's Standard and Flexible Environments.

App Engine is the platform-as-a-service (PaaS) compute offering on the Google Cloud Platform and is one of the oldest offerings on the platform. Initially conceived as a way for cloud users to quickly deploy web applications, it now also has ways to run containers and use flexible runtimes. In this course, Architecting Scalable Web Applications Using Google App Engine, you will learn about the powerful features of App Engine, its two environments, as well as its integrations with other GCP services. First, you will discover how you can identify situations where App Engine is the most suitable computer option and about its fundamental building blocks. Next, you will explore the Standard App Engine environment. Finally, you will understand the App Engine Flexible environment and build and deploy an application to this environment. When you are finished with this course, you will be very comfortable choosing App Engine for your use case and will have the skills and knowledge to build and deploy apps on different types of App Engine environments.

Course author
Author: Janani Ravi	
Janani Ravi
Janani has a Masters degree from Stanford and worked for 7+ years at Google. She was one of the original engineers on Google Docs and holds 4 patents for its real-time collaborative editing...

Course info
Level
Beginner
Rating
4.2 stars with 13 raters(13)
My rating
null stars

Duration
1h 53m
Released
11 Jan 2019
Share course

Course Overview
Course Overview
Hi, my name is Janani Ravi, and welcome to this course on Architecting Scalable Web Applications Using Google App Engine. A little about myself. I have a master's degree in electrical engineering from Stanford and have worked at companies such as Microsoft, Google, and Flipkart. At Google, I was one of the first engineers working on real-time collaborative editing in Google Docs, and I hold four patents for its underlying technologies. I currently work on my own startup, Loonycorn, a studio for high-quality video content. App Engine is the platform as a service compute offering on the Google Cloud platform and is one of the oldest offerings on the platform. Initially conceived as a way for cloud users to quickly deploy web applications, it now also has ways to run containers and use flexible runtimes. In this course, you will learn about the powerful features of App Engine, its two environments, as well as its integrations with other GCP services. First, you will learn how you can identify situations where App Engine is the most suitable compute option and about its fundamental building blocks. These include services, versions, instances, instance classes, and scaling. You'll understand auto-scaling in App Engine, as well as how to deploy and run an app locally, as well as on the cloud. Next, you will explore the App Engine standard environment. This is a highly-optimized, but also highly-constrained runtime environment provided by Google for extremely fast scaling. Standard environment applications need to be in specific versions of Python, Java, PHP, Go, and a few other languages. You will also implement automatic traffic splitting and migration, as well as Datastore and Memcache integration from your App Engine application. Finally, you will understand the App Engine flexible environment and build and deploy an application to this environment. As its name would suggest, the flexible environment allows far greater freedom to the developer in terms of choices of runtime, as well as interacting with system resources. Both standard, as well as flexible environment applications run in container-based environments; however, App Engine standard containers are Google proprietary, while App Engine flexible containers rely on Docker, which is fast becoming the standard containerization technology. When this course is complete, you will be very comfortable choosing App Engine for your use case and will have the skills and knowledge to build and deploy applications on both of App Engine's environments.

Introducing Google App Engine
Module Overview
Hi, and welcome to this course on Architecting Scalable Web Applications Using Google App Engine. App Engine is Google's platform as a service offering where you can build hosted applications with built-in load balancing and autoscaling. When you work with App Engine, all you have to do and worry about is writing code. The Google infrastructure takes care of everything else for you. An App Engine application is made up of one or more services. In this way, App Engine mimics a microservices architecture where different services perform different actions and processing. Version management in App Engine is on a per-service basis, so a single service can have multiple versions. App Engine lets you write hosted applications, which means these are run on instances that are provisioned behind the scenes. You don't directly interact with the instances on which your app is running. Every App Engine instance is associated with an instance class that determines the memory and the resources available to that instance. Once instances and instance classes are specified, App Engine takes care of all of the scaling details. If you want to host your applications on App Engine, there are two environments for you to choose from. This depends on the level of customization needed for your app. There is the standard environment and the flexible environment, and we'll study both of these in this module. Once we are familiar with the underlying concepts, we'll see how we can deploy and scale a simple App Engine app.

Prerequisites and Course Outline
Before we dive into the actual course contents, here are some prereqs that you need to have in order to make the most of your learning. This is an intermediate level course, which means if you haven't worked with cloud platforms before and aren't familiar with cloud computing basics, you'll find things a little hard to follow. You need to have a basic understanding of cloud computing, and because we are building web applications, you need to know how web applications work, you need to understand GET and POST HTTP requests. We'll be writing all of our web framework code in Python, and we'll be using Jinja templates to serve HTML files. We'll also integrate our web applications with the cloud data store NoSQL database available on the GCP. So if you have some familiarity working with NoSQL databases, that'll definitely be helpful. If you feel that you lack the required prereqs for this course, here are some other courses that you can watch on Pluralsight first before you get to this one. Choosing and implementing Google Cloud Compute Engine solutions will introduce you to cloud computing on the GCP. If you want to understand how NoSQL databases work, specifically, Cloud Datastore, Architecting Schemaless Scalable NoSQL Databases Using Google Datastore, is a course that you might want to watch first. We'll start this course off with an introduction to App Engine, Google's platform for hosted applications; we'll see how App Engine stacks up against other compute options; we'll study the standard and flexible environments on App Engine; and we'll see how services, versions, instances, and scaling work. This course is very hands on. We'll then move on to building and deploying applications using the App Engine standard environment. We'll deploy multiple versions of the same app and configure traffic splitting across these versions, we'll integrate our app with Cloud Datastore, and we'll also work with Memcache for low-latency responses. In the final module of this course, we'll work with the App Engine flexible environment, which uses custom containers to deploy applications. You'll see integrations with other GCP services such as pub/sub as well. All of the demos in this course assume that we are engineers working with this hypothetical online relator called spikeysales.com. Spikey Sales specializes in flash sales of trending products, which means they are subject to huge variations in user traffic. On sale days, traffic spikes up. Engineers at Spikey Sales are contemplating a move away from their on-premises data center to a cloud platform, specifically, the GCP. Cloud computing fits their bill perfectly. They want pay-as-you go functionality and do not want to provision resources that will stay idle during off-sale periods. Their developers are specifically interested in App Engine to quickly launch features that are scalable automatically. They don't want to have to deal with traffic splitting, migration, and other infra details.

Compute Choices
In this clip, we'll understand what exactly Google App Engine is and where it fits in Google's suite of services. As a software developer, when you're building a product or an application, there are two choices that you need to make. The first is compute. Where and how will your code run? Where will it be hosted? And the second is storage. Where and how is the data that your code uses stored? While Zooming in on these two choices, we, of course, are ignoring many other details. There are other choices as well such as networking, logging. These choices exist and are important, but they come after you've made your choice of compute and storage. There are a range of compute choices available to developers today. If you consider these choices on a spectrum, there is bare metal on the very left side of the spectrum and serverless functions on the extreme right. Other choices such as provisioning VMs, container clusters, or hosted applications lie in the middle of the spectrum. When you move from the left to the right of the spectrum, your compute choices involve less operating overhead. There is less administration that you have to do. You don't have to worry about provisioning machines at all. As you move from the right to the left of the spectrum, you gain an additional level of control over how your applications are deployed and how they run. You get more control and lower level access to the OS. Based on your constraints and the kind of application that you want to build, any of these choices might make sense for you, which is why on the GCP, there are services available across the spectrum. Well, you can't really work with bare metal environments on the cloud, but Google Compute Engine allows you to provision VM instances. The Google Kubernetes Engine allows you to work with container clusters, Google App Engine is for hosted applications, and Google Cloud Functions is for serverless compute. These choices are available not just with the GCP though. Every major cloud provider will support the same range of compute choices. Here are the equivalents on Amazon's AWS. Here at the very left of the spectrum is Google and Amazon's infrastructure as a service offering, which allow you to provision VM instances, which can host your applications. Infra as a service offerings are an easy way to get set up with cloud computing. You can lift and shift your on-premise offerings to virtual machines on the cloud. Now if you're working in a hybrid multi-cloud environment, you might want to work with container clusters. You can use Google Kubernetes Engine on the GCP and AWS EKS if you're working on Amazon. Container clusters allow you to run your apps in containers managed by Kubernetes. At the extreme right of the spectrum here is where you have event-driven serverless compute. You simply write code, which is hosted somewhere on the cloud. On the GCP, you would write code using Google Cloud Functions. On AWS, you would use AWS lambdas. These functions can be triggered by HTTP requests or other services on the GCP or AWS. And somewhere here towards the right of the spectrum, lies the platform as a service offering from cloud computing providers, Google's App Engine, which is very similar to AWS Elastic Beanstalk.

Introducing App Engine
Google's App Engine is a complete web framework and platform, which you can use for hosting web applications on the GCP. When you use App Engine, developers can focus on what they do best, writing code. All of the infra scaling load balancing is taken care of by the platform. When you are building your application using App Engine, you have to choose from one of two environments to host your application. We have the App Engine standard environment, which makes it very easy to build and deploy an application that runs reliably even under heavy load and can easily support huge spikes in traffic. When you work in the App Engine standard environment, you can only choose from a few predefined runtimes that it supports. If you want more flexibility in how you configure your applications, say you want to use custom runtimes or third-party libraries, you'll choose to go with the App Engine flexible environment. The App Engine flexible environment runs your applications in Docker containers that you configure. Once you understand the differences between these two environments in more detail, you'll be able to make the right choice for your use case. When you use the App Engine standard environment, your application runs in a proprietary sandbox. When you use the flexible environment, your app runs in a Docker container on a GCE virtual machine. If you want your choice of languages or runtimes, you'll find that the standard environment is more constrained. Because your app runs in a proprietary sandbox, you can write code only in a few supported languages and specific versions of those languages. When you use the flexible environment, there are many more languages available for you to choose from and many more customizations that you can do. When you use the standard environment, Google is basically saying there are no other runtimes possible. These are what we support, but in exchange, I'll give you scaling and a bunch of infrastructure management for free. With the flexible environment, Google says that custom runtimes are possible. You can bring whatever third-party libraries that you need because they'll run your app in a Docker container; however, we won't be offering as much support as with the standard environment. On the standard environment, you cannot access the operating system or other machine-specific resources. You have no access to the underlying VM networking and other capability. When you run in the flexible environment, apps can access certain Compute Engine resources and some operating system packages. When you deploy your apps to the standard environment, your apps will tend to be very lightweight, which means new instances can be spun up in a matter of seconds. In the flexible environment, resource provisioning is more heavyweight, instance startup takes longer. It's a matter of minutes. When your apps run in the standard environment, scaling can be of three types: manual, basic, or automatic. And we'll study the differences between these in just a bit. In the flexible environment, you only have the choice between manual or automatic scaling. The standard environment does not support background processes, while the flexible environment does. There is no SSH debugging in the standard environment whereas SSH debugging is supported in the flexible environment. With the standard environment, you can save on costs by scaling your application down to 0 when it receives no traffic. With the flexible environment, you have to have a minimum of one instance running. You can't scale to 0. The proprietary sandbox of the standard environment does not allow you to install third-party binaries, which means you can only use the SDK that the standard environment supports. With the flexible environment, you can install third-party binaries that you need. You know your specific use case. Based on all of these differences, you can choose between these two environments. Here are some principles that you can follow. When you have an app that experiences great spikes in traffic, you might want to go with the standard environment where scaling is very, very fast. The flexible environment is suitable for applications that experience consistent traffic or consistent growth in traffic. Developers typically use the standard environment when they want to deploy stateless HTTP web applications. The flexible environment is typically for general purpose apps or services. At the time of this recording, here are the runtimes that the standard environment supports: Python, Java, Node, PHP, and Go, and specific versions of these. And here are the runtimes supported by the App Engine flexible environment. You can see that there are many more runtimes listed here. You can also configure your own custom runtime. The rule of thumb is that you would choose the App Engine flexible environment for applications that require custom runtimes or third-party libraries not supported in the standard environment. The flexible environment is intended to be complementary to the standard environment. If you have specific services within your application that require more CPU, more RAM, or a specialized third-party library, that's when you can host those services on the flexible environment and integrate them with your app running on the standard environment.

Services, Versions, and Instances
An App Engine app is not a single monolithic application. In fact, it has been designed to follow the microservices architecture. What we refer to as an app on App Engine is a single regional application resource, which is comprised of a hierarchy of services. Services are made up of versions, and they run on instances. Its regional because your apps are hosted in a single geographic region of your choice. Here is a big-picture overview of the components that make up an App Engine application. There's a lot going on here. Let's take a look from the top to the bottom of this hierarchy. At the very top of this hierarchy is the application itself. This is a top-level container for multiple services. Services have versions, which run on instances. A service on App Engine behaves like a microservices and scales independently of other services in your application. When you release new features, you'll roll out your versions to a specific service. Each service has its own versions. A service is a logical grouping of processing and features that you provide within your application. Each service can be thought of as a logical component, which can share features and communicate with one another. Every App Engine application has to have at least one service, and that is the default service. When you deploy to an App Engine app without specifying a name for the service, your deployment is to the default service. Versioning in App Engine is handled at the level of a service. There are multiple versions of every service that can be deployed. You can have multiple live versions as well. Traffic is automatically sent to the latest version unless you explicitly want to split traffic across multiple live versions. Version management on App Engine is very painless because the platform takes care of a bunch of details for you. Each time you deploy to a service, a new version is automatically created. Versions of your service run on one or more instances. You can configure you App Engine application to automatically scale the number of instances running your service based on load. This is the big picture of how an App Engine application is set up.

Instances, Instance Classes, and Scaling
In this clip, we'll study how instance management and scaling works when you use App Engine. We've already seen that there are two different environments to which you can deploy your applications, the standard environment and the flexible environment, and there are a number of differences between these. Let's focus on the differences that relate to the instances on which our applications run. The standard environment instance startup is in seconds. In the flexible environment, it takes minutes. The standard environment allows manual, basic, or automatic scaling whereas the flexible environment allows just automatic or manual scaling. Now typically on cloud platforms, when we use the term instance, we refer to virtual machines. When we are talking about App Engine though, instance are not virtual machines. Instead, they can be thought of computing units on which the application is hosted. This instance includes the language runtime, the App Engine APIs, the application code, and the memory. Instances are an abstraction over and above the resources available on your VM. App Engine supports three kinds of scaling for your applications, manual, automatic, and basic. And each of these kinds of scaling run on different kinds of instances. Manual scaling requires resident instances. Automatic and basic scaling work with dynamic instances. All of these terms are completely new and specific to App Engine. We'll study each of these terms in detail, but it's important that you get a big-picture understanding first. So what are the terms that we just introduced? We introduced two types of instances, resident incidences, which are always up and running, and dynamic instances that can be provisioned on demand. We also discussed the three ways to scale an App Engine application, manual, automatic, and basic. Now let's study all of these in detail. We'll go back to instances, and let's understand what resident instances are and how they work. Resident instances run all the time. They're always ready to serve traffic. Your app is always up and running on resident instances. The advantage of using resident instances that there is no latency while services responses from your app. Having resident instances around to serve your application can improve the performance of your app, but of course, at a higher cost because you always have an instance provisioned and running your application. And as the name implies, dynamic instances starts up and shuts down automatically based automatically based on your application's needs. It can be dynamically provisioned to serve traffic if there is a spike in user traffic to your app. Now that we've understood how the two kinds of instances work, we can go back to the three ways to scale an App Engine application, manual, automatic, and basic. When you go with manual scaling, it uses only resident instances to serve traffic. It's useful for applications that rely on the state of memory over time. If you have an application to which traffic is steady and consistent, there are no spikes, and it also has to be running all the time, you'll choose manual scaling running on resident instances. Automatic scaling uses a combination of resident instances and dynamic instances. The dynamic instances are used to scale up and down based on the traffic or the load that the application receives. If you want to ensure that there are always instances serving your application, you can have a minimum number of resident instances specified when you use automatic scaling. And finally, basic scaling is what you'd use for applications which need to be available only intermittently. Basic scaling uses only dynamic instances. They are turned down when the app is idle. Every instance on which an App Engine application runs belongs to an instance class. The instance class is what determines the compute resources available to the instance and how much you pay for hosting your application. App Engine offers a range of instance classes that you can choose from. These vary in the amount of memory and the CPU limits for the instance, and they also support different kinds of scaling. There's a lot of information available here on this page. When you need to deploy an application, you might want to look up what instance class is the best for your use case. Observe here on this page that instance classes start with the letter F or the letter B. Instance classes that start with the letter F support automatic scaling. Instance classes that start with the letter B support just manual and basic scaling.

Implementing and Configuring an App Engine Application
Now that we have a basic idea of how App Engine works, we are ready to get hands on. Let's go ahead and log into the Google Cloud platform and get started with our first App Engine application. Since this is our first application, we'll build and deploy this to the App Engine standard environment. We'll be doing all of our demos in the spikey-app-engine project. A project on the GCP is a logical grouping of resources. Any resources that your provision whether they are VMs, cloud storage, buckets, or App Engine applications, all of these belong to a specific project. Here we are in spikey-app-engine. Whatever project you're starting off with, make sure that you have billing enabled for that project because you'll need that to provision resources, deploy your applications, and so on. The Navigation menu on the GCP is available via this hamburger icon on the top left. Click on the navigation menu to get access to all of GCP's products and services. In order to get started with App Engine, we'll choose the App Engine option under COMPUTE and select Dashboard. If you've never worked with App Engine on this project before, this is what the startup page looks like. The first thing you need to do is to make a choice. You need to select a language in which you want to build your application. All of the demos in this course will be written using Python. Click on the Select a language button, and you'll see a number of different options. You can build App Engine apps in Node.js, Java, PHP, Go, Ruby, and .NET. We'll go with Python. For every GCP project, you need to make a choice as to which region you want your App Engine resources to be provisioned. We'll go with the us-central region. Your choice of region depends on where the users of your app will be located. If they're going to be located in Asia, select a region in Asia. If they are going to be in Europe, select a region in Europe. Locate your applications close to where users are so that they experience lower latency when using it. When you click on the Next button here, the GCP very helpfully points you to a tutorial that you can use to understand App Engine. Let's cancel out of this tutorial first. That's what we're here to learn, how to set up our first App Engine app. In order to build and deploy our first App Engine application, we'll need access to a terminal window. And for this, the easiest way to get access to one is to use Cloud Shell. Cloud Shell is an ephemeral VM on the Google Cloud which comes with all of Google Cloud's command-line utilities preinstalled. Within Cloud Shell, you also have access to a browser-based code editor where you can quickly edit your code and configuration files. Code Editor, which is currently in beta, is what we'll be using. Here is the Explorer window on Code Editor. This gives me access to all of the files that I have in the home directory of my Cloud Shell virtual machine. Click on the File menu here, and let's create a new folder under which we'll write code for all of our App Engine applications. I'm going to call this folder spikey_gae_codes. Within this top-level folder, I'm going to create a new subfolder called spikey-greetings. Spikey-greetings is going to be the folder which contains our first App Engine applications. Create a new file within this folder called main.py. This will contain the Python code that we'll write using Flask. If you haven't worked with Flask before, Flask is an extremely lightweight micro web framework written in Python. Flask is extremely useful to quickly spin up web applications, and that's what we'll use here. Flask uses Python decorators to determine which function should be invoked for a particular URL path. The app.route decorator in Flask matches URLs to functions. Here, invoking the forward-slash or the base URL on our app will call the greetings function. The app.route decorator will invoke the greetings function that simply says Welcome to Spikey Sales. This is our very simple App Engine app. If you run this web application locally instead of on App Engine, it will be available on port 8080. And this is all there is to our first web app. Let's set up some of the other files that we need before we deploy this to App Engine, starting with requirements.txt. This is the file that we'll use to specify all of the dependencies of our Python app. App Engine will then use pip to install all of these dependencies when the application is built and hosted. Our only dependency here is the Flask web framework version 1.0 .2. You'll need to create and configure one last file before we are ready to build and deploy this application. This is the app.yaml file. This is the file which contains all of the specifications for our App Engine app. These are the configuration settings of our app, request handlers, environment variables, runtime versions, and so on. You can visit the URL that you see here on screen in order to get the complete reference for what you can configure within this file. We are going to run our first App Engine application in the standard environment using the Python 3.7 runtime. Second-generation runtimes are less restrictive. They don't have to choose only from a whitelisted set of libraries. You can run any framework library or binary if you're using a second-generation runtime. The instance_class for an app engine determines its compute resources and the price that you pay. The F2 instance class has 256 MB of RAM, a CPU limit of 1.2 GHz, and it supports automatic scaling. And automatic_scaling is what we configure next for our application. Automatic scaling, as you know, uses dynamic instance in order to scale up your application based on response latencies, the number of requests your app receives, and so on. In this particular case, we'll choose to scale up our application based on our target_cpu_utilization. We want every instance to be utilized at about 65%. The minimum number of instances that will run our application is five, which means we'll have five resident instances and all of the remaining instances will be dynamic. And this app can scale up to use at a maximum 100 instances. When your application receives a new request, App Engine might choose to create a new instance to service this request or add the request to a queue. The min and max pending latency allows us to specify the minimum and maximum amount of time a request should wait in the pending queue before additional instances are spun up to handle it. And for this particular application, we want to be able to handle a total of 50 concurrent requests.

Running Locally and Deploying to App Engine
Now that we have the code and configuration for our application setup, let's switch over to our Cloud Shell terminal window in order to deploy this app. I'm going to run this export command to change my Command Prompt so that I have more room for longer commands to be visible on screen. This is totally optional. This is what my Command Prompt looks like The first thing I'm going to do is to acquire new user credentials in order to run the gcloud command-line utility. Running the gcloud auth application-default login command will get me new credentials that I can use to authenticate myself to the GCP. Run this command, confirm that, yes, you do want to acquire new credentials, and this will give you a URL that you need to click in order to get an access token. Log in as your current user account, click on the Allow button here to give gcloud access to your data on the GCP, and go through and you'll be presented with a token. Copy over this token and paste it into your Cloud Shell terminal window. Hit Enter, and you're all set up. You can now move ahead with deploying your first App Engine app. Our code is not present in our home directory. It's present in the spikey-greetings folder. Cd into the folder, run an ls command, and you'll see the three files that you had set up earlier, app.yaml, main.py, and requirements.txt. Now before I deploy this app, I want to make sure it runs, and I want to do it in a local environment. We'll do exactly that in our Cloud Shell terminal. Run a pip install on all of the libraries present in requirements.txt. That's just the Flask library in the case of this particular app. Once Flask has been installed, let's go ahead and run the local deployment server. When you have Google's Cloud SDK installed, you have access to this dev_appserver.py, which is also available on Cloud Shell, which you can use to run the local development server to simulate our application running on production. This brings up our application on our local machine. You can view this by clicking on the Preview button on the top right of your Cloud Shell terminal VM, hit Preview on port 8080, and there is our simple web app, Welcome to Spikey Sales. Now that we know that our app works just fine on our local machine, we are ready to deploy it to App Engine. Run the gcloud app deploy command to do so. The version of this app is simply called spikey-greetings. When you hit Enter, this app will be deployed as the default service to the App Engine standard environment. We know it's the default service because we specify no additional configuration in the app.yaml file to indicate a service name other than the default. The default App Engine app is always located at project_id.appspot .com, which in our case, is spikey- apps.appspot .com. The name of our project is Spikey App Engine, the project ID is spikey-apps. Confirm yes that you do want your app to be deployed and wait for a minute or so until the deployment runs through. In the meanwhile, I'm going to switch over and show you some stuff. When you use App Engine, it sets up a bunch of Cloud Storage buckets that it uses as its staging environment. Go to Storage and Browser, and here are the buckets that have been created by App Engine. If you click through to the staging bucket here, you'll find that it holds a number of different binaries that pertain to your App Engine app. Your app running within the App Engine standard environment is hosted on container instances running on the GCP. App Engine automatically creates an artifacts bucket in order to hold the containers and images corresponding to your apps. Click through, you'll find a containers folder, within that, images, which contain the images pertaining to your app. Let's switch back to the Cloud Shell terminal window here, and our very first App Engine app has been successfully deployed. A number of files were uploaded to Cloud Storage, and our service was deployed. You can use the gcloud app describe command in order to view metadata information about this default App Engine app. You can see information about the buckets that this app uses, the defaultHostname, which is spikey- apps.appspot .com. That's where this app is hosted. The container corresponding to this app is registered with the Google Container Registry, GCR, in the US. You can see that the GCR domain is us.gcr .io. The service status for this app is SERVING, so let's go ahead and hit it. Gcloud app browse will open up a browser window for your application. But if no browser window is available, it'll simply show you the URL where you can hit your app. Hit this URL, and there is our Spikey Sales site. We've successfully built and deployed our very first App Engine app.

Viewing Application Details, Logs, Errors, and Debug Information
With our app successfully deployed, let's take a look at a few details on the App Engine page. Go to App Engine, Dashboard, and you can view some statistics about your app. We just have the one version deployed at this point in time receiving 100% of our traffic. Our app really hasn't received much traffic so far. The graph isn't updated. If you scroll down, you can view an Instance summary of the instances that are serving your application. Your app is currently being served by two instances. If you scroll down further, you can view the Billing status corresponding to this app. Your App Engine app is automatically linked with Stackdriver Error Reporting. The Stackdriver suite of tools offers monitoring, error reporting, and debug tools for all of your resources on the GCP. If there are errors in your app while running in production, you can visit Error Reporting and see what they are and manage and monitor them. There have been no errors in the last day, so we can rest easy. Using the left navigation pane, let's head over to the Services page. You can see that this is the default service that we deployed, and there is exactly one version of our application currently running. That's the only version that we've deployed. Click through to the default service, and you can view additional details. You can see the single version that we've deployed here, which is receiving 100% of the traffic. In order to view all of the details pertaining to my app on one page, I'm going to select the columns at the top right here and Select all so that all of the information is available to me on one screen. You can see that this app has autoscaling enabled, min number of instances is 5, max instances 100, and so on. If you remember, just about half a minute ago, I said that there are just 2 instances running our App Engine app, but the minimum number of instances we had set to 5. That's because other instances are still being provisioned. If you hit REFRESH, you'll find that the instances have been upped a little bit. The number of instances here is a link, and if you click on the number of instances, you'll get additional information. Here is a summary of the number of requests made to your app, and if you scroll down, you can see the individual instances. A couple of minutes have elapsed here. Let's hit REFRESH on the main page, and you'll find that our instances have finally reached the minimum number. And here are the five resident instances serving your app. If you scroll over to the very right of this page, you'll see a column called Tools, which is a drop-down showing you the various tools you have available to debug your applications. The first and most important are Logs. Clicking on Logs will take you through to Stackdriver Logging where the logs associated with your app are written out. Stackdriver Logging offers a rich set of features for you to work with your logs in order to analyze and explore them. Let's head back to our diagnosing tools here and explore another tool. This time, we'll see the Debug related tools. Stackdriver debugging is basically a way for you to debug your app while it's running in production. Stackdriver Debug is fully integrated with App Engine, and you can see that your code files are already available here. You can also add source code to Stackdriver Debug from your local machine, or from a GitHub repo, or from a Cloud Source Repository. All of these options are available to you, but the best thing about using App Engine is that it's fully integrated with Debug. If you select one of your files, such as main.py here, you can see the code right here on screen. You can use this window to instrument your code to take snapshots of your application while it's running in production, and this instrumentation adds very little latency to your App Engine apps. Once you have a snapshot for your application, you can use it to view the request that came in, the current state of your variables, and a whole bunch of other cool stuff. If you're interested in how Stackdriver Logging and Error Reporting can be used with your App Engine applications, there is an entire course on Pluralsight dedicated to exactly this. It's called Managing Logs, Errors, and Application Performance Using Google Stackdriver.

Autoscaling
When we configured the app.yaml file for our very first App Engine application, we had set up autoscaling with a minimum of five instances and a maximum of 100. Let's now put this to test. On my Cloud Shell terminal VM, I'm going to install this library called siege that will allow me to bombard my App Engine app with multiple concurrent requests. Wait for this application to be downloaded and installed, and let's put our application under siege. I'm going to run 250 concurrent requests to hit spikey- apps.appspot .com. Our server is now under siege. Let's go ahead and see what happens. Let's head over to our App Engine page here, the spikey-greetings app is what we are running a siege on, and hit REFRESH. There are still just five instances running our App. Now you'll find that App Engine scales up very, very quickly, especially the standard environment applications. These instances tend to be lightweight to spin up, and you'll find that in just a few seconds, App Engine scales up to 21 instances in my case. We sent a sudden burst of requests to our application, and a large number of instances were created very, very fast. And really, this is one of the cool things about working with App Engine. You didn't do anything in order to have your application scale. You only specified the configuration parameters, and here are my 21 instances running my app. If you scroll to the top of this page and view your request count graph, you'll see a huge spike in the number of requests thanks to our siege. I'm going to use the drop-down to switch over and view latency information for my application, and you'll find that the latencies have clearly gone up because we have so many requests coming in. You can click on the graph here, and you can see that the average latency at the 99th Percentile is 86 ms; at the 95th Percentile is 33.45 ms; and at the 50th Percentile, it's about 8 ms. You can also hover over the graph to view all of this information in one go. I'll use the drop-down in the top left to switch this graph to Loading latencies, and you can see that they have spiked up as well. The interesting and cool thing here is that because our app has scaled up so quickly, if you take a look at Error details, there are almost no errors in serving our applications, no quota denials, and no denial-of-service API denials as well. If you switch to the Traffic details on this monitoring graph, you can see that traffic has really spiked. Our server is under siege after all. You've received 115 KB, but sent back only 68 KB. The servers are clearly taking longer to respond as the siege continues. If you switch over to view all of the utilization of our instances, you can see that has spiked as well. And if you take a look at Memory Usage, that has gone up as too, all to be expected. Let's switch back to our Cloud Shell terminal window and hit Ctrl+C to lift your server's siege. Let's take the stress off our application. And when you hit REFRESH, on the Instances page of your App Engine, you'll find that your instances scale down very quickly, going down to the minimum five.

Pricing
Before we end this introductory module on App Engine, let's take a look at how App Engine is priced. For the standard environment, the price that you pay to deploy your application is based on the instance class that you choose. The cost is per instance, per hour. On the flexible environment, you need to pay separately for the vCPU, memory, and the persistent disk that you use. This is just for the basic application that you host. If you use other GCP resources, you'll have to pay for them separately. There are additional charges for Cloud Datastore, Memcache, and ingress network traffic. If you provision other GCP resources, such as say Cloud SQL instances, you'll have to pay for those as well. Now pricing is something that changes over time. Here is a link to the complete pricing documentation for App Engine. You might want to reference this before you get started. And on this note, we come to the very end of this introductory module on App Engine. We saw how we could build hosted applications with built-in load balancing and autoscaling when you use App Engine. App Engine applications are built using the microservices architecture. You deploy versions to specific services. These versions run on instances which are associated with instance classes that determine the resources available to your instance. There are two kinds of instances on which your services are deployed. You can resident instances, which are always up and running, or dynamic instances, which are provisioned on demand. Based on the kind of traffic that your application receives, you can choose from amongst three types of scaling. You can have manual scaling, automatic scaling, or basic scaling. App Engine offers two environments in which you can build an deploy your apps, the standard and the flexible environment. And based on the kind of application that you want to build, you'll choose between these. The standard environment offers a proprietary sandbox and supports only a few runtimes. The flexible environment runs your application in a Docker container that is fully customizable. After we understood the concepts, we got hands on. We saw how we could deploy and scale a simple App Engine app. In the next module, we'll continue working with the App Engine standard environment. We'll see how we can deploy new versions of our application, see how traffic is migrated to the latest version. We'll work with traffic splitting. We'll also integrate our App Engine apps with Memcache and Datastore.

Deploying Applications on the App Engine Standard Environment
Module Overview
Hi, and welcome to this module on deploying applications to the App Engine standard environment. In the first application where we got warmed up with App Engine, we worked with the standard environment, and we'll continue to do so during the course of this module as well. We saw that the standard environment is a restrictive lightweight sandbox that hosts your applications. The standard environment supports on a few runtimes and specific versions of those runtimes. When you use the standard environment, there are also restrictions on the third-party libraries that you can integrate with in your apps; however, the standard environment offers very fast scaling. So if you have an application that serves spikey traffic, the standard environment is what you'd want to choose. In this module, we'll be more hands on, and we'll build more fully fledged applications using the standard environment. We'll use the APIs that are part of the App Engine SDK to integrate with Cloud Datastore for storage. This is a fully-managed, schemaless, No SQL database on the GCP. We'll also see how we can integrate with Memcache for in-memory distributed caching. Memcache can be used to greatly reduce the response times of common queries. The App Engine standard environment makes available an intuitive, easy API for you to integrate with Memcache.

The Standard Environment and First and Second Generation Runtimes
So far, we've got a big-picture understanding of the differences between the standard and the flexible environment on App Engine. Let's study the standard environment in a little more detail. The runtimes that are available as a part of the standard environment can be divided into first-generation and second-generation runtimes. The first-generation runtimes are far more restrictive. You can only use certain whitelisted extensions and libraries when you use first-generation runtimes. With second-generation, you can use any extension or library that the standard environment supports. With first-generation runtimes, you can get access to external services only via the URL Fetch API. That's a special API. With second-generation runtimes, you have full access to the external network. First generation gives you no file system access whereas the second-generation runtime gives you read and write access to the /tmp directory. First-generation runtimes are special runtimes built and tailored explicitly for App Engine. When you use second-generation runtimes, you're actually using the runtime as they exist in the external world whether it's Python, Node, PHP, Go, etc. The mechanism used to sandbox applications for first-generation runtimes are proprietary to Google. For second-generation runtimes, Google uses a more general purpose gVisor-based container sandbox. The App Engine standard environment first generation supports fewer runtimes, Python 2.7, PHP 5.5, and Go 1.9. Second-generation runtimes offer you more of a choice of language, as well as versions within the language. For both first, as well as second-generation runtimes on the standard environment, your application runs on in the lightweight instance inside a sandbox, which is a very restrictive environment. You can't access operating system resources, the file structure, or the network. When you build an App Engine application in the standard environment, in order to access other GCP services, you'll use the built-in App Engine APIs, not the general purpose client libraries that are available. This is true no matter whether you access Datastore, Memcache, or Task queues. You'll have to use the built-in App Engine APIs because that exactly is what is supported. When you use the standard environment for local development, you'll run your application using the App Engine SDK. The code need not be portable to other platforms. The standard environment is great when you know that App Engine is the right choice for you and you don't necessarily want your code to be portable. You are willing to trade off portability for the convenience of using App Engine. The biggest advantage of using the standard environment is support for scaling. You can scale from 0 to thousands of instances very, very quickly. Scaling has been explicitly designed by Google to make it fast and lightweight. Google provides extensive support for the infra underneath. When you use the standard environment, you don't need to explicitly configure health checks for your instances. The instances are automatically monitored by the platform. The App Engine standard environment is kind of like frozen food, ready to each, or rather, ready to code.

Traffic Splitting and Migration
One important infrastructure detail that App Engine takes care of for you automatically is traffic splitting and migration. When you deploy a new version to a particular service, this automatically causes immediate migration of all of the traffic to the new version. There is nothing that you need to do, no configuration that you need to specify. Traffic will automatically be moved over. However, if your app continues to receive and process requests while you're deploying a new version, this may cause a spike in the latency of responses to those requests. You might want to then migrate traffic gradually. This is possible by adding warmup requests to your application, which you can specify in the app.yaml file. New instance which are serving the new version will receive warmup requests before actual traffic. If you have a new version of your service, but you want to test it out on a subset of users before you deploy to all of production, you can specify a percentage distribution of traffic. You can split traffic to allow you to conduct A/B testing. You can see whether your users like the new version before you roll it out entirely. Traffic splitting is only applied to those URLs that do not explicitly target a version. So if the URL request is to a particular version of a service, traffic splitting is not applied there. There are two methods that you can use to specify how traffic should be split for your app. You can specify is traffic splitting based on the source IP address or based on cookies. If you choose to split traffic based on the source IP address, App Engine will hash the IP address to a value between 0 and 999 and use the number to route the request to the right version. If you choose to do cookie-based splitting, App Engine will check the value of the cookie that you have in your request. If the cookie exists, the value will be used to route traffic. If there is no available cookie with the request, traffic will be routed randomly to any live version.

Deploying a Named Service to App Engine
In this demo, we'll deploy multiple versions of an App Engine service and see how traffic is automatically migrated to the latest version. We'll also see how we can split App Engine traffic across two or more versions. In this demo, and in fact, across this entire module, we'll continue working with the App Engine standard environment. We'll start off in the main spikey_gae_codes folder and create a new subfolder within it, which'll hold our new application. We'll call the subfolder the spikey-prod-website. Within the spikey-prod-website folder, we'll create a new folder called www, which will hold our HTML files. It'll have just one file to begin with, the index.html file, which forms the main HTML file for our web app. The contents of the intext.html can be anything. It has the title Puppies, and it has a bunch of other HTML elements to make it look pretty. Under the WWW folder which holds the index.html file, create a new subfolder called css, which will hold our style sheets. I'll just have a single file with a style sheet. I'm going to call it style.css. I'm going to paste in a few styles here so that our web page is not boring. The images of dogs that I have should look pretty after all. Let's go back to the top-level folder, the spikey-prod-website, and within that, we'll create a new file, the app.yaml file, which will contain the configuration settings of our App Engine application. We'll explicitly specify a service for this App Engine application. This will contain the service called spike-app-service. The previous time we set up an App Engine app that ran only the default service, and this setting is optional when you deploy the default service. If you want to have a specific name for your service though, you'll need to explicitly specify this in the app.yaml file. This app will run on instances of instance_class B8, which has 1024 MB of memory. The CPU limit is 4.8 GHz. The resource limits for each instance here are a little higher than in our previous application; however, the B8 instance class only supports manual and basic scaling and not automated scaling. We'll configure basic scaling for this particular application. Remember that basic scaling only uses dynamic instance, and instances will be created only when the application receives a request. We'll have the max number of instances be 10 and the idle_timeout is 10 minutes. Our dynamic instance will be shut down if 10 minutes have passed after it receives its last request. This time, we'll also set up some path handlers in our app.yaml file. When the user hits the forward-slash, the base URL for our app, the index.html file will be served from the www folder. The other parameters indicate that this is a static file that has been uploaded with our application. For other URL parts, we'll map to the corresponding parts under the www folder. We won't configure any other parts in our application so you can safely ignore this for now. Let's switch to our Cloud Shell terminal window in order to deploy this application. Cd into the spikey-prod-website folder and run gcloud app deploy. The version name that we want to give our spikey-apps service is the spikey-prod-website-v1. You can see from the messages here that when you deploy a particular service within your App Engine application, the URL at which the service is available is a little different. We can now access this particular name service within our application at service_name-dot, project ID, .appspot .com. Confirm yes that you do want this app to be deployed and wait for a couple of seconds, and you'll find that your app is soon deployed to the standard environment. Let's take a look at the metadata for the service that we just deployed using gcloud app services describe. You can see that we have exactly one version of the spikey-app-service. Let's switch over to GCP's web console and head over to App Engine and Services and take a look at the service that we just deployed. You can see on top there the spikey-app-service, and we have exactly one version here. The default service that we deployed earlier is still running for our App Engine app. You can click through and see that the simple web app we deployed on the default service is still available. But what's more interesting here is the service that we just deployed, the spikey-app-service. Click through, and her is our Spikey Sales website filled with puppies. It's a completely static application, a little more elaborate with HTML and CSS. If you go back to the main Services page, you'll see that exactly one version of the service has been deployed. And if you click through, you'll see the status of this current service. This particular service has basic scaling as we had configured in our app.yaml file, and it serves a 100% of the traffic. Clicking on the version we want right here will bring us back to our Puppies page.

Automatic Migration and Splitting Traffic
We are now ready to deploy a second version for this service. Head back to the code editor window, and let's edit the index.html file. This is the same HTML page which displayed the puppy images. I'm going to make a simple change here and add a button to the very top of this page that will allow us to expand and collapse the sidebar. Once I've made this little tweak to my website, I'm going to deploy a new version using gcloud app deploy, and I've changed the name of the version. It's now spikey-prod-website-v2. When you deploy a new version of a service, traffic is immediately migrated to the new version. So if you have existing load on your servers, might experience a spike in latency. By default, traffic is migrated immediately to the new version unless you have configured your app.yaml file to enable warmup requests. We have not enabled any additional configuration for warmup requests. When you confirm and deploy the new version of the service, traffic will be migrated to the new version immediately. Once the deployment is complete, let's head over to the App Engine Versions page. I'm going to deselect all of the columns that I had enabled earlier. This will avoid the unnecessary scroll on this page and make viewing this demo a little easier. The new v2 version of our application isn't displayed on this page yet. It's a matter of time. I'm going to hit the REFRESH, and there it is. There is spikey-prod-website-v2, which has been allocated 100% of the incoming traffic. The spikey-prod-website-v2 is currently serving. Prod-website-v1 has been stopped. Once you've deployed a new version of a service, you don't have to do anything else in order to have all of your traffic migrated automatically. All of the underlying nitty gritty details of migrating traffic has been taken care of for you by App Engine. Let's click on the new version of the service and take a look at what the updated app looks like. You can see this additional menu button here. Clicking on this menu button will allow you to collapse and expand the sidebar. Let's head back to our Versions page and click on spikey-prod-website-v1. It's no longer serving traffic. We get an Error: Not Found. Observe the URL for this version of the service when you explicitly access it. The URL is of the format version-dot, name of the service, dot, project ID, .appspot .com. Now let's say you're not really very confident that your new version is ready for all 100% of production traffic. In that case, you might want to split your traffic across multiple versions, the new one and the old one. App Engine makes this very, very simple. The first thing is to start up your older version, version v1; check the older version; and click on START; confirm that yes, indeed, you want to start this version on this dialog; and once the version is up and running, it'll say Status is equal to Serving. You can start directing traffic to both versions, v1, as well as v2. Let's first check whether the v1 app is up and running. Let's hit REFRESH on this page, and you'll see that the Spikey Sales website without the menu button is now up. With both versions now serving traffic, we can now split our traffic between these two versions. Click on the Split traffic button up to the top of your screen, and let's see how we can perform the split. App Engine offers you three choices for splitting the incoming traffic. You can choose to split by IP address, cookie, or have a random split mechanism. I'm going to choose to split traffic by IP address that we can clearly view its effects in this demo. Select the IP address option, and let's see what the traffic allocation should be. Here is the latest version v2 of our service. I'm going to add an additional version here which will serve traffic, and that is the spikey-prod-website version v1. Once I have both versions configured, I can use the slider to choose in what proportion I want the traffic to be split. I'll go with the 50/50 option. If you feel your new website is fragile though, you might choose to route a smaller amount of the traffic to it. Go ahead and hit the Save button here, and you've configured splitting of traffic across two versions of your service. Let's go back to the page listing all of the versions of our services using the left navigation pane, choose the spikey-app-service, and you can see that each version is now serving 50% of the traffic. I'm going to hit the service on a new browser tab, spikey-app-service-dot-spikey- apps.appspot .com, and you can see that traffic from my local IP address goes to the version v2 of the service. In order to see traffic splitting in action, I'm going to switch to a different Wi-Fi network using my local machine. I'm currently on CORP B404. I'm going to switch to an O-link. I've made the switch using the Network services window of my macOS. You can now see that I now have a new IP address. And now when I go back and refresh the browser for spikey-app-service-dot-spikey- apps.appspot .com, you can see that I see version v1 of my site. The source request to the service is now from a different IP address, and we've been routed to the older v1 version. Observe that the URL remains the same and does not contain the individual version numbers. We've been routed automatically to different versions based on our IP address. Once you're satisfied that the new version of the service is completely stable and ready to receive 100% of the traffic, we can go back and migrate all of our traffic to the new version. Select the spikey-prod-website-v2 version and click on MIGRATE TRAFFIC. Because we are using basic scaling, gradual migration is not supported when migrating to or from a basic scaled version. So we go ahead, hit Migrate, and all our traffic will be diverted to the new v2 version. And if you open up a new browser window and hit the website, we go to the new v2 version. This is, no matter what our IP address is, we'll always go to the new version. Now that you've understood how traffic splitting works, let's head back to the web console and get rid of this old v1 version. Select the version, hit DELETE, confirm that you want to delete it, and it'll disappear.

Introducing Cloud Datastore
The next App Engine application that we'll build will integrate with Cloud Datastore, but before we do that, let's get a big-picture understanding of what exactly this is. Google Cloud Datastore is a schemaless No SQL document database service that provides autoscaling, ACID transactions, and SQL-like queries. This is a fully-managed service that is closely integrated with App Engine. When you enable your App Engine app, you also have to set up Cloud Datastore. Cloud Datastore works very well when your data is highly structured when it's in the XML or HTML format where entities have values. You'll choose Cloud Datastore when you need highly-scaled serving for your web applications, you need very fast reads from your database, and you don't really need interactivity with your backend. Despite being a NoSQL database, Cloud Datastore offers transactional support for ACID properties, atomicity, consistency, isolation, and durability. When you have a use case that meets these requirements, you'll choose to go with Cloud Datastore as your backend storage. There'll, of course, be situations where Cloud Datastore is not the right choice for you. If you have relational data needing full SQL support, you won't choose Datastore; or if your data is unstructured in the form blobs, you're better off with a blob storage mechanism, such as Cloud Storage Buckets; of if you need interactive querying for your data, you'll avoid Datastore. Cloud Datastore comes with its own terminology that might seem rather different and strange at the first glance. So you have a Datastore kind, which is the equivalent of a table in RDBMS. Your data is broadly divided into kinds, and within each kind, you have entities. An entity corresponds to a row in RDBMS. An entity can also be thought of as an object from object-oriented programming. Each entity is made up of properties and corresponding values, which are the equivalent of columns in an RDBMS. And finally, each entity can be looked up or accessed using a unique identifier called a key. Datastore has a unique and kind of different data model, which you may not have encountered before. Kind is the category of the object. So let's say your storing e-commerce data, products might be a kind or customers might be a kind. For each kind, you have multiple entities within that kind. An entity refers to object of a particular kind, for example, an iPhone within products, John Smith within customers. And an entity can have any number of attributes, and these are properties of the entity. All entities of the same kind need not have the same properties. And finally, every entity has a key, which is used to uniquely identify that entity. Cloud Datastore is often used to model hierarchical data. All of your entities can have ancestors. Entities are arranged hierarchically within the namespace, like files in a directory system. An entity can have a designated parent, or it can have no parent at all. When an entity does not have a parent, that's called a root entity. If you want to be able to uniquely identify an entity within this hierarchy, you'll use the namespace, the kind of entity, the identifier associated with each entity, and an optional ancestor path. The ancestor path defines the parent of the entity. The Cloud Datastore model is pretty complex, but powerful. If you've never worked with Cloud Datastore before, I suggest you check out the course on Cloud Datastore on Pluralsight or you play around with Datastore on the GCP web console before you move ahead.

A Simple Guestbook Application Built Using Cloud Datastore
In this demo, we'll write a simple App Engine application that integrates with Cloud Datastore, Google's managed, NoSQL database on the cloud. This is a standard example on the GCP. We've simplified it and modified it fit our use case. We'll build a simple guestbook application where users who are logged in or anonymous users can leave comments. We'll write all of our code under the top-level gae_codes directory. I'm going to create a new folder here and call it the spikey-guestbook. Our App Engine application will be written in a new file under this folder. I'm going to call it guestbook.py. It's a simple Python guestbook application. Google offers a number of simple API modules that you can use when you are operating from within the App Engine standard environment. The users module that you see here automatically integrates with Cloud Datastore, which manages a users kind within the Datastore. This is the module that manages authenticated users to this application. The ndb module that we've imported here is the Python client library used to work with Cloud Datastore from within App Engine apps running in the standard environment. We'll build this application using jinja2 templates and the webapp2 framework. Jinja2 is an open-source templating engine for Python, and it makes it very easy for you to parameterize the HTML that you want to serve on your site. Webapp2 is a lightweight web framework that is very commonly used with App Engine apps. Initialize the jinja2.Environment, which we'll use to render our website. The name of the default guestbook to which users will add comments is going to be the spikey_guestbook. This is something that we'll be able to change in our UI. The name of the guestbook will be the parent key for all of the entries that we add to this guestbook. If a user has logged into our application before he or she comments on our guestbook, then we have some associated Author information for the guestbook entry. The Author information comprises of the user identity and email address. Author will be a nested entity of our guestbook entry, and an Author entity may contain property values for identity and email. Every property belonging to an entity in Cloud Datastore is automatically indexed. In order to turn off indexing, you explicitly set indexed to False. Every guestbook entry is stored as an entity within Cloud Datastore. The three bits of information that a Guestbook entry has is author information, which is a nested entity; content; and date. Setting auto_now_add is equal to True will automatically populate the value of a date for a guestbook entry. When you use the webapp2 framework in App Engine, it's uses classes derived from the webapp2 .RequestHandler base class in order to handle URL requests. The MainPage class responds to get requests, as you can see from the get function here, and will render our main guestbook page. There is some dynamic content on this page, which we need to retrieve from Cloud Datastore. The first bit of information that we need is the name of the guestbook from where we want to retrieve entries. The name of the guestbook for which we want entries will be available in the request, or we'll just go with the DEFAULT_GUESTBOOK. Once we have the guestbook_name we queried, the entries of the guestbook in the descending order of date, so we want the most recent entries to appear up top. The page will display the most recent 10 entries for this guestbook. If the user accessing this page is logged in, user.get_current_user will give us access to the user details. If indeed the user is logged in, we'll have a valid user object, in which case, we'll display a logout_url. If there is no user, the user hasn't signed in, then we'll display a login_url. Now we have a bunch of parameter values that we'll use to configure the display of our guestbook page. We have the user, the guestbook_entries that we want to render, the name of the guestbook, the URL that we have to display whether it's login or logout. All of these template_values we'll pass into our Jinja template when we render it. The template is in the index.html file. We haven't written that yet. It'll come up in just a bit. When the user submits the form containing a new guestbook entry, this Guestbook class will respond to the post request. Submitting a form is a post request sent to the server, and this is where we handle it. Access the name of the current guestbook, that's where the new entry was added, and get all of the entries corresponding to this guestbook from Cloud Datastore. If a user has logged in before adding a comment, we can access the Author information from the user object. Populate the user_id and the email address for the author of this guestbook entry, and then finally, set the content of this current entry and update Cloud Datastore. Guestbook_entries.put will add a new entry to our Cloud Datastore. And once the post request is complete, we set a redirect back to the main guestbook page. And finally, the code at the bottom here instantiates a new webapp2 application, which routes the forward-slash URL path to the MainPage class and the /sign post request to the Guestbook class. With out code complete, we are now ready to turn our attention to the index.html file, which contains our HTML code, as well as the Jinja template to parameterize our rendering of the page. Let's take a look at the most interesting bit of this template. Here is the Jinja specification to render the guestbook_entries that has been passed in as a template value. We ran a for loop through all of the guestbook_entries retrieved from Cloud Datastore. If author information is present, we render the user_id and the email address. If the author information is not present, we simply write out anonymous. And finally, we render the actual guestbook entry. You can explore and examine the rest of the template on your own. It should be pretty straightforward. We've already looked at the most complicated bits of the template.

Deploying and Using the Guestbook
When we work with Cloud Datastore, every field in the entities that it holds is automatically indexed. We've turned some of those off as we saw in the previous clip. Any additional composite indexes that you want to set up on Cloud Datastore has to be done using an index.yaml file. Here, we set up a simple composite index to index date field within our guestbook entry. This additional index is needed to that we can retrieve our Guestbook_entries in the reverse chronological order with the most recent entry first. Our App Engine app is almost complete. All we need to do is to set up the app.yaml file, which contains our application's configuration. We'll deploy this guestbook application to the same service, the spikey-app-service, we'll use Python 2.7, the api_version is 1, and our application is threadsafe. This configuration setting is required when you're working with Python 2.7 applications. This is what configures your application to handle concurrent requests. Our application supports the base URL path and other paths as well, and we need to specify the handlers section here within our app.yaml. All paths in this application will be handled by the guestbook.app script. The external libraries that we depend on also need to be specified within the YAML file. Here, we depend on the webapp2 library, as well as jinja2, and we are going with the latest versions of both. Setting up our application is now complete. We are ready to switch over to Cloud Shell in order to deploy this app. Move into the spikey-guestbook folder and run gcloud app deploy. Now because we have multiple YAML specifications here, for the indexes on our Cloud Datastore, as well as our application, you need to explicitly specify the YAML files as part of this command. We'll call this version of the service, the latest one, spikey-guestbook. Here are the deployment details of this App Engine application. In addition here, you can see the configurations to update. We also update datastore indexes. Hit confirm, and wait for the deployment to go through. With the new version of our service deployed, head over to our GCP web console, go to App Engine, Versions, and choose the spikey-app-service. You can see that we have two versions, and the latest one is our spikey-guestbook. If you've come to this page right away after deploying your application and you click through, you'll find that this results in an error. This is because the web portion of the deployment has gone through, but the Datastore Indexes have not yet been created. In order to see this in action, you can head over to Datastore using the navigation menu and click on Indexes, you can see that your Guestbook_entries index is still in the process of being created. Wait for the index creation to complete, and then you can switch back and hit REFRESH, and there is your guestbook. You can see from the parameter here that by default, the name of our guestbook is spikey_guestbook. Well, our guestbook looks nice and pretty, though most of these are _____. Let's try adding a new comment. I type in a comment and click on Sign Spikey Guestbook, and lo and behold, our comment appears right above the textbox, but it's anonymous. That's because we haven't logged in yet. Hover over Spikey Guestbook, and that'll give you the link to login. Click on Login, and once you've logged in with your username and password, your guestbook will appear again. Now when you try to sign the Spikey Guestbook, you'll find that the comment appears with your user ID and email. After making the post request to submit our guestbook entry, notice that we are redirected back to the main guestbook page. You can switch to a different guestbook by using the textbox here at the bottom. I want to switch to the spikey_user_comments guestbook, and once the switch has been made, you can see that our guestbook name in the request parameter has also changed. I'm going to log out from my Spikey Guestbook and then add a new entry after I've logged out. Sign the Spikey Guestbook once again, and you can see that a new comment has been added to this different guestbook, the spikey_user_comments guestbook. Let's go back to the Cloud Datastore page and view all of the entities that we've added, all of our guestbook entries. I've been logged out of my GCP web console as well because I logged out of the guestbook. Sign in once again, and here it the Cloud Datastore page. The page for Entities will list all of the entities that you have available in Cloud Datastore. We are specifically interested in the entity kind Guestbook_entries because that's what we've been playing with, and you can see that there are a total of three entries here. Two of these entries have the parent key spikey_guestbook, and that is the guestbook that these entries belong to, and one of them has the parent key spikey_user_comments. This squares with the guestbook entries that we added using our web application. If you scroll over to the right, you'll see the actual content of each entry. You can also see off to the right here that the date for each of these guestbook entries have been automatically populated. We've successfully built a simple guestbook application and integrated it with Cloud Datastore.

Introducing Memcache
If you've worked with real-world applications, you'll know that caching is an extremely integral part of any app. This is what you'd use to improve the response times of your app. In order to serve responses faster, App Engine applications can integrate very easily with Memcache, a distributed in-memory cache, in front of or in place of persistent storage. As its name suggests, Memcache is an in-memory cache, which means that if you want data to be stored permanently, you'll have to back Memcache up with some kind of permanent storage, such as Cloud Datastore. There are two flavors of Memcache available to App Engine applications. There is the shared Memcache that is absolutely free, and there is a dedicated Memcache, which is solely for your app. This is something you'll have to pay for. Both of these work in exactly the same way. Data is stored in the form of key-value pairs. The only difference is that the shared Memcache comes with no SLA and is completely free. The dedicated Memcache you have to pay for, and it comes with an SLA. Both the shared, as well as the dedicated memcache is accessible using the built-in App Engine APIs. If you're not sure that Memcache is the right product for you, the best way to get started is to use the shared memcache, which is the free default for all App Engine applications. This provides cache capacity on a best-effort basis, but you have to share your cache across all App Engine applications on the GCP. If you have a production-grade application, and you're sure that Memcache is the right product for you, you'll want to use the dedicated memcache. This provides a fixed cache capacity assigned exclusively to your application, and it's billed by the GB-hour of cache size. When you set up the dedicated Memcache, your cache data cannot be evicted due to other App Engine applications running. You can serve data from cache more predictably, and you have fewer reads from the more expensive durable or persistent storage.

Exploring Memcache
In this demo, we'll see how we can improve the response times of our App Engine applications by caching results using Memcache. Let's quickly play around with Memcache first using the web console before we use it in our App Engine app. Use the navigation menu, head over to App Engine, and choose Memcache, and this will bring up the web console for Memcache. And you can see that, by default, the shared memcache is available to us. Shared memcache is the free default available for App Engine applications. It provides caching on a best-effort basis, and its availability is subject to the overall demand of all of the App Engine applications running using this Memcache. Data in Memcache is stored in the form of key-value pairs. Let's add in a new key and see how that works. Click on NEW KEY here, and we want this Key type to be of type Python String. We'll simply call this key content, and the Value type of this key is also a String. We'll keep things very simple for now. And the actual Value of content is this message. Click on the Create value button here, and you'll find that a new entry has been added to our Memcache. You can see that Items in cache is now equal to 1. Once you have a bunch of keys stored in Memcache, you can use the UI to find a specific key. They Key type that we want to find is Python String, and the Key is content. Click on Find, and you'll see the Search results right there. This result shows you that a cache value is available for this particular key. If you hit REFRESH, you'll see that the request that we just made was a cache hit. Our Hit ratio is currently 100%. One hit and 0 misses. Let's try and find the same key once again. That will be our second hit. And in the result, let's click through to content and take a look at what value is associated with this key. This will be our third hit. If you hit Cancel to get out of this page, you'll see that we have three hits and two misses so far in our cache. Let's go ahead and flush the cache here so that all of the keys stored within Memcache are purged. This, of course, in a real-world production environment is not a great thing to do. That's why this warning pops up. We do want to flush the cache though. Go ahead and hit OK, and our cache is now clean.

Integrating Memcache with App Engine Apps
Now that we've briefly seen how Memcache works, we are ready to go ahead and integrate it with our web application. We'll work with the same guestbook app as before. The app.yaml file remains exactly the same. There are no changes here. We'll continue to need the index.yaml file because Cloud Datastore is going to be the permanent storage for our Guestbook_entries. Memcache is an in-memory cache. It's not a replacement for permanent storage. The main changes that we'll need to make in order to use Memcache will be to guestbook.py. So head over to guestbook.py. I'm going to delete and replace the code here, and then I'll walk you through what's different. The first significant change that you see here will be in the imports. From google.appengine .api, we are going to import the memcache module. This is what will allow us to work with Memcache programmatically. There are no changes to the classes representing the Datastore entities, the guestbook_entries, nor Author. The next change here in the MainPage class, which renders our Main guestbook_entries page. Here, we get the name of the guestbook and call self.get_guestbook_entries, which is a new method that we are going to write. The get_guestbook_entries functions will try to retrieve guestbook_entries from cache if it's available there. If not, it'll go to Cloud Datastore for retrieval. We'll also display a few statistics about our cache hits and misses on the main guestbook page. Access these statistics by calling memcache.get_stats, pass in the of cache hits and misses as a part of the template values that we pass into the Jinja template. We'll display these values on the MainPage so that you can see which requests hit the cache and which did not. Let's scroll down to the get guestbook_entries function, which takes in as input the name of the guestbook. We first tried to retrieve these guestbook entries from Memcache. We'll check to see whether the guestbook has its entries added to Memcache. If yes, we'll access it from there. The key that we use to save guestbook_entries to Memcache is the name of the guestbook, colon, guestbook_entries. If we find that the guestbook_entries are not present in cache, we'll simply go to Cloud Datastore and retrieve the entries as we did earlier. Once we have the guestbook_entries from Cloud Datastore, we'll add it to Memcache. The parameter 10 that you see passed in here represents the expiration time for this particular cache entry. We've purposely kept it very low to 10 seconds. There is no change to the rest of the code in the guestbook.py file. Let's switch over to index.html, and let's add in the information to show the cache hits and misses. Right here, at the center of the page, we'll render the number of Cache Hits and Misses. These are new template values that are available. The code for our integration with Memcache is now complete. We'll now switch over to a Cloud Shell terminal window and deploy this application. We'll simply update the spikey-guestbook version to use Memcache. Confirm that yes, indeed, you want to deploy this application and wait for the deployment to go through. Let's head over to the Versions page on our GCP web console and take a look at the spikey-app-service. That is the service that we just deployed. Here is the latest version with Memcache enabled. Let's click through and view this on our browser. You can see that the number of Cache Hits is currently 0 and Misses is also 0. Retrieving these guestbook entries must have added something to our Memcache. And if you go back to the web console, you'll see that it's true. There's exactly one item in our cache because of the request that we just made to spikey_guestbook. Let's go back to our web application and switch to a new guestbook called customer_forum, and you'll find that the one cache miss is now reflected in our web app. The web console now shows us that there are two items in our Memcache. The entries for the customer_forum guestbook have also been added. Let's add a new entry to our guestbook. This will call the post request and our page to be reloaded. Because our cache is so configured that cache entries are valid only for 10 seconds, you'll find that we have a lot of Cache Misses. Every request will be a miss because it's longer than 10 seconds between requests. In order to get Cache Hits, I'm going to go ahead and hit Refresh a bunch of times in quick succession. And finally, after four Cache Misses, I get a Cache Hit. Let's take a look at our Memcache page here, and it shows us that our Hit ratio is just 20%. This is very exciting. I'm going to go back to the web page and hit Refresh a bunch of quick times here. I have five Cache Hits and six Misses, and that's what is shown here on my web console as well. Let's go ahead and flush all of the entries corresponding to our two guestbooks here in cache. Click OK. The cache will be flushed. Now we can switch from a shared memcache to a dedicated memcache by clicking on Change here. Remember that a dedicated memcache is a paid service for your app. The shared memcache is free. I'll choose to go with a simple dedicated memcache 1 GB in size. Click on OK, and here you see it, my dedicated memcache. The dedicated memcache has an additional feature that is now available with the shared memcache, and that is hot keys. With this, you can analyze your hot keys, keys that receive more than 100 queries per second. Those are automatically populated here to help you with your analysis. Switch back to your application and hit Refresh a bunch of times to see your Cache Hits go up. There are a few misses here, of course, because I was beyond the 10-second boundary. And with this demo, we come to the very end of this module where we deployed applications and used the various APIs in the App Engine standard environment. The standard environment is a lightweight restrictive sandbox that hosts your applications, and it supports only a few runtimes and a few versions. The biggest advantage of using the standard environment to host your applications is the very fast scaling that it offers. When you deploy applications on the standard environment, you'll extensively use the App Engine built-in APIs. You can use these APIs to integrate with the Cloud Datastore for persistent storage. You can also use these APIs to integrate with Memcache for in-memory distributed caching. In the next module, we'll build and deploy our applications on the App Engine flexible environment, which uses the Docker containers to run our applications. This allows us to customize our runtimes how we want to.

Deploying Applications on the App Engine Flexible Environment
Module Overview
Hi, and welcome to this module where we'll see how we can deploy applications using the App Engine flexible environment. As its name suggests, the flexible environment in App Engine is far more flexible about the kind of applications that you can run, the libraries that you can use, the runtimes that you can use. The flexible environment runs your application in a Docker container, which means that it's relatively slow scaling as compared with standard environment applications. In the standard environment, instances are lightweight and can be spun up quickly, not so in the case of the flexible environment. The advantage though is that when you use the flexible environment, you can access external libraries and runtimes from your app. When you use the flexible environment, you're not restricted to just the few runtimes that App Engine standard environment supports. You can use your own customized runtimes. Allowing customizable runtimes makes your applications more portable, which means migrating to App Engine is also easier if you start off with the flexible environment.

App Engine Flexible Environment
Before we get down to implementing and deploying an App Engine app on the flexible environment, let's study some of its features starting with application execution. When you deploy applications to the flexible environment, your apps actually run within a Docker container on Compute Engine virtual machines. This is far less restrictive than the sandbox of the standard environment. The less restrictive environment means that we can use non-whitelisted binaries. If you have third-party integrations that don't work in the standard environment, the flexible environment is what you'll choose. You can also write to disk. From your apps, you can run multiple processes, and you can also choose the type of Google Compute Engine machine that you want to use based on the resources that you need. In addition to all of this, the flexible environment still gives you access to the load balancing and scaling capabilities that App Engine provides. In an earlier module, we saw that when we built applications using the standard environment, we use built-in App Engine APIs. These APIs are not available in the flexible environment. Instead, you'll use client libraries. Client libraries are what you would use to integrate with GCP services when you're running anywhere, whether it's on a VM or a container somewhere. When you use these client libraries, that makes your application more portable. When you're developing for the App Engine flexible environment, you can also run your application locally, your code should be portable, you don't have to stick with the App Engine SDK, there are fewer restrictions, and you get a lot more leeway in building your app. App Engine still offers scaling support. When you build your application using the flexible environment, scaling is different from the App Engine environment though. You should have at least one instance up and running at all times. Scaling happens via the GCE autoscaler, and scaling happens much more slowly than in the standard environment. In the case of the standard environment, App Engine took care of health checks for you, but in the case of the flexible environment, app developers write their own health checks. These health checks are loaded by platform load balancers. You need to be a little careful with third-party library calls within your health checks because any failure in the external library component can cause all of your health checks to fail. With the flexible environment, you have more control over the resources available to your application. The app can specify the Compute Engine machine type to use. You can have higher CPU and memory limits for your apps.

Deploying a Static Website to the App Engine Flexible Environment
So far, all of the apps that we've built on App Engine have used the App Engine standard environment. It's now finally time for us to build an app using the App Engine flexible environment. The flexible environment offers all of the advantages of the standard environment, such as autoscaling and load balancing. In addition, we can completely customize the runtime of our applications using Docker files. We'll start off in our home directory in code editor where under spikey_gae_codes, we'll create a new folder called spikey-nginx-website. This application will run our website on an NGINX web server within our Docker container. Within the spikey-nginx-website folder, let's create a new folder called www. This will hold our static HTML file. Index.html is the main page of our website. Let's paste in the HTML content for our website here, once again, to do with puppies, and the style sheets will be stored in a new folder under www called css. We just have the one style sheet, which is called style.css. Paste in some CSS here so that our website can look pretty. Now it's time for us to set up the Docker file to customize our runtime. The Docker file is what contains the commands to build your container image. Containers, as you already hopefully know, are lightweight, isolated environments which contain your app and all of its dependencies. We are going to host our very simple static website in an NGINX web server. The base image for our container is the nginx image. NGINX is an open-source web server that is extremely popular because it has great performance. Copy over the NGINX configuration file from our local machine into the container. This configuration file ensures that our server is listening on port 8080. This is what App Engine expects, and this is what we need to set up. App Engine automatically health checks your applications. A file in this particular directory that you see here on screen will serve as a health check. For App Engine, any response in the 200s or a 404 response is considered healthy. Technically, you need not create this file because that will return a 404 response, and then App Engine will know your application is healthy; however, Google's documentation explicitly recommends that you leave this file in. And finally, we give read access to all of our static assets in the www folder. The next step is to set up the configuration file for the NGINX web server. This is a pretty standard configuration that you can get off of the NGINX site. The important thing here is that our application is listening on port 8080. That's what App Engine expects. And finally, we are ready to set up the app.yaml file which'll contain the configuration parameters to run our app in the flexible environment. Since this is a very simple static website, the only thing that we need to specify here is the name of the service. That is the spikey-app-service. The runtime is a custom runtime, and the environment is the App Engine flexible environment. With all of this set up, let's switch over the Cloud Shell terminal window and deploy our application. Cd into the spikey-nginx-website folder and call gcloud app deploy. We'll call this particular version of the spikey-apps service the spikey-nginx-website. Confirm yes, we do want to continue with this deployment and wait for this deployment to be completed. You'll find that it takes several minutes for App Engine to deploy to the flexible environment. This is because a custom Docker image has to be built and hosted on your VM instance. If you've worked with containers before, these messages should be very familiar to you. The container is being built up layer by layer. This deployment took about five minutes to complete on my machine. Once the deployment is complete, you can head over to the Google Container Registry, go to the navigation menu, go to Container Registry, and click on Images, and you can see the image corresponding to this container. Click through to appengine, and you'll see our spikey-app- service.spikey -nginx-website. Here is the version of the image that we just built when we deployed our application to the flexible environment. Use the navigation menu to head over to the App Engine Versions, and let's take a look at the latest version of our spikey-app-service. Here is our spikey-nginx-website serving 100% of the traffic. If you scroll over to the very right and click on the Config column, that'll show you the app.yaml file that was used. You can see that App Engine automatically added in the default autoscaling parameters for this app. You can click on this particular version and take a look at our static website running within an NGINX container. You can view instance information for this application by clicking through to the two instances that are running this app. Both of the instances are listed at the bottom here. One of the cool things about using the App Engine flexible environment is that you have root access to the VM instances that run your application. You can choose to SSH into this VM and debug your app if you want to. SSH access to VM instances in the flexible environment is disabled by default; however, you can enable it if you choose to.

Google Cloud Security Scanner
An important consideration for any web application that you might implement is that they be secure, and that's where the Google Cloud security scanner can help you. The Cloud Security Scanner identifies security vulnerabilities in App Engine and Compute Engine applications. The Cloud Security Scanner is not meant to be a comprehensive security solution. Instead, it's a starting point for your security investigations. The Security Scanner when run on your app automatically crawls your application, following all links within the scope of your starting URLs, and attempts to exercise as many user inputs and event handlers as possible. At the time of this recording, these are the vulnerabilities that the Security Scanner is capable of identifying. Cross-site scripting. It'll test every user input possible and inject scripts to see whether they are vulnerable to XSS attacks. The Security Scanner can also check whether your application is vulnerable to flash-injection attacks. Other attacks that it checks for is mixed content. If your application is hosted on an HTTPS URL and it accesses URLs which are not secure, that will trigger a warning. The scanner will also check to see whether your application is transmitting passwords in clear text to the backend. It'll also flag warnings if there are invalid headers. Let's say your app says a response type is of type JSON, it'll check the format of the response with the type specified. The scanner also maintains an up-to-date list of JavaScript libraries and other libraries which we have security holds or are simply outdated. It'll flag warnings for these as well. The Cloud Security Scanner on the GCP is constantly evolving. New vulnerability classes are constantly being added, which means that it makes sense for you to schedule regular scans of your app in production or in test environments.

Scanning for Vulnerabilities Using the Cloud Security Scanner
The Cloud Security Scanner is a valuable addition to the security toolbox on the GCP. In this example, we'll see how we can run a security scan on your App Engine application. Head over to App Engine using your navigation menu and select Security scans. That's our current page. You can see that there is an API to be enabled before you use Cloud Security Scanner. Click on the blue button and enable the Cloud Scanner API. Once the API has been enable, you can go ahead and create a new scan. Give the scan a name that is meaningful to you, and you next need to specify a starting URL. The Security Scanner by default picks up the default service in you App Engine application. I'm going to edit this and switch it over to the spikey-app-service. The latest version of this website is the static website running on the NGINX server. The next step is to specify in the URLs that you want to exclude from this scan. Because our application happens to be a simple one, there are no URLs that we want excluded. But this is a great way to limit how much content your Security Scanner runs through. If you need to log into authenticate and authorize yourself to this app, here is where you'll specify the kind of authentication, either a Google or a non-Google account. We have no authentication enabled. That's our choice. The next step is to figure out a schedule for the scan. As you release new versions of your app in production, you might want to regularly run the Security Scanner to pick up vulnerabilities to catch them early. I'll go with Never because I just want to manually run the scan once. The advanced options available under this More link allow you to further configure your security scan. You can specify the kind of user agent that you want to use. I'll go with Chrome on Linux. You can choose other user agents such as Nokia, Blackberry, and so on. You can also configure the rate or queries per second at which the scan hits your site. I'll just go with 15. Clicking on the Create button here will set up our fully-configured scan, and you can click on the Run scan button to manually trigger this. For very large applications, the Cloud Security Scanner might take several hours to run. There is no guarantee as to when it'll be complete. Even for this simple app, you'll see that it takes almost 30 minutes. The cool thing here is the scanner did not find any vulnerabilities in our app. This, of course, does not mean that no vulnerabilities exist. There are still vulnerabilities the scanner might have missed. The scanner looks for only some specific kinds of vulnerabilities at this point in time. The URLs tested tab here will show you which URLs were tested during the course of the scan, and the Details will show you the configuration of our scan.

Integrating with Pub/Sub
In this demo, we'll build an App Engine application using the flexible environment that integrates with Pub/Sub. This app will publish messages to a specific topic in Pub/Sub. It'll also expose a URL that acts as a webhook to receive push notifications from a Pub/Sub subscription. In this demo, we'll see how we can use client libraries to integrate our App Engine application with Pub/Sub. The way data flows through this application is fairly complex. Let's get a big-picture understanding of what's going on before we get into the actual code. So we have our App Engine application on the left side of this page and Pub/Sub on the right side of this page. The App Engine application exposes two URL paths, forward-slash and /pubsub/push. there are two different Python methods which correspond to these two app routes. If you haven't worked with Pub/Sub before, here is what Pup/Sub is in one sentence. It's Google's message delivery system where publishers post messages to a topic and subscribers use subscriptions to pull messages. You can also have subscriptions be push subscriptions where Pub/Sub itself pushes a message out to a webhook or a callback URL. The Pub/Sub push subscription is what we'll use in this demo. Here is how the code is structured. When we make a post request to the forward-slash app route that publishes a message to a Pub/Sub topic. We'll configure this topic with a push subscription. This means that when a message is received on a topic, that message is sent to this push subscription. This push subscription has been configured to hit the /pubsub/push URL exposed by our same App Engine application. This means that any message posted to this topic by our app is sent back to our application using this push subscription. This is a big picture of the application and its integration with Pub/Sub that we are going to build over the next few clips. Let's create a new folder under spikey-gae-codes to hold our application. We'll call this folder spikey-coupons. Within spikey-coupons, we'll create a new subfolder. This will be called templates and will contain the templates that we'll use to render the main page of our app. Under templates, we'll create a new index.html file that will contain the static assets of our website. This is the same Puppies site with a simple form that will allow us to publish to a Pub/Sub topic. The code for our application will be written in the main.py file. I've pasted in the entire code here. Let's now walk through it step by step to see exactly what it does. This application uses the Flask web framework that we've encountered earlier. In addition, we also import the libraries to use Pub/Sub. This is the pubsub_v1 client module. This application requires a bunch of information, which we'll provide environment variables. The first of these is a PUBSUB_VERIFICATION_TOKEN. This is just a simple string token that we'll use to match against what we expect before we publish to a Pub/Sub topic. In addition, we'll use environment variables to know which Pub/Sub topic to publish to and our project ID. We'll have to specify the values for the first two environment variables ourselves. This third environment variable, the project ID, is available as a part of the App Engine setup. The base URL for this application, the forward-slash, can be accessed using both GET, as well as POST methods. That's what we have specified in this app.route decorator. If this URL is accessed, using a simple GET method, we'll simply print out all of the messages that we've received from the Pub/Sub subscription that we are going to set up shortly. We'll add these Pub/Sub messages to the MESSAGES list here, and we'll simply render out the entire list. If instead this particular URL is accessed using a POST method, that means this was a form submit. We extract the payload from form, which contains the details of the message that we need to publish to our Pub/Sub topic. Instantiate the PublisherClient in order to publish messages and set up the topic to which you want this message published. The publisher.publish method will publish the message that we just received from the form submit to this Pub/Sub topic. Once the message has been published successfully, we return OK to the caller. The App exposes another URL, the /pubsub/push URL, which only can be called using the POST method. This URL will serve as a webhook, which is essentially just a callback. And each time a message is published to our Pub/Sub topic, we'll set up a subscription that will push that message to this webhook URL. We don't want anyone to be able to hit this URL except our Pub/Sub subscription. We'll only accept requests if the verification token matches otherwise we'll simply say it's an invalid request and return a 400. Extract the JSON message that's available along with the request parameters and base64 decoded. Append this message that we've received from the subscription to the MESSAGES list and return OK, set up a simple method to handle errors if they occur, and run this application on port 8080. We now need to set up the requirements.txt file to specify the dependencies of our application. We depend on Flask, we depend on google-cloud-pubsub, and we depend on gunicorn. Gunicorn, which is a short form of Green Unicorn, is a lightweight and fast Python WSGI web server for UNIX. WSGI is the web server gateway interface and is a specification that describes how a web server communicates with its web applications. If you're interested in learning more about Gunicorn, you can visit their website shown here on screen. Alright, our application is now complete. All we have to do now is to set up the app.yaml file specifying the configuration parameters for our app. We are running this app using the Python 3 runtime in the flexible environment. There is a specification here that we haven't encountered before, the entrypoint. This basically starts a process that responds to HTTP requests on the specified port. This is where we start up our Gunicorn web server, and here are the environment variables that our app needs to run. The PUBSUB_TOPIC is the spikey-coupon-topic, and the VERIFICATION_TOKEN is simply 1234abc. Let's switch over to our Cloud Shell terminal window and move into the spikey-coupons folder and get ready to deploy this app. We'll first run a simple pip install to install all of the dependencies for this particular application onto our Cloud Shell VM. Wait for the pip install to complete. We still have a bunch of set up to do before we can deploy this app.

Publishing and Receiving Messages
Before we deploy our application, we need to create the Pub/Sub topic and a subscription for that topic so that we can publish, as well as receive messages. Use the navigation menu, and under BIG DATA, you'll find Pub/Sub, choose the Topics option, and here on this page, you can create a new Pub/Sub topic. I'm going to call this the spikey-coupon-topic. Click on the CREATE button here, and a new topic will be created. Click through. This newly created topic has no subscriptions. We can now create a new subscription using this button here on top. Create a subscription which will listen to this topic. I'm going to call it the spikey-coupon-subscription. Subscriptions to a Pub/Sub topic can be of two types. You can have a pull subscription where you explicitly pull messages available to a topic, or you can have a push subscription where the Pub/Sub topic will simply push to an endpoint webhook URL. Any message that is published to this topic we want pushed to our appspot.com application to the /pubsub/push path. We also need to specify the token for verification, which is simply 123abc. It's generally not possible for you to configure just any URL for your push subscription. You have to verify that this URL is indeed yours. But because this is an App Engine URL and the GCP can verify that it belongs to an App Engine app in your project, it's accepted. Click on the More options here. We'll configure that we can wait up to 30 seconds for an acknowledgement for our message. Every message received by a subscriber has to be acknowledged before it's removed from Pub/Sub's queues. That's all the configuration that we need to do. Click on the Create button, and this new subscription will be set up. Now we are ready to head back to Cloud Shell and deploy this new application. We'll call this the spikey-coupon version. Because we are deploying to the App Engine flexible environment, this deployment will take several minutes. It might take up to 10 minutes, so you need to be a little patient. Once the deployment is complete, you can head over to the Container Registry using your web console, and you can see that our App Engine app now has a new image called spikey-coupon. If you click through here, you'll find the latest version of this image. Let's head over to App Engine and Versions, and you can see that our spikey-app-service now has the latest version, spikey-coupon, which is serving all traffic. Click on spikey-coupon, and this will bring up our App Engine application, which will allow us to publish to a Pub/Sub topic. I'm going to enter a coupon code in this textbox here and click on Add Coupon. This will submit a POST request to this web page. This POST request, if you remember, will publish a new message with this coupon code to the spikey-coupon topic. This message in turn would have been pushed into the webhook URL that was exposed by our application and be available as a part of the MESSAGES list. And if you refresh this page and make a GET request to our application, the coupon is available right here on the screen. We'll set up our App Engine application as a publisher of messages to our topic, as well as subscriber receiving messages from our topic.

Summary and Further Study
And with this demo, we come to the very end of this module where we worked with the App Engine flexible environment. We saw that the flexible environment runs our application in a Docker container. We saw that the flexible environment removes many of the restrictions associated with the App Engine standard environment. The tradeoff is that your app is relatively slow to scale. The flexible environment is a great choice when you have consistent traffic flowing to your apps. When you use the flexible environment, you can access external libraries and runtimes from within your app. You can also customize your runtime how you want it. We also saw in the case of Pub/Sub that when you integrate with other GCP services from within the flexible environment, you'll use client libraries rather than built-in App Engine APIs. This makes your app inherently more portable. And on this note, we come to the very end of this course on App Engine. Before you head out, make sure you delete the resources that you have provisioned such as App Engine applications that you have deployed, delete data stored in Memcache and Cloud Datastore, delete any cloud storage buckets that you may have created, and make sure you delete your Pub/Sub topics and subscriptions. If you're interested in learning more about App Engine and building more complex applications, here is a course that you might find interesting on Pluralsight, Leveraging Advanced Features of Google App Engine. If you want to keep your apps secure and are interested in learning more about security tools that the GCP has to offer, Leveraging Cloud Armor, Security Scanner, and the Data Loss Prevention API, is a good course for you to watch. And that's it from me here today. I hope you enjoyed this course. Thank you for listening.

Course author
Author: Janani Ravi	
Janani Ravi
Janani has a Masters degree from Stanford and worked for 7+ years at Google. She was one of the original engineers on Google Docs and holds 4 patents for its real-time collaborative editing...

Course info
Level
Beginner
Rating
4.2 stars with 13 raters(13)
My rating
null stars

Duration
1h 53m
Released
11 Jan 2019
Share course

