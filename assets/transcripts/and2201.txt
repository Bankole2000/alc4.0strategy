Kotlin: Using Coroutines
by Kevin Jones

More and more languages are providing support for asynchronous programming. This course will show you how to use the asynchronous programming features of Kotlin allowing you to create applications that are more responsive.

As a developer, you want to build fast-running applications without the overhead that threads can cause. In this course, Kotlin: Using Coroutines, you'll learn how coroutines provide a way to use ‘lightweight’ threads within a process that let us take advantage of multi-core processors without much of the overhead. First, you'll learn how to create coroutines. Next, you'll explore how to use them to return data. Finally, you'll discover how to use coroutines in environments such as JavaFX and Android, where thread affinity is really an issue. By the end of this course, you'll have a thorough knowledge of how to use coroutines in Kotlin to create fast and efficient applications.

Course author
Author: Kevin Jones	
Kevin Jones
A long time ago in a university far, far away Kevin fell in love with programming. Initially on the university's DEC20 computer doing BASIC and Pascal and a little bit of Fortran. His first job had...

Course info
Level
Advanced
Rating
4.9 stars with 18 raters(18)
My rating
null stars

Duration
3h 50m
Released
10 Aug 2018
Share course

Course Overview
Course Overview
(Music playing) Hi everyone, my name is Kevin Jones, and welcome to my course on Using Coroutines in Kotlin. I'm a founder and developer at Rock Solid Knowledge, a software development company based in the United Kingdom. Asynchronous programming is a technique that lets you scale applications without overloading the operating system by creating too many threads. Kotlin provides excellent support for asynchronous programming through its use of coroutines. Some of the major topics that we will cover include understanding how to create coroutines with various builders, such as launch and runBlocking, using async and await to return data from coroutines, creating channels to allow coroutines to communicate easily, and using actors to manage state in an asynchronous environment. By the end of this course, you'll have an in-depth understanding of how to do asynchronous programming in Kotlin using coroutines. Before beginning the course, you should be familiar with programming Kotlin. I hope you'll join me on this journey to learn coroutines with Kotlin: Using Coroutines course at Pluralsight.

Introducing Kotlin Coroutines
Introduction
Hi, my name is Kevin Jones, and welcome to the introductory chapter of the Using Coroutines in Kotlin class from Pluralsight. In this chapter, we'll take a look at what we'll do in the rest of the class, and then we'll do a brief introduction to coroutines themselves. So we'd like to introduce you to coroutines during the chapter, see what a coroutine is and why it's important. The way coroutines work in Kotlin, they use things called builders to build the coroutines, and we'll see what builders are. And we'll see that to use certain functions within coroutines, we have to mark them as suspend functions, so we'll see exactly what a suspend function is and how we create them. We'll see how we can coordinate coroutines, how we can make these things work together. We'll take a look at how we can return data from coroutines rather than just create fire and forget coroutines. When we return data from a coroutine, typically a coroutine runs and returns one piece of data; however, Kotlin coroutines also support the use of channels, which may be familiar to you if you've used the Go programming language. Using channels, we can communicate between coroutines. Coroutines support the actor pattern, and we can also use a select statement to select the data that's returned from a channel. This can make our coroutines channels very expressive and very extensible. And finally, we'll talk about how to use coroutines in UI applications. Where objects in the user interface are typically constrained to one thread, we want to do background work. We can use coroutines to do that. So before we get into the details of using coroutines, in this chapter we'll talk about why. Why do we care about asynchronous programming? Why do we care about using coroutines? We'll also start using coroutines, and we'll see that at the moment coroutines are still experimental, so they're not a formal part of the Kotlin library yet, but they will be. We'll see how we set up Maven projects and Gradle projects to use these, and then finally, we'll write our first coroutine. And we'll see that the coroutine we write initially will be very straightforward. And we'll also take a look at the cost of coroutines as well. Are these things expensive to use to compared to, say, using a thread? So before we get into the details of coroutines, let's take a look at why we think coroutines are important. Coroutines let us write asynchronous code. Not necessarily multi-threaded codes, although the two things often conflated. For example, JavaScript is a single-threaded language, but the code is heavily asynchronous, and coroutines in Kotlin give us that asynchronous support. So why do we care about this? Well, computers these days are not really getting any faster. It used to be that a computer speed would double every 18 months. And back then, if your PC was too slow, you wait 18 months and it would probably be quick enough again. Then new applications would come along, PC would feel too slow again, you wait another 18 months, the speed had doubled, and the speed was generally then quick enough. However, this stopped around about 2005. There's a law in computing called Moore's Law, and many people thought that Moore's Law meant the computer speed doubled every 18 months, but that's not the case. Moore's Law states that the number of transistors on a chip doubles every 18 months. So although the speed stopped doubling, Moore's Law still applied. We are still doubling the number of transistors on a chip approximately every 18 months, although this will probably stop soon. There are fundamental limits of what we can cram onto a two-dimensional surface. So now rather than being faster, modern PCs have more cores. And we need to be able to take advantage of those cores. If you search the web for Moore's Law, you'll find many articles and many examples talking about the end of Moore's Law. For example, this one here from 2017 talking about preparing for the end of Moore's Law. And if I scroll down here, there's a very interesting graph which illustrates what I've just been talking about. On this graph, the pale blue line shows the chip speed from about 1970 to right about 2015. And you'll see that around about 2005, speed flattened out. Notice that this a logarithmic scale. You can also see the dark blue line, and that blue line shows the number of transistors on the chip. And that is a straight line, so that shows that the number of transistors on a chip is still doubling, up until 2015 at least.

Multi Threading in Java
So how do we do this in Java? How do we take advantage of this many cores inside a given processor? One way to do this is to use the Fork/Join Pool. This was introduced in Java 7, so about 7 years ago now. And the idea behind the Fork/Join Pool is that it's meant for small, related tasks. So we fire a task into the Pool, Pool executes the task, returns the result, and we provide some coordination to get the data from those tasks and bring all that data back together. Fork/Join Pools also introduce something called work stealing. So taking a look at an example, we have an array of values, we want to iterate through that array and calculate the sum of the values in that array. We could obviously do this linearly. So we could start at array entry 0, work to the length of the array, take each value at a time, and add those values together. However, we can also break the array down into chunks, calculate the value within those chunks independently, and at the end add those values together. These are small independent tasks, and we could easily run these tasks asynchronously, and in Java we do that by using the Fork/Join Pool. So let's take a look at some examples of how we might do this. So, this is the code off the slide. This is obviously written in Kotlin. The way this function works is it takes an array, it takes the start point in the array, and the endpoint in the array, and then decides if the array is too big. And if it does, it breaks this down into smaller chunks and recursively calls compute on those smaller chunks. Once the size is small enough with inside the array, it simply iterates through the array, mapping the values in the array to long values and then summing them, calling sum on those values. So at the moment, this will run purely on a single thread. I've commented out a print line here that prints out the thread we're running on, as I want to time this code, and I don't want the print line getting in the way of the timing. When you grab this demo code, if you want to see the name of the thread that each computer runs on, simply uncomment that line. So the main function creates a mutableListOf integers, it sets a limit on the size of this list to be 2 million values, it then adds 2 million values to that list, and we then call compute. Notice that we're calling compute twice here. We call it the first time just to warm up the processor, just to warm up Java. And then the second time we call it and we print out how long this takes to execute. So, let's run this. So run the main program, which compiles it, does the calculation, and this finishes here in about 53 ms, so this is one of the trickiest parts of running these demos. Depending on the machine you run the demo on, this will obviously take lesser or more time. So 53 ms is very, very quick, so let's increase the size of the limit to 20 million, and then run this thing again, and we see a corresponding increase in time, and it now takes around 867 ms. And if you run this a third time, just to convince ourselves, the timings will vary. So again, 733 ms. So it looks like it's about 0. 7 or 0. 8 of a second to run this. So we're summing 20 million entries in a list in less than a second. And that's acceptable. However, at the moment, this application will simply use one core to do this work. So it'll simply balloon into that one core. The machine I'm running on here has 8 cores, so how about we split this across multiple cores and see what happens then? So before we take a look at the multi-threaded code, just a quick look back at the compute function. This is actually quite a straightforward function. It splits the array into multiple sections and recursively calls compute to recompute the values inside that array. If we take a look at the code that's going to use the Fork/Join Pool to do this, we'll see that the concept is the same, we are still going to split the array into multiple parts, but now what we're going to do is we're going to fork off a job on the Fork/Join Pool, have that job execute, and gather the results together at the end, and then calculate the answer. And this code is a little more complex, and not only is it more complex, it's also harder to understand and harder to reason about. So we'll run this again. Let's make sure we're calculating the same amounts, so we set this at 20 million. And if you remember the last time we ran this, it took about 0. 7 or 0. 8 of a second. So if we execute this now, so this 1 takes about 0. 3 of a second. So, say this is an 8 core machine. We are making use of all 8 cores; however, we don't get to run the code in an eighth of the time. There is still some overhead in executing this code. So even though we're on a multi-processor system, a multi-core system, don't expect to have a speedup in relationship to the number of cores necessarily. So if previously we ran in 8 seconds, it doesn't mean if we run this on an 8 core machine it'll run in 1 second. As there is some overhead with scheduling, for example, and getting all the threads to run. But still, it's an improvement. However, the cost of the speedup is paid in the complexity of the code and understanding that code. So we've just run this code twice, once simply by calling compute recursively, and once by using the Fork/Join Pool to make the code asynchronous, and in this case, actually make the code multi-threaded. However, there are issues with this Fork/Join code. So conceptually, the idea is easy. I'm going to take an array, I'm going to iterate through all the elements in the array, and sum the values of those elements. However, in the Fork/Join code, there's lots of ceremony. We have to create the Fork/Join Pool, we have to add jobs to that pool, we have to gather the result of those jobs when they've finished, so we have to call fork and join and compute to actually get the results back out. And the actual functionality, the actual thing that we are trying to do, gets lost in this ceremony. And this is a really simple algorithm. You can imagine that for more complex algorithms, then it's very hard to understand exactly what's going on when you have to intertwine the work you're trying to do with the fact that you're also trying to present this work into the Fork/Join Pool. So what we'll do now is we'll take a look at this code, but written with Kotlin coroutines instead.

Computing with Coroutines
So, this is the code written using coroutines. I won't get into details at this point as to exactly what this code does and what the coroutines are doing. You'll see functions like async and runBlocking in here; however, if we compare this code to the original code, notice in the original code we call compute to get the left value, compute to get the right value, and return left + right. In the new code, it's very, very similar. We call async compute to get the left value, compute to get the right value, and then return left. await + right. So conceptually the code is doing the same thing, but structurally the code is very, very similar to the non-asynchronous code. If we scroll down, the work is the same. We're going to calculate 20 million values. Again, we call compute twice our processor, and if we run this now, so we find the code runs in about 0. 4 of a second, so maybe twice as fast as the synchronous code. In this case, not quite as fast as the Fork/Join code, but again, we do get a speedup, but the code is much, much easier to understand and much, much easier to reason about. What you'll find is depending on the type of code you're executing, and depending on the overhead, you will get better or worse speedups depending on exactly how the code is written, how the processor gets used, whether you're doing this using Fork/Join Pool, whether you're doing this using coroutines, so if speed is absolutely necessary to you, then it may be that you profile different solutions before you pick the one you want to use. If you're just trying to get a good speedup and make use of multiple cores, then the asynchronous code in this case gives you that, and the asynchronous code is much, much easier to understand than the Fork/Join code. So, the code with the coroutines looks the same as the non-Fork/Join code. It looks the same as the synchronous code that we'd written. A few extra keywords, but structurally it's the same code. This makes the code easier to read. There's way less ceremony. There's still some. We still need to use async, we still need to use await, and we saw the use of runBlocking, and we'll see what that means a little later; however, the code still runs asynchronously. So use the same underlying code as the Fork/Join code. So we are sort of supplying some semantic sugar here to make the code easier to write and easier to understand, while underneath it's still asynchronous and still producing the results that we want.

The Different Approaches to Asynchronous Programming
So I've tried to show in the previous two or three demos the benefits of asynchronous programming. We want to speed up our code, we want to make the code run more quickly, be more efficient. So there are different styles to program asynchronously. If you've done JavaScript, for example, you can use callbacks. JavaScript relies heavily on callbacks, and we can get those callbacks to run asynchronously. We can also in Java use futures. The idea behind a future is we fire off a task, and then at some point in the future we ask the result of that task to give us back its data. And both of those styles have benefits and both of those styles have drawbacks. So with callbacks, it's a nice way to do asynchronous code, it's very prevalent in the JavaScript space. And callback code will look something like this. This is Kotlin code using callbacks. So here we have an addBlog method that wants to call authenticate, and authenticate executes asynchronously, to authenticate we pass a lambda, and then inside the lambda, we call createBlogAsync, so that's going to execute asynchronously. That also takes a lambda, and inside that lambda we call processBlog. So once all these asynchronous results have returned, we can then do the work that we want to. This is a fairly standard style. And if you search on the web for something called callback hell, you'll see a much worse example of this where you have nested callbacks many, many, many layers deep. It's called a Christmas tree antipattern. If you see images of this, it's easy to understand why. So while this works, you can get lost in the details of making all of these asynchronous calls. We also have this idea of futures, or in other libraries things called promises. And Java provides a future class, and a set of future classes for us to do work asynchronously within the Java runtime. And this is generally easier to manage than callbacks. Now there are different libraries for this, so Java comes with a standard library, but there are other libraries as well we can use on the JVM. So there are many different approaches to doing futures. If you do this using standard Java, we do something call the addBlog function, call authenticate, when that's finished call thenCompose to compose this with another function. When the completes, we call thenAccept to finally process the blog and do the work on this future. This is quite a nice fluent API, but it's still an API that we have to learn, it's still extra ceremony, extra work on top of the methods we'd like to call. Well, what we'd like to do here is say go and call authenticate, call it asynchronously. When it's finished, call createBlogAsync, when that's finished, then call process Blog. Oh, and by the way, execute each of these methods asynchronously, not synchronously. We can do this using coroutines in Kotlin, and we'll see that when we use coroutines, the syntax we have is way more natural than using either callbacks or using futures. So the code we just saw written in terms of coroutines would look something like this. So we call the authenticate method, we call the createBlockAsync method, and then call processBlog. Each of these calls could be an asynchronous call. But as far as the layout of the code is concerned, it looks like standard synchronous code. So because of this, coroutines tend to be more natural to use. We'll find that when we use coroutines, if we want to build loops, for example, looping constructs with coroutines are very natural. We tend to use standard Kotlin constructs to loop. Trying to build loops when we're doing futures or when we're doing callbacks can be tricky. Same with exception handling, we can build exception handling into our coroutines very, very naturally. Again, trying to build exception handling into future code or into code with callbacks is tricky, to say the least. So the rest of this class we'll take a look at using coroutines and building asynchronous code using these coroutines. So before we get into that, we'll take a look at how we set up coroutine projects using Maven, and we'll take a look at how we set up coroutines projects using Gradle, then we'll take a look at some simple coroutines within this chapter, and then dive into the details as we go further on.

Setting up Your Development Environment
At the moments, coroutines are considered experimental. This doesn't mean that you shouldn't use them in your projects, as JetBrains have guaranteed that any code you include now will work in the future. However, what it does mean is that the coroutine libraries are not part of the standard libraries for Kotlin, the standard runtime libraries. So, in this section I'll briefly take you through how to set up a project in both Maven and in Gradle to include the coroutines libraries. So, inside Intelli-J IDEA for Maven, first of all, we'll do File, New, Project, we'll choose a Maven project, and we have Create from archetype. We do Create from archetype, and then in here we'll find there's a kotlin-archetype-jvm. And that's the one that we need. So we do Next, and give this some information, so com. rsk, and then let's just say simple for the artifactid. Do Next. Leave the defaults in this case as standard, do Next, tell this where we want to create this thing. For now I'll put this in a demos directory called demos\kotlin, then click on Finish. Create the directory. Open it in this window. And here we have the initial project with the appropriate artifacts included. So notice it's included Kotlin, we have a Kotlin version of 1. 2. 31. It's included kotlin-stdlib and some testing information as well. What this doesn't have are the libraries for coroutines. So to include those, we need to add another dependency to this list, and that dependency looks like this. So the groupId is org. jetbrains. kotlinx, the artifactId is kotlinx. coroutines-core, and the version we're using for this is 0. 22. 5. That's the version as I write this material and record this material. This may have changed by the time you're watching this, but this will work fine for the demonstrations we'll do during this class. Because coroutines are experimental, we also have to enable them in the code. To do that for Maven, we need to add a configuration section. So within the Maven project, inside the plugins, just before the execution section, we need to add a configuration section, and that configuration section just says -Xcoroutines=enable, to add to this coroutines enable as a flag when we're building the application. Now if I go into the code and look at Hello. kt, which is generated for me when I created the application, and in here it has a simple main with a simple println, printing out Hello, World. This is not using any coroutines at the moment, so we can change that by adding a call to runBlocking here, and runBlocking is a coroutine builder. And notice this import kotlinx. coroutines. experimental. runBlocking at this point. If I look at the quick help here for the tip, so at this point, if I run the code, then the code is compiling, the code is working, we're printing out Hello, World. To see a similar setup for a Gradle project, I'm going to use one of the projects we saw previously, so this is the project we used to compute the sum in an array in a collection. Inside here we have a build. gradle file. In that build. gradle file, we have a compile dependency on org. jetbrains. kotlinx:kotlinx-coroutines-core and the version is 0. 22. 5. And notice in here as well, we've added a Kotlin section, which says enable experimental coroutines. And again, we've seen this build a machine that's run already. So the Maven setup and the Gradle setups are fairly straightforward. We need to add the appropriate library and turn on experimental coroutines. And now that we have this, we are good to go. We can now go and write our first coroutine.

Writing Your First Coroutine
So like any new technology, it's often the first steps that are the hardest. We've done the setup, which is sort of a pre-step, and now we're going to write some code, but without really understanding what this code is doing. What I'm going to do is to write some code using thread structures in Kotlin, and then rewrite the same code using coroutine to give you some idea of the equivalence between the multi-threaded code and the asynchronous code, and to introduce some of the simple coroutine builders that we'll be using throughout this class. And the coroutines builder we'll be using is called launch. A simple name, it launches an asynchronous coroutine. So let's take a look at how we do that and how we use the launch coroutine builder. So this is obviously a very basic Kotlin application with essentially no code at the moment. And inside here I'm going to create a fairly complex Hello, World, and we'll do this a couple of ways. We'll do this using threads, and then we'll do this using coroutines, and take a look at the similarities, and take a look at the differences. So, the first thing I want to do is to print out the text Hello, and then we go into sleep for one and a half seconds. We do Thread. sleep and pass the value of 1500 to this, and then what I'll do is to launch a thread, so we'll launch the threads before we call println Hello. Inside this thread, we'll sleep for a second, and then we'll print out the string World. Let's change this to print so this all prints on the same line. So, a fairly complex way of writing Hello, World. If I run this code, it prints out Hello, pauses, and prints out World. So we print Hello immediately, sleep, waiting for the other thread to run, the other thread runs, we've already slept for a second inside there, and that finally catches up and prints out the value World. So in this case, we're running print Hello on the main thread, and then println World on another thread, on some pool thread, a background thread, on some thread created by the runtime. Let me comment out this code, and then let's do the same thing using coroutines. So again, I want to do a print of Hello, and again, I'm going to do a Thread. sleep of one and a half seconds. But rather than calling thread to execute some code in the background, I'm going to use something called a coroutine builder, and the coroutine builder I'm going to use is called launch. And what launch does is it'll execute some code inside a coroutine for me, and that code will run asynchronously. Now, it may run on the same thread, it may run on a separate thread depending on how we set the coroutine builders up. In this case, inside launch, I could call Thread. sleep to block the thread. However, inside coroutines, rather than calling Thread. sleep, we instead call a function called delay. So we import delay, and then we can do our println of World. So Thread. sleep blocks the thread. Delay pauses the coroutine. And delay does not block the thread. So what delay will do is it will say, ah, this coroutine wants to pause for this time, in this case, 1 second. It will cause the coroutine to pause, but it will take that thread and let it be reused for other things. So that thread can now be used for other coroutines while this coroutine is paused. When that coroutine wakes back up again, it may execute on an entirely different thread. So while coroutines are like threads, they are not exactly the same as threads. And coroutines don't have to be tied to a particular thread on which to execute; you can do that, and we'll see that a little later. So in this case, delays are a non-blocking delay, whereas sleep blocks the thread entirely. The code in this case is very similar to the multi-threaded code, but rather than using the thread builder to build a thread, we're using a launch coroutine builder to launch the coroutine. But the outcome of this when I execute the code will be the same. It'll simply print out Hello, World. And again, we see the delay there for a second while this thing is executing. So, that's our first coroutine. Very, very straightforward. So you can think of coroutines as being lightweight threads. So a coroutine is not specifically tied to a thread. They'll use threads in the background, but when coroutines are scheduled, a coroutine is scheduled onto one thread so the next time it runs it can be scheduled onto a different thread. So we can have many coroutines running on a limited number of threads. This means we can create many, many millions of coroutines where we're probably limited to creating only a few tens of thousands of threads within a process. So let's take a look and see if we can see an example of that and see how we can push the number of coroutines we create into the tens of millions. So what I'm going to do here is I'm going to create a variable to hold the result of a summation. So we'll call this variable result and we'll create an AtomicInteger to hold the result of this summation. I'm then going to spin up a number of threads. So I'll say for i in 1, make sure that's i for i in 1, 2, and initially let's try and create 15, 000 threads here. I'm going to start the thread. Inside the thread, we'll say start = true. Bring in the appropriate import, and then inside here we increment our counter. So we say result. getAndIncrement to increment the counter, and then what I'll do at the end is to print out this result. So that'll be result. get, just to see the value. So before I run this, I'm going to put a Thread. sleep here. This is just going to give all the other threads a chance to run and to catch up before we print out the results. Okay, then run this code, and we print out the value 15, 000, as we'd expect, using an atomic integer here. So how far can we push this? We try this with 15, 000 threads; how about 1 and a half million threads? So if I go in and try and run this code, so the code starts, and if I bring up the performance monitor, the Task Manager, we can see at this point we just pin the CPUs, we're running at 100% CPU across 8 cores here. So if you want to make yourself warmer, you can do this, but you're going to have CPU time. So moving this up to 1 and a half million threads doesn't look like it's a good idea, doesn't look like this is going to get anywhere very, very quickly. So, let me go and kill this process. So instead of using threads, what if instead we were to use coroutines? So rather than using Thread here, let's use the launch coroutine builder instead. We can get rid of this flag, the launch coroutine builder doesn't need to be started, it'll start automatically, and then inside here we do the same thing, we call result. getAndIncrement. We sleep for a second again, and then print out the results. And now if I run this, then we go very, very quickly, we print out the results. And we're getting the right result, we're printing out 1 and a half million, but that runs in a couple of seconds, whereas the thread code simply sat there spinning trying to create as many threads as it could and really not getting anywhere. So with coroutines we can run many millions of these things. They're much, much more lightweight than threads are, but I end up with essentially the same functionality.

Summary
So in summary then, we've taken a very brief look at Kotlin coroutines. We've seen that these provide an asynchronous programming mechanism. They are very similar to threads, and indeed when you use a coroutine, it will be scheduled onto a thread to execute. But coroutines and threads are not the same thing, and there's not a one-to-one mapping, which in a coroutine executing and a thread executing. So we can think of coroutines as being lightweight threads. We've introduced briefly the idea of coroutine builders, and in the next chapter, we'll take a look at several of these builders. So we'll take a look at things like launch, we'll take a look at runBlocking, and we'll take a look at something called a suspend function and see exactly what a suspend function is and where this is used. I hope you will join me then.

Defining Functions and Running them with Coroutine Builders
Introduction
Hi, welcome back to the Using Coroutines in Kotlin class. I'm Kevin Jones. And in this chapter, we'll actually define and run coroutines using coroutines builders and suspend functions. So the first thing we have to understand is how coroutines are started and run. Coroutines have to be run inside a context. This context sets up the code to execute the coroutine in a non-blocking fashion. And the simplest way to do this is to use a coroutines builder, and that's what we'll do in this chapter. We'll see that in many coroutines builders, such as launch and runBlocking and others as well, and we'll use a few of those in the chapter. We also find that certain functions can only be called inside a coroutine. So certain functions want to interact with the coroutines context. For example, the function we saw previously, delay. So, delay causes the coroutine to suspend itself in a non-blocking fashion. The delay function only makes sense to be run as part of a coroutine. So we need a way of letting the compiler and other code know that these functions are allowed to run inside a coroutine. To do that, we mark functions with the keyword called suspend. And in this chapter, we'll take a look at how we write those functions and how we use the suspend keyword. So, coroutines need to be managed, they need to run inside a context, and to do this, we need to be able to build a context. And this is the job of a coroutine builder. And as we've said, there are coroutine builders such as launch that we've seen, there's runBlocking, and there are others as well. So let's take a look at how we run coroutines and how we use these coroutine builders.

Using Coroutine Builders
So let's revisit the demo from the previous chapter. In that demo, we printed out Hello, World. We did it in quite a complex fashion. So we had println Hello, followed by a Thread. sleep where we slept for a second and a half, and then before that we used the launch coroutine builder, and inside here, we slept, we suspended the coroutine for a second, in fact, we called println to print out World. And if I run this, we get what we expect, it prints out Hello, World. So if we think about what happens here, we run main. Inside main, we call the launch coroutine builder, so that launch executes immediately. And that creates a coroutine for us. That coroutine is waiting to execute. It'll be scheduled on a thread, and then be run at some point in the future. We then call print Hello, and then sleep, or suspend the main thread. So that main thread is now blocked, and while it's blocked, it gives any other threads a chance to execute. Our coroutine is executing on some other thread, some background thread. That now has the chance to run. That will delay for a second, so the delay will execute there. After the delay returns, we print out World. And then the main thread will probably wake up again after the second and a half, and that will return, main will finish, and we drop out of the code. In this code, we have two sorts of codes. We have blocking codes, and we have non-blocking codes. So when we call print and then we call Thread. sleep, Thread. sleep blocks the main thread. Inside the coroutine, inside launch, and we call delay, that does not block that thread. It suspends the coroutines, the coroutine goes into the background and waits for the delay to finish, but the thread itself is able to be used. So we have these two worlds here. We have the blocking world on the main thread, and we have the non-blocking world inside the coroutine. And the job of the coroutine builder is to let us run things inside the non-blocking world. So, things like launch, so they go away and run this thing inside the non-blocking world. So it'll launch the coroutine for me. We can call blocking APIs inside the non-blocking world. So, inside the launch coroutine here, I can call Thread. sleep. And if I call Thread. sleep and pass it the value of 1000 and run the code again, the output of the code is the same, but the effect of calling Thread. sleep is drastically different to the effect of calling delay. When we call Thread. sleep that blocks the coroutines thread. Remember that delay doesn't block the thread; delay just says, put the coroutine to sleep, but leave this thread available so that other things can use it. As we saw in the previous chapter, coroutines are very, very scalable. We run a million and a half coroutines and the system didn't even blink at that. That's because coroutines are non-blocking. So when a coroutine goes to sleep or delays, it leaves the threads in use, and that thread can be used to schedule other pieces of work. So the first thing to think about is that we need to very careful when inside a coroutine that we don't use blocking calls. So let's take this code out. So what about the opposite? What about trying to call non-blocking code from the blocking world? So here, for example, if I try and call delay, at this point, we get an error. And the error says suspend function delay should be called only from a coroutine or another suspend function. So what does this mean? So first of all, let's go and look at delay itself. So this is the delay function. Let's not worry about actually what this does. But notice that the function is marked with a suspend keyword. So that sort of picks up the first part of our error, suspend function delay. So delay is marked with a suspend keyword. The suspend keyword tells the compiler and the runtime that this function can only be called for inside a coroutine. It can also be called from inside another suspend function, but that suspend function can only be called from inside a coroutine. So delay interacts with the coroutine to work with the coroutines. So delay can only be called from inside a coroutine, so inside the non-blocking world if you like. So, launch is a coroutine builder that lets us execute a coroutine. But the launch function returns immediately. So I call launch, that returns, I then drop to the next line of code and start executing the next line of code. Suppose, however, we wanted a block, I wanted to run some coroutine codes, but wait until our coroutine code is finished. So that's the job of another coroutine builder called runBlocking. So let's take a look at that.

Run-blocking Coroutine Builder
So here we are back with the code we saw previously. We used the launch coroutine builder to launch off a coroutine and delay, we print out Hello, and then we sleep. Now we ask the question, suppose you wanted to call delay here? So I want to delay for 1 and a half seconds. We can't do that because delay is a suspending function; it can only be run inside a coroutine while inside another suspending function. So we could wrap delay inside a coroutine, so I could call launch here to do that, but if I do that and put the delay inside launch, launch will launch the coroutine, but it will execute it on a background thread. So we're not going to delay the main thread. What we need is a coroutine build that will run and block until the coroutine itself is finished. And there's one of those built in for us, and that coroutine builder is called runBlocking. So the idea behind runBlocking is it says, yes, I want to run this coroutine, so now we can run delay inside here because delay is now running inside a coroutine, but runBlocking just blocks the main thread, it blocks until the coroutine itself is finished. This seems slightly odd at first, but it does have its uses, as we'll see in a moment. So, if we go and run this code, let's see if the code works as before. So inside the code, we print out Hello, World, we've used delay inside the launch coroutine builder, and we used delay inside the runBlocking coroutine builder. I suppose one advantage of this is that this is pure coroutine code. So we don't have any threading code here, we are living purely in this non-blocking world essentially here. However, this really is non-idiomatic. You rarely, if ever, put a runBlocking call inside your code like this just to run some suspend functions or some coroutine functions. Instead, the typical way of doing this is to make the entire main function a coroutine, and we do that by saying = runBlocking. So now what we've done is we've made the main function a coroutine, but it runs as a blocking coroutine, so it runs in a similar way to when it's not a coroutine, but now inside here, because we're inside a coroutine, we can now call delay. And notice here as well, we can call coroutines inside coroutines, so launch is being launched from inside main, main is itself a coroutine. You'll often see runBlocking used this way. More completely, runBlocking returns a type, and you have to do it this way, so a runBlocking of type Unit. Here the IDE is telling me that we don't really need to specify the generic type of this. For completeness sake here I'll leave it in, and there are occasions when you have to supply this, as the runtime itself can't work out what this generic type should be. Again, if I run this code, code works the same way. So again, we print out Hello, World from inside the code. A common place you're going to see runBlocking is when you're writing tests. So you want your tests to run completely, but inside the test, you'll be writing or testing coroutines. So you mark the test as runBlocking, and then inside the test call your suspend functions, so you can test the suspend functions in an environment where you know the tests will run to completion and allow the suspend functions to execute. What if you wanted to write your own functions that interacted with coroutines? So, for example, here, let me tip the runBlocking callback off, so delay is no longer valid here. So what I'm going to do instead is call a function, we'll just call it doWork. So inside this function, we're doing some work that's going to take awhile, and we want to run this thing inside a coroutine. And we know this function can execute inside a coroutine or must execute inside a coroutine. So, if I let the IDE create the function for me, and then inside here, we might do some work, and to imitate that we're doing some work, let's just call a function, let's just call delay. And we know delay is itself a suspending function. So I'll hover over the error, we've seen this before, it says suspend function delay should be called only from a coroutine or another suspend function. So, this thing either needs to be inside a coroutine itself so I can use launch or runBlocking, or I can mark doWork as a suspend function. So we use the suspend keyword and say suspend fun doWork, but we've now just pushed the issue down one layer. And if I hover over doWork, it says suspend function doWork should be called only from inside a coroutine. So we can mark our own functions as being suspend functions, and that says this function can only be run from inside a coroutine. And again, it fixed this issue, again, we can just make our main function a runBlocking function. So now main is a coroutine, it's going to block until the coroutine finishes, inside here we're calling doWork, doWork is a suspend function, which means that inside here we can call other suspend functions such as delay, and other things we'll see during the course of this class. Again, just one last time, if I run this code, and as you're sick of seeing by now, it prints out Hello, World.

Testing Suspending Functions
Suppose you wanted to test doWork. So, doWork is a suspend function. And as we've seen, this can only be called from another suspend function or from a coroutine. So how do we test this? So, in my project here, let's go to my test section, and let's add a new Kotlin class, and let's call this thing SimpleTest, and we'll make this thing a class. So inside here, let's try and write a test, first of all. So let's go and add a test annotation, we'll create a function, and the function is going to be called, really badly named, never, ever do this, firstTest. So inside here, let's just add an Assert, first of all, just to show that this test is working, so Assert. assertEquals, and we'll say expected as 2, actual is 1 + 1. And we would expect this to pass, but I just want to show the tests are running, so we run SimpleTest, and sure enough, everything is agreeing. But suppose I want to call doWork inside here and test the call to doWork. Again, if we hover over this, we've seen this before, suspend function doWork should only be called from a coroutine or another suspend function. So we can simply call our suspend function to test it. So let me just comment that out, and let's go and add a second test. So we can do @Test to add our test, fun secondTest, even more badly named than the first one. Let's copy the assert again, so we know the test will do something, and then I will call to doWork. So I said previously that one use of runBlocking is for testing, and you can sort of imagine how this works now. So here I can make my second test a coroutine. If this was a coroutine, then we could call doWork because a suspend function can be called from inside a coroutine. So to make this a coroutine, we have to build the coroutine. What's the best coroutine builder to use? Well, it's runBlocking. So if I mark the secondTest as runBlocking, that does two things. It makes the test a coroutine, but it also means that the coroutine will block until it's completed. So we guarantee that doWork will be called and any asserts that we have in here will also be called. So I go back and run all the tests. Both tests run, and we're able to call suspend functions. So we now have a way of testing our suspend functions. And this is probably the most idiomatic use of runBlocking within Kotlin.

Summary
So in this chapter, we've taken a brief look at using coroutines. We've seen how we use coroutine builders to run coroutines. And we've seen the different types of builders. So far we've looked at two of these. We've looked at launch, and we've looked at runBlocking. So launch does what you'd expect, launch launches the coroutine, schedules this thing to run on a thread, and lets the main thread where we call launch carry on working. So launch is like creating a new thread and having our work on that background thread while the main thread carries on. RunBlocking is a slightly odd beast. RunBlocking lets us bridge between the blocking world and the non-blocking world. So what runBlocking says is run any code inside here, but block, wait, until this coroutine is finished, and then carry on running. So we run the code, block, and then carry on the main thread. So, we've seen that we can also create suspend functions, and suspend functions are marked with a suspend keyword. These things can only run inside a coroutine context. So you can call a suspend function from another suspend function, but eventually the top suspend function you have must be run from inside a coroutine. There are occasions where we want to run suspend functions outside the standard coroutines. For example, we might want to test them. And that's the primary use of runBlocking. So runBlocking allows us to build this bridge between the blocking world and the non-blocking world such that we can do unit tests. For example, one of the simple examples we've had to let main run as a blocking coroutine. So now that we've seen how to build simple coroutines, in the next chapter, we'll see these things in more details. We'll see how to use coroutines, we'll take a look at job objects, we'll see how coroutines can talk to each other, how coroutines interact.

Waiting on, Join-ing to, and Cancelling Coroutines
Introduction
Welcome back to my class on using coroutines within Kotlin. My name is Kevin Jones, and in this chapter we'll see one way we can interact with coroutines. In particular, we'll see how we can wait on, join to, and cancel coroutines. So up until now, we've seen how to create coroutines with coroutine builders. But suppose you want to wait for a coroutine to finish. You've caused the coroutine to do some work, you're waiting for the results of that work, and you want to do some further processing when you have those results. Delay simply doesn't cut it. While you can use delay, just a pause and wait for a coroutine to finish, you have no idea how long that coroutine is going to take. You could delay for a second and the coroutine takes a tenth of a second, you could delay for half a second and the coroutine takes 5 seconds. You can't simply use delay. You need a way of saying to a coroutine tell me when you're done. So the way we do this, the way you wait until the coroutine is finished is by using a function called join. So we call join and by using join, one coroutine can wait for another. Conversely, suppose if you can't wait any longer. You think I've been waiting long enough, this coroutine looks like it's never going to come back, it's taking too long to execute, or we've spun up four or five coroutines, when the first one comes back we'll use its data, but we don't want to use the data from the other four. To do this, you want to cancel the coroutine. So in this chapter, we'll see how we do both these things. We'll see how we can join to a coroutine and we'll see how we can cancel the coroutine. So join, first of all. So joining a coroutine is similar to joining a thread. The calling code blocks until the coroutine has finished. So we spin up a coroutine, we then join to that coroutine, and we'll see how we do that in a moment. When we join we now block until the coroutine we've joined to has finished its execution. If you've done any multi-threaded code, you'll know this is very similar to the way one thread waits for another thread to finish. We do this via something called the job interface. So, when we call launch to launch a coroutine, launch returns something of type job. This job object that we get back has a join method, and we can call this join method to join the coroutine. So by calling the join method, we are now waiting on the other coroutine. There are some other things we can do on the job interface. For example, we can check to see if the coroutine we are joining to has already finished. So it's possible I guess to poll the coroutine and say have you finished yet? If it has finished, we can do one particular thing, and if it hasn't finished maybe we go off and do something else, or maybe at that point we decide we've waited too long and we can then cancel the coroutine. So let's see how this works. Let's go and write some code to join coroutines.

Joining Coroutines
So back to our original demo. So again, we're calling launch, we're launching a coroutine, we print hello, wait for the coroutine and print World. Again, just to prove this thing is still working, sure enough we print Hello, World. So we said we didn't really want to use delay here, as we don't know how long to wait for. So what we can do instead is join the job. So by joining, we wait for the coroutine to finish, and then in this case we can finish. The way we do that is by using the return value from launch. So if I take a look at the launch definition, we can see that launch returns something of type job. And if I look at the job definition, there's a few things here we'll come to a little later. So job has a companion object, which holds a key, and we'll see how that key can be used a little later on in this chapter, and if I scroll down here, we'll see the job has various properties, isActive, isCompleted, isCancelled. And if I keep scrolling down, we'll find our join method. So we can use join to join this coroutine. So if I go back into my original code, I can say val job = Launch. And then rather than calling delay, I can say job. join. So now we'll launch the coroutine, we print Hello, we then join to the coroutine waiting for it to complete, that will delay for a second, print out World, and then we should be done. Again, running the code, should work in exactly the same way, slightly more efficient. We're not delaying for some arbitrary time now. We're just saying wait until this coroutine is completely finished and then come back to me, and then I can carry on doing whatever I was doing.

Cancelling Coroutines
Joining coroutines is fairly straightforward. But what about cancellation? Cancelling coroutines is a little more involved, as we'll see as we go through this. So we'd like to be able to cancel a coroutine if it runs too long, for a given value of too long, so obviously this is an arbitrary decision, it's up to us to decide what we mean by too long. It may be that we expect some to run within a certain time, and if it hasn't done that, then we might want to cancel it. It might be that we've kicked off two or three coroutines to go and do similar tasks, and we just want to use the data that comes back from the first one to return, in which case we can cancel the other two. So we have the option within a coroutine to cancel it. But there are things we need to think about when we do this. So, if we cancel a coroutine, what about any resources it has open? What about exceptions that are thrown as part of the cancellation? How do we go about dealing with these things? So when we do cancellation, we have to be careful about how we do this. And, in fact, because of this, cancellation is cooperative. So from outside the coroutine, I can try and cancel the coroutine, but unless the coroutine itself cooperates with me, it won't be cancelled. It will carry on running. And this is really important, the coroutine itself could be doing things that are simply not cancellable. So simply shutting the coroutine down is generally not a good option. So, within the coroutine itself, if we don't check for cancellation, then we won't be cancellable and we won't be cancelled. So if I rate a function a suspending function, that suspending function has to check that it's being cancelled, and then when it's being cancelled, it can end. Again, this is similar to threads. When we want to cancel threads, we tend to do this in the cooperative manner, and there's no built-in mechanism for this for threads, but we generally have some sort of flag, some sort of Boolean that we set when we want to tell the thread that it can cancel itself, that we no longer need it. The same is true with coroutines, but with coroutines this mechanism is built in essentially. Now, all built-in suspending functions cooperate. So, for example, if you're in the middle of a delay function and you cancel the coroutine, delay will check to see if it's been cancelled, and if it has, the coroutine itself will become canceled. There are other built-in suspend functions as well as delay, and they are all cancellable functions, so we can cancel all of those things. So how do we cooperate? So if we want to write a suspend function, how do we go about writing a suspend function that can be cancellable? Well, there are two ways of doing this. Your suspend function can itself call a built-in suspend function, and that built-in suspend function will check for cancellation and do the appropriate thing. And a good choice for this is the yield suspend function. So yield just says give up this coroutine for a short amount of time and then come back to me and let me do the work. With yield, you can yield for 0, for example. You can just say yield 0, that will give up the thread the coroutine is running on, check for cancellation, and if it's being cancelled, cancel the coroutine. If it hasn't been cancelled, you come back and you carry on doing the work. You can also withinside the coroutine explicitly look and see if you've been cancelled. We've just seen there's a job object, the job object has a cancellable property, and you can look at that property and say have I been cancelled? And if I have, then stop working, exit the coroutine. So either of these, so depending on exactly what you need, depending on whether you want to do the work yourself, you can choose either of these options, and either one is fine, both of these are supported, and both of these are called out if you read the coroutine documentation. Okay, so let's go and write some demo code to see how we can do cancellation. So to show cancellation, I'm going to create a long-running job. So, let's do something like this. We'll say val job = launch, and inside the launch, we'll loop for 1000 iterations, and inside this loop let's just print a dot. So that'll print out 1000 dots. Also that will run very, very quickly. So before you print the dot, let's delay for a tenth of a second, 100 ms. So this will simply create the coroutine for me and start executing it. If we do nothing else here, main will exit and we'll stop the coroutine. So to stop that happening, let's put a delay inside main, so we'll delay by 2 and a half seconds to allow us time to print out 24, 25 dots from withinside the coroutine. Notice that I've marked main as runBlocking, so I can call delay inside here. And then what I want to do is once this returns, I want to cancel the job. So to do that, we call job. cancel. So that will simply cancel the job for me. Now cancellation is cooperative, so at this point, I've asked the job to cancel, but I don't know if it's cancelled yet. So if we leave it like this, I'll call job, I'll cancel, and again, main could exit before the job itself is cancelled. So once I've asked the job to cancel, I then need to wait on the job. So to do that, we do job. join. We can then say done, and then exit main. So if we run this code, we should see 20-something dots printed out, 24, 25 dots printed out, and then the job should end. So again, we'll go and run this, print out a number of dots, and then finally print out done. So we wait two and a half seconds, leave the printed dots out, call job. cancel, wait for the cancellation to happen, and then call job. done. So this is such a common idiom, we do this so frequently, that there's a single call we can make, and that single call is job. cancelAndJoin to do this all in one go. And again, if I run this, we should see exactly the same behavior. So we see the dots printed, cancelled, join, print out done, and everybody's happy at that point. So that's very, very simple cancellation. And here the cancellation is managed by the call to delay, so delay one of the built-in suspending functions and delay knows how to process a cancellation.

Co-operative Cancellation
So we've just seen job cancellation, but in that case, we use one of the built-in suspending functions to manage the cancellation for us. But suppose we want to do this ourselves. Suppose in our own code we wanted to cooperate with cancellation. So the way we do this is by using a property called isActive, and isActive tells us whether our coroutine has been cancelled or not. When we create a coroutine, we get past something called a coroutine scope, and the coroutine scope contains this property. So it contains the isActive property. We can access this property from inside any builder. So from inside the launch builder, the launch builder has been passed this coroutine scope, and I can look at the isActive property simply inside of the builder at any time and use this to decide whether or not we've been cancelled, and if we have, take the appropriate action. If I'm inside a suspending function and I want to take a look at this property, we can't do that, at least at the moment. Apparently this is coming, so at some point in the future you will be able to do this, but currently you can't simply go and look at the isActive property. However, there are other ways of doing this, so instead of suspending function, there's another mechanism we can use to go and look at this property. We'll see that in the next chapter. So in this chapter, we'll see how we can cooperate inside the coroutine builder; in the next chapter, we'll see how we do this inside the suspending function itself. So, let's go and take a look and see how we do cancellation through cooperation. This is the code we saw earlier. We've made a couple of changes. We've changed some of the timings. We're delaying 100 in both cases. And we're still calling cancelAndJoin. So here if I run this, we print out a couple of dots, and then we're done. To prove that it's delay, that it's managed in the cancellation for us, let's change this to a Thread. sleep. So again, a Thread. sleep in this case of 100 ms, and again, if I go and run the job, so now we've done delay, we've called cancelAndJoin, but we haven't cancelled. This is going to run for 10 seconds, and at the end of the 10 seconds, print out the done report and then it will finish. So the Thread. sleep is not taking part in the cancellation. It was the delay that's managing the cancellation for me. So you have a scenario here where we're not cooperating, and if we don't cooperate, we don't get cancelled. So, another way of involving ourselves in cancellation is to use something like the yield function. So yield says give up control to this coroutine, let something else execute, and then come back to me. But yield will also allow us to take part in cancellation. So again, if I run this, we launch the coroutine, we call yield, at this point it's running very, very quickly, so we are print out many, many dots, but we do eventually cancel. So we call cancelAndJoin and print out done. That shows that we have returned from cancel, we have cooperated, and we have taken part in the cancellation and cancelled the coroutine itself. We could even mix the two, so inside here we could call now Thread. sleep. I'm not sure why somebody would want to do this, but you could now sleep and yield, and in this case, if I run the code, we print out some dots, and again, because yield is running, yield will check the cancellation flag and if we've been cancelled, we'll stop the coroutine for us, and we'll print out done to show that we've ended. So here we're doing cancellation, and we're relying on the in-built suspend functions. Suppose we wanted to manage the cancellation ourselves. So let's take a look at a slightly different technique here. So, inside the coroutine, we'll print out a dot, we'll do a Thread. sleep, which we know is non-cancellable, but then rather than calling yield, we'll check ourselves to see if we've been cancelled. And to do that, we'll use the isActive flag. So I'll say if I'm not active, which means I've been cancelled, at this point, what we need to do is to throw an exception, and we throw the exception to tell the coroutine builder, to tell the coroutine infrastructure, that we've been cancelled, and to cancel this coroutine. And the exception we throw at this point is CancellationException. We throw a CancellationException, that's picked up by the coroutine infrastructure, and that will cancel the coroutine for us, cause the coroutine to end, we'll come back, print out done, and we should see the same result. So again, if I run this, again, it's now us, again, it's the coroutine being cancelled, but now we are doing this, and we are doing this by checking the isActive flag inside the coroutine ourselves. So if we never have occasion to want to call another suspend function or one of the built-in suspend functions, we don't want to call yield for whatever reason, we want to manage the cancellation ourselves by doing some processing before we get cancelled, then we can check the isActive flag to do that. Throwing a cancellation exception is what the built-in suspend functions do on cancellation. And in general, this is a good idea, as it allows us to catch the exception and then tidy up. However, if we know we're handling cancellation ourselves, there are other things we can do. So what I could do here, for example, is check isActive and then return. Now because I'm inside a nested lambda inside a coroutine, I can't just put return here. We have to use a non-local return. So to do that, I can either do return@launch, which says return out to the outer caller, or I can do return@repeat. I have to be careful what we do here. If I move this print call, so it's before the call to not isActive, and then run this code, we are simply repeating every time. So in this case, we're not cancelling properly. So we call repeat, we print the dot, we say if I'm not active, return, but we just return back to the repeat call again, do the next one, do the next one, do the next one, eventually repeat ends and out we come. And we can see if I scroll across here how many dots are being printed out. There will basically be 1000 dots printed in this case. If I change this, so rather than doing @repeat, we do @launch and run the code, then we get far fewer dots. So now what happens is we start the coroutine, we print out the dots, we cancel, we then return out of the coroutine, and we are done.

Handling Exceptions
We've just seen how to use cancellation, and we've seen that if we use one of the built-in suspending functions, then that will manage the cancellation for us. Or within our own function, we can look at the isActive properly and then manage cancellation ourselves. We saw that using isActive, one way to cancel would be to throw an exception, and we threw cancellation exception. The built-in suspending functions do the same. So when we cancel something, if we are cooperating and we're using the built-in suspending functions, then cancellation throws exceptions. Now all suspending functions will throw an exception when cancelled, and the exception they throw as we've just said is CancellationException. We can use this to close any resources that our code is using. So within our code, we could wrap the coroutine in a try catch, catch the CancellationException, and then close down any resources, shut any resources, and make sure we tidy up behind us. There's one other issue here, though. If we have a try in our code, we'll often have a try finally. And inside that finally, we might want to run some cleanup code. That finally will need to run suspending functions; however, what we don't want to happen is for those suspending functions to be cancellable. So what could happen is we end up inside our finally block, we are calling a suspending function, somebody cancels, and that suspending function throws CancellationException. So what we can do is inside a finally block, we can use a special context. Now we haven't really talked about coroutine context yet, that will come up in the next chapter, but we'll sort of take a glance ahead here and take a look at the context we need to use to ensure that when we are tidying up inside our finally block that the tidying up code itself does not throw any exceptions, or at least does not throw any CancellationExceptions. We can also, when we are cancelling, specify the reason for the cancellation, so we can do that by calling job. cancel and passing it CancellationException with some text. And we can use that text or the data inside the CancellationException within our coroutine to see why we were cancelled, and maybe do something based on that. You could also specify any other exception, so you could call job. cancel and pass it some exception. However, be very careful with this. If we use the launch coroutine builder and somebody cancels our work, passing an exception, that exception gets passed up the call stack, and as it gets passed up the call stack, it'll tear down the thread and probably kill the application in which the exception was thrown. Now, if we're using the async coroutine builder, which we haven't seen yet, then we can use our own exception type. But just be careful. If you are going to cancel a job, it's probably best to use the CancellationException, not to use some random exception type to do that cancellation. So now that we've done that, let's go and write some code and see how we handle these exceptions. This is the code we've been using to play with cancelAndJoin, so just run this, just to show that it still works and print out some dots, we cancel, we wait, and then we're done. So what we can do is inside here is wrap this code inside a try catch, so we can do try catch, and then in here we can catch an exception, and let's catch an exception of type CancellationException. While inside here let's print a message, we'll do a println, just make sure we do it on a clean line, and then we can just println the message, so we'll just say println cancelled. We can also provide a finally, so we can say finally, and again, we'll add a couple of printlns to this, and now if you run this code, we can see we print the dots, and then we print cancelled, and then we print In finally. So we can see that cancellation when we're using cooperating cancellation, we're calling yield here, throws an exception. And we can catch the exception, and we can handle that exception. Now, suppose that with In finally we want to run a suspending function that makes sure suspending function won't throw an exception, so won't be cancelled. So what we can do inside here is we can use another coroutine builder. In this case, we can just use run, it just says go and run this code for me. But to this coroutine builder, we pass what is essentially we can think of at the moment as a flag. So we can say NonCancellable. And then we can wrap our code inside this NonCancellable coroutine, then if we are calling a suspend function in here, and somebody else cancels the job immediately, no exception will be thrown. So the finally block will run to completion without throwing any exceptions. If I run this, we're not going to see anything different at this point, just the fact that the println In finally will be executed as before. Suppose we want to pass our own reason for cancellation, maybe to log the reason why we were cancelled. And we can do that, but to do that we have to split cancelAndJoin into two calls. So, we have a job. join and a job. cancel, and then to cancel we can pass a CancellationException, and then to this we can pass our own reasoning. So we can say Too many jobs, for example. And then inside the catch block, we can print out that message. So we can say Cancelled, and let's use our string interpolation and say ex. message. And if I run this code, we see the cancelled message tells us why, there are too many jobs. We can also pass any other exception. So here we're catching CancellationException. We don't always in our code catch these exceptions, we just know that if the job is cancelled it'll return and we can carry on processing. The coroutine infrastructure will catch these exceptions for us and make sure they're not propagated. However, if I throw another exception, let's just throw exception here and run the code again. So notice a couple of things have happened. We've still got the CancellationException because we know that's been thrown, we still have the finally block, but the other exception has been thrown, and that exception simply gets passed up the call stack. So, we then end up throwing an exception inside thread main. So if we do this in standard Java code or standard Kotlin code, so this exception gets thrown to the top of the thread, and that thread will exit, and it will exit in an unknown state. So we could be leaving locks in place, we could be leaving many other resources in place that should be tidied up. So almost certainly you should never be throwing exceptions in cancellation other than CancellationException.

Handling Timeouts
So one reason for cancelling coroutines is if we're deciding they're taking too long. So we know we can join, but join doesn't take a timeout, it's when we join to a coroutine we're going to wait forever. So we might just want to check the coroutine, see if it's still active, and if it is and we're running out of time, cancel the coroutine. However, a better mechanism will be to simply timeout. And in Kotlin coroutines, we can do that, we can use timeouts within our code to say after a certain amount of time, I no longer want to wait for this coroutine, you can cancel it and we are done. So if we could timeout the code, then we don't need cancellation. We don't need to call the cancel method explicitly. Again, this is the code we are going to use to show the timeouts, similarly to the code we've seen previously. Again, just to show this working. Run the code. So we're waiting a tenth of a second, and in that time we print out a number of dots. So in the past we've joined this code and we've cancelled this code. What we'd like to now is to say, well, I actually only want to run this 400 ms, and after that I'd like you to timeout, so if it takes longer than that, timeout and cancel the coroutine. To do that, we use another coroutine builder, and that coroutine builder is withTimeout, and we pass it a timeout. So in this case, we're saying it's 100, it defaults to milliseconds, we can change that. So if I execute this code now, the coroutine runs for 100 ms, and then what happens is a timeout fires and the coroutine throws an exception. And if I go to the end here, we get exception in main, exception in thread main, and the exception that's thrown is a TimeoutCancellationException. So if we are going to use timeouts, then we have to handle this exception. So essentially this behavior falls back onto us. We are saying with timeout, the timeout in the background is just checking how long the coroutine is running. When we've run for too long, it's going to throw an exception, and we need to handle that. So this isn't ideal, having to wrap the entire withTimeout inside try catch just in case it times out. So there is another way to handle this. So let me get rid of this try catch. And then rather than calling withTimeout, we can call another coroutine builder called withTimeoutOrNull. So now what will happen is if the coroutine works, the job object will be set. If the coroutine doesn't work, then the job object is set to null. So let's check that. So we can say if job = null, then let's just print a message here, do a println timedout. And if we run this code, we can see indeed that we time out in the code.

Summary
So we know we often need to wait on coroutines or we often need to cancel coroutines. So in this chapter, we've seen the use of join, so that one coroutine can wait on another. We've seen the use of cancel, and mentioned that cancel is cooperative. To cooperate, we can use one of the built-in suspending functions, so delay or yield, or we can manage the cooperation ourselves by looking at the isActive flag. In either case, you need to be careful of exceptions. So, a CancellationException will be thrown, which you can process within your code to do any extra tidy up that is needed. You can also in theory throw any other exception for cancellation, but be careful when you do that because the exception will be propagated up the stack frame. You can also use timeouts. So you can use withTimeout to say this coroutine times out after a certain time, that will throw an exception, to a timeout exception, so again, be careful of that. Or you can use withTimeoutOrNull, which will return null when the coroutine completes if the timeout has expired. So doing this chapter and in previous chapters we've briefly mentioned something called a coroutine context. So in the next chapter, we'll take a look at that coroutine context and see how it's used and see how it's used to make coroutines very, very extensible. So join me then.

Understanding Coroutine Contexts
Introduction
Welcome back to the Using Coroutines in Kotlin class. My name is Kevin Jones, and in this chapter we'll take a look at coroutines contexts, understand what they are, and how to use them. So all coroutines run as part of a context. And that context determines how to coroutine behaves. The context is created by the launcher, and we haven't discussed this yet, but coroutines can have child coroutines, and we can flow the context from the parent coroutine to the child coroutine. So the child coroutines can inherit some of the behavior of the parent. The framework comes with different contexts, and we'll see what these are as we go through this chapter. And we can also do what's called joining context on merging contexts. So we can take some data from one context and merge it into another, and use that combined context to launch a coroutine. So one of the things defined by a context is a dispatcher, and this dispatcher determines the thread on which the coroutine is run. We can run coroutines on either a pool thread, so something like the fork/join pool thread, we can use something called an unconfined thread, and we'll come back to this unconfined thread and what this means later, or we can specify our own thread, so we can create a thread and say I'd like you to run the coroutine on this thread, please. We do this through a dispatcher, and we supply the dispatcher as part of the context when we create the coroutine. We have different contexts built into the framework, and each of these contexts defines the thread on which the coroutines can be run. And these are listed here. So these are the names of the context, so there's an unconfined context, there's a newSingleThreadContext, coroutineContext, the CommonPool context, or the DefaultDispatcher. And we'll take a look at each of these in the next demo, and we'll see the behavior each of these has for a given coroutine. So why don't we take a look at that now. We'll write some code and our code will specify the context, and we'll see how that changes the thread on which the coroutine is run.

Examining Coroutine Contexts
What I'd like to show first is the thread on which a given coroutine runs. So to do that, we're going to create a number of jobs, we're going to launch these jobs, and we're going to add each job we create to a list of jobs, and then we'll wait on every job on that list for each job to finish. Each job when it gets launched will just print out the name of the thread it's executing on. I've created a createJobs function, it's an extension function of CoroutineScope. And the reason we've created this as an extension function of CoroutineScope is that we need to use a couple of parameters from CoroutineScope, a couple of members, in particular defaultDispatcher and coroutineContext. So, inside this function, we're using the launch coroutines builder, and we're using it in a way we've seen it before and in a way we haven't seen it before. So here the first one we call launch, and inside here when the coroutine gets launched, it's using the default context. So we print out default, and then we print out the name of the thread on which we're executing. And then the subsequent launches we specify the context on which I wanted this thing to run. So we specify the DefaultDispatcher context, the Unconfined context, the coroutineContext, the CommonPool context, and the newSingleThreadContext. In main, I create an ArrayList of Jobs, I call createJobs to create each of these jobs, and then wait on the jobs. When each job is finished, then the main will finish, but at the end of this we'll have printed out the names of the threads that we're executing on. So if I run this, so what can we see? So these don't necessarily finish in the order in which they were created, so default here is the default context, and in this case, we create a coroutine on a thread from the ForkJoinPool's common pool. So we get this commonPool-worker-1 thread that uses the default context. And if you notice both default, which is the name I've given it, defaultDispatcher and commonPool all use the ForkJoinPool. You can change this behavior, so you can create your own thread pools and you can specify a thread pool in the context for it to use. Unconfined runs on the main thread. We'll take a close look at the Unconfined context in a later demo. The coroutineContext also runs on the main thread. So notice the comment here, when we launch with a coroutineContext, we use the context of the parent, and the parent context is wherever our main is running in. Main is running inside runBlocking. So that uses the context of the parent coroutine. So we'll get main thread. And then the last one we see printed out is the newSingleThreadContext. So for that, the value for this is OwnThread, that's just text we pass in, and we see when we create the newSingleThreadContext coroutine, that runs on a thread called OwnThread. So that will get its own thread to run in. And again, we'll come back and take a look at newSingleThreadContext a little later. So we can also take this createJobs call and run it inside another context. So, let's just put some printlns here to put some spacing in, and then call launch to launch coroutineContext, and then inside here just do exactly the same thing called createJobs and print out each of those jobs. We'll also list the name of the thread this coroutine was launched on. So, again, let's run this. So for the original call to createJobs, again, we get the default defaultDispatcher and CommonPool running on the ForkJoinPool thread as we'd expect, Unconfined and coroutineContext are running on thread main, and newSTC runs on its own thread. If I look at the threads run inside the launch coroutine, the launch thread is on the ForkJoinPool. Default, default dispatcher, and CommonPool are also the ForkJoinPool. CoroutineContext, remember, is the parent context, and the child coroutine we create runs on the context of the parent, and the parent context is now ForkJoinPool, not main. So the coroutineContext is now the pool context we run inside that, Unconfined runs within the context on which it was started. When we're running from inside main, it runs on the main thread, and now we're running inside a launched context, it runs on whatever context was given us, whatever dispatcher was used, so that would be ForkJoinPool again. The only one that's the same is newSTC. NewSTC still runs on its own thread. So you can see that depending on the context you use, the coroutine will run possibly using a different dispatcher, and you have some control over this. You can specify the sort of dispatcher you'd want to be used for your coroutine, and obviously the dispatcher you use may change the behavior of that coroutine. So this gives you quite a lot of flexibility in how your coroutines are executed. So we've seen that when we create a coroutine, we can specify the context, and that context will specify a dispatcher. So just to briefly go over what each of these dispatchers are, if you choose CommonPool, then this will use the fork/join pool. This is the default pool used in the current implementation. This could change in the future, so it's possible, although unlikely in the short term, that in future versions of coroutines, rather than using the fork/join pool, there may be some other pool used to run coroutines by default. If we specify coroutineContext, then that inherits the context from the current coroutine. So if we're running on the main context, we'll launch inside that context. If we're running from inside another coroutine, we'll use the fork/join pool context almost certainly. DefaultDispatcher, just pick whatever the default one is. And again, at the moment, default is the fork/join pool. We can also specify newSingleThreadContext. So this runs the coroutine on a specified thread, and as we see here, this is an expensive operation because we have to create a thread to do this. If we're using the pool threads, it is highly likely that that pool is being created and those threads already exist. Here we have to spin up a thread each time you want to do this for a newSingleThreadContext. Expensive operation and also the thread has to be managed by your code. So we'll take a look at this later on in this chapter. And finally, unconfined. So this is a slightly unusual one. This start the coroutines in the calling thread until you hit the first suspension point. After that, it resumes the coroutine on a thread as determined by the suspending function. So what do we mean by that? So let's take a look at the unconfined context now and see what happens when we use this thing. So what we have here is something similar to the last demo. I'm launching a coroutine, I'm specifying coroutineContext as the context. Then inside here I'm printing out the name of the thread I'm running on, delaying for 100 ms, and then printing out the name of the thread that I'm running on after the delay. And if I run this code, what we should see is that the thread name both before and after the delay are the same. So, we're running on the thread, on the main thread, and we're getting that main thread because our main is runBlocking. What I can now do is change this launch, so rather than being coroutineContext becomes Unconfined. And then we run the code. So now it says coroutineContext, and of course, it's now undefined context. So before the delay it's on thread main, but after the delay it's on a different thread. So now on this coroutines default executor thread. And the thread we come back on is determined by the suspending function. So if I change this delay to a call to yield, and then run the code again, we start on main and we finish on main. So just to emphasize again, if we're using unconfined, you'll start on the thread of the launching coroutine, but after the suspending function, you will continue on maybe a different thread inside a different dispatcher. This can be useful, for example, if you're using things like RxJava with Kotlin coroutines.

Accessing the 'Job' Object
In an earlier chapter, we talked about cancellation, and we talked about the isActive flag, and we said that that flag is only available within the coroutine, and it wasn't available within the suspending function. But we did say there was another way of getting at this data from within the suspending function. And the way of doing this is by actually accessing the job object from inside the suspending function. So the suspending function when called has access to the coroutineContext, and the currentJob is in that context. So we can reach into that context and pull out the job, and then from there we can look, for example, at the isActive value. To do this, the context is a dictionary, and we use the Job as they key. So let's write some code and see what this looks like. So if we create a coroutine here, so we can say val job = launch, if I take a look at the job object, I can say job. isActive. So job has this isActive property and the isCancelled property and isCompleted property, so we can use these things to determine what we want to do within the coroutine. However, within the coroutine itself, job is not available. So the job variable wouldn't have been initialized and won't be available within the coroutine. But there's a scope issue as well, that this is essentially another function inside that function and that job variable simply isn't available. But I might want to access certain aspects of the job within this coroutine. So, as a silly example because we can get the isActive flag anyway, I might want to get the value of the isActive flag on the job. So let's do this. I want to println here and say isActive. And I want to print out whether the job is active or not using the job itself. So, to do that, we're going to actually access the coroutineContext, so inside here, we can say coroutineContext. And this coroutineContext is a dictionary, and if we go and look at this, so coroutineContext is of type coroutineContext, and coroutineContext looks like a dictionary's got a get method on here, for example, and we can use the get method to get a data within this coroutineContext. To do that, we can use the job interface. And if I look at the job interface, the job interface is a companion object called key, so I can say Job. Key to get out the value. And what that will return for me is a value of the current job from within the coroutineContext. And from here I can say isActive. Now this is going to complain because this could return a null value, so I need to use our favorite bang bang here to say trust me, I know what I'm doing, this is not going to be null at this point, so we can get out this value. And if I do a job. join here just to give this thing a change to complete running, and then execute the code, then we see the coroutine is active at this point, which is what we'd expect. Because key is a companion object of job, we don't need to use this full syntax here. Instead I can just say coroutineContext Job bang bang. isActive, and that will give me exactly the same results. So this is just part of the conciseness of Kotlin. Kotlin knows here that I'm reaching into a job and will look for the companion object on job, will look for the value of that companion object, and use that value as the key into this dictionary, and then return the value from the dictionary. So this is one way where we can access the job itself from within the coroutine that we are executing.

Understanding Parent Child Relationships
Something we mentioned in passing earlier is that coroutines can have children. So we end up with these parent-child relationships for coroutines. So coroutines exist in a hierarchy. And what this means is you can flow the coroutineContext from a parent task to any task that it creates. And this has consequences, some of which are very, very useful. So, for example, we can cancel the child tasks of a parent coroutine. So let's write some code to create child routines and see how we can cancel them and see some of the issues surrounding this cancellation. So let's try this. Let's create a coroutine and we'll give this a name of outer and we'll just provide a launch here. And inside this coroutine, let's launch another coroutine. And inside here, let's do our usual, we'll do repeat, let's say 1000 times, print out our dot and then delay for 1 ms. Wait for this to finish, so outer. join, put an empty line in, and let's print out a message, so println just to say that we are finished. And let's see what happens here. So, we can run this code, and when we run this, the outer coroutines launches the inner coroutine. We wait on the outer coroutine. The outer coroutine finishes almost immediately, so the inner coroutine at this point almost certainly hasn't finished. We've only printed out 1 dot when it should have printed out 1000 dots. It should have run for approximately 1 second. So if we want this inner coroutines to be dependent on the outer coroutine or vice versa, we want the outer coroutine to wait on the inner coroutine, we can flow the coroutineContext. So here if I call launch and flow in the coroutineContext, we now set up a parent-child relationship between these coroutines. So if I now run this code, so now we wait on the outer coroutine, that waits on the inner coroutine. So joining on the outer one, we're waiting for that to finish. That's flowed its context to the inner coroutine, and that's going to wait for the inner coroutine to finish before it finishes. So we have a parent-child relationship here. So what about consolation? If I take the outer one and call cancelAndJoin, and let's put a delay in here just to force this to wait even after the cancellation and run the code, so we launched the outer coroutine that launches the inner coroutine flowing its context, we cancel, join, that waits until the outer one is completed, we delay, but there's no output, so cancelling the outer coroutine cancels the child coroutine. But suppose we'd hit the coroutineContext out. And then do a cancelAndJoin and run the code. So now the inner coroutine runs. So by not flowing the context, we've set up no relationship between the outer coroutine and the inner coroutine. So joining on the outer one doesn't wait on the inner one, cancelling the outer one doesn't cancel the inner one. So if you want to set up a parent-child relationship, you need to flow the coroutineContext from the outer coroutine to any child coroutines you want to use. So we've seen that we can cancel the outer coroutine, and that cancels the children. We can also cancel the children. So from the outer one, let's call cancelChildren. We have to be careful here because we're calling cancelChildren, and there's a good chance that at this point the child coroutines haven't started. So if we call delay first of all, and let's put a slight delay in this, this gives the child coroutines a chance to start and then we can cancel them. Let's see what happens. So if I go back and run this code, so we see that we print out some dots, and then we finally cancel this thing, and we're not printing out 1000 dots here, many less than that. And we finally print out Finished. So outer. cancel cancels the outer. So one last thing to note is that the parent is notified if the children have been cancelled. So if I wrap the inner coroutine here in a catch handler and catch the CancellationException, and let's print a message saying Outer exception, the parent still has to cooperate. So to get this exception, the parent still needs to call a suspending function. So let's call delay here and pass in a value, let's say 2 seconds, which is more than enough to see this happening. So now if I run this code, we see outer isCancelled is False. So the outer coroutine has not been cancelled, but we still get an outer exception. We still end up here. So the outer coroutine will still end. So at this point, the outer coroutine won't be active, it'll finish at this point because the exception has been thrown. However, we could handle the exception ourselves and just go on off and do something else. It's important that our parent coroutine creates children. If those children are cancelled, the parent probably needs to know, so the exception is propagated to the parent to tell the parent the children are being cancelled, and it can then carry out any operation it needs to to put itself into the correct state before it continues.

Combining Coroutines
Coroutine contexts can also be combined. It might be that we want to take information from one coroutine context, combine it with another one, and then use that combined context to do the work. So contexts are just maps and they combine just the same as maps. So we combine by adding up two maps together. The keys in the left context are replaced by matching values in the right context. But like maps, missing keys are not added. So this is just a way of replacing value in one context with a value from another context, not adding values to the context. And also because of this, order may be important the way we combine these things. So let's take a look and see how we can combine context and how this code will work. So one reason it can be useful to combine context is to give our context a name. So, for example, in here if we print out the name of the context I'm currently working in, and then run this code, we can see it says I'm working in thread main, I've turned on debugging and coroutines number 1. What I could now do is in here is create a job object where we launch a coroutine. I can use this syntax, I can say CoroutineName to give the coroutine a name and then combine it with coroutineContext. If I now print out the name of the thread I'm working on and wait for this job to finish and run this code again, what we'll see is when we print out the thread name, we get the new name of the context as well. So this is useful, a little debugging trick for providing names for contexts. When we're debugging asynchronous codes, help like this can be invaluable.

Using the SingleThreadContext
So one last thing with contexts, and that's the newSingleThreadContext. And with this, we need to be aware. The newSingleThreadContext has to be treated with care. With this SingleThreadContext we create a thread and run our coroutine on that particular thread. Threads are expensive resources and we should reclose the thread when we finish with the context. So let's take a look at how we create this context and how we should treat the threads within this context. So let's go and create a coroutine on a single thread context. So we can say val job = launch, but here we'd say newSingleThreadContext. Give this thing a name, so let's call this thing STC, and then inside here let's just print out the name of the context that we are running on. And as is usual, let's just do job. join and wait on the context. And we can go and run this, and everything seems fine. It says singleThreadContext, I'm working in thread STC, which is the name of the thread context, and the name of the coroutine. The problem with this is that we've created a thread, and this thread is an expensive resource. So we need to manage this thing very, very carefully. So a better way to handle this is to actually create the SingleThreadContext, passing in the name, and then wrap this in Kotlin's use construct. And what this will do is it will close the thread after we finish this, so it will shut down the thread after we're finished with it. Into this use construct, we pass in the context as a parameter, and then we can use the context inside here. So now what we can do is we can take the job that we are going to create, move this code inside here, but rather than passing in newSingleThreadContext here, let's just pass in the context. So the outcome of this is going to be the same. We'd have the same result. We're still going to print out, I'm working on a specific thread, but at the end of this because we're inside this use block, we're going to close that thread. So we'll stop the thread when we finish with it. We stop the thread when we finish with the context. So just to run this and see what happens, the outcome is the same, but this is a much nicer way and a much better way of doing this, in that we are managing the context correctly, we're managing the thread correctly in this case. Now this is not the only way, so as long as you're aware that when you create a newSingleThreadContext you are going to create threads to use, and it's up to you to manage those threads, as long as you do that correctly then however you choose to do that is fine. Just be aware that can be an issue.

Summary
So in this chapter, we've talked about coroutine contexts, and contexts are one of the hearts of coroutines. You understand how context works and how context flow gives you a great insight into the way the coroutines work. So we can flow context from parent to child, so we can use this flow to set up parent-child relationships. This determines how and where the children execute, so on which thread and which context they execute, which dispatcher. You may need to take care with context, particularly the newSingleThreadContext. And we can also combine context to give us behavior information we might not otherwise be able to use. So now that we've seen contexts, the next thing to take a look at is how to return data from a coroutine. We haven't seen that yet. We've seen how to return jobs from a coroutine and work on those jobs, but suppose you want to return data and work on that data. So in the next chapter we'll take a look at the async and await constructs and use those to get data from a coroutine and work on that data.

Composing Functions and Returning Data from Coroutines
Introduction
Welcome back to the Using Coroutines with Kotlin class from Pluralsight. My name is Kevin Jones, and in this class we're going to take a look at how we return data from coroutines and how we can compose functions together. For those of you coming from a. NET background, this is the async await pattern. So we'll take a look at what we'll call here cooperating coroutines. So until now, all the coroutines we've used have been fire and forget. So we've sent the coroutine off, it's done some work, but we haven't returned any data back from that coroutine and we haven't had any need to sort of cooperate with our coroutine as far as its data return is concerned. Well, what if we want to get data from a coroutine? What if we have a coroutine that's going off to, say, a database or a network call, pulling back some data, and we want to process that data once the coroutine has that data and has retrieved any data that it needs. Or what if we wish to discover why a coroutine has finished? So again, maybe a coroutine is going to return a value back to us to tell you whether it's been successful or not in the work that it's done. To do this, we use something called the async coroutine builder. And again, if you're coming from a. NET background, and if you used the async and await keywords, this is a very similar approach to async and await in that environment. We've seen already that the launch coroutine builder simply returns a job object, and we can use this job object to inquire after the coroutine. So we can wait on the job object, we could ask the coroutine has it been cancelled, is it still active, we can use the job object to cancel the coroutine, to cancel the coroutine's children if it has any. What the launch builder does not do is return any data. It's fire and forget. So we have another coroutine builder called async. And the async coroutines builder returns an object of type Deferred. So this deferred object is like a promise in other languages or other environments or like a future in Java. So we can take this deferred, we can store it somewhere, and then we can access this deferred later in our code. We can use this deferred object to get any data or the returned values from the coroutine we've just sent off, and we'll see that the deferred object when we wait on it or await on it as we'll see the code is called, that await call will block until the deferred is completed and we get the data back from that object at that point. The deferred derives from job, so we can still do the same things we did before, we can still cancel the coroutine, we can still join the coroutine, so it's just a specialized form of the job object. So now that we've seen that, let's go and take a look at async coroutines and how these things work within Kotlin.

A Simple Async Await Example
The first thing I'd like to do is just show a simple example of using the async launcher. But before we do that, let's just try and motivate why we can use this thing. So here we have two suspend functions, one called doWorkOne, one called doWorkTwo. They both when they are called delay for a certain amount of time, and then they both return some random value. I want to run these as part of a coroutine. So let's do something like this. We can say val job = launch, so it'll launch these inside a coroutine, and at the end here as usual we'll do job. join, just to wait until this job is completed. Inside the launch, let's do val r1 for result 1 = doWorkOne, and then val r2 = doWorkTwo. I'm going to wrap these two calls inside a measured time milliseconds, so we can see how long these two calls take. So again, we can say val time = measureTimeMillis, and at the end of this, let's print our two values. We want to print out the result, so we can say result is going to be $ r1 + r2, and then after the call is completed, we'll print out the time. So we'lls ay println and something like Done in $time. And then if we run this, we'll see the result is 52, so the addition of 2 random values, and it's done in about 300 ms. Now if we look at the code here, doWorkOne is a suspend function, and that takes approximately 100 ms to run. DoWorkTwo is a suspend function, and that takes approximately 200 ms to run. So these two functions run concurrently. So even though they're running inside a coroutine, and even though they're running as suspend functions, the work still happens one after the other, so doWorkOne runs to completion and then doWorkTwo runs to completion. So the fact that we're running suspend functions inside a coroutine doesn't make those functions themselves asynchronous. It makes the entire block of work asynchronous that we are doing. So what we can do now is we can use the async coroutine runner to run these two functions asynchronously. So here we can do async and wrap doWorkOne in async runner, and then we can do the same thing with doWorkTwo, so again we can call async and wrap doWorkTwo in async runner. Notice now we can't add r1 and r2 together, so r1 is now the result of the async and r2 is the result of the async. And the async runner returns deferred to both r1 and r2 are of type deferred. And defers are generic, and the generic type is the return value from the method. So doWorkOne returns an int, so the async is of type Deferred Int. R2 is also of type deferred. And if we take a look at deferred just briefly, we'll see that deferred derives from job. So a deferred object is just a job, and the job object we've used previously to do things like waiting on coroutines. So deferred also has a method called await. And await waits for the coroutine to finish, and then returns the data back from the coroutine. So by calling await here, we get back the values returned from the coroutine. So if we run this code, we'll get a different result because we are adding different values together, random values, but notice now we've done it in 200 ms. So what was previously approximately 310 ms now is approximate 210 ms. So what we're doing now is we're causing each of these suspend functions to run concurrently. They're no longer running sequentially, they're running concurrently. We then will wait for both of them to finish. And essentially what ends up happening is we end up waiting for the longest one. And the longest one takes about 200 ms to run, the delay is 200 ms, so doWorkOne finishes very quickly. We'll wait for that one. We get the result back. But doWorkTwo won't have finished yet. That will not finish until 200 ms has gone by. At that point, we now have both results, we can print out the result of both results, and print out the time, and we can see that by doing this work asynchronously rather than sequentially, we end up just waiting for the longest piece of work to execute. So this is sort of the simplest use of async await. So just to show there's nothing really special about the async coroutine builder from a concurrency point of view, let's just go and enforce the idea that these things do run concurrently. So here I've just changed things slightly. I've replaced the two doWork functions with a single function that just takes a string, and then we're going to call a couple of times, and then we have a log function, and that log function prints out the message that's passed to it and the name of the thread that we are currently running on. And what I'd like to do is this. So, inside the main we're going to do val job = launch again, so we'll create a simple job here and do job. join to wait on this. Inside my launch, you'll do val result, and we'll use the async coroutine builder. And we'll share the context for this. Just to see that this coroutine builder is the same as launch, we can share the context. So our async job becomes a child of the main job, of the launch job, if you like, in this case. And then asynchronously let's call doWork and let's just pass it the string Work 1. Outside of the async let's call doWork again, and let's pass this the string Work 2. And then let's run this code. So we see here that Work 2 starts and it's running in the ForkJoinPool. Then Work 1 starts, Work 1 ends, and then Work 2 ends. So both Work 1 and Work 2 are running concurrently because the nature of async. We're launching the job asynchronously, so these two are running concurrently. Now if I change this code, so here we do a result. await, and then run the code again, so now the behavior is very different. So now Work 1 starts and we wait until Work 1 ends, and then Work 2 starts and then Work 2 ends normally. So just to emphasize this, the async jobs run concurrently with the other jobs. And by using await, we'll block, wait for that job to complete, and then carry on with any work that we are doing.

Writing Idiomatic Async Functions
One of the common patterns you'll see in other languages, and C# I'm looking at you here, is to name functions something async and then make the entire function asynchronous, and then use await to await on that function. This is sort of not idiomatic in Kotlin. I will come back and explain why in a moment, but let me just show you the pattern first of all. So let me change this code. So here, first of all, let me get rid of the body of main, and then for the doWork function, I'm not going to mark this as a suspend function. So I'm just going to mark this as a normal function. But I'm going to make it async by saying = async here, so this becomes an asynchronous function, and then this is going to return a deferred of int. Now notice once we do that, our return is now invalid, but what we can now do is use a non-local return here and say return@async and the return the value that way, and that will turn this into a deferred of 42 for me. So the first thing to realize here, let me take the runBlocking off main, and inside main I can just say val result = doWork. So we can call this function as if it was a normal function. And this function will then return the deferred value from that doWork to me immediately. Now because this is an async function, we typically change the naming pattern for this, and rather than calling it simply doWork, we call this doWorkAsync. So we use async as a naming pattern to say, look, when you call this, I'm actually not returning a value that you can use immediately here. I'm going to go off and do some work asynchronously and then I'll return a value that you can use in the future. And again, the type of result here is going to be a deferred of int, not the end value itself. So to use that, what I need to do is call result. await, but again, we'll come to our favorite error, suspend function await can only be called from a coroutine or another suspend function. So this is an ideal place to use something like runBlocking. So here we can do a runBlocking and wrap the await call inside runBlocking. And let's just print out the result of that call. And again, if we run this code, then we get the result 42. So again, just note the function we're calling here, doWorkAsync, is not a suspend function. The function is a normal function, but it's used in the asynchronous coroutine builder to build the function for us. We can call these functions as we do any other functions in any part of our code, but to get access to the value from the deferred, we then need to get that value from inside a coroutine. In this case, we're using runBlocking to set up our coroutine to allow us to access that value. This is very similar to the way something like you get in. network, C#, or the async keyword, and awaiting on the result. The reason this is sort of non-idiomatic in Kotlin is that it's not necessarily obvious when you call a function like doWorkAsync that it is async. The doWorkAsync is just a naming pattern. We don't have to call a function doWorkAsync, we could just call it doWork, and in that case it's working asynchronously. It's often better to be explicit in the code and to take any function you want to run asynchronously and wrap that in an async coroutine builder, rather than making the function itself asynchronous. You might prefer to use this pattern, and that's perfectly reasonable. But be aware generally you can just wrap any function inside an async and have that function return a deferred value to you.

Lazily Starting Async Functions
One last thing I'd like to take a look at is the idea of lazy evaluation when we're using async. So we've seen that when we call an async method, that function executes, even though we don't get the result back until we call await. Suppose we'd like to not even execute the method until we call await. We can do that with async as well. So here I've changed our doWork method and I just renamed it to doWorkLazy and change what it logs out. If inside my code here, I launch a coroutine, so we have val job = launch job. join, and then inside the launch coroutine, we do val result = async, and then inside here we call doWorkLazy, and we get back the results and we just print out the value of that result. So we just do println, result is $ result. await. And we've seen this many times now, so we run this code. So we get the answer result is 42, but we also see, and again, hopefully this is fairly obvious, that the method is run. So we see the log of that method called, so Be lazy in the worker, and Lazy done in the worker. What's not so obvious is if I take out this println, just comment this out, and then run the code, is that even though we're not getting the value back from the doWorkLazy call, it's still executing. We only see the first method here, the Be lazy call, as there's a delay in here. And by the time the delay finishes, the main function is finished. So the launch is finished. And we can fix that by flowing the context. So here if I pass in the coroutine context, now the async call is a child of launch, and if we run this now, we join on the top level coroutine, the async coroutine is a child of that, so we end up waiting on both coroutines. So now we can see even though we're not calling await that the doWorkLazy function is being called. Suppose we didn't want that to happen. Suppose we wanted to say, actually what I'd like to do is only to call the lazy function in this case when I get the await call. So we can do that by passing another parameter here. And we can say start = CoroutineStart. LAZY. So actually make this thing lazy. Just to show you this is a demo, I'm going to remove the coroutineContext here. And then if I run this code, so what's happening now is we're waiting on the top level coroutine, we're never calling the doWorkLazy method. We are starting the async coroutine, but the doWorkLazy method is never being called because we said I want to evaluate this in a lazy fashion. In this case, that coroutine won't get called until we call await. So I put the await call back in, and then execute the code. Again, we now call the lazy method and we get back the result and we can print out the results. So what you can do in this case, you can start a bunch of async processing. You might just decide that you want those things started, but you don't necessarily need to use them. So you might just say you want to start a whole bunch of things, but you don't necessarily want them to run. You might choose a particular path, and when you're on that path, run certain aspects of the application. And by calling await on the return deferred objects, at that point the coroutine will start properly and it will go and get the result for you and return the data back to you.

Summary
So in this chapter, we looked at the async coroutine builder. This pattern is common in other environments. In particular, C#. So in C# we have these two keywords, async, await, and this builder in some ways mimics that pattern of using async and await. However, the difference here is that rather than being keywords in the language, they're both methods. So we use async to create the async coroutine builder, and then we can use the await function on the return deferred object to get the data back from that async builder. So Kotlin's only other concern really here is to prefer sequential code, so in our code we can simply launch a number of async routines one after the other, methods get called one after the other, so they appear to be sequential inside the code. And then we can await on those functions as we need to to get the data back from them. The functions we call inside the async coroutine builder could be async functions themselves, we could use the async builder on those, or those functions could be a suspending function that we call from inside the async builder. So either approach is reasonable. You'll generally see the second approach used more than the first, so defining it as a suspend function and wrapping it in the async coroutine builder. The async builder returns a deferred object. Remember a deferred derives from job. Deferred has this extra method we use called await. Await returns the data from that object. But the deferred object is just a job object. You can join, you can cancel, you can check the status of the coroutine through the deferred object in the way you would with any other coroutine. Okay, so now that we've seen some of the basic launches with coroutines, we've seen await, we've seen async, we've seen launch, we've seen runBlocking, we talked about how we return data from a coroutine, what we're now going to do is dive a bit deeper. We're going to take a look in particular at something called channels. We use channels to communicate between coroutines. In the next chapter, we'll see the use of channels. In the chapter after that, we'll take a look at something called select, which allows us to choose between channels, and then after that we'll build actors using these channels.

Using Channels to Communicate Between Coroutines
Introduction
Welcome back to the Using Coroutines Class in Kotlin from Pluralsight. My name is Kevin Jones. In this chapter, we'll dive into the exciting world of channels, and we'll see how we can use channels to set up a communication between coroutines. So in this chapter, we'll examine why we want to use channels, what benefits they give us in our code? We'll take a look at what channels are and how we set these things up, so we'll see how we create channels, we'll see the channels are created as blocking channels, we'll take a look at what are known as buffer channels, we'll see how we can synchronize between channels, and we'll see how we can iterate over the data in a channel and close the channel and the source of implications that that closing has within our code. So why channels? Why do we have channels? We've seen already that if we use the async coroutine builder, we can return a deferred object, and this allows coroutines to communicate. But this is very limited. We kick off the async coroutine, that returns a piece of data, and we have to all wait to get that data back. It would be nice to have a more general communication mechanism where we could fire up a coroutine, have that coroutine sending data that other coroutines can consume and can use. And this is what channels offer us. They offer us a very general communication mechanism. So we can create a channel, a number of coroutines can write down that channel, and a number of coroutines can read from that channel. So rather than a simple one-to-one mechanism, we can use channels to do one-to-one, one-to-n, n-to-1 or n-to-n communication. So what are these? So as I said, we use these things to communicate between coroutines, we send to and receive from a channel, we can send or receive more than one item of data, and channels are blocking, so when we use a channel and I send to it, the send call blocks until something receives from the channel. Conversely, the receive call blocks until something sends to the channel. We can set up buffer channels, so we can limit if we need to this blocking. So we can have a send call that sends to a buffer channel and sends multiple values into the channel until the buffer is full. We set the size of the buffer within our code. When we use channels, we might need to know when the channel has finished. So we can set the mechanism to close the channel and when that's done then our receivers can do the appropriate thing when the channel is being closed. So how do we use these? How do we go about creating and using channels? So there's a channel class inside Kotlin, and we create the channel telling it the type of data we want to send down the channel. So here we're saying I want a new channel of type int, and I can send some data to that channel. We can send the data down the channel, and we can receive the data back from the channel. So both send and receive are suspend functions, and as it said on the slide, we can use channels as a rendezvous point. So, if two coroutines are waiting to exchange data, one can send, it will block until the other channel is ready to receive. When the second channel receives, these two coroutines are now rendezvoused at this particular point, and then can carry on doing the work they were doing previously. So given that, let's dive in and take a look at how we can use channels within our code.

A Simple Send/Receive Example
Now that we have that background on channels, let's take a quick look at how we create and use a channel. So there's a channel type in Kotlin. And I can say val channel = Channel. And the channel type itself is generic. So we need to tell the channel the sort of data we're going to send down it. We can then use this inside a coroutine. So we use our launch coroutine builder, and let's send some values to the channel. So let's do a for loop here, so x in 1 to 5, then inside here let's print out that we're about to send the data, so we'll do a send $x, and then we'll call the send method on the channel. So we say channel. send and then we'll send x. Let's get the job back from this, so val job = and let's just wait on that job. So, job. join, just to wait. And we can go and run this code. Okay, so we've launched the coroutine, we've sent the first value, and as we send that value, we block. So, the job hasn't finished, job. join hasn't returned, the coroutine is still running, and we blocked inside the send on the channel. So until something receives a value, we can't send the next value. So let's end this process, and then in here let's do a channel. receive. We are inside a runBlocking coroutine here, so receive is fine, that's going to work, and receive is a suspending function, and when we call receive, we will get back a value. So let's just go and print out that value. So let's do a println channel. receive. So just to be obvious that were receiving something, we say println receive and then the value we receive from the channel. If we go and run this code, so we see we send the value 1, we receive the value 1, we then send the value 2, so you've unblocked the channel, but we're still blocked because there's nothing to receive this next value. So to complete the send and the receive, let's just write some code to receive the other four values that are going to be in this channel. So let's do a repeat here and then copy this println and then receive into the repeat, so we'll receive the first one, repeat four times, and receive the next four values. And just rerun this. So now we're doing send 1, receive 1, send 2, 3, receive 2, 3, send 4, 5, receive 4, 5. So we are sending and receiving on the channel. And the receive essentially unblocks the send. So we do the send, that blocks, we do a receive, that pulls the data out, we'd go around and do the next send.

Closing Channels
So we have the code here as we've just seen to send to a channel and to receive from the channel. However, this code has explicit knowledge. This code knows how many items are going to be sent down the channel. It knows the channel sending 5 and it receives 5. Suppose we didn't know that. So let's change this code slightly. So we've done the first receive, and then here we're doing the other 4. If we change this value to 5, and then run the code again, so we've received the last item, but now we've called receive again, and like send, receive is a blocking function. So receive will sit there and will never return from our call to receive. So what we'd like is a way of notifying the channel that we've done, we've finished sending everything, we're going to any receiver can shut down its processing and can carry on doing whatever it needs to do. And the way to do that with channels is to call channel. close. So after this for loop here, let's do channel. close, and that will close the channel. And if you run this code again, so now what happens is that when we run this code, we receive the fifth item. but the next call to receive is being called on the closed channel, and we get a ClosedReceiveChannelException. Now, of course, we can handle that exception ourselves if we want to, or we can maybe process the channel in a slightly different way. And there are other APIs inside Kotlin to let us process these channels and also manage the closure. So rather than calling the repeat call here, what we can do instead is use a for loop, and we can say something like for y in channel. Again, let's just go and print out this message, delete the initial repeat. We also need to make sure we don't call receive again, as using the for loop receives the value for me, tidy this up slightly so we can just say $y, and then if we run this job, then we print out all of the values and we close down correctly. So we receive the last value, close has come into the channel, the channel has been closed, the coroutine has ended, job. join returns, and we're all done quite happily.

Using Channels for Producer Consumer
So one of the common patterns we come across in code, and the pattern we're using here is that of producer consumer. So here we have a small piece of code that's producing some data into a channel and then some other piece of code that's consuming the data from that channel. And Kotlin has helper coroutine builders to help us create producers to produce this data. And then other code we can use to consume the data that's being produced from such a builder. So to do that, let's first of all refactor this code to break it down to a couple of functions that we can use. So let's create a function called produceNumbers, and this function will return a channel of type Int. Inside here we'll get rid of the job because we're no longer using that, and we'll return the channel from this code. Inside main, let's call produceNumbers here, get rid of the job, leave the for loop, and get rid of the job. join, as we're returning the job in this case. And if we go and run this, we should see the same output as before, and indeed we do. So we're sending five values and we're receiving five values. So rather than creating the channel ourselves here, what we can do is make our produceNumbers use the produce coroutine builder. We'll set = produce. This actually returns, rather than returning something of type channel, this returns something of type ProducerJob. And then inside the codes, inside the coroutine builder itself we have access to the channel that we are sending on. So here we can just send the value that we want to. There's no need to close the channel, that's managed by the producer, and there's no need to return the channel, that's managed by the coroutine builder itself. We don't need to run this inside a coroutine, as we're already inside the produce coroutine, so already our code becomes much, much simpler. It's now very similar, in fact, it's now exactly the same as standard sequential code, sending data to some output. I saw one extra print statement to show that this function ends correctly. When we're finished, we'll just do a println of done to say that we are done. So in the receiver, we'll keep this, we'll say val channel = produceNumbers, so we've got the numbers out of this thing, but rather than using the for loop here to iterate over the channel, what we can now say is channel dot, and this is a method called consumeEach. Now remember the channel type here is of type ProducerJob. We can take a look at ProducerJob. ProducerJob is something of type Job; it's also something of type ReceiveChannel. So ProducerJob is both a job and channel. If we look at the consumeEach call and consume each, it's an extension function on ReceiveChannel. And this simply iterates over the collection. So this just does the for loop for us. So here we can say consumeEach, and then inside the body of the consumer we can simply print out the value we get back. And we can use it to do that. And again, at the end here, let's just do a println, and inside here just to differentiate this, we'll say Main done. And again, if I run this code, so again, we're producing the numbers, sending 1, 2, 3, 4, 5, consuming 1, 2, 3, 4, 5, done from the producer, and then done inside main. And the key thing to note here is that our producer code is now much, much simpler. We don't need to launch a coroutine, we don't need to create the channel ourselves, it's just done for us by the coroutine builder.

Pipelining Channels
So we can also chain channels together in a technique called pipelining. So at the moment we're producing single numbers into this channel here. What I'd like to do is to take the output from this channel, pipe it into another channel, and then do some extra work on those numbers inside that channel. Just to make the output cleaner, let me just go and remove this println. And remove the call the done here. And also rather than using a for loop, let's go make this truly brutal and let's have a val x = 1, and then here let's just say while true, so we'll just pump numbers down this channel, and we'll send x++. And of course that needs to be a var. And then what we'll do if I take this produceNumbers is I'm going to create another producer, and let's call this one squareNumbers, and this producer will itself take a channel. So we'll take a channel, we'll call the channel numbers, the channel it takes will be of type ReceiveChannel. So we can only receive things from this, and it's going to be a ReceiveChannel of type Int. So the channel gets split into two halves. There's a receive side and the send side. Into here we can only receive numbers. It's also going to be a producer. So what this thing will do is do a for x in numbers, which is the receive channel, send to send out of the produce channel, and let's square these numbers, so x times x. So inside my main, let's rename this to be producer, and let's create another channel called square, and to create this channel, we use the squareNumbers function. And remember squareNumbers itself takes a channel. So we can pass the original producer to that channel. So now we are taking the data out of the produceNumbers channel, passing them into the squareNumbers channel, and then let's consume those numbers. So rather than calling consumeEach here, this is an infinite loop, so this will just carry on forever. And let's just consume the first five numbers. So it'll do for I in 1 to 5. We'll print out square. receive. When we're done, we'll print out done, and then just to make sure that everything is done correctly, let's go and cancel these channels. We'll do square. cancel to close the channel, and producer. cancel to close the channel. I also need to change runBlocking here to tell it what the specific return type is. So in this case, we say runBlocking is of type unit, and it just lets the compiler know to generate the right signature for this code. So now that we've done, what we should see when we run it is 5, the first 5 squares printed out, followed by a our same main done. So if we go and run this code, so indeed we get 1, 4, 9, 16, 25. So this is a very nice technique. The fact that we can chain together these channels allows us to build processing pipelines to process the data as we see fit. So here obviously we're just producing and managing numbers, but the channel can take any type of data that we want it to and pass any type of data down this channel and then process that data. And then through the channels, we can map the data, we can filter the data, so we can build quite complex processing pipelines out of these channels of data.

Using Channels to Fan-out and Fan-in Data
So, so far we've seen the ability for one channel to send and one channel to receive. However, there's no limits on the number of channels that can send and the number of channels that receive. So, in the code we have here, we've simply factored out the consumer call. So here we have a produceNumbers as a sending numbers, our consumer is consuming those numbers and printing out the values received, plus the thread name, and then in main we produce the numbers, consume some numbers, and then wait a second, that kills main, we cancel the producer to stop it sending numbers, kill our main, and we drop out of the application. And if we see this running, we should see our 10 numbers printed out. So here we receive 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, all inside the same coroutine. So let's change this up slightly. So inside here let's change our consumer, so it takes an ID of type Int, and inside the println, we say processor and we pass it this ID, so processorNumber and we say $id here. And then what we'll do is rather than running a single consumer, let's run a number of consumers. So let's go and set up, let's say, five consumers. And then on the consumer, pass that ID through, just the value that comes out of the repeat each time, so that's going to be it, so now we're launching five consumers, we still have one producer. So we're still producing the same amount of numbers, so we're going to produce 10 numbers, but now we have 5 consumers to consume those numbers. And if I run this code again, so now what we're going to see is different processes, different consumers, consume the data. So the first time our consumer number 3 received the value 1 on commonPool-worker-4, and this is coroutines number 6. And then processor 0 got 2, processor 2 got 3, and so on and so forth. And then further down consumer 0 received 7. Consumer 2 received 8, consumer 4 received 9, consumer 1 received 10. So each of these consumers consumes this data in turn as it comes out of the producer. So if we don't necessarily want to consume these values in order, if they're independent of each other, we can set up multiple consumers to consume the values from a producer. And this is called fan out. So we are taking one producer and we're fanning out the results from that producer into multiple consumers. We can also do fan in, so let's take a look at that next. So for fan in, let's change the code slightly. Let's create a channel, and this will be a channel that can send and receive strings, so we'll just say Channel of type String. And then what I'm going to do is create a suspend function, and that suspend function will be called sendString, and this will just send strings to the channel. So sendString will pass the channel into this, this will be our type Channel String, we're going to pass the string to send, and we're going to pass a delay time. So rather than delaying from arbitrary time in here, we'll tell it how long to delay for, and that's of type Long. Then inside here we'll have a while true loop and we'll do a delay for whatever the interval was, and then we'll send the string to the channel. So channel. send to send the string. Back inside main, we'll launch a couple of coroutines. We're going to run these in the same coroutineContext, and we can cancel them when we finished. We call send String. To this string we pass the channel. We pass some text to send, so let's just say foo, and we pass the interval. Let's say 200 ms. And we'll do this again. We call sendString, we'll pass bar, and let's say rather than pausing for 200 ms, we'll pause for 500 ms for this one. Then what we'll do is we want to receive on a single consumer. So we're going to send for a multiple producers and receive on a single consumer. And this is the idea of fan in. So here let's do a repeat, and we'll just repeat six times, just receive six strings and print out the values that we receive. So we do a receive on the channel. receive. So we're creating two producers in a single consumer. Once we finish the repeats, once we've got all the six values that we want to, we'll take the coroutineContext and call cancelChildren to cancel all the children within that one coroutineContext. So this is a technique we've not seen before. Previously we've used the job to cancel the children, but we can also use the coroutineContext to cancel children as well. So now that we have this, what are we going to see if we run this code. Okay, so we get 1, 2, 3, 4, 5, 6 entries. If we look at the delays here, we get foo foo, so they were 200 ms apart. Then the next sendString kicked them to 500 ms, so that sends the message, so we get foo foo followed by bar, all received by the same consumer. Foo is sent again, foo is sent again, and then finally the next sendString kicks in and sends bar. Again, all received by the same consumer. So here we have the opposite what we had before. So previously we had fan out where we had one producer sending to multiple consumers. On this side we had fan in where we have multiple producers sending to a single consumer. At the end of this chapter, we'll build a very simple load balancer, and that load balancer will use both of these techniques, so we'll do fan in and fan out to set up our load balancer to work.

Buffered Channels
So here we have a scenario where we have a channel that wants to send data, but the receiver is not quite ready yet, so the sender channel is set up, we have a delay of a second before we set up the receiver. We're going to try and call receive 10 times on the receiver. What we'll see is with the time that receiver gets to run, the channel can only set the limit to the amount of data. So if I run this code, so the channel sends 0 and the receiver receives 0, the channel sends 1, and the receiver receives 1, the channel sends 2, but then we're done. So the channel would like to send 10 items, but as the receiver isn't ready to receive those items, we'll only manage to send 3 before we end the process. What we'd like to happen is if the channel is ready to send, but there the receiver is not ready to receive, to maybe create a buffer channel to allow the sender to start sending data even if the receiver isn't quite ready to get it yet. And we can do that when we create the channel by telling the channel how large a buffer to create. So here, for example, we create a buffer sizer 4 and then execute this code again, what we'll now find is that as soon as the sender is set up it will start to send data. So it sends the first 5 items here, so it sends 4 into the channel, it sends the next 1, and then blocks. Receiver then kicks in and receives the items, and we can then start sending and receiving as we go along. So that buffer allows me to sort of pre-warm the channel even if the receiver itself isn't ready to get the data. Be aware obviously if you do this, even though you aren't going to synchronize at some point between the client and receiver, the client is going to start pumping out data before the receiver might be ready to receive it.

Understanding Channel Fairness
So one more thing to think about when we're using channels and we're producing consuming data is the channels are fair. So if I have two channels trying to receive an item of data, one channel won't hog that data. The data will be passed to one channel, then the next, then the first channel, then the next, and so on and so forth in a round robin basis. So to see an example of that, let's just write some code that proves that here. So we're going to create a channel here, and we'll call this channel discussion. And the channel is going to be a channel of type Comment. So we can see now we have this data class called Comments and now rather than sending an Int or a str ing to the channel, we're sending some other data type. And then what I want to do here is I want to launch two coroutines, and both of these coroutines will want to consume the data from the discussion channel. So we'll launch in the same coroutineContext, so we can cancel them when we've finished. And then what I'm going to do here is I'm going to create an object called child, so we'll have two children in this discussion. And the children will express something during the discussion. So the first child is going to say "he did it, " and if I duplicate this code, the second child is going to say "she did it. " So the first child wants to send the text "he did it" to the channel, and the second child wants to send the text "she did it" to the channel. And we write the child in a moment. So when we create the child, we give it the text they're going to send to the channel, and the name of the channel to use to which to send that text. So child is going to be a suspend function, and that suspend function will take the text as a String, and the channel to send that text to. So that will be of type Channel of Comment. So inside here, we are going to iterate, so we'll say for comment in discussion, so pull the comment out of the discussion. Increment the number of times this comment's been used, so comment. count++, print out the comment, so we print out the text for the discussion, and we print out the hit count inside the comment, delay for a certain amount of time, let's just say 300 ms here, and then send the comment back to the channel. So once we've done that, we set up the initial discussion, so we do discussion. send and send an initial comment into this thing to set up the entire discussion. Delay for a second to let these things ping back and forth for awhile, and then cancel the children. So what we're doing here is we're using the same channel in two different places. So we set up the child, we pass the discussion channel to that child, we set up a second child, and pass the same discussion channel to the second child. We call discussion. send, which sends a comment object to the first channel. Inside the first child, that will receive the comment object, print out some information, and then send it back into the channel. At this point, the framework has a choice. It could deliver the comment object to the original channel, or it could deliver it to the second channel we've set up. And what we'll see is that the comment object is delivered to each channel in turn. So if I run this code, we see he did it, she did it, he did it, she did it. Notice that it's the same comment object going back and forth, so the count of the comment is going up, comment object is being shared fairly across the two consumers of the channel, so you won't get one consumer hogging the channel. Each consumer will get to see a chunk of the data within the channel.

Load Balancing Channels
So now that we've seen channels in operation, let's try and pull this together in something a little more complex. Let's try and write the simple load balancer. So here we're going to have a producer. This can produce lots of work. And he wants that work spread across multiple agents to do the work for it. So the producer sends the work into a channel, we'll have many agents listening on that channel, and each of these agents will pick up a piece of work. When the agent is finished, it will send that piece of work to a channel, and all agents use the same channel, and that channel will be read by a consumer. It's a single consumer that will read each piece of work. So the producer is going to use fan out to fan out to these channels, the consumer is going to use fan in to read back from these channels, and we'll spread in the loads over multiple workers. So let's take a look at this now. Okay, so the heart of this application is going to be a worker, and that worker is going to receive a piece of work from a channel, process the work and send it back down a different channel. So the first thing I'd like to introduce in here is the work object. So this is the thing that will be received from and sent down a channel. We'll then have a worker, and the worker is going to be a suspend function, and that suspend function will simply take two channels. So we'll call this function worker, it'll have an input, which will be a channel of type Work and an output, which will also be a channel of type Work. Then the suspend function will iterate over the input channel, so for w in input, and do some work on the values in the input channel. So notice the work object we're passing three longs, x, y, and z, and what the worker will do is multiply x and y together and then delay for z. So we're just using this to set up a random delay so we can see the worker actually doing some work. So we're going to say w. z = w. x times w. y. We'll then delay for w. z, and then we'll send the results down the output channel. So output. send and we'll send the work down the output channel. So the worker, initially at least, is quite simple. Take some input, produce something, and then send some outputs. So the next thing I want is a function to set up the workers, and we'll call this thing run. So our run function will create an input channel, and this will be of type Channel of Work, and an output channel, also of type Channel of Work. Inside the run function, we'll create some workers. So let's declare a variable at the top of our code, and that variable is the number of workers we want to create. So, say go and create this number of workers, use the launch coroutineBuilder, so we want these to run asynchronously, and inside here create a worker object and pass to it the input and the output. So once we have that initialized properly, we want to send work to the worker. So to do that, let's create another function called sendLotsOfWork. So this function will be launched from the run function, so inside here, again we'll use this as a coroutine, so we'll just do a launch of sendLotsOfWork, and we're going to send lots of work down to the input channels for the workers. We specify how much work to send, so again, we'll create a variable to hold this called totalWork, and inside sendLotsOfWork, we'll repeat for totalWork and do input. send. I'm going to send a work object, and inside here I want to generate random numbers. And at the bottom of this code, we have an object of type RandomRangeSingleton, and then an extension method on ClosedRange, which uses RandomRangeSingleton to generate random numbers from a given range. So my input. send will look like this. So in a work object, the first value of which is a random number between 0 and 100, and the second value of which is a random number between 0 and 10. So that will send the work to the workers. So once the workers are done with their work, I'm going to want a function to receive that work. So we define a function called receiveLotsOfResults, and this has given the input channel, so inside here I'm going to say for work in channel, and I'm just going to print out the values we get back from the work. So this is going to tell us what x and y were and the results. Hopefully x time y comes out to be that result. So as well as launching sendLotsOfWork, we have to launch receiveLotsOfResults to make sure we receive the data, and we make sure that receiveLotsOfResults is receiving on the output channel, not the input channel. Once we have that inside main, we can call run, and then we should probably delay for a few seconds just to get the results back. So let's just delay for 5 seconds to see how many results we get. Now if I run this code, so we're seeing here the result of this work. So we're sending some work to the worker processors. They are taking the values coming in, calculating the results, and then sending that output back to the result processes. So my sender sends work down what we've called the input channel and sends work to a worker and sends a piece of work. The receiver receives work back from the output channel and then prints out the results of that work. We've created two channels, an input channel and an output channel, and we've created in this case 10 workers and 20 pieces of work. Now there are some things left to be desired here, so for example, we're not managing the channels properly, we're not closing the channels when we're finished with them, we're just delaying at the end to give our work enough time to finish. So we'd like to know for sure that this load balancer is finished working. And in the code in the demos, we add another channel, something that takes a Boolean value that we wait on and send a message down to say yeah, we're now done and you can now close down quite happily. There are other ways of doing this. That's the solution that I chose to show in this case. So this demo brings together some of the things that we saw in the chapter. We do fan in, we do fan out, we use multiple channels to do work, and we set a type down the channel that's not just an int or a string, it's actually the type that we define, and we can use that type to define the sort of work that we want to do within the channel itself.

Summary
So channels provide a robust communication mechanism to allow coroutines to share data. So rather than using something like async and await, where a single coroutine returns a single piece of data that another coroutine can consume, we can use channels to communicate across coroutines. We've see the channels are a rendezvous point. We see that when we do a send or receive on a channel, that's send or receive is blocking. We can see the channels need managing. So when we use a channel, we need to be able to set the thing up, we need to be able to control how and when it's used. We've seen the blocking channels might be an issue, and to get around some of those issues, we can use buffer channels. We can give the channel a buffer size. And we've also seen that ideally we need to close the channels when we finish with them, just to make sure that any resource the channel is using is tidied up behind it. So now that we've seen channels, in the next module we'll take a look at selecting on channels. So selecting on channels gives us a really nice way of sending different types of data into a channel and choosing what to do within the channel based on that type of data.

Waiting on Multiple Coroutines Concurrently by Using Select
Introduction
Welcome back to the Writing Coroutines in Kotlin class from Pluralsight. My name is Kevin Jones, and in this chapter, we'll take a look at how we can wait on multiple coroutines by using a select statement. So the Kotlin coroutine library provides a select statement. And with select, we are trying to solve this problem where we have multiple suspending functions, and we want to execute when any one of those functions is done. So rather than waiting on a single function, we are essentially waiting on multiple functions, and we're saying to the coroutine runtime when running these functions finishes, let me know, and then I can then execute some work. And we can do this using select. So, select allows multiple channels to be waited on at the same time. We use what are known as clauses to select from those channels, and as we'll see, select is biased to the first clause. So what we mean by that is if we are waiting on multiple channels, and the first channel is always sending data, we'll only ever get data from that first channel. The way we use select is like this. So you have a select statement. A select statement can return a value, but here we are saying it's a select of type unit, so there is no return value. We then have two channels, in this case both core producers, so producer1, producer2. We're receiving from those channels, and essentially what the select is doing is waiting on both of those channels. When one of those channels returns, I'm going to execute the lambda, I'm going to execute the code, and in this case we just print out the value of the channel. Select is biased, so if the producer1 keeps sending out data, and when the select is called, that data is available, we'll always get the data from producer1, even if producer2 also has data. So the select is biased to the first channels in its list. So let's a look and see an example of how we would use this.

Using Select with Channels
So let's write some code using producer, and then write the select to wait on that producer. So our producer can look something like this, we'll call it producer1, and it will equal produce, which is the producer coroutine builder we've seen previously, and in here we'll loop forever, delay for a certain time limit, let's say 200 ms, and then send down the channel a message. And we'll just send from producer 1. Then let's write another function that's going to select from this channel. So this will be a suspend function. We'll call it selector, and for now as selector we'll just take one channel, so we'll call it message1, and this will be of type ReceiveChannel of type String. And we'll code this in a moment. Then inside main, we'll say val m1 equals producer1 to set up the producer coroutine, and then we'll loop a number of times, let's say 15, and inside here we'll call the selector method, and we'll pass it that channel. Then inside the selector, we want to select from that channel. So inside here, we'll use select, we'll specify that select returns nothing, so we'll select of type Unit. Then we'll take the first channel, which is message1, and call it onReceive function. OnReceive is passed the value we are receiving, so inside here we'll just print out that value. So what we should see here is every 200 ms or so, the console printing out the value from producer1. And let's go and run this code, and indeed that's what we see. So without counting these up, we are looping 15 times, so there should be 15 lines here saying from producer1. So let's add a second producer. So simply copy and paste this code. We'll call this producer producer2, and we'll send the message from producer2. We'll add a second receiver to our selector, and we'll call this message2, and then in the repeat loop, we'll create another producer, so we'll say m2 = producer2, and we'll pass this to the selector. And then inside the selector, as well as receiving on message1, let's also receive on message2. And let's change producer2. So producer1 produces every 200 ms; let's change producer2 so it produces every 300 ms. And again, we're iterating 15 times. We're repeating 15 times. So what are we going to see? Well, let's run the code and find out. So what happens? So producer1 fires after 200 ms and sends out this first piece of data, and the select picks up that data. Then after 300 ms, producer2 is fired, and we pick up its data. After 400 ms producer1, after 600 ms producer2, then after 600 ms, producer1 fires, so we get its data, and then after 800 ms, producer1 fires again. So we can see each time one of these producers fires, we pick up the data from that producer. So suppose we change the code to do this. Let's not put a delay here. Let's take the delay out of producer1. Let's also remove the delay from producer2. So we comment out both of these delays and then run the code again, and look at the output. We'll see that we are getting some output from producer2, but mostly it's from producer1. So producer1 and 2 are producing output at the same rate here, but the select is greedy. So we get producer1, then 2, then 1, 1, then 2, then 1, 1, 1, 1, 1, 1, 1, then 2, and so on and so forth. So we go and consume as much data as they can from 1. Occasionally it'll come around, find that 1 isn't quite ready yet, but there is data from 2, and then consume the data from 2, but be aware the select is greedy. If there's data waiting on that first channel, it will always take it, regardless of how many times it's taken it before and regardless of the fact that if this data were waiting on channel 2. So this is not a round robin procedure here, it'll always grab the first data it can find.

Handling Closed Channels with Select
So we saw examples of channels that are constantly producing streams of data and selecting on those channels. Suppose we don't have that. Let's change this code slightly and take out the loops here and just do a couple of simple sends. So producer1 sends 1 message, producer2 sends 1 message, we still have the select that's waiting on producer1 and producer2, and inside main, we're still going to repeat 15 times. So if I run this code, let's see what happens. So what happens here? Notice we get a message from producer1, so it sends out its data. Remember the select is greedy, so the select clause comes back around and tries to get the data from producer1 again, but at this point, the channel is closed. And what happens now is that the select clause throws an exception, and we get this ClosedReceiveChannelException. And really, this isn't acceptable; we really need a way to code around this. So what we can do in our code is rather than calling onReceive, we can do an onReceiveOrNull. And if the channel is closed, then the OrNull says rather than throwing an exception, send a null value through the channel. So, inside of here, rather than printing out the value. So let's change the way this behaves. So as our select call, rather than selecting on Unit, let's have it selecting on String, and then in the Receive calls, we're going to return a value. So we'll return the value if it's non-null, or if it is null, let's return the value Channel 1 is closed. And then let's do the same for Channel 2. So we select a value, or we return the string Channel 2 is closed. So our select statement returns a string, so let's change our selector function to also return a string. Once we've done this, we then need to return the string value from the selector method. And we can either do this by adding a return statement, or more idiomatically, we can just make the method equal to its body. So now what happens is the select executes returns a string, and that return string is returned back from the selector. Once we've done this, let's just print out the value returned from the selector. And now if we run the code, what we should see is that we get the first value from producer1 and then we constantly get channel 1 is closed, channel 1 is closed, again, showing that the selector is greedy, it's hitting the ReceiveOrNull, first time in, it's taking up the value, and subsequent calls the channel is close, it's just always executing on that channel. If we reverse these two clauses and run the code again, we get the reverse effect. So we get from producer 2, and then channel 2 closed, channel 2 closed. So again, just showing from one more time that the select statement is a greedy statement.

Using Side Channels
So, what else can we do with channels apart from a simple select and detecting that the channel itself is closed? We can also do something called a select on send. So within the select we can do a send. That send sends to the channel if the channel is ready, but what we can also do is we can send to a side channel. And this allows us to say try and send this channel, but if that channel is busy, actually send the data to another channel. So rather than blocking, waiting on the channel to execute, we can actually carry on working by using a sort of side channel to do the extra work that we needed to do. So the primary work is done on one channel, but then the extra work when that channel is overflowing can be done on this side channel. So we can do this as sort of do a non-blocking send. We can also poll the channel. So we can ask the channel if it can send or receive, so rather than blocking, waiting for the channel, we can say to it, are you ready, and then send the data. And we can also timeout. So we can also wait for a specific time, and if nothing comes through the channel in that time, simply timeout and go off and do something else. And this will simply stop us blocking forever. So let's take a look at side channels and how we might use them. So let's start by writing a simple producer and consumer. So here let's write a produceNumbers producer, and this thing will just be a producer of type Int. And in here we're going to produce 10 numbers. So for num in 1 to 10, we'll delay for 100 ms to make it look like we're doing some work, and then send that number down the channel, and then just print out a message when we're done. Inside main, we can create this producer, so we'll say val producer = produceNumbers, and then consume each of those numbers. So we'll do a producer. consumeEach, and inside here we'll just print out our number, so we'll do a println of $it. And then inside the consumer, let's delay for 500 ms. So the producer is trying to produce numbers every 100 ms, and the consumer is only able to consume them every 500 ms. And if we run this, we should see the number printed out once every half a second, so approximately 2 numbers printed every second. So, suppose our producer would like to carry on producing messages even if the consumer is busy. And we can do that by doing a select on send. So rather than simply sending the number down the channel, we can use a select clause. So we can say select and make this a select of type Unit in this case, and then inside the select clause, rather than calling send, we'll call onSend and send the number. And onSend takes a lambda, so let's put that in now. And this case, the onSend will do nothing after we've done the send. So now once we've done this, we run this code again, we should see no difference in behavior. We should still see the numbers produced approximately every half a second, and indeed we do. But what we can now do is let's pass a second channel to the producer and let's call this the side channel. And this will be of type SendChannel, again, of Int, as we're producing Ints, and then inside the select we'll do a side. onSend. And again, we're going to send the number, and again, this has a lambda. So now we need to create a side channel to send to produceNumbers. So that's just a channel. So here we can say val side = Channel of type Int, and we can pass that side channel into the producer. And then in a separate coroutine, let's launch this, so we can say launch, and then inside here doe side. consumeEach. And inside here we'll do the same thing, we'll just print out a message, and this time let's just print out side and then the value of the number that we are receiving. So remember that producer is producing numbers every 100 ms. The main consumer is only able to consume those every 500 ms. But now with the select, the producer is saying if I can send to the consumer, send it, if I can't, then send this data off to the side channel and let it do some work instead for me. So if I go and run this code, what we now see is the main consumer consumes the first number, and then the side consumes 2, 3, 4, and 5 while the main consumer is busy. The main consumer kicks in again and consumes number 6, and then side consumes 7, 8, 9, and 10. So by dong a select on send, we can set our producers up so they are never blocked. They can be sending this data off to other channels to do the work while the main channel is busy or the main channels are busy, in this particular case. So one last thing, suppose our producer is producing data too slowly, or suppose the producer gets blocked, and our receiver only wants to wait for a certain amount of time. So to do that, we can timeout. So again, let's create another producer. Let's just call this thing producer. And this again will just produce integers. So in here we'll do a while true. Inside the while true loop, let's delay for 50 ms. And then let's just send i++ where i is going to be an integer. So we'll say var i = 0. And then inside our main method, let's write a select, and again, it's a select of type unit, and inside this select, we go into select on the producer. So let's create that producer, so we can say var msg = producer, and inside the select do msg. onReceive, and inside the receive, let's just print out the value. So we'll do a println of it inside here. So like before, if I run this code, we simply print out the number. There's no repeat here, so we are simply grabbing that first number and printing out that number. So let's change the delay on the producer, so say, from 50 ms to, let's say, 5 s, and then run this code again. So now we're going to wait for 2, 3, 4, 4 seconds before the number is set. And we've decided that our receiver doesn't want to wait that long. In fact, the longest it wants to wait is, let's say, 100 ms. So what we can do inside the select is we can say onTimeout. And we give this a value, and again, inside here let's simply print out a message that says we're going to print out the fact that we've timed out here. And then run the code. So now we wait 100 ms and we timeout. And again, this is reasonable behavior. When you're doing any concurrent work, if you're doing any multithreaded work, you don't want to be blocking waiting forever for something to send you data. There will be occasions where if you do that you will wait forever. If you do that, you might find the application hangs, or you end up with deadlocks while you're waiting for multiple things. So you often need the ability to time out. And we can do timeouts on our select as well.

Summary
So in this module, we've seen how to use select, and we've seen that select lets us wait on many channels at the same time. And what this essentially gives us is control flow over channels. And this means it gives us a great deal of flexibility in the way that we use channels. Remember that when we use select, we can receive over the channel, and that will block while we're waiting for the data. We can use send over the channel to send to side channels, so we don't block while we're doing a send. Remember that the receive is greedy, it'll take whatever data is available, so it won't round robin over the channels. We can timeout on the channels, and remember that we can use timeout within the select, so we don't need to wait forever on these channels. So now that we've covered channels, next we'll take a look at actors. actors allow us to write concurrent applications and not worry too much about how we protect the state. We'll see that in the next chapter.

Using Actors to Communicate Between Coroutines
Introduction
Welcome back to the Using Coroutines With Kotlin class from Pluralsight. My name is Kevin Jones, and in this chapter we'll take a look at using actors within Kotlin. So what I'd like to do first is to have a think about why you might want to use actors, and actually what are actors, in a software sense, of course. So what are actors? So we can think of actors as lightweight processes. So they do small piece of processing, a small piece of work. They have no shared state, so all the state is contained within the actor itself, and actors communicate via messages. So if I want to talk to an actor, I send in a message; if an actor wants to talk to the outside world, it sends a message to the outside world. And this should sound familiar. Actors are essentially channels, but with the concept of state inside them. So an actor is like a channel that has a self-contained piece of state that the actor can work on. So why do we have actors? So actors provide a great way of protecting data. So because this state is fully maintained within the actor, we don't need to use mutexes or critical sections or any other mechanism whereby we synchronize access to that state. The actors themselves never share state; we maintain the state within the actor. If you want to send state between actors, we use messages. So because actors never share state, there's no need to ever compete for locks. So we minimize the amount of synchronization we have to do within the actor. So actors essentially give us another synchronization model on top of things like locks or mutexes or critical sections that we already use within our code. So how do we use actors within Kotlin? Well, Kotlin has an actor coroutine builder that allows us to build actors. So before get into actors themselves, let's take a look at how we currently protect any shared state. So for example, if we have an application that's trying to read to and/or write from a piece of shared state, we might need to protect that state from concurrent access. And there are various ways of doing that. We can mark the state as volatile, for example. Does that always work? Almost certainly not, but what that lets us do is flush the state constantly to main memory in a multi-processor environment. We have atomic type state, which is fine for certain things. So atomic int, for example, let's us atomically read or write an integer value. And we'll see in a moment where that can help. We can also provide locks. So we can provide coarse-grained locks around states, or another way to do this is to actually never let the state escape a thread. If we can confine state within a thread, then no two threads can get at that state. So each of these mechanisms, atomic types, locks, and thread confinement, give us a way to protect state within an application. So let's take a look at how we do this before we get onto seeing how we use actors.

Motivating Actors
In this example, I want to take a look at a simple counter class and the various issues we have with that class and the various ways we have of solving those issues. So this class is pretty straightforward. It has a private variable that's initialized to 0 that we call counter. It has an increment method, which in this class does a counter++. It has a value property that allows us to retrieve the value of the counter and to reinitialize it again. And it has a run function. And this run function does a couple of things. It measures how long the run takes. It also runs a set of jobs inside a coroutine and then calls back on an action within those jobs. So we see jobs = List of number ofJobs, and so we create that number of jobs and add it to the list. Within each job we repeat the number of times the count is passed in, and we execute the action each time inside that repeat. And we use that code here. So we create a counter object, and then we run it, and we run it twice. The first one is just to warm up the code, so we want to get the jitter active, make sure everything is loaded, make sure everything is running correctly. We then reinitialize this value to 0, and then we run it a second time. So when we run it, we tell it to run its coroutines in the common pool. We want it to create 1000 jobs and we want each job to count 1000 times. So in total we're going to increment this counter a million times. And then we're going to log out the number of jobs we executed, the number of times within each job we looped, the total time this took to execute, and the value of the counter. And each time around if we use 1000 jobs and we enter it 1000 times, the value of that counter should be 1 million. So if I run this now, what do we get? Well, it runs fairly quickly. It runs in 29 ms. It says it's completed a million actions, so the answer should be a million. But if we look at the value of the counter, it's only 403, 000, so obviously something has gone wrong. Let's just run this a second time and see what answer we get back a second time. Executes in 28 ms and the value is now 317, 000. So what's the problem here? So the problem is within this counter class. Within the class, we are doing increment, which is a counter++, and that's not an atomic operation. Under the covers, the processor reads the value from the counter, increments that value, and then writes the value back to that counter. We have a thousand coroutines trying to do that at the same time. And those coroutines are getting in each other's way. So one coroutine reads the value and increments it; another coroutine comes along and then reads the value before the first coroutine has written that value back again. So both coroutines have read the same value, they increment it once, and write the same value back. So even though we are doing a million increments, we're not doing them in the correct order. And this is the problem we're trying to fix. How do we write this code so that this counter++ is going to be thread safe? It's safe in a very hot-threaded, or hot-coroutine in this case, environment. And we'll take a look at a couple of solutions to that in this demo and then move on and take a look at actors. So here I've kept the code exactly the same, except I'm running the counter a second time. This is the same counter object, so an instance of counter. It's the same run, so I'm running in the CommonPool, same number of jobs, and the same count. But now the callback I'm doing a withContext. And the context I'm passing in is a single thread context. So what will happen here is every time the coroutine executes and wants to increment the counter, it will call back to our lambda, and our lambda is going to switch context to the single thread context and then increment the counter on that thread. This will give us thread safety, because all the increments are going to be done on the same thread. So we should get the right result now. So let's run this and see what happens. So indeed we get the right results. Counter value is a million. But notice the time. Whilst previously it took 25 ms, now it's taking 2 and a half seconds to execute this, so that's two orders of magnitude slower. And the reason it's that much slower is that we are marshaling back to the single thread for every increment. So we're saying it doesn't matter how large this piece of work is, break it down into very, very fine-grain chunks and marshal those fine-grain chunks back onto one thread and do the increment on one thread, which is what the logResult here says, this is a fine-grain piece of work. In some circumstances that's fine, and in some circumstances you'd need that, but we have to be aware of the drawbacks here. It will slow your code down greatly. What we could do here is something slightly different. Rather than marshaling back for every increment, we could simply just run the increment on the single thread. So rather than running the counter in the CommonPool and letting many threads hit the counter, in this case we can just say, well, look, I'm only going to run this on a single thread, so we use the same single thread context, and on that single thread, increment the counter. So let's reinitialize the counter and then run this and see what happens. Okay, so we've still got the fine-grained running in 2 and a half seconds with the correct answer, but notice now we have this course-grained run that also gives us back the correct answer. Okay, so the time is slightly slower than the base level counter running in the common pool, and we sort of expect that. The base level counter is doing a million iterations, but it's doing it across multiple threads. We are doing a million iterations essentially on the single thread, but we get the right results. So what we're seeing here is we are marshaling every piece of work up front onto that single-threaded context. We're running all of the coroutines on the single-threaded context, and they're doing each of their thousand iterations on that context in one go. We're not marshaling back each time. This will give us the right result, but it could be too slow. Again, in this case, it's not so bad, as we're only incrementing a counter. But it could be that marshaling everything back onto a single thread, even in this course-grained way, is not quick enough for what we need. It doesn't give us the flexibility for what we need. So there are other techniques that we can use. So I've introduced two new classes here, one called AtomicCounter, and inside AtomicCounter we're using a AtomicInteger rather than just integer. Notice the AtomicCounter class derives from counter, overrides the increment method so that we call increment and get on the atomic value, and then overrides the value property so we get the value back from the AtomicInteger. We also have a MutexCounter. And the MutexCounter uses a mutex, and then inside increment calls withLock, so that it locks each time around the loop. And then to use these in my code, I create a new AtomicCounter, run the AtomicCounter in the CommonPool, create a new MutexCounter, and run the MutexCounter in the CommonPool, and then list out how long it takes to produce the result. So let's run this now that these are all in place. So here we can see a fairly typical set of results. The base counter is by far the quickest, but it gives us the wrong answer. The fine-grained counter is slow because we're constantly marshaling back from the CommonPool thread to a single thread, but gives us the right answer. The coarse-grained counter is quick and gives us the right answer. The AtomicCounter is also reasonably quick, perhaps not quite as quick in this case as the coarse-grained one, but in some cases this is all you need, and again gives us the right answer. And notice the mutex is slow, so the mutex is doing a lock each time, so it's a lock, increment the counter, lock, increment the counter. So this is not quite as bad as fine-grained, but we're marshaling back and forth with threads all the time, but still has drawbacks. Now again, this is a really simple example. We're just incrementing an integer here. There are occasions where we have to use lock, for example, where we're trying to lock across multiple updates or multiple concurrent actions. In that case, mutex. lock might be absolutely what you need. And there are going to be occasions where you have to marshal back on a particular thread. Think of user interfaces, which we'll cover in the next chapter. In the user interface, I might need to do some work on a background thread, but the updates might have to be marshaled back onto the main UI thread because the user interface can only be updated on the UI thread. So all of these techniques get used in different places. Just be aware that you might need to do some locking, you might need to marshal onto a particular thread, and you have to choose the appropriate technique at the appropriate time. Okay, now that we've seen this, let's go and see how this applies to actors.

Writing an Actor - Demonstration
So actors consist I guess of three main parts. There's the coroutine, and we'll see in a moment that Kotlin provides a coroutine builder to build an actor for us. Actors maintain a state because we only ever execute the actor within a single coroutine, then that state is automatically protected within the actor itself. There's no need for any further locking, there's no need for any further state management. We can access that state freely within the coroutine. And then we have messages. So we use messages to communicate between actors. So to create an actor, we use the coroutine builder. So we say in this case functional myActor = actor, and we specify in the coroutine builder the type of message that the actor is going to process. So let's take a look at some examples. We're going to build various applications using actors, using messages, to see how these actors can communicate and how these actors manage state.

Writing an Actor
So we're going to rewrite the code from the previous demo where we do a counter increment using actors. Now, I apologize up front here. This code is going to be way more complex than simply incrementing a counter, and that's the very nature of actors. And the idea here is not to compare how we'd increment a counter using actors with how we'd increment a counter not using actors. The idea here is just to get an understanding of how actors work. So while the code is way more complex, it's more flexible in other situations. So let's see what that code is now. So notice we have the same run method. I've taken it out of the class here so the run method again just takes the number of jobs to execute, and then within each job does a repeat and executes the action withinside that repeat. So that's going to be exactly the same. So to use actors, the first thing we need are messages. And an ideal way to use messages within Kotlin is to use sealed class. So we defined a base sealed class and we'll call this thing CounterMsg. And then we need derived classes from this that are going to be the messages themselves, and we'll have three derived classes. The first two will be singletons, so I want an object called InitCounter to initialize the count, and that's going to derive from CounterMsg. We'll have another one called IncCounter that again derives from CounterMsg. And then finally we need a class to get the counter value, and we'll call this one GetCounter, and GetCounter, when it's created, will be initialized with a deferred. And we'll use that deferred to tell us when the counter is finished, so we know we can go and get the value from the object. We'll call this thing response and we'll give this a type of CompletableDeferred. It'll be a CompletableDeferred of type Int. And we will be getting an Int value out of this counter. And again, this will derive from CounterMsg. So just to emphasize here, Init to initialize the counter, increment to increment the counter, and then the get to get the value when the counter is finished. So now that we have the messages, we can create an actor. So we'll create a counterActor, and the counterActor is going to be an actor of type CounterMsg. So inside the actor, we're going to initialize our counter value to 0 in the same way that we did in the counter class previously. And then we're going to process the various messages. So we can say for var msg in channel, so these messages come in through the channel. So the actor is a mixture of channel and state. And the messages get received through the channel. So inside here we want to process the messages, so we can say for msg in channel, then because we have sealed classes here, we can use the when statement so we can say when msg. So if the msg is an InitCounter, we can just set the counter value to be 0 if I get the correct syntax. If the message is an IncCounter, then we can increment the counter, so counter++, and finally, if the message is a GetCounter, what we now want to do is to set the messages response value to be complete to say that we finished and give the value of the counter. So the actor in this case is actually fairly simple. It takes one of three messages, it initializes itself, it increments its counter, and it tells the outside world that we finished incrementing. So let's go and use this. So similarly to the previous demo, inside main, we set the total number of jobs to be 1000, so we're going to create 1000 actors, and then we're going to get each actor to increment its counter 1000 times. So let's create an actor, we'll say val counter = counterActor. We then need to initialize the actor. So we do counter. send and send it an InitCounter message. So that sets the actor and it says to it initialize your value to 0. I then want to launch the run method. So we do run, we're going to run this in the CommonPool, we're going to tell it how many jobs to use, and how many increments to run inside each of those jobs. And then inside this run method callback, we're going to do counter. send and send the increment message, and that will get the actor to increment its counter each time it gets that message. This run method waits on all the jobs that is flies off. If it flies off 1000 jobs, awaits them all to complete before it comes back. So the run method doesn't return until all the jobs are completed, and the actor has finished managing its count. At that point, we're going to send the actor another message to get the value out. So we can now say counter. send and we're going to send it the GetCounter message. The GetCounter message takes a deferred object. So we can say var response = CompletableDeferred, and it's a CompletableDeferred of type Int, so we call GetCounter and pass it the response, then once we've got the response back, we can print out the value of the response. So here we can do a println result is response. await. The reason we use the CompletableDeferred here is simply to get a value back out of the actor. There are other ways of doing this and we'll see this a little later. Later on we'll have actors communicating with each other using messages. So in this case, we have one actor we're sending messages in. Once we have the actor, it's then a matter of how do I get the data back out of it. So in this case, we're getting the data back up by sending in a message telling it give me back the data. And it's giving me back the data inside this ComputableDeferred. So if I run this code, we get back the right result. So in this case, we create one actor, we execute the actor inside 1000 coroutines, and inside those coroutines we send it 1000 messages. So because the actor is itself a coroutine, and that coroutine code is guaranteed to be executed sequentially, there's no need to manage any state in here. We can simply do counter++ inside the single actor, and the state is managed for us by the very nature of the coroutine itself. So we do get simplified state management, but what we give up for that is a more complex program model. So I'm not saying here that we're going to use this program model every time we need to protect state, but if we have complex state that we want to protect and it's hard to reason about how to protect that state, then actors might be a good way to go. So let's do one other thing here. Let's print out the time that this takes to run in as well. So the run method wraps up the jobs in a measureTimeMillis and it returns that time back to us. So inside run here, we can say val time = and get the time back from the run method. And before we print the result, let's print out how long it takes. And if we run this again, so about 1. 7 seconds, so much, much slower, almost a magnitude slower than if we weren't using actors. So, for example, the atomic increment took about 30 ms to run if you remember, so it's slower and it's more complex. But in certain scenarios where we have complex state, this is a better solution. Something else to think about is that each actor here does a certain amount of work, so each actor is maybe looping 1000 times to increment the counter, so you have 1000 actors. This time will vary depending on the amount of work that has to be done. So, for example, if I reduce the number of coroutines to 100 and increment the count to 10, 000, and then run this code again, notice when it was 1000 1000, time was 2 seconds. If I run this now, the time comes down, it's now about 1. 3 seconds. So you need to choose the model you're using depending on the complexity of the state that you have, and depending on the complexity of the work that you have on that state, and depending on those two things, you'll probably find that one of these models works better than the other. There's always one key thing when writing complex multi-threaded code or complex asynchronous code. You should always take a base measurement first, and then after that base measurement change the code to see which model best suits. You'll also find that might change depending on the system you're running on, so on this system, for example, I'm running on a Windows machine, it's a four core machine, each core will be an operation here, and that will affect the speed of processing. If you're running on an 8 core machine or a 16 core machine, then you might find that your behavior will vary depending on the number of cores. So always take a base level measurement and always try different scenarios to see what works best on a given class of machine and for a given problem.

Rock Paper Scissors with Actors
So, as well as using actors for protecting state, we can also use actors as a communication mechanism. Actors are all about messages. So what we'll do here is write a simple game of rock, paper, scissors. So to do this I've created a couple of message classes. We have a move class with a rock move, a paper move, and a scissors move, and we have a game class with a start game, a play, and a throw. Notice the start takes a deferred object. Again, this is a way of knowing when this particular game is finished, and we'll use that deferred object to get the result out. So for this to work, we're going to create a couple of actors. We're going to create a playerActor, and the playerActor is going to play the game, and we're going to create a coordinatorActor, and the coordinatorActor is going to coordinate both players. And these two actors will communicate using messages. So the way we play this game is inside main we'll create a CompletableDeferred, we'll create a coordinatorActor, and then we'll start the game by sending a start message to the coordinatorActor. And we know it's done when that CompletableDeferred has been completed. So we await on the deferred. So inside the coordinatorActor, we are going to be passed a CompletableDeferred, so we need to declare a variable to hold onto that passed in deferred object. The job of the coordinator is to create two players to play the game. So we'll have player1 is equal to a playerActor and player2 is equal to a playerActor. And then our coordinatorActor needs to respond to gain messages. So inside here, in the same way we had in the previous demo, we'll have a when to carry out certain actions when we receive a message, and the first message we're going to receive is a start message, so when we get the start message, we need to grab the completableDeferred out of the message and store it in our variable, and then we need to tell both players to play, and we do that by sending each player a play message. And as well as the play message, we're going to send the players our channel, so the players can call back into this actor. So we say to the players, start your play, when you decided what your play is, whether it's rock, paper, or scissors, tell me, tell the coordinator. And we also give each player a name, so player1, player2, is just the name of the player. So the player actor is structured very similarly. So inside here each player has a name, and each player is going to listen on the channel for a specific message. The message the player gets is going to be a play message. So when the player gets the play message, we store our name away, so we know who we are, and then once we've done that, we'll randomly decide on a move. So, we just pick a selection, so we either set the move message to be rock or paper or scissors. Once we've decided on the move, we send that move message back down the channel. So the message object is the play message, the coordinator has put their own channel into the play message, so we can do msg. sender, that's the value of the channel for the coordinator, we send a message to that channel, and the message we now send is the throw message. So throw is one of the game messages. And to the throw message, we tell that message our name and the move. So the coordinator will get one throw message from each player. So inside the coordinator, we need to process the throw message. So again, there's an if statement and it's is Throw. So inside here, the first throw message that comes in we grab the actor, and we grab the move, and then what we do is we block. We call receive on the channel. So we are waiting for the next message. We know we're going to get two messages, we get the first one, and then we wait for the second one. Once we have the second one, we grab the actor from the second message and the move from the second message. What we can now do is calculate who's won the game. And we'll do that in a function called announce, and we'll write that function in a moment. The announce function we pass the name of playerA and the move playerA made, the name of playerB and the move playerB made. Once that's done, we can then tell the original caller that we finished. So both players have thrown, we've announced the move, and I'm done, and we do that by calling complete on the CompletableDeferred. So the announce function is not particular complex, there's just a lot of it. So inside the announce function, we just take a look at the moves. If they're the same, then we have a draw, and then we compare moveA's rock to moveB and moveA's scissors to moveB and moveA's paper to moveB. Depending on which one we have, either A wins or B wins. So here we have two actors coordinating using messages. So we use the coordinatorActor to start the game. That kicks off two playerActors. They do some work, send the result of their work back to the coordinator, the coordinator waits for both of them to respond, and then based on the response, announces a result. Let's go and run this and see if it works. So in this case, player1 throws rock, player2 throws paper, so player2 wins. Let's run this multiple times and see what happens. So let's just repeat this 10 times and put the closing brace in, make this slightly larger, run the code again, and we should see a mixture of results. So paper beats rock, scissors and scissors draws, scissors beats paper, scissors and scissors draws, and so on and so forth. So again, we're getting coordination across multiple actors. And this is another extremely important use of the actor model, doing coordination by using multiple messages.

Calculating Pi The Hard Way with Actors
So let's take a look at one last example. We're going to calculate pi. And the idea here is that we bring together the two things. We bring together the idea of actors sending messages to each other, and we also bring together the idea of isolation, so an actor doing a chunk of work in isolation. So there's a formula to calculate pi called the Leibniz formula, and that looks something like this. So we can say pi = 4 times 1 minus a third, plus a fifth, minus a seventh, plus a ninth, minus, plus, minus, minus, and this goes on to infinity. And the more terms that we calculate, the closer this value gets to pie. So what we can do inside this term is we can break the term down into chunks. If we have four actors, for example, and we have 100, 000 iterations of this term, we can pass 25, 000 of those units to each actor, so the first actor gets the first 25, 000 parts to calculate, the second actor gets the next 25, 000 parts, and so on and so forth. So what we have here are two actors. We have a worker actor. So the worker actor decides how many iterations there are going to be, and in this case, we're going to use 2 billion. So a lot of iterations to do this. We know how many workers there are going to be, and we tell the workerActor how many workers there are going to be, so we do that by sending the workerActor a start message. And part of the start message is how many workers to use. So inside the start message handler, we store away a response object and we store away the number of workers to use to calculate pi. We then break the range of iterations down, the 2 billion, equally amongst the workers. So if I've got 2 billion iterations, and I've got 4 workers, then each worker is going to get half a billion iterations. And we have to ensure that each worker gets its own range. So the first worker will get from 0 to 499 million, the next 1 will get from 500 million to 1 billion, and so on and so forth. And we send each actor a message, and the message tells it where to start and where to end, and also the channel to send the response back to when it's finished. And it's going to send back a result message when it's done. The value at the end here, the i, is just used to identify the worker we're going to use. So that will be a number between 0 and the number of workers. And we'll see that in a moment. So we'll see that we can print out the worker id, and that will show us which workers are doing work. So we start the pi calculation going by sending a message to the workerActor. The workerActor then sends messages to each piActor, and each piActor does its part of the calculation. Each piActor then sends its result, this total, back to the workerActor, and it sends that in a result message. Inside the workerActor we work out how many results we've had. If the number of results we've had back is equal to the number of workers, we then set our deferred and say yeah, it's complete, and pass back the total. Inside main, we await on the deferred, and we finally print out the result. So we can see two things here, we can see isolation, so each worker is working on its own chunk of code and its own state, and we can see message passing between actors to manage coordination. And we can use this to show, for example, the efficiency of using multiple threads when we have large chunks of work to do. So if I set this calculation going with just one worker, I'm going to print out two things. The first thing I'm going to print out here is the range, so which range of iterations the worker is working on, so start to end, and then in the worker itself, every 50 million iterations around this particular loop, I'm going to print out the worker ID, so that'll be a number between 0 and the number of workers that we've created. And then at the end we'll print out the result, so hopefully this will be close to the value of pi, and the total time it took to get to that result. So if I go and execute this code, so we see that we only have one worker, and it's calculating everything for us, so between a range of 0 to 2 billion. And the 0s that are being printed out here is that worker ID, so each time around this loop, each 50 millionth iteration, we print the worker ID. So we only have one worker going. So this calculate pi as 3. 14159 in about 17 seconds, so 16. 5 ms. So if I increase the number of workers from 1 to 4, what we might expect to see is that time reducing from 16 ms to around about 4 ms, maybe 5 ms. So let's run this and actually see what happens. So now we get four workers, so there are the various ranges. We see the IDs of the workers printing out, so each one is sort of doing some work in turn, and then we get an answer. And again, we get 3. 14159, this time in about 6 ms. So we have four workers where previously we had one, but the amount of time to do the work is not a quarter of what it was previously, it's slightly more than a quarter. And that's because there's overhead. There's overhead with things like thread switching, there's overhead with just context switching between the coroutines. So we do get a benefit here of using multiple workers, but the benefits might not be everything that you think it is, because there's overhead in managing all the threads and all the coroutines that are actually doing the work here. So hopefully in this example we can see where actors might be useful where you have large chunks of work to do that really should be done in a thread-safe way and you want to communicate between the things that are working. This is where actors really come into their own.

Summary
So in summary then, actors are essentially channels with state. And we can use actors to avoid some of the pitfalls of concurrency. They're essentially lightweight processes, and they're directly supported by Kotlin, so we have an actor coroutine builder within Kotlin. Actors communicate using messages, and inside an actor we don't need to worry about locking, we don't need to worry about shared state, because the actor encapsulates the state that we have. Okay, so now that we've seen actors, there's one last thing to cover in this class, and that's using coroutines inside a user interface, and we'll cover that next.

Using Coroutines in UI Applications
Introduction
Welcome to the final chapter of Programming Coroutines in Kotlin class from Pluralsight. My name is Kevin Jones, and in this chapter we'll take a look at how we can use coroutines in UI-based applications. So UIs have a problem. And the problem is that typically inside a UI all controls must be accessed through the main user interface thread. And the reason for this is that we don't want to use synchronization to access these controls. It's difficult to apply that synchronization right through the application, and it's difficult to manage that synchronization, and it may well slow the UI down. However, we still want to run long running tasks inside a user interface application. We might want to get data from a network. We might want to write to disk. We might want to do calculations. So we need to perform these tasks away from the main thread. If you perform these tasks on the main thread, then we'll generally block up the main thread and make the UI very unresponsive. So to perform these tasks away from the main thread, we will have better performance, or at least we will perceive better performance. As far as the user is concerned, the user interface is still active, we can still use it, or we are away on the background doing some work. However, whatever work we do, if that work produces results, then those results have to come back to the UI thread to update the user interface. And this doesn't matter in Java if we're on Android, if we're on JavaFx, if we're on Swing, we still have to be able to update the user interface from the main user interface thread. So coroutines in Kotlin support user interfaces. To do this, we bring in a library, which will be the kotlinx-coroutines-javafx library if we're running in JavaFx, or the kotlinx-coroutines-android library if we're using this in Android. Then you import the appropriate namespaces to use this code either in Android or in JavaFx. In this class, the examples I'll show will be in JavaFx, mostly so we can run this very easily on the desktop. So if we want to use Kotlin coroutines in a user interface application, then we have to ensure that any update to the user interface application is done on the UI thread. So we can run work in the background, but then what we can do is launch a coroutine and pass it the UI context, and that will guarantee that the work the coroutine is doing is done on the user interface thread. So the typical way we do this will be to do on a background thread or in a context that's not the UI context, and then when we want to update the user interface, launch back onto the user interface thread and update the user interface through the UI context. So let's go and write some code and see how we use this in practice.

Using Coroutines in User Interfaces
The application we have here is a very simple JavaFx application, and if I run this, we can see that it has a label which holds a counter, and it has a button. And when I click on the button, we simply increment the counter. So nothing too radical inside the application. So this application is written using TornadoFx, which is a library that wraps up JavaFx and it's a library written in Kotlin, a framework if you like written in Kotlin, and provides a very nice way of building JavaFx applications using standard Kotlin idioms. And what we'll do is we'll build on the simple application as we go through the next few demos. So the application is very straightforward. There's a stage where we set the width and the height, and there's a single view, and that view is a BorderPane, and inside the BorderPane we have a vertical box that has a label and has a button. The label is bound to a counter, which is currently a simple integer property, so when we update the value of that counter, the UI is updated automatically, and the button has some text, which says click to increment, and then an action which calls the increment method, and that increment method simply updates the counter value. So the first thing I'd like to do is to fake the user interface and pretend that it's doing a lot of work. And we'll do that by putting a Thread. sleep here. So the idea is the user clicks the button and the UI has to go off and do lots of work before it can come back and update itself. Now let's go and run this code. So inside here now if I click, we'll wait a few seconds, and after a few seconds the UI changes, and that looks fairly normal. If I click again and try and drag this window around, while that click is active, the main user interface thread is blocked. And this is the behavior that we are trying to avoid. So let's go about doing that by using coroutines. So in this case, there are a couple of ways of doing this. What we could do is launch the increment method inside a coroutine. And if we do that, this Thread. sleep, rather than running on the main thread, I'm blocking the main thread, will now run on a background thread. So we're now doing the work on the background thread. However, we know the reverse issue where we're trying to update the user interface, this counter from that background thread, and we shouldn't do that. So what we could do is inside the increment method launch the update back on the UI thread. So we do that by using launch and by using the UI coroutine context. So now if I run this code and click on the button and drag the window around, we're dragging the window around while the background thread is asleep, but then the value still gets updated. So do that again, if we click and drag the window around, then again the value was updated. However, there is an easier way in this case. Let me go and copy this code, just to save it, and we'll call this oldincrement. And then in the increment method, rather than doing Thread. sleep, let's do a delay, and because we're calling delay we have to mark this as a suspending function. We don't need to run back on the UI thread here now. As we go in the launch call here, have this entire call just run on the UI thread. So again, if I run the code, click, drag the window around, we can now drag the window around without causing any freezes. And the reason for that, remember, is that the delay function is not a blocking function. So the delay function just gives up its time slice and eventually will come back when that time slice is available again. So in the case, the UI thread will carry on running as it was before. We can also cancel this behavior. So let me add another button to this and do that simply by copying the one that we already have and then pasting it back in again, and in here let's just say Click to cancel. So now what I'm going to do is in the original button I'm going to capture the returned value. Remember that returned value is a job, and the top here, let's do this, let's have a lateinit var of counterJob, and that's going to be of type Job. So we launch the coroutine and we capture the job. And then inside the cancel button, I'm simply going to call counterJob. cancel to cancel the job. So what we should see when we run this, if we click the increment button, and then click the cancel button, and the UI should never get updated. So let's try that. So there's our two buttons, click to increment, click to cancel, wait a couple of seconds, and indeed the UI hasn't changed. So we cancel the jobs in the same way we would in a non-UI application. Grab a reference to the job object, call its cancel method, and that cancels that coroutine.

Using Actors in User Interfaces
So we can also use user interfaces with actors. And as a final example, we're going to use our old friend the piActor we created earlier. So here this is the code we saw for the console pi class, we have the piActor, we have the workActor. I've taken out the main method here so we can't run this from the console. So we're going to run this pi code from within the JavaFx application. So if you remember, the way the piActor communicated back to the main thread was through a deferrable. So let's declare that here. So we can have a CompletableDeferred that we can use within the code. Let's change the title to say pi. Let's change our first button to say Click to calculate. And then let's change the name of this to say calculatePi. And then we'll get rid of the suspend function here, and we'll add the calculatePi suspend function in a moment. So we want a suspend fun calculatePi, and this code will be somewhat similar to the main code from the previous chapter. So here we'll create our CompletableDeferred object, and then we need to use the workerActor defined in the pi code. So the workerActor here is the thing that starts up the pi calculation. So, we do workerActor, passing it a coroutineContext, and we're going to use CommonPool for this. So it runs on the background threads. We're going to call the send method. What we're going to send to this is a Start message, and that Start message takes the deferred and the number of workers to use. After this finishes, the deferred will be completed, so to get that value, we can call response. await, and the result of that await is the value of pi. So in our code previously, we had a counter, let's change the name of that to pi, and then rather than being a SimpleIntegerProperty, this now needs to be a SimpleDoubleProperty as pi's double value, and then we bind here to pi. So we can say pi. value = response. await. And before we run this, before we calculate pi, let's just set pi to a value equals to pi. So if we recalculate it, we can see that this being reset and then being recalculated. So I go ahead and run this. Click on calculate pi. We can see in the output window the actors running, and then eventually the answer comes back 3. 142. If I calculate the game, we would reset it to 0, I can drag the window around, the actors are still running in the background, and when those actors stop running, we should get the result, and indeed we do, 3. 142. Okay, so that's pretty nice. So let me close the window and let me look at the code. So in here currently we'll launch the user interface, we get back a job from the launch, and then we try and inside the cancel call that Job. cancel method to cancel the job. So let's see if that works. Let's run this again. Click to calculate, click to cancel, and we haven't cancelled the job. So at this point, we've tried to cancel the top-level coroutine, but the actors aren't really associated with this context. The actors don't get cancelled. What does get cancelled is the top-level coroutine, so the actors are still running in the background, but the user interface doesn't get updated, as we've essentially cancelled the suspend function. So the suspend function stops running. The UI never gets updated, but the actors are still running in the background. What we'd like to do when we click on cancel is to cancel those coroutines as well, to cancel those actors as well. So let's see how we can do that. So I want to modify this code slightly. As we don't need this counter job here to do the cancellation, I'm going to remove that code from here, remove these comments, and remove that code from here. So what I'm going to do is remove the counterJob, as we don't need that to do the cancellation. Instead what I'm going to do is to introduce a new variable, and that variable is going to be of type job. So the top of the code here, create a job, and I'll call it actor, actor of type job, and we create an instance of that. And then what I'd like to do is for every actor is to associate that actor with the job that we just created. So when we set off the actor here, we specify the context the actor runs in, we can also specify the actor's parents. So in this case, this is the actor's parent job. So for both my piActor and my workerActor, I'm going to say parent = actor. And we'll see another way of doing this in a moment as well. Then inside the JavaFx code, rather than calling counterJob. cancel, what I'm going to do instead is call actor. cancel. And actor. cancel will cancel the top-level job. That will then cancel the actors running and they're doing their calculation and the workerActor. Now we need to remember that cancellation is cooperative. So to cancel my piActor here, this piActor has to check to see if it's being cancelled. So let's do that. So inside here, let's just call this every time we run the loop. So if I'm active, then print out the message and do the calculation. And if I'm not, well, what do we do if I'm not. So, else, let's go and throw a CancellationException. So we know at this point that we've been cancelled. This is possibly too fine-grained, and maybe I should do this every thousand on the loop or every million times around the loop, as this is a very, very tight loop. But in this instance, just isActive at the top of the loop here is fine. For the workerActor, there's really nothing much to do. This workerActor will typically be inside waiting for the messages, so it should cancel automatically as part of its standard process. So let's go run this code. So if we click to calculate, we can see the worker is running away. If I click to cancel, the workers have stopped. So we've definitely cancelled the process here. However, there's still a problem. If I click to calculate again, it doesn't restart the calculation. So let's fix that. So to fix that, so the problem we've got is that the job object is cancelled. So when I click to calculate again, that's tries to call calculatePi. CalculatePi kicks off the workerActor, but the workerActor is associated with a job, and that job is now cancelled. So what we need to do is to reinitialize the job. So in here we want to reinitialize the job. Well, we only want to do that if the previous work was cancelled. So how do we know that? Well, inside the pi code when we are cancelled, we throw a CancellationException. So we can just catch that exception. So we can wrap the workerActor in a try catch, we can catch CancellationException, and then inside here let's print out a message that says log Cancelled, and then let's do actor = Job to recreate the job. And we have to do one more thing. If we cancel the actors, we also have to fire the deferred, just to make sure everything completes successfully. And now if we run this code and calculate, see the worker is running, cancel, and we get the message saying the thread was cancelled. If I start again, then the worker starts running again, and we should get the results. And there we go. So we can use actors inside UI threads; we can also cancel them. Honestly, we build into this, the more work it needs, but these are a very good way of offloading work on background threads and maintaining state correctly.

Summary
So we already know that coroutines make it easier to run work in the background. Really that's the whole point of these things, to run work asynchronously away from the main thread. And that makes these things ideal companions to a user interface. When you want to execute that work back on the foreground thread, then you can launch the coroutine using the UI context. We've also just seen how easy it is to integrate actors into a user interface as well and use those actors to perform complex work in the background. So that's it from me for this course. I hope you've enjoyed it.

Course author
Author: Kevin Jones	
Kevin Jones
A long time ago in a university far, far away Kevin fell in love with programming. Initially on the university's DEC20 computer doing BASIC and Pascal and a little bit of Fortran. His first job had...

Course info
Level
Advanced
Rating
4.9 stars with 18 raters(18)
My rating
null stars

Duration
3h 50m
Released
10 Aug 2018
Share course