Essential Cloud Infrastructure: Foundation
by Google Cloud

In this course, Essential Cloud Infrastructure: Foundation, you will learn how to deploy solution elements, including infrastructure components such as networks, virtual machines, applications services, and more.

This course, Essential Cloud Infrastructure: Foundation, introduces you to the comprehensive and flexible infrastructure and platform services provided by Google Cloud Platform. Through a combination of video lectures, demos, and hands-on labs, you explore and deploy solution elements, including infrastructure components such as networks, virtual machines and applications services. You will learn how to use the Google Cloud Platform through the console and Cloudshell. You'll also learn about the role of a cloud architect, approaches to infrastructure design, and virtual networking configuration with Virtual Private Cloud (VPC), Projects, Networks, Subnetworks, IP addresses, Routes, and Firewall rules.

Course author
Author: Google Cloud	
Google Cloud
Google Cloud can help solve your toughest problems and grow your business. With Google Cloud, their infrastructure is your infrastructure. Their tools are your tools. And their innovations are your...

Course info
Level
Intermediate
Rating
4.9 stars with 11 raters(11)
My rating
null stars

Duration
1h 35m
Updated
17 Jan 2019
Share course

Welcome to Essential Infrastructure: Foundation
Essential Cloud Infrastructure: Foundation Course Intro
Hello, and welcome. My name is Jasen Baker with the Google Cloud Platform, and welcome to the Essential Cloud Infrastructure Foundation course. Now in this course, we're going to answer the question what is GCP? Essentially, it's a collection of managed services and product offerings. Now those services could give you a lot of control, since it's virtual machines, or all the way to things like App Engine, in which we actually abstract a lot of the difficulties from you, and you just simply deploy the code. But wherever you want to be, this is that foundational course that's going to get you started. Now what's very important about this course is we're going to start with our introduction to Qwiklabs. Qwiklabs is going to allow us to automate the environment for you. So you don't have to whip out a credit card. We will automate this deployment. You will be allowed to work inside of the Google Cloud on Google's dime for a specific period of time. So you can experiment all that you want. You can destroy the environment, and trust us, you can't break it. We're also going to learn how to interact with Google Cloud Platform. So that's going to introduce things like the Google Cloud Console, the Google Cloud Shell, the API, SDKs. Whatever your flavor of interaction, we definitely will cover all of those different aspects. Another one is virtual networking. This is the core foundation. How do your virtual machines connect to each other? If you have applications that are all over the world or customers that are global, you need to understand how Google does networking. It's much, much different than probably what you've come from. It's essentially a single, flat network that spans the globe. Now integrated with that, we have features such as autoscalers, load balancers, routers, firewalls. All of these actually are not appliances that you're used to in your data center. These are essentially rules that Google has distributed its global fiber network. So imagine that you don't have a load balancer as a thing. It's just simply a set of rules. Firewalls are rules. As traffic comes in, where does it go? It's not a physical device you have to worry about. So I think you're going to find that particular portion, that particular module very, very interesting. Then finally, we will conclude with virtual machines. So once you have laid out the foundation, set up your network, we'll talk about virtual machines. Essentially, how do they work in the cloud environment? If you're moving from the physical environment and physical servers, how do you translate to what Google has to offer? Now think of what a virtual machine is. A virtual machine is essentially a collection of memory, CPU, some kind of storage, and network connectivity, and all of these components can be pieced together in what we call Google Compute Engine. And we'll talk about how all of these will combine together, how they're going to scale, and the different nuances in choosing what happens with that. Now what's really cool is we're going to talk about custom virtual machines, how you can customize it to your exact needs, preemptible virtual machines, which are VMs that can come off at 80% off of list price. We offer things like per-second building and committed use discounts. So if you want to commit ahead of time to a certain amount of utilization, you can certainly do so. But what I want to show you is exactly how we're going to combine all of these features into a very productive infrastructure.

Introduction to Google Cloud Platform Infrastructure
Module Overview (Intro)
Hello, and welcome. I'm Philipp Maier, a course developer with Google Cloud Platform, and this is module one, Introduction to GCP Infrastructure. Before we start using all of the different services that GCP offers, we need to talk about what GCP is. Once you understand the infrastructure from a high level, you're going to learn how to use GCP. Using what you learned, you'll be able to interact with the platform in two short labs. And to round up your learning experience, I will provide a quick demo of projects.

Google Cloud Platform (GCP) Infrastructure
When you take a look at Google Cloud, you'll see that it's actually part of a much larger ecosystem. This ecosystem consists of open-source software, providers, partners, developers, third-party software, and other cloud providers. Google is actually a strong supporter of open-source software. Google Cloud consists of Chrome, Google devices, Google Maps, Gmail, Google Analytics, G Suite, Google Search, and the Google Cloud Platform, or GCP. GCP itself is a computing solution platform that really encompasses three core features, infrastructure, platform, and software. You can think of GCP as a suite of cloud-based products and services that is continuously expanding. Many of the products and services have unique blue hexagonal logos, such as the ones shown on this slide. It's important to understand that there's usually more than one solution for a task or application in GCP. To better understand this, let's look at a solution continuum. Google Cloud Platform spans from Infrastructure as a Service through Platform as a Service to Software as a Service. Notice that each alternative solution on this continuum causes concern about different objects, like managing components, systems, or resources. This changes the role of the operation staff, like IT ops, SysOps, all the way through NoOps, and changes the items that are being managed, like CPUs, memories and disks, or service applications with autoscaling. Throughout this infrastructure specialization, we'll be covering this entire solution continuum. Let's start with the infrastructure. An IT infrastructure is like a city infrastructure. The infrastructure is the basic underlying framework of fundamental facilities and systems such as transport, communications, power, water, fuel, and other essential services. The people in the city are like users, and the cars and bikes and buildings in the city are like applications. Everything that goes into creating and supporting those applications/buildings for the users/citizens is the infrastructure. The purpose of this specialization is to explore as efficiently and clearly as possible the infrastructure services provided by GCP. You should become familiar enough with the infrastructure services that you will know what the services do and basically how to use them. By the end of this class, you will be prepared to learn anything that you need to do to use the Google Cloud Platform. In other words, we won't go into very deep-dive case studies on specific vertical applications, but you'll know enough to put the building blocks together to build your own solution. Specifically, this series of courses consists of four parts. First, we will cover the foundation of the essential infrastructure, which will cover the basic technologies. Next, we will focus on the core services, which are the building blocks of the essential infrastructure. Then we will cover the augmented infrastructure, which are the systems built on top of the essential infrastructure for scaling and automation. Finally, we will focus on the application infrastructure consisting of containers and the services specifically provided to make it easier to develop applications for your users. The individual bullet points represent each module that we will cover.

Using GCP
Let's look at how to use GCP. There are three basic ways you can interact with the Google Cloud Platform. You can use the Google Cloud Platform Console, which provides a web-based graphical user interface that you access through console. cloud. google. com. If you prefer to work in the terminal window, the Google Cloud SDK provides the gcloud command-line tool. GCP also provides Cloud Shell, which is a browser-based interactive shell environment for GCP that you can access from the GCP Console. Cloud Shell is a temporary virtual machine with 5 GB of persistent disk storage that has the Google Cloud SDK preinstalled. Throughout this specialization, you will apply what you learn in different labs. These labs will have instructions to use the GCP Console, such as on the Products & services menu, click Compute Engine, VM Instances. Let's dissect these instructions. First, within the GCP Console, you will click on the icon with the three horizontal lines, which is the products and services icon, as you can see on the left. This opens a menu, as you can see on the right. All of the major products and services are listed in this menu. Second, within the menu, hover over Compute Engine to open a submenu. Finally, click on VM Instances within the submenu. You will get more comfortable with these instructions and the GCP Console as you work on labs. Labs will also use command-line instructions. You will enter these instructions either in Cloud Shell or an SSH terminal by simply copying and pasting them. The right side of the slide shows an example of what a command and its output will look like. In some cases, you will have to modify these commands, for example, when choosing a globally unique name for a cloud storage bucket. Besides the Cloud SDK, you will also use client libraries that enable you to easily create and manage resources. GCP client libraries expose APIs for two main purposes. App APIs provide access to services, and they're optimized for supported languages such as Node. js and Python. Admin APIs are for functionality for resource management. For example, you can use admin APIs if you want to build your own automated tools.

Lab: Console and Cloud Shell (Overview and Objectives)
Lab: Console and Cloud Shell (Review)
In this lab, you created a Cloud Storage bucket using both Cloud Console and Cloud Shell within GCP. Cloud Console can do things Cloud Shell can't do and vice versa. Cloud Console can keep track of the context of your configuration activities, it can use a Cloud API to determine from current system state what options are valid, and it can perform repetitive and more leverage activities on your behalf. Cloud Shell, on the other hand, offers detailed and precise control, and through its command, a way to script and automate activities. That being said, don't think of them as alternative. Think of them as one extremely and flexible and powerful interface.

Demo: Projects
Next, we will explore projects, which are the key organizer of infrastructure resources and relate these resources to billing accounts. Resources can only be created and consumed within projects in a way that projects isolate related resources from one another. You will see how to create, delete, and switch context between projects. Some of these actions cannot be performed in the Qwiklabs environment due to security restrictions; therefore, I'm going to demonstrate them in my environment. So here I am in the GCP Console. And if we see up here where it says My First Project, I'm going to click on that, and this shows me the current projects that I have created. Now to go ahead and create a new project, I'm just going to hover over here on the plus icon, and that is clearly identifying as the way to create a project. Now first I'm asked for a project name. This is really just a human-readable name, a way for you to identify your projects within your Console, and it's not used by any of the Google APIs. So let me just say this is My Awesome Project. And when I do that, you'll see that down here there's automatically a project ID which has been generated. Now this, on the other hand, is globally unique, meaning that no one else can be using that project ID. If you don't like your project name, you can always go ahead and change it after you have created your project, but the project ID will stay this value once you've created your project. So let me go ahead and click Create. And this is going to pop up a notification up here, and it's just going to say that it's currently creating my project, and it'll also let me know once that is completed. So we see it's actually completed, so let me go ahead and switch to that new project, which I do through the same interface that I used to create the project. And now I can go to the project settings, and here, as you can see, I can change the project name, as I mentioned earlier, and I also have my project ID. And there's also a project number. This is also a globally unique identifier and cannot be changed either once the project is created. Now there are a lot of services associated with this project. So for example, if I now want to go ahead and create a Google Compute Engine instance, I would first have to activate that service, and that would pop up then a notification and let me know when this is active. And this really just takes a minute or two, but is a step that's required for every new project that you create. Now once you don't need a project anymore, you could go and shut it down. The button is right up here for that, SHUT DOWN. And really what that does is it requests the project to be deleted, specifically within 30 days. So if I process this right now, it's telling me that the billing and traffic serving will stop, I will lose access to the entire project, and all the project owners will be notified and can stop the shutdown within the 30-day window. In my case here, I want to actually go ahead and shut this down. To do that, I need to verify the shutdown procedure with the project ID, so I'm just going to type that down here. So it's also showing me that ID, so I can directly copy that. And I click on SHUT DOWN. This is going to process now. And here I get a notification of when exactly that project is going to be deleted, which is a month from today. So let me go ahead and close that. So now we see I just have the two projects in here that I originally had. Now to do anything else, I really need to select a project, so let me select this first project. Now you can also switch between projects using Cloud Shell, which you've seen in the previous lab. So let me go ahead and activate Cloud Shell. Because this is the first time activating Cloud Shell, you'll get another notification saying do you want to activate Cloud Shell? And this is now establishing a connection, so we're just going to wait for that to load up. And now I am within Cloud Shell for this specific project. We can see that up here in my session it's currently saying the project I'd, which if I scroll down here, we see that is the project ID for that project. And I can also type in a command to identify the current project, so let me do that. So the command I'm going to type is gcloud config list, and it is going to list all the configurations. And specifically, we see that the project ID is listed here. Now what happens if I go into the GCP Console and now switch to a different project? So instead of this first project, let me switch to this other project. Okay, so we can see the Console itself has changed. But in Cloud Shell, if I now ask again for the project ID, which I can actually be more specific, use the same command, but also use the grep command and then specifically ask for the project, then it's going to tell me that I'm still within that first project ID. The other way you can tell it is if you look at the command line, you see that down here I first have the username, @, and then I have the project ID. And you also see it within the session up here, the first project ID is currently still listed. So how do we change that? Well, you could close the Cloud Shell right now and reopen it, or you could open a new session, which I can do here by clicking on this plus icon. And if in here now I ask for the project, we can see that I'm looking at that second project. Another way to do this is you can actually just switch the project directly within the command line. And a good strategy is always to store some of the IDs and project numbers that you have within a shell variable, so let's go ahead and do that. I'm going to create a variable called PROJECT_1_ID, and I'm going to get that project ID. Just copy it right here and paste it directly into Cloud Shell. So now I have a variable that is holding that. Now the command to actually change the project is gcloud config set project, and I'm just going to use that variable then, so PROJECT_1_ID, and this says it updated now. We can see that because the command line here has updated. And I can also, again, query for that project, and we can see that now my Console is at that project and my Cloud Shell has also changed. So in this demo, I showed you how to, how projects are created and deleted, how to switch context between projects, and how to use Cloud Shell with projects. Most importantly, the Console's current project is independent from the Cloud Shell's current project. But as you saw, you can use the Cloud Shell command prompt as an indicator, and you can issue a command to change the current project in Cloud Shell.

Lab: Infrastructure Preview (Overview and Objectives)
Lab: Infrastructure Preview (Review)
In this lab, you were able to launch a complete continuous integration solution in just a few minutes. You demonstrated that you had user access through the Jenkins UI and that you had administrative control over Jenkins by using SSH to connect to the VM where the service is hosted, and by stopping and then restarting the services. Many of the activities that occurred in this lab were nearly transparent, and they used resources and methods that you'll learn about in the rest of the specialization, for example, the acquisition and configuration of a network IP address, the provisioning of a virtual machine instance along with the installation of software on that machine, and the passing of default state information from the environment during the setup process.

Module Review
In this module, I gave you an overview of the Google Cloud Platform infrastructure. Then we looked at how to use GCP, which you got to experience in two short labs. I also gave you a demonstration of how to use projects, which are the key organizer of infrastructure resources. Now that you can interact with GCP, it's time to explore two of the foundational components of GCP's infrastructure, namely networking and virtual machines. So, what are you waiting for? Move on to the next module to learn more.

Virtual Networking
Module Overview (Intro)
Hello, and welcome. I'm Philipp Maier, a course developer with Google Cloud Platform, and this is module two, Virtual Networks. GCP uses a software-defined network that is built on a global fiber infrastructure that makes GCP one of the largest and fastest networks. Thinking about resources as services rather than as hardware will help you understand the options that are available and their behavior. For example, a persistent disk isn't really a physical device. It's a service that you acquire and use over a network. So, a good understanding of GCP begins with a solid understanding of how GCP has implemented networking. In this module, we will start by introducing virtual private cloud, or VPC, which is Google's managed networking functionality for your Cloud Platform resources. Then, we're going to dissect networking into its fundamental components, which are projects, networks, subnetworks, IP addresses, routes and rules, along with billing. Next, you will explore GCP's network structure in a lab by creating networks and subnetworks of many different varieties and exploring the network relationships between them. After that, we will look at common network designs, like a bastion host isolation, which you will get to implement in a lab.

Google Cloud Platform (GCP) VPC
With Google Cloud Platform VPC, you can provision your GCP resources, connect them to each other, and isolate them from one another in a virtual private cloud. You can also define fine-grained networking policies within GCP and between GCP and on-premises or the public clouds. Essentially, VPC is a comprehensive set of Google-managed networking objects that we will explore in detail throughout this module. Projects are going to encompass every single service that you utilize. Networks come in three different flavors, default, auto mode, and custom mode. Subnetworks allow you to divide or segregate your environment. Regions and zones represent Google's data centers, and they provide continuous data protection and high availability. VPC provides IP addresses for internal and external use, along with granular IP address range selections. As for virtual machines, in this module, we'll focus on configuring a VM from a networking perspective. In the next module, we'll go deeper into how to set up and configure virtual machines. Finally, we'll conclude with routes and firewalls. IP forwarding, protocol forwarding, load balancing, cloud DNS, and VPN tunnels are built on top of these objects and are covered separately in a later course.

Projects, Networks, and Subnetworks
Let's start by looking at projects, networks, and subnetworks. In the previous module, I introduced projects as the key organizer of infrastructure resources. Specifically, a project associates objects and services with billing. Now, what's unique is the fact that projects actually contain entire networks, up to five networks per project, to be exact. These networks do not have IP ranges, but are simply a construct of all of the individual IP addresses or services that are within that network. GCP's networks are global, spanning all available regions across the world. So, you can have one network that literally exists anywhere in the world, Asia, Europe, Americas, all simultaneously. Inside of a network, you can segregate your resources with subnetworks, and as I mentioned earlier, there are three different types of networks, default, auto mode, and custom mode. You will explore these three types in the first lab of this module. However, let me preface that. While an auto mode network can be converted to a custom mode network, a custom mode network cannot be converted to anything else. Essentially, once custom, always custom. Let's look at an example of how networks can isolate systems in GCP. On this slide, we have an example of a project that contains five networks. All of these networks span multiple regions across the world, as you can see on the right-hand side. Each network contains separate virtual machines. Since VMs A and B are on the same network, network 1, they can communicate over internal IP addresses even though they are in different regions. Essentially, your virtual machines, even if they exist in different locations across the world, take advantage of Google's global fiber network. Those virtual machines are going to appear as though they are sitting in the same rack when it comes to network configuration protocol. VMs C and D, on the other hand, are not in the same network; therefore, these VMs must communicate over external IPs even though they're in the same region. The traffic between VMs C and D isn't actually touching the internet, but it's going through the Google edge routers, which has different billing and security ramifications that we're going to explore. To better understand this slide, let me define regions and zones. A region is a specific geographical location where you can run your resources. Each region has one or more zones. For example, the us-central1 region denotes the region in the central United States that has zones us-central1-a, us-central1-b, us-central1-c, and us-central1-f. For an up-to-date list of GCP regions and zones, please refer to the online documentation, as new regions and zones are constantly added. This slide has a region, Region 1, with two zones, Zone A and Zone B. Subnetworks can extend across zones within the same region, such as subnet-1. This subnet is simply an IP address range, so you can carve up IP addresses within that range. Notice that the first address in the range, 10. 0. 0. 1, is reserved for the router address. The last address in the range, 10. 0. 0. 255, is reserved for the broadcast address. Even though the two virtual machines in this example are across different zones, they will still communicate with each other using the same subnet IP address. Essentially, a single firewall rule will apply to both VMs even though they are in different zones. In an on-premises environment, you might design subnetworks in the traditional way that is based on the stacks of routers and switches within your environment, essentially, a top-down hierarchy, as you can see on the right-hand side, where you have a master network 10. 0, and you've carved it up into your core switches and core routers, specifically into 10. 1 and 10. 5. Each of these might represent different environments, such as marketing, ERP, or development. In GCP, you just simply set up a network, and you create multiple subnets for marketing, ERP, and development. As you can see, networks do not have IP ranges, so subnetworks don't need to fit into an address hierarchy. While subnetworks can be used to manage resources, there are other ways of managing resources, like Cloud IAM, labels, tags, and managed instance groups. These are covered throughout the different courses of the specialization.

IP Addresses
Now that we've covered GCP networks at a high level, let's go deeper by exploring IP addresses. In GCP, each virtual machine can get two IP addresses assigned. One of them is an internal IP address, which is going to be assigned via DHCP internally. Every VM that starts up and any service that depends on virtual machines gets an internal IP address. Example of such services are Google App Engine and Kubernetes Engine, which are explored in other courses. When you create VMs in GCP, their symbolic name is registered with an internal DNS service that translates the name to the internal IP address. DNS is scoped to the network, so it can translate web URLs and VM names of hosts in the same network, but it can't translate hostnames from VMs in a different network. The other IP address is the external IP address, which is optional. In essence, you can assign an external IP address if your device or machine is externally facing. That IP address can either be assigned from a pool, making it ephemeral, or it can be assigned the reserved external IP address, making it static. Keep in mind that you're billed for reserving external IP addresses even when they're not attached to a running VM. Regardless of whether you use an ephemeral or static IP address, the external address is unknown to the OS of the VM. The external IP address is mapped to the VM's internal address transparently by VPC. I'm illustrating this here by running ifconfig within a VM in GCP, which only returns the internal IP address. Let's explore this further by looking at DNS resolution of both internal and external addresses. Let's start with internal addresses. Each instance has a hostname that can be resolved to an internal IP address. This hostname is the same as the instance name. There are also internal fully qualified domain name, or FQDN, for an instance that uses the format hostname. c. project-id. internal, as shown on this slide. If you delete and recreate an instance, the internal IP address can change. This change can disrupt connections from other Google Compute Engine resources, which must obtain the new IP address before they can connect again. However, the DNS name always points to a specific instance no matter what the internal IP address is. Each instance has a metadata server that also acts as a DNS resolver for that instance. The metadata server handles all DNS queries for local network resources and routes all other queries to Google's public DNS servers for public name resolution. I previously mentioned that an instance is not aware of any external IP address assigned to it. Instead, the network stores a lookup table that matches the external IP address with the internal IP address of the relevant instance. Now let's look at external addresses. Instances with external IP addresses can allow connections from hosts outside of the project. Users can do so directly using the external IP address. Public DNS records pointing to instances are not published automatically; however, admins can publish these using existing DNS servers. Domain names can be hosted on GCP using Google Cloud DNS. This is a managed service that is definitely worth considering if you don't want to create your own BIM server in another VM. Another networking feature of GCP is alias IP ranges. Alias IP ranges lets you assign a range of internal IP addresses as aliases to a virtual machine's primary network interface. This is useful if you have multiple services running on a VM and you want to assign each service a different IP address. In essence, you can configure multiple IP addresses representing containers or applications hosted on a VM without having to define a separate network interface. You just draw the alias IP range from the local subnet's primary or secondary CIDR ranges. This diagram provides a basic illustration of primary and secondary CIDR ranges and VM alias IP ranges. Configuring alias IP ranges, this grabs commands for setting up a subnet with secondary ranges and for assigning alias IP addresses to VMs.

Routes and Rules
So far, you've learned about projects, networks, subnetworks, and IP addresses. Let's use what you've learned to understand how GCP routes traffic. By default, every network has routes that let instances in a network send traffic directly to each other, even across subnets. In addition, every network has a default route that directs packets to destinations that are outside the network. Although these routes cover most of your normal routing needs, you can also create special routes that overwrite these routes. Just because a packet has a route to a destination, does not mean that it can get there. Firewall rules must also allow the packet. The default network has preconfigured firewall rules that allow all instances in the network to talk with each other. Manually created networks do not have such rules, so you must create them as you will experience in the first lab. Routes match packets by destination IP address; however, no traffic will flow without also matching a firewall rule. A route is created when a network is created, enabling traffic delivery from anywhere. Also, a route is created when this subnet is created. This is what enables VMs on the same subnet to communicate internally. This slide shows a simplified routing table, but let's look at this in more detail. Each route in the routes collection may apply to one or more instances. A route applies to an instance if the network and instance stacks match. If the network matches and there are no instance tags specified, the route applies to all instances in that network. Compute Engine then uses the route's collection to create individual read-only routing tables for each instance. This diagram shows a massively scalable virtual router at the core of each network. Every virtual machine instance in the network is directly connected to this router, and all packets leaving a virtual machine instance are first handled at this layer before they are forwarded on their next hop. The virtual network router selects the next hop for a packet by consulting the routing table for that instance. In this diagram, the green boxes are virtual machine instances, the router is the yellow at the center, and the individual routing tables are indicated by tan boxes. GCP firewall rules protect your virtual machine instances from unapproved connections, both inbound and outbound, known as ingress and egress, respectively. Essentially, every VPC network functions as a distributed firewall. While firewall rules are applied to the network as a whole, connections are allowed or denied at the instance level. You can think of the firewall as existing not only between your instances and other networks, but between individual instances within the same network. Also, if for some reason all firewall rules in a network are deleted, there's still an implied deny all ingress rule and an implied allow all egress rule for the network. You can express your desired firewall configuration as a set of firewall rules. Conceptually, a firewall rule is composed of the following parameters. The direction of the rule. Inbound connections are matched against ingress rules only, and outbound connections are matched against egress rules only. The source of the connection for ingress packets or the destination of the connection for egress packets. There is the protocol and port of the connection, where any rule can be restricted to apply to specific protocols only or specific combinations of protocols and ports only; there's the action of the rule, which allows or denies packets to match the direction, protocol, port, and source or destination of the rule; the priority of the rule, which governs the order in which rules are evaluated, the first matching rule is applied; and the rule assignment. By default, all rules are assigned to all instances, but you can assign certain rules to certain instances only. Let's look at some GCP firewall use cases for both egress and ingress. Egress firewall rules control outgoing connections originated inside your GCP network. Egress allow rules allow outbound connections that match specific protocols, ports, and IP addresses. Egress deny rules prevent instances from initiating connections that match non-permitted port, protocol, and IP range combinations. For egress firewall rules, destinations to which a rule applies may be specified using IP CIDR ranges. Specifically, you can use destination ranges to protect from undesired connections initiated by a VM instance towards an external destination. For example, as shown on the left, an external host. You can also use destination ranges to protect from undesired connections initiated by a VM instance towards specific GCP CIDR ranges. For example, as shown in the middle, a VM in a specific subnet. Ingress firewall rules protect against incoming connections to the instance from any source. Ingress allow rules allow specified protocol, ports, and IP addresses to connect in. The firewall prevents instances from receiving connections on non-permitted ports and protocols. Rules can be restricted to only affect particular sources. Source CIDR ranges can be used to protect from undesired connections coming to an instance either from external networks or from GCP IP CIDR ranges. In addition, source text can be used to protect from undesired connections coming from specific VM instances that are tagged with a matching tag. This diagram illustrates a VM receiving a connection from an external address, and another VM receiving a connection from a VM in the same network. You can control ingress connections from a VM instance by constructing inbound connection conditions using source CIDR ranges, protocols, ports, and source tags on instances. However, source tags can only be used for VM to VM connections, such as the one shown here in the middle.

Billing
Before you apply what you just learned, let's talk about networking billing. It is important that you understand under what circumstances you will be billed for GCP's network. This table is from GCP's documentation, and it provides general network pricing. First of all, ingress or traffic coming into GCP's network is not charged. All egress traffic to the same zone, to a different GCP service within the same region, or to other Google products like YouTube, Maps, Drive, from a VM in GCP with a public or private IP address is not charged either. However, there is a charge for egress between zones in the same region and between regions. All these charges are for egress through internal IP addresses. There are different charges for egress through external IP address, regardless of whether the instances are in the same zone. Another thing to consider when designing your network is your throughput and round-trip latency between virtual machines. This is going to vary by location, so check your application's requirements against current specifics for VPC when choosing where to place your VMs. For example, VM to VM communication within a single zone has much more consistent performance than VM to VM communication between regions in a single continent or even across continents. Keep in mind that as VPC is constantly evolving, there are some features that are marked beta. These features do not have a service-level agreement, or SLA, and the online documentation states which features are currently in beta. If you make design changes, you might have to delete networks and subnetworks. If that is the case, start by deleting your VMs and any related firewall rules. Then, depending on whether you have an auto-type network or a custom-type network, you might only be able to delete the entire network, or you might be able to delete the subnetworks independently of the entire network. You will explore this in the next lab.

Lab: Virtual Networking (Overview and Objectives)
Lab: Virtual Networking (Review)
In this lab, you created networks and subnetworks of many different varieties, started VMs in each location, and then explored the network relationships between them. The choice of where to locate instances in the GCP network involves separation of control, fault isolation for availability, and consequential changes in the latency and traffic egress charges. So if you want to make sure that the backup system is safe, you might want to locate it on a different continent from the primary system. However, making that choice means increased latency and potential data egress charges.

Common Network Designs
Let's use what we have learned so far and look at common network designs. Specifically, we have gone over projects, networks, subnetworks, regions, and zones. The question now is how do all of these elements work together? In short, they provide a rich set of alternatives for managing groups of resources with varying availability and access control requirements. So, what does that mean? Well, basically, you can now manage resources at a very granular level, depending on how specific you need to get. If you need to work things globally, you have that capacity to do so. But you can also restrict yourself to very finite resources. Let's start by looking at availability. If your application needs increased availability, you could place two virtual machines into multiple zones within the same subnetwork, as shown on the slide. Using a single subnetwork allows you to create a firewall rule against the subnetwork 10. 2. 0. 0. Therefore, by allocating VMs on a single subnet to separate zones, you get improved availability without additional security complexity. Next, let's look at globalization. In the previous design, we placed resources in different zones in a region, which provides isolation from many types of infrastructure, hardware, and software failures. Putting resources in different regions, as shown on this slide, provides an even higher degree of fail independence. This allows you to design robust systems with resources spread across different failure domains. Also, using a load balancer, which we'll cover in a later course, you can route the traffic to the region that is closest to the user. Globalization does not get you the simplified security that we just saw with a single subnetwork. However, if the VMs are in a single network, as shown here, they can still communicate through GCP's internal global network. Let's take this separation one step further by placing resources in different regions within different networks and different projects. These resources are now isolated, which prevents compromise of one part from spreading to other parts. However, using VPC network peering, these resources can still communicate over a private address space. Finally, in this last case, the VMs are isolated into separate projects, but within the same zone. This can be useful for identity and access management, which is covered and detailed in the later course. For example, if software development is project one and test engineering is project two, you can assign different people to different roles in the projects for management separation. Consider dividing a system up into multiple projects for better access control, but remember that a network cannot span projects, so using separate projects implies that the VMs must communicate via the internet. Another common network design is the bastion host isolation. Bastion hosts provide an external-facing point of entry into a network containing private network instances. This host can provide a single point of fortification or audit and can be started and stopped to enable or disable inbound SSH communication from the internet. For example, on this slide, Instance 1 represents a service provided to an internal corporate audience; therefore, this instance does not have an external IP address. In order to gain access to this instance, you can create a maintenance host known as a bastion host. You will configure such a network design in the upcoming lab and verify connectivity. The last common network design is a network address translation, or NAT gateway isolation. Similar to the previous design, we have an instance that does not have an external IP address. In this case, you can configure another instance in the same network as a NAT gateway with IP forwarding. This allows Instance 1 to communicate with another instance on a separate network via the gateway. The two networks do not have to be in the same project for this design to work.

Lab: Bastion Host (Overview and Objectives)
Lab: Bastion Host (Review)
In this lab, you created a web server VM and restricted access to it by removing the external IP address. Then, you created a bastion host to gain access to the web server over its internal IP address. Normally, you would harden the bastion host by restricting the source IPs that can access the bastion host by adding new firewall rules. Also, when you're not using the bastion host, you would shut it down. There are other security alternatives to provide routine administration access to a web server, like using Cloud VPN, which is covered in a later course of this specialization.

Module Review
In this module, I gave you an overview of GCP's Virtual Private Cloud. We looked at the different objects within VPC, like projects, networks, IP addresses, routes, and firewall rules. I also provided a brief overview of how your network design choices can affect billing. Then you applied the different concepts that we covered in a thorough lab. Next, we looked at common network designs such as a bastion host isolation, which you got to implement in the lab. Now that you have a solid understanding of how GCP has implemented networking, let's move on to learn more about other services. Next up is Compute Engine, which offers scalable, high-performance virtual machines.

Virtual Machines
Module Overview
Hello, and welcome. I'm Philipp Maier, a course developer with Google Cloud Platform, and this is module three, Virtual Machines. Virtual machine instances, or VMs, are the most common infrastructure component, and in GCP they're provided by Compute Engine. A VM is similar to but not identical to a hardware computer. VMs consists of virtual CPU, some amount of memory, distort, and an IP address. Compute Engine is very flexible and offers many options, including some that can't actually exist in hardware. For example, a micro VM uses a CPU that it shares with other virtual machines, enabling you to get a VM with less capacity at a lower cost. Another example of a function that can't exist in a hardware is that some VMs offer burst capability, meaning that the virtual CPU will run above its rated capacity for a brief period using the available shared physical CPU. The main VM options are CPU, memory, and disks. Now, this is going to be a very robust module. There's a lot of detail to cover here with how virtual machines work in GCP. First, we're going to start with the basics of Compute Engine, followed by a quick little lab to get you more familiar with creating virtual machines. Then, we're going to look at the different CPU and memory compute options that enabled you to create different configurations. Next, we will look at images and at the different disk options available with Compute Engine. After that, we will discuss very common Compute Engine actions that you might encounter in your day-to-day job. This will be followed with an in-depth lab that explores many of the features and services covered in this module.

Compute Engine
There is a spectrum of different options in GCP when it comes to compute and processing. We're going to focus on the traditional virtual machine instances in this module. All of the other items that you see here are going to be covered in later courses. Now the difference is Compute Engine gives you the utmost in flexibility. Run whatever language you want; it's your virtual machine. This is purely an Infrastructure as a Service model. You have a VM and an operating system, and it's up to you to manage it and handle aspects, such as autoscaling, where you'll configure the rules about adding more virtual machines in specific situations. Autoscaling will be covered in the Scaling Automation course of the specialization. The primary work case of Compute Engine is pretty much any general workload, especially enterprise applications that were designed to run on a server infrastructure. This makes Compute Engine very portable and easy to run in the cloud. Other services like Kubernetes Engine, which consists of containerized workloads, may not be as easily transferable as what you're used to from on-premises. So what is Compute Engine? At its heart, its Infrastructure as a Service. It's physical servers that you're used to running inside the Google environment with a number of different configurations. Both predefined and custom machine types allow you to choose how much memory and how much CPU you want. You choose the type of disk you want, whether you want to just use standard hard drives, SSDs, local SSDs, or a mix. You can even configure the networking and run a combination of Linux or Windows machines. In this module, we're going to cover several different features such as machine right-sizing, startup scripts, metadata, availability policies, and pricing and usage discounts. Let's start by looking at the compute options. Compute Engine provides a number of different machine types. Specifically, there are predefined high CPU, high memory, standard, and shared-core machine types. If those machine types don't fit your need, you can also customize your own machine. Your choice of CPU will affect your network throughput. Specifically, your network will scale at 2 Gb per second for each CPU core up to a maximum of 16 Gb per second worth of throughput, which is going to be achieved if you have 8 virtual CPUs. When you're migrating from an on-premises world, you're used to physical cores, which have hyperthreading. In GCP, we call these vCPUs, or virtual CPUs. A vCPU is equivalent to one hyperthreaded core. Therefore, if you have a single core hyperthreaded CPU on-premises, that would essentially be two virtual CPUs to one physical core. So always keep that in mind as oftentimes people will immediately do a test. They'll say I have a four core physical machine, and I'm going to run four cores in the cloud and ask why their performance isn't the same. Once you pick your compute options, you want to choose your disk. You have three options, standard, SSD, or local SSD. So basically, do you want these standard spinning hard disk drives, HDDs, or flash memory solid-state drives, SSDs? Both of these options provide the same amount of capacity in terms of disk size. Therefore, the question really is about performance versus cost, as there's a different pricing structure model. Basically, SSDs are designed to give you a high number of IOPS per dollar versus standard, which will give you a high amount of capacity for your dollar. Local SSDs have an even higher throughput on lower latency than SSD persistent disks because they're attached to the physical hardware. However, the data that you store on a local SSD persists only until you stop or delete the instance. Typically, a local SSD is used as a swap disk, just like you would if you wanted to create a RAM disk, but if you need more capacity, you can store those on a local SSD. You can create instances with up to 8 separate 375 GB local SSD partitions for a total of 3 TB of local SSD space for each instance. Standard and non-local SSDs can be sized up to 64 Tableau for each instance. The performance of these disks scales with each gigabyte of space allocated. As for networking, we've already seen networking features applied to Compute Engine in the previous module's lab. We looked at the different types of networks and created firewall rules using IP addresses and network tags. Something else you'll notice is that you can do regional HTTPS load balancing and network load balancing. This doesn't require any pre-warming because, again, this isn't a specific hardware device that needs to analyze your traffic. These are simply traffic engineering rules that are coming into Google's network, and VPC is applying your rules destined for your IP address subnet range.

Demo: Compute Engine
Let's go to the GCP Console and look at the compute and disk options that we just discussed. So on the Products & services menu, I'm going to navigate to Compute Engine and then VM instances. Here I'm going to click Create. Now this shows us the create instance page, and if we see here under Machine type, there is a drop-down menu, and I see all the predefined machine types. Notice that we have the micro and small CPU configuration. Now in these cases, these are shared CPU. They have completely different characteristics than the dedicated virtual machines, and we will discuss those in more detail later. Now in case the standard types don't work out for you, you can also customize your machine. So over here, by clicking on Customize, you can see that you can actually define the numbers of core or the amount of memory that you want to have. If I go down, I also have the option to change the boot disk. So if I click on the Change button here, you'll see that I have different images here. We're going to discuss images a little bit later in the module, but for now, under Boot disk type, I also have a drop-down list here, and I see that I have both as options, the Standard persistent disk and the SSD persistent disk. So I could choose that, and I could define a size. Let's say 100 GB. Now that's going to be my boot disk, but I can also add additional disks. By expanding this section over here and then clicking on Disks, I have the option to add additional disks to my machine. So if I Add item, click on Select, and then click Create disk, here I now have all the three different disk types that we just discussed. So the new one that we have here is the Local SSD disk. And if I choose one of these and then define a size, let's say again 100 GB, you can see that I automatically get the estimated performance. And when I increase that size, you'll see that the performance also updates along with that. So that's how simple it is to go into the GCP Console and create a virtual machine.

Pricing and Discounts
When it comes to virtual machines, GCP offers a variety of different options in order to keep the prices low. First, virtual machines are built per second with a 1 minute minimum. Second, Google offers sustained use discounts, which are automatic discounts that you get for running a VM instance for a significant portion of the billing month. Compute Engine also offers preemptible instances, which come with up to an 80% discount. However, Compute Engine might terminate or preempt these instances with a 30 second notification if it requires access to those resources for other tasks. Compute Engine actually always terminates preemptable instances after they run for 24 hours, but I'll say more about preemptable instances later. The ability to customize the amount of memory and CPU through custom machine types allows for further pricing customization. Speaking of sizing your machine, Compute Engine provides VM sizing recommendations to help you optimize the resource use of your virtual machine instances. When you create a new instance, recommendations for the new instance will appear 24 hours after the instance has been created. Let's further explore VM charges and discounts. Remember that Google offers sustained use discounts, which are automatic discounts that you get for running a VM instance for a significant portion of the billing month. Specifically, when you run an instance for more than 25% of a month, Compute Engine automatically gives you a discount for every incremental second you use for that instance. The discount increases with usage, and you can get up to 30% net discount for instances that run for the entire month. These discounts are applied automatically. There's no action required on your part to enable these discounts. Now, inferred instances means that for billing purposes, the same type of machine used in the same zone will be combined into a single charge so that you get the most discount, as if it were one machine in use the whole time. And combined resources means that memory and virtual CPU of the same type are combined so that you get the discount on the greatest resource consumption in custom types. There are even deeper discounts for VM usage when you purchase committed use contracts known as committed use discounts. Compute Engine also has free usage limits, which as of this recording, provides free usage of 1 f1-micro instance per month with up to 30 GB of HDD persistent disk and up to 1 GB of network egress. This example shows a customer's usage that comprises eight distinct instances, as we can see here on the left. The instances are combined to find the smallest number of simultaneous running instances, which are called inferred instances. In this case, Compute Engine combines the instances to make four inferred instances with the longest possible duration, as we can see on the right. Compute Engine then calculates sustained use discounts based on the percentage of time that each of these inferred instances was running in a month.

VM Access and Lifecycle
When it comes to accessing a VMware, the creator of an instance has full root privileges on that instance. On a Linux instance, the creator has SSH capability and can use the GCP Console to grant SSH capability to other users. On a Windows instance, the creator can use the GCP Console to generate a username and password. After that, anyone who knows the username and password can connect to the instance using a Remote Desktop Protocol, or RDP client. I listed the required firewall rules for both SSH and RDP here, but you don't need to define these if you're using the default network that we covered in the previous module. The lifecycle of a VM is represented by different statuses. I will cover this lifecycle on a high level, but I recommend referring back to this diagram as a reference. When you define all the properties of an instance and click Create, the instance enters the provisioning state. Here, the resources, such as CPU, memory, and disks, are being reserved for the instance, but the instance itself isn't running yet. Next, the instance moves to the staging state where resources have been acquired, and the instance is prepared for launch. Specifically, in this state, the Compute Engine is adding IP addresses, booting up the system image, and booting up the system. Once the instance is running, it will go through preconfigured startup scripts and enable SSH or RDP access. Now, there are a lot of things you can do while your instance is running. For example, you can live migrate your virtual machine to another host in the same zone instead of requiring an instance to be rebooted. This allows Google to perform maintenance that is integral to keeping the infrastructure protected and reliable without interrupting any of your VMs. There are many other things you can do while your instance is running, such as moving of your VM to a different zone, taking a snapshot of the VM's persistent disk, exporting the system image, or reconfiguring metadata, some of which we will explore in later labs. Some actions require you to stop your virtual machine, for example, if you want to upgrade your machine by adding more CPU. When the instance enters this state, it will go through preconfigured shutdown scripts and end in the terminated state. From this state, you can choose to either restart the instance, which would bring it back to its provisioning state, or you can delete it. You also have the option to reset a VM, which is similar to pressing the Reset button on your computer. This action wipes the memory contents of the machine and resets the virtual machine to its initial state. The instance remains in the running state through the reset. There are different ways in which we can change a VM state from running. Some methods involve the GCP Console and the gcloud command, while others are performed from the OS, such as for reboot and shutdown. It's important to know that if you're restarting, rebooting, stopping, or even deleting an instance, the shutdown process will take about 90 seconds. For a preemptable VM, if the instance does not stop after 30 seconds, Compute Engine sends an ACPI G3 Mechanical Off signal to the operating system. Keep that in mind when writing shutdown scripts for preemptible VMs. As I mentioned previously, Compute Engine can live migrate your virtual machines to another host due to a maintenance event to prevent your applications from experiencing disruptions. A VM's availability policy determines how the instance behaves in such an event. The default maintenance behavior for instances is to live migrate, but you can change the behavior to terminate your instance during maintenance events instead. If your VM is terminated due to a crash or other maintenance events, your instance automatically restarts by default, but this can also be changed. These availability policies can be configured both during the instance creation and while an instance is running by configuring the automatic restart and on host maintenance options. When a VM is terminated, you do not pay for memory and CPU resources; however, you are charged for any attached disks and IP addresses. In the terminated state, you can perform any of the actions listed here, such as changing the machine type, but you cannot change the image of a stopped VM. Also, not all of the actions listed here require you to stop the virtual machine. For example, VM availability policies can be changed while the VM is running, as discussed previously.

Lab: Creating Virtual Machines (Overview and Objectives)
Lab: Creating Virtual Machines (Review)
In this lab, you created several virtual machine instances of different types with different characteristics. Specifically, you created a small utility VM for administration purposes, a Windows VM, and a custom Linux VM. You also accessed both the Windows and Linux VMs and deleted all your created VMs. In general, start with a smaller VM when you're prototyping solutions to keep the cost down. When you're ready for production, trade up to a larger VMs based on capacity. If you're building in redundancy for availability, remember to allocate access capacity to meet performance requirements. Finally, consider using custom VMs when your application requirements fit between the features of standard types.

Compute Options
Now that you have completed the lab, let's dive deeper into the compute options that are available to you in GCP by focusing on CPU and memory. When it comes to creating and configuring a VM, you have three options. You can use the web console as you did in the previous lab, the Cloud Shell command line, or the RESTful API. If you have very complex configurations that you'd like to automate and process, you might want to programmatically configure these through the RESTful API by defining all the different options for your environments. If you plan on using the command line or RESTful API, I recommend that you first configure the instance through the web console and then ask Compute Engine for the equivalent REST request or command line. This way, you avoid any typos and get drop-down lists of all the available CPU and memory options. Speaking of that, let's look at the different machine types that are currently available. Now, I put this in as a reference chart here to just give you an idea of the different options that you have available. These predefined machine types are managed by Compute Engine and come in four classes, standard, high memory, high CPU, and shared core memory machines. Shared core machines are great for prototyping solutions because they are cost effective for running small, non-resource intensive applications. The difference between the standard, high memory, and high CPU machine types is the ratio of number of vCPUs to memory. Standard machine types are suitable for tasks that have a balance of CPU and memory needs. Specifically, standard machine types have 3. 75 GB of RAM per virtual CPU all the way to 64 virtual CPUs with 240 GB of RAM. Next, high memory machine types are ideal for tasks that require more memory relative to virtual CPUs. These machine types have 6. 5 GB of RAM per virtual CPU. Finally, high CPU machine types are ideal for tasks that require more virtual CPUs relative to memory. These machine types have 0. 9 GB of RAM per virtual CPU. Now, this table is constantly going to change, and in fact, some of these configurations aren't available everywhere, so let's explore this by choosing regions and zones. The first thing you want to consider when choosing a region and zone is the geographical location in which you want to run your resources. However, there are other considerations to keep in mind, such as the fact that Google has been consistently and constantly deploying new hardware architectures. These new hardware architectures are not deployed to all zones at the same time; therefore, you're going to find that there are different CPU architectures in different zones. In fact, there can be up to three generations of difference in those processor types. Now, what that means to you is that your application might benefit from some of these advanced Intel technologies that have been released. In this case, from a billing perspective, nothing changes. You pay the exact same amount regardless of the type of individual CPU processor that you might be using. Google is constantly increasing the number of regions and zones and updating the supported CPU architecture. For an up-to-date list, refer to the documentation link provided on this slide, or go to cloud. google. com and search for regions and zones. Coming back to machine types, if the predefined machine types don't fit your compute needs, you can always create a custom machine type. You already performed this in the lab, but I want to highlight that you can customize your CPU, memory, and GPU needs. These custom VMs are generally more expensive than the predefined VMs, but they provide you with more flexibility. Now, how does Google give discounts on custom machines? You'll notice that custom machines don't really fall into a category, so we can't lump them together as we've seen so far. Instead, for custom machine types, Compute Engine calculates sustained use discounts based on virtual CPU and memory usage and applies the discounts described by the sustained use's discount table that I showed earlier. For example, consider the scenario on the left where you have two instances that have different shapes and run at different times of the month. Compute Engine breaks down the number of virtual CPUs and amount of memory used across all custom instances and combines resources to qualify for the biggest sustained usage discounts possible. In this case, Compute Engine applies the following sustained use discounts, as seen on the right. You would receive a 30% discount of the cost of using 2 virtual CPUs and a 30% discount of the cost of using 4 GB of memory because you used each resource for the whole month. You would also receive a 10% cost of using 2 virtual CPUs and a 10% discount of the cost of 2 GB of memory because you used each resource for half of the month. In essence, Compute Engine will aggregate all of the CPU and memory resources times the amount of time that they were used and apply those sustained use discounts. As I mentioned earlier, a preemptible VM is an instance that you can create and run at a much lower price than normal instances. See whether you can make your application function completely on preemptible VMs because an 80% discount is a significant investment in your application. Now, just to reiterate, these VMs might be preempted at any time, and there is no charge if that happens within the first 10 minutes. Also, preemptible VMs are only going to live for up to 24 hours, and you only get a 30 second notification before the machine is preempted. Also, there are no live migrations nor automatic restarts in preemptible VMs, but something that we will highlight is that you can actually create monitoring and load balancers that can start up new preemptible VMs in case of failure. In other words, there are external ways to keep restarting preemptible VMS if you need to. One big use case for preemptible VMs is running a batch processing job. If some of those instances terminate during processing, the job slows down, but it does not completely stop. Therefore, preemptible instances complete your batch processing tasks without placing additional workload on your existing instances and without requiring you to pay full price for additional normal instances.

Images
Next, let's focus on images. When creating a virtual machine, you have the option of choosing the boot disk image. This image includes the boot loader, the operating system, the file system structure, any preconfigured software, and any other customizations. Gcloud is included in every virtual machine image that you choose from Compute Engine. These images are TAR gzip'd files, and they are stored in a private area of Cloud Storage. When choosing an image, you can select either a public or custom image. As you saw in the previous lab, you can choose from both Linux and Windows images. Some of these images are premium images, as indicated in parentheses with a p. These images will have per second charges with the exception of SQL Server images, which are charged per minute. Premium image prices vary with the machine type; however, these prices are global and do not vary by region or zone. You can also use custom images. For example, you can create a custom image by preinstalling software that's been authorized for your particular organization. You also have the option of importing images from your on-premises or workstation or from another cloud provider. This is a no cost service that is as simple as installing an agent, and I highly recommend that you look into it. You can also share custom images with anybody in your project or among other projects too.

Disk Options
At this point, you've chosen an operating system, but that operating system is going to be included as part of some kind of disk, so let's look at disk options. Every single VM comes with a single root persistent disk because you're choosing a base image to have that loaded on. This image is bootable in that you can attach it to a VM and boot from it, and it's durable in that it can survive if the VM terminates. To have a boot disk survive a VM deletion, the Delete boot disk when instance is deleted box needs to be cleared in the instance's property. As I discussed earlier, there are different types of disks, so let's explore these in more detail. The first disk that we create is what we call a persistent disk. That means it's going to be attached to the VM through the network interface. Even though it's persistent, it's not physically attached to the VM. This separation of disk and compute allows a disk to survive if the VM terminates. However, persistent disks are bounded to their zone in that they can't be moved between zones. You can also perform snapshots of these disks, which are incremental backups that we will discuss more later. The choice between HDD and SSD disks comes down to cost and performance. To learn more about this, I recommend referring to the documentation link here because performance is improving quite often. Another cool feature of persistent disks is that you can dynamically resize them even while they're running and attached to a VM. You can also attach a disk in read-only mode to multiple VMs. This allows you to share static data between multiple instances, which is cheaper than replicating your data to unique disks for individual instances. Now, local SSDs are different from persistent disks in that they're physically attached to the virtual machine. Therefore, these disks are ephemeral, but provide very high IOPS. For up-to-date numbers, I recommend referring to the documentation. Currently, you can attach up to 8 local SSD disks with 375 GB each, resulting in a total of 3 TB. Data on these disks will survive a reset, but not a VM stop or terminate because these disks can't be reattached to a different VM. You also have the option of using a RAM disk. You can simply use tmpfs if you want to store data in memory. This is going to be the fastest type of performance available if you need small data structures. I recommend a high memory virtual machine if you need to take advantage of such features, along with a persistent disk to backup the RAM disk data. In summary, you've got a number of different disk options. Persistent disks can be rebooted and snapshotted, but local SSDs and RAM disks are ephemeral. I recommend choosing a persistent HDD disk when you don't need performance, but just need capacity. If you have high performance needs, start looking at the SSD options. The persistent SSD disks offer data redundancy because the data on each persistent disk is distributed across several physical disks. Local SSDs provide even higher performance, but without the data redundancy. Finally, RAM disks are very volatile, but they provide the highest performance. Now, just as there is a limit on how many local SSDs you can attach to a VM, there's also a limit on how many persistent disks you can attach to a VM. As illustrated in this table, this limit depends on the number of cores of the VM. For example, if your machine has 8 or more cores, you can attach up to 128 disks, so you can create massive amounts of capacity for a single host. Now, remember that little nuance when I told you about how throughput is limited by the number of cores that you have? That throughput also shares the same bandwidth with disk I/O. So if you plan on doing a large amount of disk I/O throughput, it will also compete with any network egress or ingress throughput. So remember that, especially if you're going to be increasing the number of drives attached to a virtual machine. There are many differences between a physical hard disk in a computer and a persistent disk, which is essentially a virtual network device. First of all, if you remember with normal computer hardware disks, you have to partition them. Essentially, you have a drive, and you're carving up a section for the operating system to get its own capacity. If you want to grow it, you have to repartition, and if you want to make changes, you might even have to reformat. If you want redundancy, you might create a redundant disk array, and if you want encryption, you need to encrypt files before writing them to the disk. With cloud persistent disks, things are very different because all the management is handled for you on the back end. You can simply grow disks and resize the file system because disks are virtual network devices. Redundancy and snapshot services are built in, and disks are automatically encrypted. You can even use your own keys, and that will ensure that no party can get to the data except you.

Common Compute Engine Actions
Now that we have covered all the different compute, image, and disk options, let's look at some common actions that you can perform with Compute Engine. One common action might be moving an instance to a new zone. For example, you might do so for geographical reasons or because a zone is deprecated. If you move your instance within the same region, you can automate the move by using the gcloud compute instances move command. If you move your instance to a different region, you need to manually do so by following the process outlined here. This involves making a snapshot of all persistent disks and creating new disks in the destination zone from that snapshot. Next, you create the new VM in the destination zone and attach the new persistent disks, assign a static IP, and update any references to the VM. Finally, you delete the original VM, its disks, and the snapshot. Speaking of snapshots, let's take a closer look at these. Snapshots have many use cases. For example, they can be used to back up critical data into a durable storage solution to meet application, availability, and recovery requirements. These snapshots are stored in cloud storage, which we'll cover in a later course of this specialization. Snapshots can also be used to migrate data between zones. I just discussed this when going over the manual process of moving an instance between two regions, but this can also be used to simply transfer data from one zone to another. For example, you might want to minimize latency by migrating data to a drive that can be locally attached in the zone where it is used. Which brings me to another snapshot use case of transferring data to a different disk type. For example, if you want to improve disk performance, you could use a snapshot to transfer data from a standard HDD persistent disk to a SSD persistent disk. Now that I've covered some of these snapshot use cases, let's explore the concept of a disk snapshot. First of all, this slide is titled Persistent disk snapshots because snapshots are available only to persistent disks and not to local SSDs. Snapshots are different from public images and custom images, which are used primarily to create instances or configure instance templates in that snapshots are useful for periodic backup of the data on your persistent disks. Snapshots are incremental and automatically compressed so you can create regular snapshots on a persistent disk faster and at a much lower cost than if you regularly created a full image of the disk. As we saw with the previous examples, snapshots can be restored to a new persistent disk, allowing for a move to a new zone. Before taking a disk snapshot, you should prepare the persistent disk. You can create a snapshot of a persistent disk even while your applications write data to that disk. However, I recommend freezing or unmounting the file system before you take a snapshot. This is the safest and most reliable way to ensure that your disk buffers are cleared, which improves snapshot consistency. Specifically, when connected to your instance using SSH, stop any applications that are reading or writing data to the persistent disk, and either freeze the file system or unmount the file system. To freeze, use the command sudo fsfreeze, and to unmount, use sudo unmount, as shown on the slide. Another common compute action is to resize your persistent disk. The main benefit of increasing storage capacity is to improve I/O performance, as illustrated in this table. This can be achieved while the disk is attached to a running VM without having to create a snapshot. Now, while you can grow disks in size, you can never shrink them, so do keep this in mind.

Lab: Working with Virtual Machines (Overview and Objectives)
Lab: Working with Virtual Machines (Review)
In this lab, you created a customized virtual machine instance by installing base software, which was a headless Java runtime environment, and an application software, specifically a Minecraft game server. You customized the VM by preparing and attaching a high-speed SSD, and you reserved a static external IP address so that the address will remain consistent. Using that IP address, you then verified the availability of the gaming server online. Next, you set up a backup system to back up the server's data to a Cloud Storage bucket, and you tested that backup system. You then automated backups using Chrome. Finally, you set up a maintenance script using metadata for graceful startup and shutdown of the server. Many of these techniques, including the script automation, can be adapted to administration of production servers in any application.

Module Review
In this module, we covered the different compute, image, and disk options within Compute Engine, along with some common actions. Remember that by default VMs have a single network interface with a local internal IP address. The external IP address is mapped to the internal IP address by a network address translation service. So, the VM itself knows nothing about the external IP. Also, the default disk type is a persistent disk, which is network attached to the VM. You can get higher performance disk types, but there is a tradeoff because you lose many of the services that are provided by persistent disks. Finally, remember that many of the common things you can do with physical disks might be a duplication of features already provided automatically by the disk service. So, either they are unnecessary or they won't provide the benefit that you expect.

Essential Cloud Infrastructure: Foundation Course Outro
This is Jasen Baker was a Google Cloud Platform, and thank you for taking the Essential Cloud Infrastructure Foundation course. So in this course, hopefully you got an introduction to the Google Cloud Console. You have some better understanding of some of the different networking concepts and how we do networking inside of Google Cloud Platform itself. You probably set up virtual machines. So in this case here, you set up a virtual network, you've set up a bastion host, you've created virtual machines, maybe you even set up a Minecraft server. This can be a really great way to kind of relate to your kids, or if you're a kid at heart like me, hey, something to set up for yourself. But what we do with these labs is now we kind of give you a real-world example of setting up the virtual machines, connecting the network, setting up the security policies and the firewall rules, interacting with the Google Cloud Shell as through the command line, as well as the web-based interface.

Course author
Author: Google Cloud	
Google Cloud
Google Cloud can help solve your toughest problems and grow your business. With Google Cloud, their infrastructure is your infrastructure. Their tools are your tools. And their innovations are your...

Course info
Level
Intermediate
Rating
4.9 stars with 11 raters(11)
My rating
null stars

Duration
1h 35m
Updated
17 Jan 2019
Share course
