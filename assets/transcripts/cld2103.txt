Choosing and Implementing Google Cloud Compute Engine Solutions
by Janani Ravi

As cloud computing grows in popularity, the first use-case is the provisioning and managing of cloud compute virtual machines. This course will show you the advantages of cloud VM instances on the Google Cloud Platform over on-premise machines.

Provisioning and managing Google Cloud Compute Engine instances, i.e. VMs, is simple and straightforward. In this course, Choosing and Implementing Google Cloud Compute Engine Solutions, you will learn how to create, run, and manage virtual machines on the Google Cloud Platform (GCP). You will start off by understanding the breadth of offerings from the Google Cloud Platform - ranging from pure IaaS offerings such as the Google Compute Engine to pure PaaS offerings like the Google App Engine. Next, you'll see how you can create and work with these VM offerings on the cloud. You'll create and connect to Linux as well as Windows machines, reserve static IP addresses, attach local SSDs to VMs, communicate between VMs on a network and connect to Cloud Storage buckets. You'll then move on to administrating these instances on the cloud. You'll see how availability policies, to handle VM migrations, can be configured, how disk images and snapshots can be created, and how you can instantiate VMs using these images and snapshots. Finally, you'll be shown how to startup and shutdown scripts to customize VMs can be run. At the end of this course, you will be comfortable creating, connecting to, and working with virtual machine instances on the Google Cloud Platform.

Course author
Author: Janani Ravi	
Janani Ravi
Janani has a Masters degree from Stanford and worked for 7+ years at Google. She was one of the original engineers on Google Docs and holds 4 patents for its real-time collaborative editing...

Course info
Level
Beginner
Rating
4.9 stars with 23 raters(23)
My rating
null stars

Duration
1h 58m
Released
11 Sep 2018
Share course

Course Overview
Course Overview
Hi. My name is Janani Ravi. And welcome to this course on Choosing and Implementing Google Cloud Computer Engine Solutions. A little about myself. I have a master's in electrical engineering from Stanford, and I have worked at companies such as Microsoft, Google, and Flipkart. At Google, I was one of the first engineers working on real-time collaborative editing in Google Docs. And I hold four patents for its underlying technologies. I currently work on my own startup, Loonycorn, a studio for high-quality video content. In this course, you will learn how to create, run, and manage virtual machines on the Google Cloud Platform. We start off by understanding the range of offerings from the Google Cloud Platform ranging from pure IaaS offerings such as Google Compute Engine to pure PaaS offerings like the Google App Engine. We'll create a GCP account and understand how VMs on the cloud are priced. We'll then study how we can create and work with these VM offerings in the cloud. We'll connect to Linux, as well as Windows machines, reserve static IP addresses, attach local SSDs to VMs, communicate between VMs on the network, and connect to cloud storage buckets from VMs. We'll then move on to administrating these instances on the cloud. We'll see have availability policies to handle VM migrations can be configured, how disk images and snapshots can be created, and how we can instantiate VMs using these images and snapshots. We'll also see how startup and shutdown scripts to customize VMs can be run. At the end of this course, you should be comfortable creating, connecting to, and working with virtual machine instances on the Google Cloud Platform.

Understanding GCP Compute Options
Module Overview
Hi, and welcome to this course on the Google Cloud Platform. Here in this course, we'll see how you can choose and implement Google Cloud Compute Engine solutions. Just like AWS from Amazon and Azure from Microsoft, the Google Cloud Platform offers a complete range of solutions on the cloud. It offers Infrastructure as a Service, Platform as a Service, and serverless compute options. The GCE or the Google Compute Engine is virtual machine instances, which are the Infrastructure as a Service offering from the GCP. Google offers a wide range of scalable, high-performance, virtual machine instances running in Google's datacenters and using their fiber network. You can choose the OS image that you want running on your virtual machine instance. You can run Linux or Windows-based images. You can also run specialized images such as for SQL Server. Google's pricing for these VMs is very competitive. Google builds in second-level increments so you only pay for the compute time that you use. In addition, you have sustained use discounts and discounted prices for committed use as well. In addition, you also have the option to use preemptible instances for cost-saving. Preemptible instances are instances that can be shut down at any point in time. They are great when you want additional compute capacity without relying on persistent storage.

Prerequisites and Course Outline
Let's see what you need to know so that you can make the most of this course. You need to have a basic understanding of cloud computing, and you need to know how virtual machines work. I'm assuming here in this course that this is not the first time that you're working with virtual machines. You may not have used the Google Cloud Platform before though. If your only experience has been with on-premises datacenters or software running on desktops, you might want to cover some of these prereq courses before you come to the GCP. Cloud Computing: The Big Picture will give you a basic understanding of how the cloud works. And Fundamentals of Cloud Computing will teach you about Infrastructure as a Service, Platform as a Service, and storage on the cloud. Both of these are available on Pluralsight. In this course, we start off with a basic introduction to Google Compute Engine virtual machines. This will help you choose the right VM for your requirements. We'll cover GCE features and limitations. We'll see how the pricing works, and we'll compare it to other GCP technologies that are available for compute. In addition, we'll start off by creating our first virtual machines and connecting to them. We then move on to implementing other features that we might require for our VMs. We'll see how we can reserve static IP addresses and see how we can use a VM to work with Google Cloud Storage. We'll see how we can expand and attach new persistent discs to our VMs and add local SSDs as well. We'll then move on to the management and administration of our GCE virtual machine instances. We'll talk about availability policies and metadata management. We'll create custom images and snapshots of our boot disks, and use those to re-create VM instances. Our examples will assume that we are working at a hypothetical online retailer, an e-commerce site called SpikySales. com. Our organization conducts flash sales for trending products, which means on sale days, the spike in traffic is very, very high. SpikySales has just made up its mind to move its compute load to the cloud. They've realized that cloud computing fits their use case perfectly. They can pay as they go, and there is no idle capacity during the off-sale periods. This allows them to save on costs. Because this is the first time that they are trying out the GCP, the first teams that have volunteered to move to the Google cloud are the internal website and tools teams. Before they use the advanced features and solutions that GCP has to offer, they want to use the Infrastructure as a Service option for ease of migration.

Compute Choices
Let's start off by briefly talking about cloud computing and the choices that we have to make when we decide to move our application loads to the cloud. Cloud computing is the practice of using a network of remote servers hosted on the internet to store and manage our processes rather than an on-premises datacenter or a personal computer. Moving to the cloud involves making a number of different choices between different solutions that are on offer. But the two main choices that we have to make are compute. Where and how does code run? Where does our machine locate it? Is it on-premises? Is it in a colocation center? Or is it in a remote datacenter? The second choice that we have to make is storage. Where is our data stored? And what kind of storage are we using? As you well know, if you're running an application in production, storage and compute options are not the only choices available. There are a host of other choices that we have to make about networking, security, logging, audit logs. All of these are critical, but particularly those choices are driven by the choices that we make for compute and storage, so from that point of view can be considered to be less important. If you're familiar with compute choices available in the modern world, you're probably aware that they lie along a spectrum. At the very left end of the spectrum is the actual physical machine. This is typically referred to as bare metal in computer technology. Bare metal refers to the hard disk and the physical machine set up where you host your application. When you move a little towards the right in the spectrum, you have VM instances. Virtual machines emulate an actual computer system. VMs are actually software which runs on top of physical hardware, and it mimics a separate computer. Virtual machines are capable of performing tasks such as running applications and programs just like an actual physically separate computer. As we move further right on the spectrum, we come to container clusters. Containers are an abstraction that allow you to package your application and all of its dependencies in an isolated manner. Containers are far more portable than virtual machines and can be deployed quickly and reliably on any VM. As we move higher up in this abstraction hierarchy, we come to hosted applications. For a software company, hosted applications are their product. For example, in SpikySales. com, the production website, their e-commerce site, is their hosted app. A further step of abstraction even beyond hosted applications is serverless functions. These are pieces of compute that can be hosted anywhere and simply execute the code that you want them to. These are typically used for event handling. You might have noticed that as we move right in this spectrum, there is less operational overhead, less administrative overhead, fewer provisioning of instances, more developer friendly. A developer can just get his or her code up and running very easily to the very right of the spectrum. As you move towards the left in the spectrum, you'll find that you have more control and more low-level access. Because you're not abstracted away from the actual hardware, you can tweak the hardware to make your performance better faster. But there is more administrative overhead. All cloud providers offer compute choices along this entire spectrum as does Google. Google Compute Engine is their virtual machine offering. If your requirements are such that you want lower administrative overhead and faster deployments, you might choose to use the Google Kubernetes Engine. Kubernetes is a container orchestration framework and works with Docker containers. If your developer team is not interested in provisioning virtual machines or container clusters, but want their apps to be up and running very quickly and automatically scaled, they'll tend to use the Google App Engine. This is their hosted apps offering. If your engineering team needs to write quick, lightweight code for event handling, Google has Cloud Functions. This is Google's automatically scaled serverless functions offering. As you might already be aware, this spectrum of offerings is not just available on the Google Cloud Platform. There is an equivalent on the AWS and the Azure cloud as well. Let's take a quick look at the Amazon equivalents here. Corresponding to Google Compute Engine, we have the AWS EC2, the Amazon Elastic Compute Cloud. Amazon runs container clusters using AWS EKS, which is Amazon's elastic container service for Kubernetes. Amazon provides a hosted application offering using AWS Elastic Beanstalk. And, finally, Cloud Functions on Google are basically just AWS Lambda. They are exact equivalents. We'll quickly assign the right categories to each of these compute solutions. The AWS EC2 just like the Google Compute Engine is IaaS, the Infrastructure as a Service offering. The AWS Elastic Beanstalk just like Google's App Engine is the PaaS, or the Platform as a Service offering. Because this course focuses on IaaS or the Infrastructure as a Service offering from the Google Cloud Platform, let's quickly understand the differences between bare metal physical computers and IaaS. When you are using bare metal, your applications run directly on the operating system, which is directly on top of the hardware available in the physical computer. When you're using Infrastructure as a Service offering, there is an additional hypervisor. A hypervisor is sometimes called a virtual machine monitor, and it's basically software, firmware, or hardware which creates and runs virtual machines. Because bare metal refers to the actual physical computer, they're not very portable. The operating system often relies on your specific hardware requirements. Infrastructure as a Service offerings VMs are far more portable than physical computers. The processing units in bare metal machines are the CPUs, whereas the processing units on VMs are vCPUs or virtualized CPUs. A vCPU is a portion or a share of a physical CPU that is assigned to a virtual machine. Your organization might use bare metal machines if they're running their own physical datacenter. Your system administrators will then have to manage the entire operating and administrative overhead in the case of bare metal. In the case of Infrastructure as a Service, the cloud platforms help. Much of the ops burden is managed by the service provider by a cloud platform.

The Web Console and Cloud Shell
Let's get familiar with the Google Cloud Platform by logging in to their web console. In this demo, we'll also see how we can use a cloud shell, a Linux terminal window available on an ephemeral VM on the cloud. In order to log into the web console of the GCP, you need to go to console. cloud. google. com. If you have a Gmail account, you have an account on the GCP as well. And you can simply use your Gmail account in order to log in here. If you haven't logged in before, you might be taken to a screen which looks somewhat like this. This is our dashboard, and we haven't selected a project, which is why we see nothing on this dashboard. All resources on your Google Cloud Platform have to lie within a billing unit called the project. Each team within your organization might have its own project. You can create a new project by clicking on the drop-down at the top here. This will pop up a dialog showing you all of the projects that you can access from this particular account. I'm going to click on New Project at the top right here in order to start a new project for this course. I'm going to call this project spikey-internal. All of the engineering teams which work on building apps for use within the SpikySales organization such as HR, apps, tools, analytics, etc., will have access to this spikey-internal project, and this is the project they're going to use to create their resources. You can assign a meaningful name to the project. Every project has an associated unique ID, and you can edit this ID by clicking on the Edit link here. I'm going to change the idea of my project to be spikey-internal-123. Go ahead and click on the Create button at the bottom here, and this will spin up a new project for you to use. And we'll immediately be taken to the project dashboard. If you're spinning up resources on a cloud platform, you need some way to access these resources from the command line. Google offers something called a cloud shell, which is command line access to cloud resources directly from your browser. The cloud shell is basically an ephemeral VM present within this project. And if you click on the cloud shell icon that you see on the top right here that says Activate Google Cloud Shell, this will give you command line access to this ephemeral virtual machine directly from the browser itself. You'll find that this is the terminal window that we use the most often when we study the GCP. The cloud shell connects to a Linux virtual machine and is associated with a specific project. It supports all Linux commands. The hamburger icon that you see on the top left is the Navigation menu that will take you to all of the computing resources that GCP has to offer. Let's click on the Navigation menu, and you can see that the compute engine is present at the very top. This is because I know I'm going to be using the Compute Engine link really often for demos in this course, which is why I have pinned the compute engine to the top of my Navigation menu. You can do the same thing if you want to. It'll just make things a little simpler for you. Click on VM instances under Compute Engine, and you'll be taken to the main page where you can start creating your virtual machines. In order to perform some of the tasks in the demos of this course, you'll need to enable billing for this particular project. So I suggest you go on to billing and associate a credit card with your account. The total cost for all the tasks that you do in this course should not exceed, let's say, $10. In fact, if you have free trial credits, then you're likely to stay within the limits of those credits when you run the demos of this course.

VM Configration Choices
When you want to use Cloud Platform provider's Infrastructure as a Service option, there are still a number of choices that you need to make. You need to figure out where your virtual machine is going to be located, which geographical region, the kind of networking that you want to choose, the kind of configuration that your virtual machine needs to have in order to support your applications, the metadata that will be associated with each of your virtual machines, the storage requirements for your application, and, finally, all of the administration, how you plan edge to provision and manage these VM instances. I know that I said earlier that VMs are operationally easier to work with than bare metal. But there is still cognitive overload. There are way too many features and too many choices for all of these. So how do you remember all of the choices that you have to make? Let's use a simple mnemonic that we'll refer to several times in this course in order to remember stuff--Loch Ness Monster. The LO for location, C for configuration, NE for networking, SS for storage, M for metadata, and STER for administration. This Loch Ness monster will help you keep track of all of the choices that you have to make when you're setting up your virtual machines. Notice the SS for storage there. SS is present twice because it's really important. All compute resources on the GCP are located within zones. Zones are availability zones similar to a datacenter. You can think of a zone as a single datacenter, and you can think of a set of zones, which are located close to each other connected with a high-speed network, as a region. When we refer to a network on the GCP, we refer to the VPC, or the virtual private cloud, which is made up of a group of user-controlled IP addresses. These IP addresses are logically apportioned into subnets, and there are firewall rules that govern what traffic can flow to each of these resources on this network. An example of a zone located in the United States is the us-central1-a. Us-central1 refers to datacenters spread across the state of Iowa. A refers to one datacenter or one zone within this region. The region is us-central1, and it's located in Iowa. Now any VM instance that you provision without explicitly specifying a VPC that it belongs to automatically goes to the default network. The default network is one that Google creates for you automatically. You don't have to do anything. It also configures a bunch of firewall rules on this default network, which allows all of the VM instances on this network to communicate with each other, and also allows you to SSH into these instances. Whenever you provision a new virtual machine on the Google Cloud Platform, you will be asked for which zone you want this virtual machine to be located, such as us-central1-a, and which region you want to the VM to belong to. Any zone that you choose is automatically part of a region. Going back to our Loch Ness monster, now that we have dealt with location, let's go on to C, that is, configuration. Now there are two basic choices that you need to make when you set up a virtual machine instance. First is the kind of machine that you want to use. The machine type determines the memory size, the number of vCPUs on the machine, and the maximum persistent disk capability. The second is a choice of an operating system image for your VM, whether you want to use a public free image or a custom image, or a paid image. When you provision a virtual machine on the GCP, you're presented with a wide array of machine types. So you have predefined machine types, or you can build your own custom machine types, and there are a variety of predefined types available as well. Predefined machine types on the GCP are a fixed set of types that Google offers. They have a fixed ratio of memory to vCPU counts. Custom machine types, on the other hand, can be explicitly tailored to your specific requirements. You can independently specify the number of vCPUs that you want for your compute and the amount of RAM memory that you want on your machine. Predefined machine types on the Google Cloud Platform come in a number of different categories. Let's understand what they are. The simplest of these is the standard machine type. This is what you'll tend to choose if your applications do not have any special requirements for compute or memory. Standard machine types offer 3. 75 GB of memory per vCPU. Standard machine types are available with 1, 2, 4, 8, up to 96 cores. Standard machines have the prefix n1-standard. If your applications have high memory requirements, you'll tend to use the high-memory category of predefined machine types. These offer 6. 5 GB of system memory per vCPU. High-memory machines can have up to 96 vCPUs and are prefixed by n1-highmem. If your processing requirements are higher than your memory requirements, you might choose to go with a high-CPU machine. These offer just 0. 9 GB of system memory per vCPU. These machine type names are prefixed by n1-highcpu. If your application requirements are small, and they're not resource intensive, you might choose to go with shared-core machines. These tend to be more cost-effective. These machines come with micro-bursting capabilities that allow your VM instances to use additional physical CPU for extremely short durations. If the system memory requirements for your application are far higher than the high-memory machines, then you can go with memory-optimized machines. These offer 14 GB of system memory per vCPU. Such machines are typically used for in-memory databases or business applications. All three machine categories, standard, high-memory, and high-CPU, also offer GPU support. GPU's are not supported on shared-core machine types or memory-optimist machine types. Once you've decided what machine type is suitable for you, you'll need to decide the base image that you want installed on your VM. You can choose from public or custom images. Public images are those OS images that are maintained either by Google, by open-source communities, or third-party vendors. Many of these images are freely available, and all projects on the GCP have access to these images and can use these images in order to create VM instances. Not all public images are free. You might have to pay for some of them as well, such as for Windows Server, SQL Server, and so on. Custom images are images that are available only within your project or within your organization. These are images that have been specially set up to work, let's say, within SpikySales. com. It's possible for you to create a custom image of your own and use it within your organization to create instances.

Creating and Editing a VM Instance from the Web Console
In this demo, we'll see how you can create a VM using GCP's web console. We start off in the VM instances page, which we access by going to the Navigation menu by clicking on the hamburger icon in the top left, Compute, and then VM instances. Click on the Create button in order to start creating our first VM. You'll find that the web console is very user friendly. This will take you to a page that will lead you through the process of creating a VM. Our VM requires a unique name. We'll call it the spikey-internal-site. This is the VM that will host our organization's internal website. The next is the choice of location. Notice that there is a region drop-down here. This will allow you to locate your VM anywhere in the world. Let's start off by choosing us-central1. That is in Iowa. That is our region. And our zone is us-central1-c. Notice on the right here that your location choices affect how much your VM is going to cost. If you click on the Details link, you'll see additional information showing you how the cost for your VM is being calculated. It depends on the number of vCPUs and memory, the standard persistent disk, and it also applies the discount to give you a monthly charge. Let's say you were to switch the region where this VM was located. Instead of being located in Iowa, it's going to be located somewhere in Europe. You'll find that your monthly cost changes. In fact, it's a little more expensive in Europe than in Iowa. If you create your VM in SÃ£o Paulo in South America, you'll find that it's even more expensive, $39 per month. Let's go ahead and stick with the Iowa region for now. Notice that the machine type is set to the basic standard machine type. I'll click on the Customize link here and customize it to fit our requirements. This will open up a UI which has a number of sliders. You can use these sliders to configure the number of cores on your machine and the memory for your machine. You can also extend the memory by clicking on the Extend memory checkbox. If you're in need of a custom machine with extremely high memory requirements, this is the option that we use. This, remember, is not a standard machine type. It's a custom machine type for your requirements. And these are the sliders that you'll used to build a custom machine type. If you scroll down a bit, you'll also see the option to associate GPUs with your machine. Let's switch back to the basic view for now. And let's move on with creating our VM instance. The next choice that we have to make is the image that we want to load on to our VM by default. Google chooses the Debian Linux image. You can click on the Change button here in order to change the OS image that you want on your instance. All of the public images that are available either maintained by Google, third-party vendors, or open-source communities are listed here on this tab. You can go ahead and choose one of these images. If you're looking for an image to run a specific application, such as SQL Server, you can click on the Application images and see the list of images that are available here. For this demo, I'm going to stick with the default image that Google has chosen for me, the Debian Linux 9 (stretch) version. Go ahead and click on Select. And let's move on with configuring our VM. Every virtual machine that you create on the GCP is associated with a service account. Service accounts allow for service-to-service authentication. If you have an application running on this virtual machine, it will use the service account to authenticate itself to other APIs on the GCP. Below that, you can see the access scopes for this service account. Access scopes determine what APIs and resources the service account can access. We are going to allow the service account full access to all cloud APIs. If you want this virtual machine instance to host an internal website, we need to enable HTTP and HTTPS traffic to this VM. This we do by simply clicking on these two checkboxes. The firewall rules for this VM will automatically be configured. Whatever configuration you set up using the web console, you can specify on the command line as well using the gcloud SDK. You can click on the command line here, and this link will show you the corresponding command line for this VM set up. You haven't worked with the command line yet. Don't worry, we'll do so very soon. Now go ahead and click on Create, and this will instantiate and create your very first virtual machine on the GCP, the spikey-internal-site. The green checkmark next to your VM name shows that the VM is up and running. You can click through and look at all of your instance details on this page here. The Monitoring tab will give you a quick look at usage graphs for this VM for the CPU, network, and so on. Switch back to the Overview tab, and Stackdriver Logging is the link that will give you access to the log files that are associated with this VM. Stackdriver is the name of a company that was bought over by Google in 2014, and they provide monitoring and logging tools. Click on the Back button of your browser in order to navigate back to your instance details page. Let's click on the Edit link at the top and see what is configurable for an already-created instance. Notice that for an instance that is running, you cannot update the zone and the machine type. Click on the Stop button at the top here. This will allow you to stop your running instance. This pops up a confirmation dialog. Yes, indeed, I do want to stop my instance. And I'm going to click on the Edit link once again to see what I can edit once my instance has been stopped. Notice that I can now change the machine type. This is an option that was not available to me when my instance was running. I've customized my machine to have just one vCPU but 5 GB of memory. This is a custom machine type. I'm going to scroll down and click on Save. My machine's configuration has now been updated. I'm going to click on this back arrow on the top left here to go back to my VM instances page, spikey-internal-site. And we started once again by clicking on the three-dot menu on the right. I'm going to click on the Start option so that I restart my instance now that I've updated my machine type. And from that, you want to start it and wait for it to be up and running as seen by the green checkmark.

Creating a VM Using the gCloud Command Line Utility
Now if you're working with VM instances, chances are you want to script the creation of VMs. You can do this using the gcloud command line utility that the Google Cloud Platform provides. In order to use gcloud from your local machine, you need to install the cloud SDK. This you can do from this link that you see here onscreen. Notice the URL, cloud. google. com/sdk/docs/quickstart-macos. This is the Quickstart link for the Mac OS because that's the machine that I'm using. But if you notice on the left, you'll see Quickstarts for the other operating systems as well. From the left navigation pane, use the link based on your OS--Linux, Debian and Ubuntu, Red Hat, Mac OS, Windows, whatever your choice. I scroll down here on this page. The gcloud SDK for the Mac OS is available in the form of a tar gzipped file. Click on the link in order to download the file onto your local machine. Once the tar gzipped file has been downloaded, I open up the folder which holds my tar gzip file and double-click on it in order to untar and unzip it. I'm going to switch over to the terminal window and run the ls -l command. This is the folder where I've untarred and unzipped the gcloud SDK binaries. I'm going to run the install. sh script in order to set up my Google Cloud SDK. This install script will walk you through the process of setting up cloud SDK on your local machine. It asks whether you want to allow it to update your path variable. I'm going to click on Yes because I do want it set up on my path. This install script will also make the corresponding updates for my bash_profile file. In order for the updates that have been written out to your bash_profile file to take effect, you need to reopen this terminal window or run the command source ~/. bash_profile. You can now use the gcloud command line utility. Let's see what accounts we're authenticated with on gcloud. Run the gcloud auth list command, and you'll see that we haven't really logged in yet. So we now need to log in, and we'll do so by running gcloud init. This will walk you through configuring your gcloud SDK. I'm going to choose to re-initialize this current configuration, that is choice 1. In order to configure my Gcloud SDK, I need to log in, and that's the prompt that I see here. Yes, I do want to login. This will automatically open up a browser window that allows me to log in with my current account, which is cloud. user@loonycorn. com. Go ahead and enter your password and log in to your GCP. Gcloud SDK running on your local machine requires some additional permissions. Make sure you authorize it. Click on the Allow button here. And you're now authenticated with the Google Cloud SDK on your local machine. Switch back to your terminal window. It now asks you to choose the current project. I'm going to choose 2, that is, the spikey-internal project. For every project, you can choose to configure your default compute region and zone. I'm going to say No here because I want to be able to create instances in different regions and zones. And my initial configuration is now complete. Now when I run the gcloud auth list command once again, you can see that I'm authenticated as cloud. user@loonycorn. com. Let's take a look at our updated bash_profile to see what path variables were added. If I scroll down to the bottom here, you'll see the path variables that were enabled by the Google Cloud SDK. You can configure and manage compute instances or VMs using gcloud. You can see all of the available commands by calling help--gcloud help compute instances create. And here are the create options that you can use when you first set up a VM. Having gcloud installed on your personal machine is very useful. But for the purposes of this course, I'm going to primarily use cloud shell from my browser window. Gcloud is already installed on your cloud shell ephemeral virtual machine. Simply run gcloud init and go through the same series of steps that we saw earlier in this demo. Once gcloud has been initialized, let's use the command line in order to spin up a new VM instance. I'm using the gcloud beta compute command. The project is spikey-internal-123. Specify the project ID. The name of the instance is spikey-internal-analytics. I want to create it in the us-east1-b zone. The machine type is no n1-standard-1. This is a standard machine. The image family is debian-9. And the image project is no debian-cloud. The Debian image family is available from the Debian Cloud project. I'm using a 10-GB pd-standard hard disk. That is my boot disk device. And the name of my boot disk device is spikey-internal-analytics. Because I've chosen just a 10-GB boot disk, it gives me a warning indicating that I might have poor I/O performance. That's okay for this demo. Go ahead with the creation. If you hit Refresh on your web console, you'll see that the new spikey-internal-analytics instance has been created, and it's up and running. If you run the command gcloud beta compute instances list, this will show you a list of all the instances that you created in this project. Here we have just two--spikey-internal-site and spikey-internal-analytics, both of which are running.

Preemptible Instances and Instance States
In this demo, we'll see how we can create and start up a preemptible instance on the GCP. We'll also see how we can check the status of an instance using the command line. Now preemptible instances are instances that you can create and run at a far lower cost than other instances that we've set up so far. However, Google Compute Engine does not consider preemptible instances to be completely your own. GCE might terminate or preempt those instances if it requires access to those resources. A preemptible instance will definitely be restarted at least once every 24 hours. If your application is fault-tolerant and can withstand instance restarts, then preemptible instances are a great way to save on costs. Preemptible instances are very similar to spot instances on the AWS without requiring the upfront reservation. Let's start off in the VM instances page, click on the Create Instance link in order to create a new instance. This is going to be a test instance so we'll call it spikey-internal-test. Because it's only going to run our test applications, it's okay for it to be preemptible. Make sure you locate your instance close to where you will be actually using it. Let's say you have a development team based in Mumbai, you might want to locate this instance in asia-south1. You can configure whether this instance is preemptible by clicking on this extra link, Management, security, discs, networking, and sole tenancy. Within that, you have an option called Preemptibility. By default, this is set to Off. But you can switch it over to On in order to make your instance preemptible. You can also create preemptible instances from the command line. Click on the command line link at the very bottom, and here is the gcloud command to create the same preemptible instance. Notice the --preemptible here. That's what makes this instance preemptible. Click on Close, and let's switch back and create our preemptible instance. While this instance is being spun up, let's understand the various states in which our instance can exist. When you first create a new VM instance, it is in the provisioning state. That's when it reserves vCPUs and memory for that instance and sets up the root persistent disk. The instance isn't running yet. The next state of an instance is the staging state. Here resources have been acquired by the instance, and the instance is being prepared for launch. We've assigned IP addresses to it, and the boot process is running. When the instance is up so that you can run your applications, and it's open for connections, that is the running state of an instance. You can SSH or RDP into the instance. You can live migrate. You can change the instance, and so on. From a running state, an instance can get into the stopping state. This is in the case of failure or when you explicitly shut the instance down. This is a state where the shutdown script has yet to run. This is a temporary state, and the instance will soon transition out of the stopping state and get into a terminated state. Once the instance has been terminated, you can choose what you want to do next with the instance. You can go ahead and delete it or restart it so that it starts in the provisioning state once again. You can use the command line to see the current status of all of your instances by calling gcloud compute instances list. This shows us that we have three instances at this point in time and spikey-internal-test, our preemptible instance, is in the staging state. If you run the same command again after waiting for a minute or so, you'll see that this instance has now transitioned to the running state. Spikey-internal-test is now up and running. You can also use the gcloud command line tool to get more detail about a specific instance by using the describe command. Commands which specify instance names in the GCP typically also require a zone specification. If the zone is not specified, GCP will try its best to guess which zone this instance is located. The zone is not in asia-southeast1-a. I've responded n indicating that this is not the right zone. And when the command runs through, you'll find that the GCP has figured out that it's in us-east1-b. All the configuration details of this instance can also be viewed here on this screen using this command.

GCE Pricing
We've seen a sample of how much VM instances cost in different regions around the world. Let's see the various components that make up pricing for GCE VMs. The first component that goes into how much your VM costs is the number of seconds for which the VM has been running. This is the Instance Uptime. Now what's really cool about using the Google Cloud Platform is that you have per-second billing. That means you're not rounded up to the nearest hour or to the nearest minute after a minimum of 1 minute. After 1 minute has passed, then for every second that you use the instance, you will be billed. The GCP also offers free VM usage up to a certain limit. This is the Always Free Usage Limits, 1 f1-micro VM instance a month, 30 GB of standard persistent disk a month, a 5-GB snapshot storage per month, and 1 GB of egress network from North America per month. These are the free usage limits. You will be charged for any resources that you use beyond these free usage limits. The GCP wants to incentivize you to use their resources as much as possible. This they do by providing very good Sustained Use Discounts. The longer your VMs run, the lower the rate for running your VMs. Sustained Use Discounts don't apply to a single VM instance that you have to keep running. In fact, they are grouped by machine types. If you're using predefined machine types, you can group all instances of the same type in the same zone and the same project, and that is how long your machine has been running. And that's how the Sustained Use Discounts are calculated. It's not possible to categorize your machines by machine type if you're using custom machine types. In this case, the GCP will separately group the memory usage and the CPU usage for all of the instances in the same zone and same project in order to apply Sustained Use Discounts. You can make avail yourself of additional discounts from Google if you commit to using GCP resources for a certain time period. If you provide an upfront commitment, you get price reductions in exchange. If you provide a commitment of 1 to 3 years, your discounts can be up to 57-70%. If you're using Premium Images for your VM instances, that is, images which you have to pay for over and above your VM instance, the cost depends on the image, as well as on the machine type. For example, a VM running the SQL Server Enterprise edition costs about $0. 40 per core per hour. There is no easy way to assign an exact price for these Premium Images. The exact calculations are quite involved, and it's good practice for you to look at roughly what the Google's estimates are when you're creating your VM. There are a bunch of other costs involved in using your VM instances as well. There is additional network pricing. Network ingress costs tend to be free. Egress charges vary depending on where your VM is located. You have additional image storage costs as well, so if you build up custom images, the costs work out to about 9 cents per gigabyte per month. If you reserve a static IP address and don't assign it to an instance, Google will charge you for that as well. Unused IP addresses are about 1 cent per hour for the unused static IP. If you're planning to use GPUs for machine learning or any other purpose, they can be pretty expensive. They cost an additional $100-$550 per GPU per month. If you're under-utilizing your VM resources, Google provides automated sizing recommendations. It'll provide machine type recommendations to help optimize resource utilization. These recommendations are generated automatically from Stackdriver Monitoring data. Your VM instance has to be up for at least 24 hours for your sizing recommendations to be generated. And on this note, we come to the very end of this introductory module on the Google Compute Engine. We saw that the Google Cloud Platform offers Infrastructure as a Service and Platform as a Service options. Google has a spectrum of offerings ranging from VMs to cloud functions. This module and this course is primarily focused on GCP's virtual machine instance offerings. This is the Infrastructure as a Service compute solution from Google. We saw that Google makes it very easy for you to spin up virtual machines in a variety of performance, sizing, and memory options on its datacenters. These GCE VMs run either Linux or Windows-based images. The GCP also offers a variety of ways for it to be more cost efficient for you to run VMs on the cloud. There are attractive pricing features such as Sustained Use Discounts and Committed Use Discounts. If your applications are fault-tolerant, then you can also use preemptible instances in order to save on costs. Preemptible instances can be preempted by Google at any point in time. They'll definitely be shut down once every 24 hours. In the next module, we'll see how we can connect to the VM instances that we just created and then understand the various storage choices that we have--persistent disks, as well as local SSDs.

Working with GCE VM Instances
Module Overview
Hi, and welcome to this module where we'll learn to manage and administer the VM instances that we created earlier. We'll start off by seeing the various options that we have to connect to our VM instances running on the cloud. SSH is automatically enabled for all VMs on the default network, and that's what is the most commonly used to connect to our VMs. It's often the case that the applications that you have running on your VM require a static IP address, which we use to connect to those applications. We'll see in this module how you can reserve static IP addresses on the GCP. We'll also take a look at the various storage choices that we have available with the GCP. We'll see how we can connect to cloud storage packets from our GCP VMs. We'll study block storage versus object storage in some detail. Block storage is made available to our virtual machines by our persistent disks. We'll see how we can add additional persistent disks to our existing VMs. We'll also see how we can configure a new instance using local SSD disks.

Connecting to a VM Using SSH
Let's start off by seeing how we can connect to the VM instances that we created in the last module. This is the VM instances page, and we have three VM instances up and running, one of which, spikey-internal-test, is a preemptible VM. Notice the drop-down available at the right end of every VM. This is what gives you the various options that you have to connect. You can use the gcloud command line utility in order to SSH into your VM instance. If you're working on your local machine, this will be your preferred option. You can see the gcloud command here. Just copy/paste this command into your terminal window and connect to a particular instance. If you do not want to use gcloud, and you want to use a different SSH client provided by a third party, that is possible as well. Click on the Use another SSH client option, and this will open up a documentation window, which will show you how to go about using third-party SSH software in order to connect to your VM. Here we'll choose the simplest option to connect to our VM. We'll connect via SSH in the browser window. In the drop-down, choose the option which says Open in browser window. And this will connect to your virtual machine. This opens up the Linux terminal window to your VM right here in the browser. And from within this VM, you can ping the other VM that you've created in this project. You're connected to spikey-internal-site, and you can call the ping command and ping the spikey-internal-analytics VM. The firewall rules on the default network to which both of these VMs belong allow internal communication between all of the resources on the default network, which is why this ping is successful. You can also SSH from one VM terminal window to another. Simply call SSH and specify the name of the instance within this project, and you can directly SSH into that machine. Notice from the terminal prompt here that you have now SSHed into the spikey-internal-analytics machine. Type exit to close the SSH connection to your spikey-internal-analytics. You're back in the spikey-internal-site VM instance. You can use the terminal window prompt in order to tell which machine you're currently SSHed into. Let's switch back to the VM instances page for a second and click through to spikey-internal-site. Now if you observe the configuration settings of this VM, you'll see that we've allowed HTTP, as well as HTTPS traffic. Now this means we can host a web application on this VM. Let's switch back to the command prompt on our VM instance. I'm going to run sudo apt-get-update in order to update the packages on my virtual machine. The next step is to install an Nginx server in order to run a simple website. I'm going to use the apt-get install command in order to get the nginx-light package. Once this package has been installed on my virtual machine, I'm going to run the nano editor in order to edit the index. nginx-debian. html file. This is the HTML file that is first served when we hit our website. I'm going to call it Welcome to Spikey Sales internal site. That's the title. I'll leave the other formatting as is. I'll edit the body of this HTML document to say Welcome to the Spikey Sales internal site! Here is where you can find links to everything you need as an employee. Hit Ctrl+X in order to save this file, and run the curl command to see whether your web server is up and running. The curl returns successfully. Your website is up. Switch back to our VM instances page. Notice that every VM that we have set up here has an internal IP address and an external IP address. Both of these IP addresses for each VM are ephemeral by default, which means they can be changed or updated at any point in time by the GCP. Notice the little arrow next to the external IP address of our spikey-internal-site. This arrow indicates that this particular instance has been enabled for HTTP and HTTPS traffic. Click on the arrow here, and let's see if we can access our Nginx web server, the site that we just got up and running. Immediately you'll see that the HTTPS site does not work because we haven't configured to set it up. If you change the URL to be HTTP rather than HTTPS, you'll find that we are able to hit our website, Welcome to the Spikey Sales internal site!

Reserving a Static IP Address
In this demo, we'll see how you can reserve a static IP address for our virtual machine instance. Now before we go into the demo, let's take a look at our Loch Ness monster here. We are up to NE, the networking configuration options that are available for your VM. Now by default, when you set up VM instances, they belong to the default network on the GCP. The default network is a GCP network configured automatically by the GCP and to which all resources belong by default. Every VM instance has two categories of IP addresses associated with it--the internal IP address and the external IP address. The external IP address of the VM instance is what resources on the internet can see. Any resource which does not lie on the same VPC as this VM instance must use its external IP address, whereas internal IP addresses can be used by other resources that lie on the same VPC. The internal IP address is what VMs on the same network use to communicate with one another. IP addresses can also be static or dynamic. Dynamic IP addresses are also known as ephemeral IP addresses. Static external IP addresses are assigned to a project long term until they're explicitly released, and they remain attached to a resource unless they are explicitly detached. Ephemeral IP addresses, whether internal or external, remain attached to a VM only until the VM is stopped or restarted. In order to allow for resources on any VPC network to communicate with one another or with the external world, explicit firewall rules have to be configured. On the default network, firewall rules for internal communication, as well as rules to allow SSH into or pinging of instances are automatically configured. Firewall rules can be explicitly configured in order to allow or deny specific kinds of traffic to and from your VM instance. We'll start our demo off in the VM instances page as before. Notice our spikey-internal-test. It has been stopped automatically by the GCP. It's a preemptible instance after all. Notice that we have our spikey-internal-site up on the IP address, 35. 194. 19. 5. This is the ephemeral external IP of our VM instance. In order to reserve a static IP address for our VM instance from the Navigation menu, choose VPC network, and choose the External IP addresses option. Since you've created VM instances, you already have some IP addresses. If you click Refresh, you'll see the two ephemeral external IP addresses that we have associated with our two VM instances. Our preemptible instance has been stopped and no longer has an IP address associated with it. Observe that the IP addresses of both our VM instances start with the same first 3 bytes, that is 35, indicating they're on the same VPC. Click on the Reserve Static Address link at the very top in order to reserve a static IP. GCP opens up a very simple form for you to fill up. The first is the name of the IP. I'm going to call it spikey-internal-site-ip, and it's a static address for the VM hosting our internal website. The description is optional, though it's useful to fill one in. Notice that the network service tier for my project is the premium tier. The premium tier allows me to use Google's high-speed links for my traffic. The network charges for the premium tier will, of course, be higher than the standard tier. The premium tier offers higher performance at a slightly higher cost, and the standard tier is for cost-sensitive workloads. You'll have lower costs for outbound traffic. Notice the warning message at the bottom of the screen here. Static IP addresses which are not associated with a VM instance are billed separately by Google, which is why I'm now going to associate this IP address with this spikey-internal-site. This is the VM instance for this static IP address. Notice that we've chosen our IP address to be of type regional, and the region is us-central1. Regional IP addresses make sense if you're attaching them to a VM instance or using it for network load-balancing. If you're reserving a static IP address for an HTTPS, SSL proxy, or TPC proxy load-balancing, you need to choose the global option. Click on the Reserve button at the bottom in order to reserve your static IP address. If you go to the External IP addresses page, you'll see that your spikey-internal-site now has this new static IP address. If you switch to the internal website that we have hit earlier and hit Refresh, you'll find that the original IP no longer works for your Spikey Sales internal site. If you use the new static IP address, then that will work. Go ahead and paste the static IP address on your browser, and notice that we've managed to hit our site once again. Let's go back to our External IP addresses page. It's possible to promote your ephemeral IP to be a static IP address by clicking on the drop-down that you see here onscreen. You can simply switch this to static, and your ephemeral IP address will be promoted to a new static IP address. Make sure you specify a meaningful name and description. You can see from this External IP addresses page here that both your VM instances now have static IP addresses. You can also work with IP addresses using the gcloud command line utility. Open up your cloud shell, and call gcloud compute addresses listed, and this will list out all the static IP addresses that you've reserved in this project. Both of our IP addresses are currently in use. Each IP address is attached to a corresponding VM instance. You can unassign a static IP address from a VM instance by deleting its access configuration. Let's see what its access configuration is by calling gcloud compute instances describe on the spikey-internal-analytics VM instance. A bunch of details are printed to screen. And notice under networkInterfaces, we have accessConfigs, and the name of our accessConfigs is external-nat. We can unassign the static IP address that's associated with this spikey-internal-analytics VM instance by deleting this access config. The name of the access configuration that we want to delete is the external-nat. Once the access configuration has been deleted, when you hit Refresh on your External IP addresses page, you'll see that your spikey-internal-analytics-ip is not assigned to any VM instance. The In use by column says None. When you use the gcloud compute addresses command, you'll see that we still have two static IP addresses. One of them is in use, that is, the spikey-internal-site-ip. The other one is reserved. It's not in use. We'll be billed for this reserved instance. You can use either the web console or the gcloud command line to delete this static reserved IP address altogether. Use gcloud compute addresses delete, specify the name and the region of the IP address, and go ahead and delete this static reserved IP. Hitting Refresh on the External IP addresses page will show you that the IP address has disappeared. Let's switch back to our VM instances page using the Navigation menu. Because we deleted the static IP address associated with spikey-internal-analytics, it has no external IP at this point in time. Observe that without an external IP, you can't SSH to this instance.

Creating and Connecting to a Windows Instance
Let's talk about the GCE VM instance configuration. We'll continue our discussion of the Loch Ness monster. Configuration forms the C of the Loch Ness monster, and configuration can also be in terms of the base images that we use on our VM instance. Base images can be public or custom images, and public images can be either free or premium images. Debian and CentOS are free images. Premium images are Red Hat, Linux enterprise edition, Windows, and so on. If you want something beyond the free images that are available for your GCP VMs, you can use the GCP Marketplace, which is a marketplace of images for common uses such as WordPress, SQL Server, and so on. You'll definitely find an image that meets your requirements. In this demo, we'll see how you can create and manage Windows instances on the GCP. We start off in the VM instances page, click on the Create Instance link at the very top, and let's name our instance spikey-internal-windows. Now GCP charges for creating Windows instances are different from Linux instances because Windows is a premium image. Let's open up the Details link to see how we are charged for Windows. In order to use a Windows image, we need to click the Change button on the boot disk to have our boot disk boot up from Windows. It's also a public image, meaning all projects have access to Windows images. If you scroll down here on this list, at the bottom you'll notice the Windows Server 2016 Datacenter image. This is the OS image that we'll choose for this instance. If you'll notice our boot disk size at the bottom here, you'll see that it has been automatically set to 50 GB. This is the minimum boot disk size required for a Windows image. If you try to change this to a smaller number, GCP won't allow it. Switch back to 50 GB, and click on Select. We now have our Windows boot disk. The pricing details on the top right have been updated, and you can see that this VM instance will cost us nearly $56 per month. Much of this additional charge is because of our Windows Server datacenter image. We accept the default option for all of the other configuration settings and click on Create. One thing you need to be aware of here is that Windows instances take far longer to spin up as compared with Linux instances because it takes much longer to complete the sysprep process on Windows. The GCP console might show that your VM instance is up and running even if the sysprep process is not yet complete. We need to perform an additional check to see whether our Windows instance is successfully up and running. We'll connect to the serial port of our Windows instance using this gcloud compute command from the command line, cloud compute instances get-serial-port-output, and specify the name, as well as the zone of your Windows instance. If you scroll through the output, you'll see that we do not have a success message here indicating that the instance is not yet up and running. I'm going to wait for a few more minutes before I run this command once again. And, finally, after about 3 or 4 minutes, you can see that this instance is successfully up. When you see the Success message onscreen, that's when the sysprep process has completed running. Your instance is ready to be connected to. Now on the Google cloud platform, before you connect to a new Windows instance, you need to create a new password to log in to that instance. Click on the spikey-internal-windows instance here, and this will give you the option to set your Windows password. Click on the Set Windows password button, and this will pop up a dialog allowing you to specify a new user for your Windows machine, and a password will be automatically generated for you. Make sure you copy this password down to a safe location somewhere. You'll need to use it when you connect to your Windows machine using RDP. RDP stands for Remote Desktop Protocol. It's the proprietary protocol developed by Microsoft, which you can use to connect to Windows machines. RDP requires that you have an RDP client set up. Now you can already have a desktop version of the RDP client, or if you're working on the Chrome browser, RDP is available as an extension on Chrome. In order to keep things lightweight, I'm going to install the Chrome RDP extension. Remember, this is not supported by Google. It's a third-party extension. Because I'm currently on an incognito window, I can't install this extension, so I'm going to switch over to a regular Chrome window in order to install RDP. I'll click on the RDP button in the spikey-internal-windows instance and install the Chrome RDP extension. Installing this extension is very straightforward. Simply click on Add to Chrome, and this extension will be added to your browser. Once this extension has been added, it will automatically be populated with the IP address of your Windows instance. And you can click on the Connect button. If the IP address does not populate automatically, simply get the IP address from your instances page and click on Connect. The username for this Windows machine, cloud_user, is automatically populated. Paste in your password. Leave the domain field empty because this user is not associated with a domain. Click on the Continue button here in order to continue connecting to our Windows machine. And we are connected. Administrative paths on Windows are typically performed using the PowerShell command line. Click on the Start button, and right click on the PowerShell icon here in order to run as administrator. Confirm that you want to allow PowerShell to run as administrator. Click on the Yes button here, and there you are. You have PowerShell up and running. I'm going to increase the font size here. I'm going to right-click on the PowerShell top bar, click on Properties, and change the font to be a larger one. Notice how we are fully within our Windows instance and have the power to administer it the way we want to. If you want to disconnect from the Windows instance, click on the arrow on top, and click on the Disconnect button there. This takes us out of our Remote Desktop client, and we are back to our browser incognito window. Because Windows machines are so expensive, I'm going to stop this VM from running by clicking on the Stop button. Go back to your VM instances details page, and once the machine has stopped running, click on the three-dot menu to the right of the instance and click on Delete in order to delete this VM instance icon for deletion, and my Windows machine will now disappear.

Storage Technologies
In this clip, let's talk about the various storage options that are available when you work on the Google Cloud Platform. If you remember your Loch Ness monster mnemonic here, figuring out storage is really, really important, which is why it's denoted by a double S. The first and most important the choices that you make for your computing are where you run your code and where the data is stored. We've already spoken about the compute options available on the GCP in some detail. Let's now talk about storage. Now when we talk about storage technologies, you typically have two kinds of data--unstructured data in the form of blogs. Examples of unstructured data are image files, media files, or anything which has a binary format. Or your data might be structured, data with a predefined schema. In the case of structured data, you might want to use this data for transactional processing or OLTP, or you might want to use this data for analytical processing in order to extract business insights. On the GCP, you have two options for storing data for transactional processing. You can use cloud SQL if your data site is small or cloud spanner if you want transactional processing and ACID++ properties on a global scale. Or if you're interested in storing data for analytical processing, you can choose to go with BigQuery, Google's data warehouse, or BigTable, which is a columnar store. There are two options that you have to store unstructured data on the GCP. Your unstructured data might require block storage or object storage. Block storage refers to the disk drives that you connect to your VM instance. Block storage is physically addressable storage accessible from your compute solution. The GCP offers a number of block storage devices that you can connect to your VM instances. Persistent hard disk drives are cheaper, but they have higher latency of access. For lower latency and better performance, you might choose persistent solid-state drives. These are more expensive, though, as compared with plain, vanilla HDDs. The GCP also offers you the option to connect a high-speed local SSD to your VM instance. Unlike persistent disks, local SSDs are physically attached to your VM instance. This tight coupling offers superior performance and very high input/output operations per second. These low-latency, high-speed disks are only suitable for temporary storage. They are not durable. GCP also has the option to connect RAM disks to your VM instance. RAM disks basically mimic a file system using RAM memory. So this is very useful when your application expects a file system structure but requires fast access. The other kind of storage that works well for unstructured data is object storage. Object storage stores data in the form of discrete units. These discrete units are logically addressable by compute, as well as human users. Object storage on the GCP is available using GCS buckets, Google Cloud Storage buckets. This diagram serves as a quick reference for you to see all of the storage options available for unstructured data on the GCP.

Persistent Disks vs. Local SSDs
When you're setting a block storage to connect with your VM instance, you'll have the choice between persistent disks and a local SSD. Let's understand the characteristics of these in detail so that you can make the right choice. Persistent disks are basically hard disk drives or solid-state drives that are in the same zone or region as your VM instance. These can be resized on the fly, and these can also be moved across zones. You can create images and snapshots in order to back up the contents of your persistent disks, and these persistent disks have data encrypted at rest. You can also use custom keys to encrypt this data. Google ensures that the data that you store within these persistent disks are always secure. When we've been setting up our VM instances so far, we've always specified a boot disk which holds our OS image. The boot disk is a persistent disk that every VM instance needs to have. This contains the boot loader, the operating system, and all of the other software needed to boot up our VM instance. The cool thing about the boot disk on the GCP is that they are durable. You can delete the VM instance but keep the disk, and use that same boot disk to re-create another VM instance. Persistent disks on the GCP are pay as you allocate, so if you allocate 100 GB disk, you have to pay for the entire 100 GB even if you just store 1 GB of data. Now that we've understood what persistent disks are, let's see how persistent disks differ from the local SSD. Persistent disks are durable network storage devices that your VM instances can access, kind of like physical disks on a computer. Persistent disks are attached to your VM instance over a network, and they can belong to the same zone or even the same region. Local SSDs on the other hand, are physically attached to your VM instance, which means they offer very high performance and low latency. Persistent disks have data redundancy built in. GCP manages the striping of your disks so you don't have to do it yourself. In the case of local SSDs, though, there is no inbuilt data redundancy. Persistent disks can be used to store your OS boot image. Persistent disks are bootable. Local SSDs are not. Persistent disks offer durable storage. That means even when your VM instance is restarted, the data that you store in your persistent disk is available to you. Local SSDs are not durable. In the case of instance restart, the local SSD data is completely lost. Persistent disks can use the slower- and lower-cost hard disk drive technologies or can be solid-state drives. As you can infer from its name, local SSDs are just SSDs for better performance. The maximum amount of storage you can get when you use persistent disks is 64 TB. In the case of local SSDs, this is far lower. You can connect multiple local SSDs to get a total of 3 TB max storage. When you use persistent SSDs, you can create snapshots or images of the data in your disk in order to back it up or re-create VM instances from your snapshot or image. Local SSDs cannot be used for snapshots or images. The big advantage that you have when you use local SSDs is its superior performance. It's very, very fast, especially for random-access data. Local SSDs are typically used when you want a very fast scratch disk or a cache, and you don't require data persistence on instance restart.

Creating and Attaching Persistent Disks
You can expand the block storage available for a VM instance by adding a persistent disk to it. In this demo, we'll create a persistent disk and associate this disk with the VM instance that we've already instantiated. Let's start off here in our spikey-internal-site VM. We'll click on the Edit button here in order to attach a new persistent disk to this VM. Scroll down this Edit configuration page here until you come to the Boot disk and local disks section, and click on Add item. This is where you can attach a new persistent disk to this VM. If you click down on the drop-down option under Name, this will show you all of the persistent disks available in this project, or you can choose to create a new disk. We'll call this persistent disk the spikey-internal-site-disk-1, and we'll make this a blank disk. We don't want a disk from a pre-existing image. The size of this disk will be 20 GB. You can choose a larger size if you want to, but, remember, persistent disks are pay as you allocate, so it's better to start off with a smaller sized disk and resize the disk when you think you need a larger one. Go ahead and click on the Create button here in order to create this persistent disk, and attach it to this VM instance. Click on the Save button in your Edit configuration page. The persistent disks that you attach to your VM instance using the web console are by default zonal persistent disks. They are present in the same zone as your VM instance. The GCP also provides the option of a regional persistent disk, which is in a different zone but in the same region as your VM instance. However, this can only be configured using the gcloud command line at this point in time. Once your persistent disk has been attached to your VM, you need to format this persistent disk. New persistent disks start with no data or file system. Switch over to the Browser tab where you have SSHed into your spikey-internal-site VM instance. Here we are going to run the lsblk command in order to see the disks that are attached to this VM. You can see our newly connected 20-GB persistent disk with the name sdb listed here. Let's format this disk using the command that you see here on screen. You can see that I'm using a simple EXT4 file system without a partition table. Notice at the end of this command, we specify the /dev/sdb disk. Make sure you don't end up formatting your boot disk. Once our disk has been formatted, you can now mount this disk on to your VM instance. You'll first create a mount directory under /mnt/disks. I'm going to create a directory called disk-2 under here. We'll then run the sudo mount command in order to mount a newly attached persistent disk to the disk-2 directory. Running the ls -l command under /mnt/disks folder will show us disk-2 listed there. Let's now make this persistent disk writable. We'll run the chmod command and give write access to all users on this disk. You can stop right here, or you can go a little further. You can add the persistent disk to the /etc/fstab file so that the device automatically mounts again when the instance restarts. We'll first make a backup of this file so that we don't muck it up in some way. We'll copy the current fstab file to etc/fstab. backup. We'll run the blkid command on our newly created and attached persistent disk in order to find its ID. This is what we'll add to the fstab file. Make a note of the ID here. Select it and copy it to a clipboard or some notepad on your machine. Run the chmod command on the fstab file in order to make it writable. We'll then open up this file using the nano editor, nano etc/fstab. It just has this one entry here containing the UUID of your old disk. We are going to go ahead and add the UUID of your newly attached persistent disk here as well. Hit Ctrl+X and save this file, and run the cat command to make sure that your update has been saved. Everything looks good here. You have now configured your persistent disk to mount once again to the same folder once you restart your instance. Now that we've seen how to have your persistent disk automatically be mounted on VM instance restart, I'm going to restore my fstab file here to its original form. I'm going to be using the same VM instance in order to take a snapshot of my boot persistent disk and also to create images, and I don't want any extra stuff in here. Before we end this demo, switch over to your list of VM instances, and click on the spikey-internal-site. If you scroll down, you'll notice that this VM instance has two persistent disks within it--a boot disk and an additional disk. If you click on the Disks link on the left navigation pane, you can see a list of all the disks that you've created within this project. Instead of creating a new disk within the Edit configuration of a VM instance, you can create a disk using the link that you see right on top here. Once you've created a persistent disk, you can then attach the disk to a VM.

Connecting a Local SSD to a VM Instance
We've spoken of using local SSDs as high-speed cache memory for your VM. Let's see how you can set up an instance using a local SSD disk. Click on the Create Instance link here in your VM instances page, and let's set up an instance as usual. I'll call it the spikey-internal-fastsite. I want my firewall rules to be set up so that fastsite can serve HTTP, as well as HTTPS traffic. Click on the link here which says Management, security, disks, networking, and sole tenancy. This is where we'll set up our local SSD. Expanding this throws up many more configuration options for our VM. I'm going to select the Disks tab here. This will give me the option to add a new disk to my virtual machine. Local SSDs can only be connected to your VM at the time of instance creation, so you can't attach a local SSD to an existing VM. This will show you a form that will navigate you through creating a local SSD. I'm going to call it local-disk-1. And I want my local SSD to be a blank disk with no file system on it. I'll need to format this disk myself. Now the type of disk I want to attach is not a standard persistent disk. Instead it's a local SSD scratch disk. The maximum disk size for a local SSD is 375 GB, and you can attach up to 8 for a single VM. If you scroll down here, you can use the slider that you see in order to specify the number of SSDs that you want. I've left it at 1 for now. Click on the Done button at the bottom in order to create and attach this disk to our VM. Click on the Create button in order to create this VM instance with a local SSD attached. We'll now SSH into our new VM instance in order to format and mount this local SSD. We'll run lsblk as we did before. And notice that we have a 375-GB SSD attached. Let's format our disk using the sudo mkfs. ext4 command, and you'll see that this formatting runs for a little bit because our disk is large. It's 375 GB. We'll then create a mount directory for this disk as we did earlier with the persistent disk. I'm going to call this ssd-disk-1. And then we'll run the sudo mount command in order to mount this disk. We'll run the chmod command in order to make this disk writable. It's writable for all users. Run the ls -l command on the /mnt/disks folder, and you'll see that the SSD disk has been successfully mounted. And on this note, we come to the very end of this module where we learned to work with and administer GCE VM instances. We started off by seeing how we can use SSH to connect to VMs on the cloud. We then saw how we can reserve static IP addresses so that applications on our VM can be accessed using a static IP. We then discussed in detail block storage versus object storage, and we understood how persistent and local SSD disks worked. In the next module, we'll focus on how we can manage GCE VM instances. We'll see how snapshots and custom images work, and we'll also see how we can move your VM instance between zones in a region.

Managing GCE VM Instances
Module Overview
Hi, and welcome to this module where we'll see how you can manage your GCE VM instances. We start off by looking at availability policies on the GCP. Availability policies determine how your VM instances behave in the case of a maintenance event. We'll also see how you can simulate these maintenance events in order to test how your VM behaves. We'll also talk about metadata that is associated with an instance and is available by querying a metadata server. We'll also see how you can configure metadata on your VM to run a startup script whenever the VM is instantiated and gets booted up. We'll also see the snapshot service and the image service available on the GCP for your boot persistent disks in case you want to migrate your applications to another zone. It might be required to move your instance between zones. We'll see how to do that quickly and easily on the Google cloud.

Configuring Availability Policies
In this demo, we'll see how you can configure the availability policies for your VM instance. We'll also see how you can simulate maintenance events so that you understand how your VM instance behaves. We've seen configuration settings for availability policies, but we haven't studied in detail yet. The availability policy of a VM determines how that VM behaves when an event occurs that requires Google to move your virtual machine to a different host machine. Let's say that a particular data center experiences an outage. The availability policy will determine how a VM in that datacenter will behave when it has to be moved. By default, any VM instance that you create on the Google cloud is configured with the Live Migrate availability policy. This means that the instance remains running even when Google moves the instance to another host machine. This is the default configuration. If it's okay for your machine to shut down for a short period of time, you can configure your availability policy to be Terminate and Restart. GCE will shut down that instance during a maintenance event, terminate it, and restart that instance elsewhere. You also have the choice to have your instance support Automatic Restart. This means if that VM instance crashes, the Google Compute Engine will automatically restart it. It won't remain stopped. Let's take a look at the availability policies that have been configured by default on our spikey-internal-site instance. Click through to the configuration settings, and click on the Edit link at the top so that you can edit it's availability policy. We won't actually perform the edit, but we'll see what the default is set to. If you scroll down to the bottom, under the Availability policies section, you'll notice the default settings. Notice that this instance is configured to automatically restart if it crashes, and on host maintenance, the VM instance will be migrated. Let's not change anything here. I'm going to hit the Cancel button at the bottom of the page and go back to the VM instances page, which lists all of our instantiated VMs. Now I'm going to activate the cloud shell and then use a gcloud compute instances command in order to simulate a maintenance event. This command is in beta, that's why it's available at gcloud beta compute. Call the simulate-maintenance-event, and specify that you want this event to occur for the spikey-internal-site in the us-central1-c zone. Even as the maintenance event occurs on this instance, you'll find that this instance is live migrated. That means when you click on Refresh, you'll see that this instance continues to be up. Once the maintenance event is complete, you'll find that this instance continues to remain running, and you can also access the website that's running on the spikey-internal-site instance. Make sure you access it using HTTP and not HTTPS. Let's click through to another VM instance, the spikey-internal-fastsite, and change its availability policy. Click on the Edit link on top in order to change these configuration settings. We'll change automatic restart to Off. This means that the VM won't be automatically restarted if it crashes. We'll also change Migrate VM instance to Terminate VM instance instead. So if there is a maintenance event, this instance will be terminated and not migrated. Scroll to the bottom here, and click on the Save button, and wait for your instance to be updated. Once the instance has been updated, let's go back to our VM instances page and simulate a maintenance event on spikey-internal-fastsite. We do this via our cloud shell command line using the same gcloud beta compute instances simulate-maintenance-event command. You need to specify a zone here, and I forgot to, which is why GCP prompts me for a zone. Asia-southeast1-a is not the right zone for this instance. I click on No, and I choose from the options here. Number 41 is us-east1-b, which is the correct zone. Once this simulated maintenance event is complete, refresh your VM instances page, and you'll find that spikey-internal-fastsite has been stopped. The instance has been terminated due to the maintenance event, and because this is an instance with a local SSD, this cannot be restarted.

Instance Metadata
Going back to our Loch Ness monster mnemonic, let's now take a look at the metadata that you can configure on your GCP VM instance. Metadata that is associated with a VM can be labels on the VM in order to logically group your resources for billing or other purposes. You can specify tags for firewall rules. You can specify startup and shutdown scripts using metadata as well. Most of the resources that you instantiate on the GCP support labels. Labels are simple key-value pairs that can be associated with any GCP resource. It's a lightweight way to group related resources. Labels can be used to tag your production, dev, and test environments. You can group resources together for billing and so on. Network tags are another kind of metadata. These are text attributes that you apply to VM instances as a way of applying firewall rules to allow and deny traffic to your instance. Routes can be specified using network tags as well. Labels, which are key-value pairs, and tags, which are just values, not keys and values, are both forms of metadata that apply to your VM instance. These reside outside of your VM instance on a separate server called a metadata server. Having metadata on a separate metadata server is very useful because this metadata server then can be queried programmatically from within the VM instance and also from the compute engine API. This metadata can be used to get additional information about the instance. Here is a standard URL that you can query in order to access metadata information about your VMs. This can be programmatically queried without authorization. This means that you can get information about an instance, the information that the instance chooses to expose, without having access to that VM instance. That's pretty cool. The metadata server is most commonly used to store the startup and shutdown scripts that are associated with any VM instance. Other common attributes that you can set up on the metadata server are the instance hostname, the ID of the instance, and maybe the service account that the VM instance uses. These are just a few examples of metadata that you can configure for a VM.

Configuring Instance Metadata
In this clip, we'll see how you can set up and query metadata that is associated with your instance. Let's start off in the VM instances page and click through to the spikey-internal-site. If you click on the Edit link on top, that will pop up the configuration settings. And within this, you can query your instance metadata. Scroll down to the Custom metadata section that's available just under your availability policies. Here I've set up a key-value pair to specify the environment for this instance. This is the prod environment. I'm going to click on the Add item button that's available here in order to specify another key-value pair. I want to indicate that the billing-team for this instance is the internal_tools team. Click on the Save button at the bottom in order to update your VM instance. You've successfully associated metadata with this instance. Let's use the cloud shell in order to query the metadata. When you run the gcloud compute instances describe command on the spikey-internal-site, that will retrieve the metadata for this instance as well. If you scroll up, you'll find a section which says metadata. And under that you'll find items. The key and value pairs are available here. The environment for this instance is prod, and the billing-team is internal_tools. We know how to use the UI to add metadata to an instance. Let's now do this using the gcloud command line tool. You can use the add-metadata command in order to add the --metadata to_be_deleted=true to the spikey-internal-analytics VM. Here I've used metadata as a way to tag the instances that I plan to delete. If you click through to the spikey-internal-analytics VM on the web UI and scroll to the bottom, you'll find that our custom metadata key-value pairs have been associated with this VM instance; to_be_deleted has been set to true. You can remove the custom metadata associated with an instance using the command line as well. Gcloud compute instances remove-metadata is the command. Specify the name of the instance and the metadata key that you want to delete. This is the to_be_deleted key in our case. Once the deletion is complete, you can check in the configuration settings UI to see whether the deletion was successful. You'll find that it was.

Configuring Startup Scripts
Instance metadata is very useful when you configure it to run startup scripts when your VM gets up and running. Let's start off by creating a brand-new instance. We'll call this the spikey-internal-site-startupscript. We'll use custom metadata to configure a startup script for this instance that will install and set up an Nginx web server. We want this VM instance to be accessible by our HTTP. Click on the checkbox which says Allow HTTP traffic. Click on the link that you see here that gives us additional configuration options for this VM. This is where we manage security, disks, networking, and other options. And here is where you can configure a startup script. Startup scripts are part of custom metadata. But because there's so commonly used, they have their own textbox within your web console. Under Automation, you can paste in your startup script right here. Here I've simply done an apt-get update and installed the Nginx server. I've then used the cat command to edit the index. nginx-debian. html file with a little HTML code. That's all you need to do here. Scroll down to the bottom, and create your VM instance. When this VM instance starts up, it will have the web server up and running, and you can click on the IP address and see Welcome to Spikey Sales. Our Nginx server was installed on our VM, and our web server started up using our startup script. If your startup script is long and very involved, you may not want to paste it into the web console. Instead, you can use the command line to point to a startup script. I'm going to create a file called install. sh, which contains my startup script, and paste in the same script to get our Nginx server up and running. This is the same script that we pasted into the web console earlier. Hit Ctrl+X and save this file. We'll now use the gcloud command from the command line in order to create a brand-new instance called spikey-internal-site-startupscript-fromshell. It's going to be located in the us-east1-b zone. And we specify the metadata-from-file flag on the command line and set startup-script to be equal to install. sh, the file that we just created. Execute this command, and wait for the instance to be up and running. Click on the Refresh button, and you'll see that our new VM instance with the very long name has been created successfully. We haven't enabled HTTP traffic for this instance yet, so click on the Edit link within Configuration settings, and allow HTTP traffic. Click on the Save button, and you'll now be able to access the website. Once the instance has been updated, back in the VM instances page, click on the IP address of the instance, and you'll get back to Welcome to Spikey Sales. This is our Nginx server. When you use the gcloud utility on the command line, you can specify shutdown scripts in exactly the same way as you do startup scripts. The only difference here is that the --metadata-from-file sets the shutdown-script metadata. I'm not going to actually execute this command. It works in very much the same way like the startup script did. I'll leave it to you to check out how this works.

Images and Snapshots
Before we create VM instances using snapshots and images, let's quickly understand what they are. An image is a binary file that can be used to instantiate VM root disks. You typically create images from the persistent disk that contains your operating system image. Images also contain the boot loader and can contain additional customizations if you want them to. There is a special service on the GCP called the GCP image service, which is used to manage the custom images that you create on the GCP. Under the hood, an image is basically a compressed gzipped file stored in an internal GCS bucket. GCS buckets are the object storage technology available on the Google Cloud Platform. Snapshots, on the other hand, are also binary files which contain the exact contents of a persistent disk. This disk need not be the root disk though. This is a point-in-time snapshot, which means that this is an exact copy of your disk contents at a particular instance in time. Snapshots are managed by the GCP snapshot service. And under the hood, they are also a compressed gzipped file stored in a GCS bucket. An important difference between images and snapshots is the fact that snapshots can perform incremental backups as well. So a snapshot is not very heavyweight. Typically one speaks of snapshots and images in the same sentence. Snapshots and images are conceptually very similar, but there are many differences in the nitty-gritty of how they are implemented. If you create an image from a persistent disk, the typical use case is to use that image as a basis to create new VM instances. If you're creating a snapshot of a disk, you use the snapshot to back up the data that is present in that disk. Disk images are not incremental. Each time you create an image, it will encapsulate all of the information that is present in that disk. Snapshots are incremental and can be done in a relatively cheap manner. Disk images tend to be relatively expensive. Images can be used directly by the GCP to instantiate a new VM instance or a managed instance group. Persistent disk snapshots must first be used to create a persistent disk, and then you can use that persistent disk to create an instance. All of this is managed automatically by the GCP, though, so you won't see it when we work with images and snapshots. Images are more heavyweight. They can be grouped into image families and versions separately. Snapshots are just snapshots. There is no support for families here. Images can be shared across projects on the GCP, whereas snapshots are very specific to a particular project. Both images and snapshots can be accessed globally. A very standard rule of thumb is use snapshots for data backup and images for operating system customizations.

Using Boot Disks
In this demo, we'll first see how we can create a boot disk using a public image and then instantiate a VM from this boot disk. Click on the Disks link in the left navigation pane in order to view all of the persistent disks that are associated with this project. Click on the Create Disk link at the very top in order to create a new persistent disk. I'm going to call this spikey-debian-boot-disk. We can accept default values for the other settings including the region and the zone for this disk. Click on the Source image drop-down, and choose the operating system image that you want to put on this boot disk. I'm going to choose the debian-9-stretch image. This choice automatically prefills the minimum size of this disk, which is 10 GB. I'm going to go ahead and click on the Create button to create this boot disk from this Debian image. Once this boot disk has been created, notice that the In use by column is empty because this boot disk hasn't been associated with a VM instance yet. Click on the VM instances link on the left navigation pane, and let's create a new instance that will use this boot disk. I'm going to call this the spikey-vm-boot-from-debian-disk. That's the name of my instance. And I'm going to change my boot disk to use the one that I've already created before. Within this configuration pane that opens up for your boot disk, click on the tab which says Existing disks. This will show you all of the persistent disks that you can choose from that are available within this project. We just have one at this point in time. Click on Select. We'll now use the boot disk that we created earlier. Click on the Create button, and that's it. This will create a new VM instance using the boot disk that you created earlier. I'm going to SSH into this instance once it has been created, and I'm going to run the uname command here in order to see the details of the OS that I'm running. You can see that this is using the Linux Debian 9 OS. This is what we had configured in our boot disk. On the VM instances page, if you click through to the spikey-vm-boot-from-debian-disk instance and scroll down to the bottom, you'll see that the boot disk's name is the disk that we had set up earlier, the spikey-debian-boot-disk.

Using Boot Disk Snapshots
In this demo, we'll see how you can create a snapshot of a persistent disk that you already have and then instantiate a new VM using this snapshot. All the snapshots that are available on your project are available on this Snapshots webpage, which you can access by clicking on this Snapshots link on the left. Snapshots are managed by Google's snapshot service and are useful for periodic backup of the data that lives within your persistent disks. You can also use snapshots to create a custom image that you'll used to instantiate a VM, and that's what we'll do here. Click on the Create snapshot button here and GCP will walk you through the process of creating a snapshot. I'm going to call this the spikey-internal-site-disk-snapshot-1. The source disk for this snapshot is going to be the spikey-internal-site boot disk. You can also create snapshots from the command line by using the gcloud SDK. Click on the command line link here to see the command that you would use and the parameters that you would specify to create this snapshot. We can now go ahead and click on the Create button for this snapshot. Remember that snapshots on the GCP are incremental. The first successful snapshot is a full snapshot. It contains all of the data in the persistent disk. Subsequent snapshots tend to be incremental. Click on the Create button, and this will create our first snapshot for the spikey-internal-site boot disk. Because this is a snapshot of a boot disk, we can use this snapshot to create a VM instance. Go to the VM instances page, and click on the Create Instance link. I'm going to call this instance the spikey-internal-site-snapshotted. That's the name of my VM. And I'm going to change my boot disk so that it reads from the snapshot. Click on the Snapshots tab on this configuration setting here, and choose the snapshot that we just created of the spikey-internal-site-disk. Notice that this snapshot is automatically made available to us here on this tab. Click on the Select button here, and let's create a new VM instance using this snapshot. This VM instance should support HTTP traffic. Click on that checkbox here, and then click on the Create button. Once the VM has been created and is up and running, because it used the boot disk of our spikey-internal-site VM, it should have the Nginx server running as well. And you'll see that that is indeed the case. When you click on the IP address of the VM, this will bring up the same website that we had on the original spikey-internal-site VM. This VM was created using a snapshot of the persistent boot disk of the original VM.

Creating and Using Custom Images
On the GCP, it's possible to import your boot disk images to set up your VM instances on the compute engine. Now this is a fairly involved process, especially if you want to import boot disk images from your physical datacenters to the Google cloud. In this demo, we'll see a slightly simpler scenario where we create a custom image from a persistent disk on our running VM instance and instantiate a new VM instance from that image. Click on the Images link on the left navigation pane, and this will take you to all the images that we have available on the GCP. This includes the public images that we've seen earlier. Click on the Create Image link at the very top in order to create a new image from your existing disk. I'm going to call this the spikey-internal-site-image-1. Scroll down and specify the source disk for this image. I'm going to use a disk that I've used before, the spikey-internal-site. Now on the GCP, it's possible for you to create a custom image from a persistent disk even when that persistent disk is attached to a running VM instance. But this is not recommended though. The image that you create will be more reliable if you put your instance in a more steady state, and this might involve stopping your instance. Notice the warning here, This disk is attached to a running instance. To create an image, you either need to stop the instance or explicitly select the checkbox which says Keep instance running. Let's follow best practices here. I'm going to the VM instances page, and I'll stop the spikey-internal-site instance. Click on the three-dot menu and choose the Stop option. Once the VM instance has been stopped, we can now create an image from the persistent disk that is attached to this VM. Go back to the Images link by clicking on the left navigation pane here, and let's create an image once again. Give the image a name, and select the source disk for this image. We'll use the spikey-internal-site disk. Click on the Create button and wait for this custom image to be created. This image is a custom image because in addition to the Debian OS, it also has the Nginx web server. You can click on the command line link here in order to see how you would create this image using the command line. Once the image has been created, you can see it listed on your images webpage at the very top, spikey-internal-site-image-1. This image doesn't belong to any image family, and it's created by the spikey_internal project. Let's head over to our VM instances page in order to create a new VM with this image. We'll first restart our spikey-internal-site, so click on this Start button. The instance will come up soon. Let's create a new instance until then. We'll call this the spikey-internal-site-fromimage. Accept all of the default parameters, and choose the boot disk. And here you'll choose the Custom images tab. Under here, you'll find all of the custom images that you've created listed. There's exactly one custom image available here at this point in time. I'm going to select this image, and I'm going to create my VM instance. Make sure you allow HTTP traffic to this instance so that we can hit our website. Click on the Create button and wait for the instance to be up and running. You can now click on the IP address to see whether your Nginx website is up. And you'll see that, yes, indeed it is. Your custom image included the Nginx web server, and that's up and running on this new VM instance.

Moving Between Zones in the Same Region
In this demo, you'll see how you can move a VM instance between zones on the GCP. Now there are several reasons why you might move an instance to a different zone or to a different region. Maybe your users are more geographically distributed. Maybe the application that accesses your instance the most often lives in a different region. If you're thinking about moving your VM instance, you can move within the same region or to a different region. The same series of steps apply except that when you're moving within the same region, just to a different zone, you can use the gcloud compute instances move command directly. If you want to move your instance to a different region, then there is a long manual procedure that's involved. You can do it in an automated manner. The same steps are performed under the hood in both cases. In the first case, it's automated by the GCP. In the second case, you'll have to do it yourself. If you want to move a VM instance to a new zone, this is the long series of steps that have to be performed. Each of these steps are self-explanatory, and I'm not going to go through this in detail. The cool thing is if you're moving the VM instance within the same zone, you can use the gcloud command directly, and the gcloud command will perform all of these steps for you. Let's start off in the VM instances page, and we'll use the cloud shell and call gcloud compute instances move. This will move the spikey-internal-site instance from the us-central1-c zone to us-central1-f. And, really, that's all that you need to do. Wait for a little bit for the move to be completed, and you'll see that your spikey-internal-site instance is now in us-central1-f. All of the details that are involved in moving this VM instance, creating a persistent snapshot, making sure the IP remains the same, all of this has been taken care of for you by the GCP.

Copying Files Between VMs and the Local Machine
When you're working on a cloud platform, a common use case is for you to move files from your local machine to a VM instance. Let's see how you can do that on the GCP. This is the terminal window on my local Mac machine. I'm going to run the pwd command here to see my current working directory. I'm under /Users/jananiravi/gcp_vms. If I list the contents of this directory, you'll see that I have a file named some_file_with_stuff. txt. I'll run the cat command to see what's in here, and there is some text in here, some important data. I can use the gcloud compute scp command in order to copy this file onto my spikey-internal-site VM. I can indicate the VM instance I want to copy to by name, and I'm simply copying into the home directory of that instance. Gcloud auto-detects the correct zone for this particular instance and copies this file over. I've already previously connected to my spikey-internal-site VM via SSH. When I run ls -l here in my home directory, I see that the file is not present. And this is a little confusing. Gcloud on my local machine indicated that the file was copied over successfully, but it isn't here. This is because when you use the gcloud scp command by default, it mimics the current working directory that you had on your local machine and copies over the file to the same directory here on your cloud VM instance. You can see that the some_file_with_stuff. txt file is present here under /home/jananiravi. If you cat the contents of this file, you'll see the important data that was present here. If I want the file from my local machine to be copied over to the home directory on my VM instance, the cloud_user's home directory, I need to explicitly specify this. I'll use the gcloud compute scp command as before, but notice my destination. It is cloud_user@spikey-internal-site. This is what I need to copy over the file to the cloud users home directory on my VM instance. Now when I switch to my VM instance, I can cd to the cloud_user home directory, and I'll find my file there. That pwd command will show me my current working directory, that is, /home/cloud_user. And if I run an ls command here, I'll see the some_file_with_stuff. txt copied over here. Notice here that in the cloud_user home directory, we have an additional file called some_file. txt. This is just a file that I created here with some random text using the nano editor. I'm back to the terminal window on my local machine. I'm going to create a new test folder under here and cd into that folder. Once I'm in the test folder, I'll use the gcloud compute scp command to copy from my VM instance onto my local machine. Now by default, gcloud will look for some_file. txt on the /home/jananiravi. There is no such file or directory there. I need to specify cloud_user@spikey-internal-site in order to access the cloud_user home directory. Some_file. txt is, indeed, present there, and it's copied to my local machine successfully. If you run the ls -l command here, you'll see that the file is present. You can run the cat command to see the contents of this file. The GCP also offers another very cool way to upload data from your local machine to the cloud. Let's create a new file using the nano editor. I'm going to name this file another_way. txt, and this is the file I'm going to upload to my GCP VM. This file is present here under gcp_vms/test. Switch over to your browser where you've connected to your VM instance, and then click on the gear icon that you see on the top right. This gear icon gives you options to upload and download files from your local machine. Click on the Upload file option here. This will bring up an Explorer window where you can choose the files that you want to upload to your GCP VM. And, really, that's all that you need to do. This file will be available in the cloud_user home directory of your GCP VM. You can copy files to and from your VM instance without installing the gcloud SDK on your local machine.

Summary and Further Study
And with that last demo, we come to the very end of this module and to the end of this course on the Google cloud compute engine. We started this module off by taking a look at the availability policies that you can configure on your VM instance. Availability policies determine how your instance will behave during a maintenance event. We also saw how we could simulate these maintenance events on the command line. We then moved on to talk about instance metadata, which are basically key-value pairs or just values that you can associate with your VM instances and that can be queried programmatically without authorization to your VM instance. We saw how we could use the metadata associated with an instance in order to specify startup scripts for that instance. We understood the similarities and differences between snapshots and images and saw how we could use these on the GCP. We also saw how we could move an instance between zones using the gcloud compute move command. Moving a VM instance is typically a long manual process, but if you want to move between zones in the same region, the GCP takes care of a lot of the details for you automatically. If you're interested in computing on the cloud, here are some other courses on Pluralsight that you can watch. The AWS Simple Systems Manager for EC2 will get you started with VM instances on the AWS cloud, and Microsoft Azure Virtual Machines is a course that you might want to watch if you're interested in cloud computing on Azure. And that's it from me here today. Thank you for listening.

Course author
Author: Janani Ravi	
Janani Ravi
Janani has a Masters degree from Stanford and worked for 7+ years at Google. She was one of the original engineers on Google Docs and holds 4 patents for its real-time collaborative editing...

Course info
Level
Beginner
Rating
4.9 stars with 23 raters(23)
My rating
null stars

Duration
1h 58m
Released
11 Sep 2018
Share course

